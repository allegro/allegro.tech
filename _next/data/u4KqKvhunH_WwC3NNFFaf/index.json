{"pageProps":{"posts":[{"title":"INP — what is the new Core Web Vitals metric and how do we work with it at Allegro.","link":"https://blog.allegro.tech/2024/07/INP-new-core-web-vitals.html","pubDate":"Mon, 01 Jul 2024 00:00:00 +0200","authors":{"author":[{"name":["Kacper Stodolak"],"photo":["https://blog.allegro.tech/img/authors/kacper.stodolak.jpg"],"url":["https://blog.allegro.tech/authors/kacper.stodolak"]}]},"content":"<p>Site performance is very important, first of all, from the perspective of users, who expect a good experience when visiting the site.\nThe user should not wait too long for the page to load. We all know how annoying it can be when we want to press an element\nand it jumps to another place on the page or when we click on a button and then nothing happens for a very long time. The state of a\nsite’s performance in these aspects is measured by <a href=\"https://web.dev/articles/vitals\">Web Vitals</a> performance metrics and most importantly by a set of three major\nCore Web Vitals metrics (LCP — Largest Contentful Paint, CLS — Cumulative Layout Shift, INP — Interaction to Next Paint). They are\nresponsible for measuring the 3 things: loading time, visual stability and interactivity. These metrics are also important for the\nwebsites themselves because, in addition to the user experience, they are also taken into account in terms of the website’s positioning\nin search engines (SEO), which is crucial for most websites on the Internet, <a href=\"https://allegro.tech/\">Allegro</a> included.</p>\n\n<p>In this post, you can read about <strong>INP</strong> — the new Core Web Vitals metric assessing overall responsiveness of the page which <strong>replaced\nFID (First Input Delay) as of March 12, 2024</strong> (<a href=\"https://web.dev/blog/inp-cwv-launch\">source</a>).</p>\n\n<h2 id=\"what-is-inp\">What is INP?</h2>\n\n<p><strong>INP</strong> (<strong>I</strong>nteraction to <strong>N</strong>ext <strong>P</strong>aint) – is a new WebPerf metric that measures the overall responsiveness of the website to user\ninteractions throughout the user’s visit to the page. INP value is the measured time from registering a user event to rendering a new frame\nin the browser. It uses <a href=\"https://www.w3.org/TR/event-timing/\">Event Timing API</a> under the hood. Good responsiveness\nof the website means that the browser presents “visual feedback” of the interaction as quickly as possible\n(more about the meaning of “visual feedback” in the context of the INP metric in the next section ;)) .</p>\n\n<p>An interaction can be a single mouse click event or a group of events like a tap interaction (<code class=\"language-plaintext highlighter-rouge\">pointerup</code>, <code class=\"language-plaintext highlighter-rouge\">pointerdown</code>, and <code class=\"language-plaintext highlighter-rouge\">click</code>).</p>\n\n<p>At this point, INP only observes:</p>\n<ul>\n  <li>Mouse clicks</li>\n  <li>Tapping on the screen (on touchscreen devices)</li>\n  <li>Keyboard interactions (physical or on-screen)</li>\n</ul>\n\n<h2 id=\"how-is-inp-measured\">How is INP measured?</h2>\n\n<p><img src=\"/img/articles/2024-07-01-INP-new-core-web-vitals/inp-scheme.png\" alt=\"INP measurement scheme. Division into 3 phases: Input delay, Processing time and Presentation delay.\" class=\"image\" /></p>\n\n<p>INP measures the time from detecting user input to presenting a new frame in the browser.\nThis process has three phases:</p>\n<ul>\n  <li>Input delay – delay from detecting user’s interaction to calling event callback</li>\n  <li>Processing time – calling code with event handlers</li>\n  <li>Presentation delay – presenting new frame by the browser (render, paint, compositing)</li>\n</ul>\n\n<p>Where can you look for improvements? First of all, in phases one and two.</p>\n<ol>\n  <li><strong>Input delay</strong> phase – the interaction can happen anytime during the user’s visit. The main thread in the browser\nmay be busy at this time because of some already ongoing task. This situation can increase how long\nthis phase lasts. Blocked main thread = longer time to call the event callback.\n<img src=\"/img/articles/2024-07-01-INP-new-core-web-vitals/inp-scheme-input-delay.png\" alt=\"INP - scheme of the Input delay phase\" class=\"small-image\" /></li>\n  <li><strong>Processing time</strong> – it is the time when event callbacks with the engineer’s code that handles user interaction are executed\n(<code class=\"language-plaintext highlighter-rouge\">onClick</code>, <code class=\"language-plaintext highlighter-rouge\">onKey</code>). It is crucial not to block the main thread for too long with the code that handles interactions.</li>\n</ol>\n\n<p><img src=\"/img/articles/2024-07-01-INP-new-core-web-vitals/inp-processing-time.png\" alt=\"INP - scheme of the Processing time phase\" class=\"small-image\" /></p>\n\n<h3 id=\"how-is-the-final-inp-value-of-the-visit-calculated\">How is the final INP value of the visit calculated?</h3>\n\n<p>Up to this point the article was focused only on INP values for single interactions. As mentioned INP is measured for the entire\nuser visit. It is possible to find various information on how the final INP value is calculated.</p>\n\n<p><a href=\"https://web.dev/\">Web.dev</a> informs:</p>\n<ol>\n  <li>For visits with few interactions (&lt;=50): INP is the highest measured value during the visit</li>\n  <li>For visits with large numbers of interactions (&gt;50): the highest value for every 50 interactions is ignored. Next INP is the highest value from the remaining measurements.</li>\n</ol>\n\n<p><a href=\"https://debugbear.com/\">DebugBear.com</a> informs that INP is reporting 98 percentile of all measured interactions.</p>\n\n<p>Example 1: if the visit had <strong>100 interactions with 50ms and two with 300ms: 50 ms will be reported</strong><br />\nExample 2: if on the same visit there were <strong>3 interactions with 300ms</strong> then <strong>it will report 300ms</strong></p>\n\n<h3 id=\"important\">Important!</h3>\n\n<ul>\n  <li>An important aspect to understand is that “presenting visual feedback” does not have to mean a noticeable visual effect\nfor the user. Some interactions do not give the user any visual feedback of the interaction and such interactions also report\nits INP value. <strong>The INP metric only measures the time to completion of the rendering (presenting a new frame) process\n(even if visually nothing has changed for the user)!</strong> For example, a button element that triggers an HTTP request may not display any visual feedback, such as a spinner animation, but the browser will still report the INP as soon as the next frame is rendered.</li>\n  <li>What about long animations? – For example: if an animation, which is the visual effect of some interaction, lasts 400ms,\nit does not mean that our INP value will be increased by the duration of the animation. CSS-based animations, and Web Animations\n(in the browser that supports the API) are handled on a thread known as the “compositor thread” and do not block the main thread.</li>\n  <li>If the interaction handling requires fetching/requesting some external resources (like executing an HTTP request), then the\ntime of handling such operation is not included in the INP value. It is because operations like this are asynchronous\nand handling the result of such operations is being performed in other tasks.</li>\n</ul>\n\n<h2 id=\"what-is-a-good-inp-value\">What is a good INP value?</h2>\n\n<p>The sum of Input Delay time, Processing Time and Presentation Delay phases is the final INP value for the interaction.\nGoogle set three threshold ranges (<a href=\"https://web.dev/articles/inp#good-score\">source</a>):</p>\n<ul>\n  <li>Good: &lt;= 200ms</li>\n  <li>Needs Improvement: &gt; 200ms and &lt;= 500ms</li>\n  <li>Poor: &gt; 500ms</li>\n</ul>\n\n<p><img src=\"/img/articles/2024-07-01-INP-new-core-web-vitals/good-needs-improvement-poor.png\" alt=\"INP values - recommended thresholds ranges.\" class=\"small-image\" /></p>\n\n<h2 id=\"why-is-it-important-to-stay-below-recommended-thresholds\">Why is it important to stay below recommended thresholds?</h2>\n\n<p>Core Web Vitals is a set of the most important performance metrics that determine overall evaluation of\n“Page Experience” on three different criteria:</p>\n<ul>\n  <li>Loading — Largest Contentful Paint metric (LCP)</li>\n  <li>Visual stability — Cumulative Layout Shift metric (CLS)</li>\n  <li><strong>Interactivity — Interaction to Next Paint (INP) — On March 12, 2024 INP officially replaced FID and took\nover the role of the Interactivity metric in the Core Web Vitals (CWV) set</strong></li>\n</ul>\n\n<p>All Core Web Vitals are scored based on their performance in the field at the 75th percentile of all\npage loads. Google collects data from real users (Real User Monitoring – RUM).</p>\n\n<p>In search ranking, sites are evaluated as individual URLs. For example, this means that in this aspect\nthe two addresses <code class=\"language-plaintext highlighter-rouge\">allegro.pl/oferta/offer-1</code> and <code class=\"language-plaintext highlighter-rouge\">allegro.pl/oferta/offer-2</code> are rated separately.</p>\n\n<p>Google doesn’t share the exact data on how their ranking algorithm works, but what is clear is that the overall\n“Page Experience” determined by Core Web Vitals has an important impact on how each website URL is ranked in\nsearch results. Because of that it is best to stay in the “good” rating thresholds for all the\nCore Web Vitals metrics not to be affected in any negative way.</p>\n\n<h2 id=\"inp-vs-fid\">INP vs FID</h2>\n\n<p>Previously (until March 12, 2024) the role of the metric that determined a page’s responsiveness to user’s\ninteractions in the Core Web Vitals set was the FID metric. Both metrics evaluate the user’s\nperception of an application’s responsiveness. As the name suggests, FID (First Input Delay) measures the delay of\nprocessing only for the first user interaction (input). It is not the only difference because FID does it in a different way.\nUnlike INP, it measures the time from detecting a user interaction to the start of its processing.\nFID relates only to the first of the three phases described above (Input delay).</p>\n\n<p><img src=\"/img/articles/2024-07-01-INP-new-core-web-vitals/inp-scheme-vs-fid.png\" alt=\"INP vs FID scheme.\" class=\"small-image\" /></p>\n\n<h3 id=\"key-information-summary\">Key information summary:</h3>\n<table>\n  <thead>\n    <tr>\n      <th>FID</th>\n      <th>INP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Only first interaction</td>\n      <td>All users’ interactions during the visit</td>\n    </tr>\n    <tr>\n      <td>Delay from registering an event to start of processing (input delay)</td>\n      <td>Time from registering an event to rendering visual effect (input delay + processing + presenting)</td>\n    </tr>\n    <tr>\n      <td>Result is defined in milliseconds (ms)  </td>\n      <td>Result is defined in milliseconds (ms) </td>\n    </tr>\n    <tr>\n      <td>Determines the speed at which the site is ready for interaction </td>\n      <td>Determines overall page responsiveness  </td>\n    </tr>\n  </tbody>\n</table>\n\n<h2 id=\"inp--debugging\">INP — debugging</h2>\n\n<h3 id=\"1-using-rum-data-to-find-slow-interactions\">1. Using RUM data to find slow interactions</h3>\n\n<p>If there is such a possibility, the best way to start a debugging journey is to analyze data collected\ndirectly from users (known as <strong>RUM</strong> – <strong>R</strong>eal <strong>U</strong>ser <strong>M</strong>onitoring). For INP, such data can provide information\nabout which element was interacted with and the INP time values in all three phases.\nThis can be crucial for finding specific elements on a page that are most frequently interacted with by\nusers and which interactions are reported to be long (&gt;200ms). Data like this may differ from those\ncollected manually or collected during synthetic testing, due to hardware differences in users’ end devices.</p>\n\n<h3 id=\"2-measuring-time-of-a-single-interaction-with-google-chrome-extension--web-vitals\">2. Measuring time of a single interaction with Google Chrome extension — web-vitals.</h3>\n\n<p>In addition to other helpful information about Web Vitals, this extension gives us measurement results\nfor single interactions with a distinction for all 3 phases. After turning on the right option in the extension\nsettings, you can find the metric logs in developer tools in the “Console” tab.</p>\n\n<p><img src=\"/img/articles/2024-07-01-INP-new-core-web-vitals/web-vitals-extension-settings.png\" alt=\"Console logging option in the web-vitals extension settings\" class=\"small-image\" /></p>\n\n<p><img src=\"/img/articles/2024-07-01-INP-new-core-web-vitals/web-vitals-extension.png\" alt=\"The resulting output of the web-vitals Chrome extension.\" class=\"small-image\" /></p>\n\n<p>Web-vitals Chrome extension can be found <a href=\"https://chromewebstore.google.com/detail/web-vitals/ahfhijdlegdabablpippeagghigmibma\">HERE</a>.</p>\n\n<h3 id=\"3-javascript-snippet\">3. JavaScript snippet</h3>\n\n<p>If you can’t use <code class=\"language-plaintext highlighter-rouge\">web-vitals</code> Chrome extension, you can use this JS snippet:</p>\n\n<div class=\"language-javascript highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kd\">let</span> <span class=\"nx\">worstInp</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span>\n\n<span class=\"kd\">const</span> <span class=\"nx\">observer</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"nx\">PerformanceObserver</span><span class=\"p\">((</span><span class=\"nx\">list</span><span class=\"p\">,</span> <span class=\"nx\">obs</span><span class=\"p\">,</span> <span class=\"nx\">options</span><span class=\"p\">)</span> <span class=\"o\">=&gt;</span> <span class=\"p\">{</span>\n  <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kd\">let</span> <span class=\"nx\">entry</span> <span class=\"k\">of</span> <span class=\"nx\">list</span><span class=\"p\">.</span><span class=\"nx\">getEntries</span><span class=\"p\">())</span> <span class=\"p\">{</span>\n    <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"o\">!</span><span class=\"nx\">entry</span><span class=\"p\">.</span><span class=\"nx\">interactionId</span><span class=\"p\">)</span> <span class=\"k\">continue</span><span class=\"p\">;</span>\n\n    <span class=\"nx\">entry</span><span class=\"p\">.</span><span class=\"nx\">renderTime</span> <span class=\"o\">=</span> <span class=\"nx\">entry</span><span class=\"p\">.</span><span class=\"nx\">startTime</span> <span class=\"o\">+</span> <span class=\"nx\">entry</span><span class=\"p\">.</span><span class=\"nx\">duration</span><span class=\"p\">;</span>\n    <span class=\"nx\">worstInp</span> <span class=\"o\">=</span> <span class=\"nb\">Math</span><span class=\"p\">.</span><span class=\"nx\">max</span><span class=\"p\">(</span><span class=\"nx\">entry</span><span class=\"p\">.</span><span class=\"nx\">duration</span><span class=\"p\">,</span> <span class=\"nx\">worstInp</span><span class=\"p\">);</span>\n\n    <span class=\"nx\">console</span><span class=\"p\">.</span><span class=\"nx\">log</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">[Interaction]</span><span class=\"dl\">'</span><span class=\"p\">,</span> <span class=\"nx\">entry</span><span class=\"p\">.</span><span class=\"nx\">duration</span><span class=\"p\">,</span> <span class=\"s2\">`type: </span><span class=\"p\">${</span><span class=\"nx\">entry</span><span class=\"p\">.</span><span class=\"nx\">name</span><span class=\"p\">}</span><span class=\"s2\"> interactionCount: </span><span class=\"p\">${</span><span class=\"nx\">performance</span><span class=\"p\">.</span><span class=\"nx\">interactionCount</span><span class=\"p\">}</span><span class=\"s2\">, worstInp: </span><span class=\"p\">${</span><span class=\"nx\">worstInp</span><span class=\"p\">}</span><span class=\"s2\">`</span><span class=\"p\">,</span> <span class=\"nx\">entry</span><span class=\"p\">,</span> <span class=\"nx\">options</span><span class=\"p\">);</span>\n  <span class=\"p\">}</span>\n<span class=\"p\">});</span>\n\n<span class=\"nx\">observer</span><span class=\"p\">.</span><span class=\"nx\">observe</span><span class=\"p\">({</span>\n  <span class=\"na\">type</span><span class=\"p\">:</span> <span class=\"dl\">'</span><span class=\"s1\">event</span><span class=\"dl\">'</span><span class=\"p\">,</span>\n  <span class=\"na\">durationThreshold</span><span class=\"p\">:</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"c1\">// 16 milliseconds minimum by the spec</span>\n  <span class=\"na\">buffered</span><span class=\"p\">:</span> <span class=\"kc\">true</span>\n<span class=\"p\">});</span>\n</code></pre></div></div>\n\n<h3 id=\"4-performance-section-in-developer-tools-in-the-browser\">4. “Performance” section in developer tools in the browser</h3>\n\n<p>The “performance” section with its recording option can provide all the necessary information about\nwhat is happening in the browser and in the main thread. It also allows you to detect long tasks, check the exact call stack in any recorded moment,\nrendered frames, cyclic and synchronous style recalculations and more. It can be your best friend during\ndebugging a slow interaction :)</p>\n\n<p><img src=\"/img/articles/2024-07-01-INP-new-core-web-vitals/devtools-performance-recording.png\" alt=\"Recording button placement in Chrome developer tools.\" class=\"small-image\" />\n<img src=\"/img/articles/2024-07-01-INP-new-core-web-vitals/devtools-performance.png\" alt=\"Performance section in Chrome developer tools.\" class=\"small-image\" />\n<img src=\"/img/articles/2024-07-01-INP-new-core-web-vitals/devtools-performance-interaction.png\" alt=\"Details of the recorded interaction.\" class=\"small-image\" /></p>\n\n<h3 id=\"5-synthetic-tests-tools\">5. Synthetic tests tools</h3>\n\n<ul>\n  <li>PageSpeed Insights (Web App tool): <a href=\"https://pagespeed.web.dev/\">https://pagespeed.web.dev/</a></li>\n  <li>INP debugger (Web App tool): <a href=\"https://www.debugbear.com/inp-debugger\">https://www.debugbear.com/inp-debugger</a></li>\n</ul>\n\n<h3 id=\"6-other-helpful-tips\">6. Other helpful tips</h3>\n\n<ul>\n  <li>Use CPU throttling during debugging the interaction - some INP issues can be noticeable only on slower devices.</li>\n  <li>You can turn it on in the developers tools → “Performance” tab settings → CPU</li>\n  <li>Local overrides - you can override script locally (more info: <a href=\"https://developer.chrome.com/docs/devtools/overrides\">https://developer.chrome.com/docs/devtools/overrides</a>)</li>\n  <li>Blocking scripts locally\n<img src=\"/img/articles/2024-07-01-INP-new-core-web-vitals/devtools-blocking.png\" alt=\"Blocking request URL in devTools.\" class=\"small-image\" /></li>\n  <li>Remote debug on physical devices\n    <ul>\n      <li>Android: <a href=\"https://developer.chrome.com/docs/devtools/remote-debugging\">https://developer.chrome.com/docs/devtools/remote-debugging</a></li>\n      <li>iOS: <a href=\"https://developer.apple.com/documentation/safari-developer-tools/inspecting-ios\">https://developer.apple.com/documentation/safari-developer-tools/inspecting-ios</a></li>\n    </ul>\n  </li>\n</ul>\n\n<h2 id=\"optimizing-inp\">Optimizing INP</h2>\n\n<h3 id=\"1-splitting-long-tasks-into-smaller-ones\">1. Splitting long tasks into smaller ones</h3>\n\n<p>Some operations causing long tasks can be broken up into smaller ones. It helps the browser to perform other\ncritical operations like rerendering, handling event handlers etc. One of the methods to break up such\nlong tasks is using <code class=\"language-plaintext highlighter-rouge\">setTimeout</code>. Using this, you can move part of the code to be done in another task.</p>\n\n<p>More information: <a href=\"https://web.dev/articles/optimize-long-tasks#use_asyncawait_to_create_yield_points\">https://web.dev/articles/optimize-long-tasks#use_asyncawait_to_create_yield_points</a></p>\n\n<h3 id=\"2-optimizing-of-event-handling\">2. Optimizing of event handling</h3>\n\n<p>For long and complex operations handling the interaction, it is worth considering what is most critical\nto display to the user. All non-critical operations can be postponed for execution after the browser has\nrendered the next frame. This can be done using a combination of <code class=\"language-plaintext highlighter-rouge\">requestAnimationFrame</code> and <code class=\"language-plaintext highlighter-rouge\">setTimeout</code> functions.\nThis combination gives us the assurance that the given callback will execute no sooner than in the next frame.</p>\n\n<div class=\"language-javascript highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nx\">element</span><span class=\"p\">.</span><span class=\"nx\">addEventListener</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">click</span><span class=\"dl\">'</span><span class=\"p\">,</span> <span class=\"p\">()</span> <span class=\"o\">=&gt;</span> <span class=\"p\">{</span>\n  <span class=\"nx\">criticalOperations</span><span class=\"p\">();</span>\n\n  <span class=\"nx\">requestAnimationFrame</span><span class=\"p\">(()</span> <span class=\"o\">=&gt;</span> <span class=\"p\">{</span>\n    <span class=\"nx\">setTimeout</span><span class=\"p\">(()</span> <span class=\"o\">=&gt;</span> <span class=\"p\">{</span>\n      <span class=\"nx\">nonCriticalOperations</span><span class=\"p\">();</span>\n    <span class=\"p\">},</span> <span class=\"mi\">0</span><span class=\"p\">);</span>\n  <span class=\"p\">});</span>\n<span class=\"p\">});</span>\n</code></pre></div></div>\n\n<h4 id=\"short-explanation-about-what-is-happening-in-the-above-code-snippet\">Short explanation about what is happening in the above code snippet:</h4>\n\n<p><code class=\"language-plaintext highlighter-rouge\">criticalOperations()</code> is run synchronously when the event fires. Then, <code class=\"language-plaintext highlighter-rouge\">requestAnimationFrame</code> (rAF) is called, which\nschedules the given callback to the moment right before the next frame is rendered, meaning right before layout/paint/commit cycle.\nIf there is any other synchronous code, it is run now. Then comes the time to run the rAF, but the only operation is\n<code class=\"language-plaintext highlighter-rouge\">setTimeout(..., 0)</code>, which adds it’s callback to the next event loop cycle, which is after the layout/paint/commit, which at\nthis point has already been scheduled.</p>\n\n<p>The final order looks like this:\nclick event → <code class=\"language-plaintext highlighter-rouge\">criticalOperations()</code> → <code class=\"language-plaintext highlighter-rouge\">requestAnimationFrame</code> call → synchronous operations finished, browser schedules rendering →\nrAF callback is run, schedules <code class=\"language-plaintext highlighter-rouge\">nonCriticalOperations</code> using <code class=\"language-plaintext highlighter-rouge\">setTimeout</code> → layout/paint/commit → frame is drawn on screen → <code class=\"language-plaintext highlighter-rouge\">nonCriticalOperations()</code></p>\n\n<p>So, in combination, <code class=\"language-plaintext highlighter-rouge\">requestAnimationFrame</code> + <code class=\"language-plaintext highlighter-rouge\">setTimeout</code> ensures that <code class=\"language-plaintext highlighter-rouge\">nonCriticalOperations()</code> run after the frame is rendered.\nThey need to be used in tandem to achieve that, none of them achieves it separately.</p>\n\n<h3 id=\"3-be-aware-of-layout-thrashing\">3. Be aware of “Layout thrashing”</h3>\n\n<p>Some operations from JavaScript code can force layout style recalculation in order for the browser to calculate, for example, the new position of elements.\nSometimes, suppose an operation like this appears in the wrong place in the code. In that case, it may be necessary for the browser to perform style recalculation\nin the middle of the task (synchronously), making it much longer. Especially if the recalculation affects many elements. Such situations occur most\noften when the styles of an element are changed and then immediately the values of those styles are requested in JavaScript. Avoid mixing read and\nupdate DOM operations in the same task.</p>\n\n<div class=\"language-javascript highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// Example: BAD</span>\n<span class=\"kd\">function</span> <span class=\"nx\">changeBoxSize</span><span class=\"p\">(</span><span class=\"nx\">box</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n  <span class=\"nx\">box</span><span class=\"p\">.</span><span class=\"nx\">classList</span><span class=\"p\">.</span><span class=\"nx\">add</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">big</span><span class=\"dl\">'</span><span class=\"p\">);</span>\n\n  <span class=\"c1\">// Log box height</span>\n  <span class=\"nx\">console</span><span class=\"p\">.</span><span class=\"nx\">log</span><span class=\"p\">(</span><span class=\"nx\">box</span><span class=\"p\">.</span><span class=\"nx\">offsetHeight</span><span class=\"p\">);</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<div class=\"language-javascript highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// Example: BETTER</span>\n<span class=\"kd\">function</span> <span class=\"nx\">changeBoxSize</span><span class=\"p\">(</span><span class=\"nx\">box</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"c1\">// Log box height</span>\n    <span class=\"nx\">console</span><span class=\"p\">.</span><span class=\"nx\">log</span><span class=\"p\">(</span><span class=\"nx\">box</span><span class=\"p\">.</span><span class=\"nx\">offsetHeight</span><span class=\"p\">);</span>\n\n    <span class=\"nx\">box</span><span class=\"p\">.</span><span class=\"nx\">classList</span><span class=\"p\">.</span><span class=\"nx\">add</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">big</span><span class=\"dl\">'</span><span class=\"p\">);</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>In the first (<code class=\"language-plaintext highlighter-rouge\">BAD</code>) example the browser has to run a styles recalculation process synchronously to calculate the new height of the box element(“Forced reflow” in the browser).</p>\n\n<p>In the second (<code class=\"language-plaintext highlighter-rouge\">BETTER</code>) example there is no such problem. We can log the height value calculated during the latest rendering process.\nAfter that there is a changing element styles operation. It’s fine in this example because it’s not going to force the browser to run styles\nrecalculation synchronously during the currently running task.</p>\n\n<h3 id=\"4-using-css-content-visibility\">4. Using CSS content-visibility</h3>\n\n<p>You can optimize rendering offscreen content by using the proper value of the <code class=\"language-plaintext highlighter-rouge\">content-visibility</code> option. It can help the browser to specify\nrender priority (higher for content in the viewport and lower for out of viewport elements).</p>\n\n<p>Read more: <a href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/content-visibility\">https://developer.mozilla.org/en-US/docs/Web/CSS/content-visibility</a></p>\n\n<h3 id=\"5-minimizing-dom-size\">5. Minimizing DOM size</h3>\n\n<p>In Lighthouse reports you can find recommendations for pages to contain fewer than ~1400 elements and the tree should not be deeper than 32 levels.\nKeeping the number of elements in the DOM as small as possible is important because large DOM can slow the page down in multiple ways, such as:</p>\n\n<ul>\n  <li>Increased time of the first render due to network efficiency and load performance.</li>\n  <li>Runtime performance — The browser must constantly recompute the position and styling of nodes.\nLarge DOM can cause long styles recalculations that block the main thread for a long time.</li>\n</ul>\n\n<p>Read more: <a href=\"https://web.dev/articles/dom-size-and-interactivity\">https://web.dev/articles/dom-size-and-interactivity</a></p>\n\n<h3 id=\"6-web-workers\">6. Web Workers</h3>\n\n<p>If some very long operations are hard to optimize, you can use Web Workers to run your JavaScript code in a dedicated thread. It allows\nyou to not block the main thread during, for example, complicated calculations. However, there are some limitations to this solution.\nThe code executed in the worker has its own global context (it does not have access to the window object). In addition, it is not possible to\nperform direct operations on the DOM.</p>\n\n<p>You can find more information here: <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers\">https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers</a></p>\n\n<h2 id=\"inp-in-allegro--a-few-examples\">INP in Allegro — a few examples</h2>\n\n<h3 id=\"1-slow-interactions--long-tasks\">1. Slow interactions — long tasks</h3>\n\n<p>At Allegro, we have taken many actions and attempts to improve the INP score. <strong>By far, the most effective were attempts to diagnose\nlong interactions based on RUM data and optimize them</strong>. This is crucial because one long interaction can spoil the INP results of the\nentire website (for visits with a small number of interactions, the time of the longest interaction is reported as the final INP result of the visit).</p>\n\n<p>After locating and examining the troublesome interactions, it turns out to be crucial to <strong>divide long tasks into smaller ones</strong> and to defer non-critical\noperations until the next frame is rendered. This way, we let the browser decide how many of these tasks it can run before needing to perform another action,\nsuch as style recalculation, rendering the next frame, etc. Otherwise, if we put the entire complex interaction handling into a single long task,\nwe do not give the browser any space to maneuver. In this scenario, <strong>the next frame can be rendered only after this long task is completed</strong>, as\nit will block the main thread for too long.</p>\n\n<p>Below you can find an example of optimizing a long interaction on the offer page, which was opening and closing full-screen mode in a photo gallery,\nat the top of an offer page. In this case, the long task was split into two smaller ones using the <code class=\"language-plaintext highlighter-rouge\">setTimeout</code> function with a <code class=\"language-plaintext highlighter-rouge\">delay</code> parameter value set to 0.</p>\n\n<p><img src=\"/img/articles/2024-07-01-INP-new-core-web-vitals/example-long-task.png\" alt=\"Example 1. All interaction handling in one long task.\" class=\"image\" />\nExample 1: All interaction handling is contained in one single task, which the browser reports as a “Long task”.</p>\n\n<p><img src=\"/img/articles/2024-07-01-INP-new-core-web-vitals/example-task-render-task.png\" alt=\"Example 2. Deferred task executed later so as not to block and delay the rendering process.\" class=\"image\" />\nExample 2: The same interaction handling after being split into two tasks. The entire non-critical part has been separated into the next task,\nwhich can be started by the browser at a time suitable for it. In this case, you can see that a new frame was rendered between the two tasks,\nand then the rest of the interaction handling was executed.</p>\n\n<p><img src=\"/img/articles/2024-07-01-INP-new-core-web-vitals/example-task-task-render.png\" alt=\"Example 3. Deferred task executed just after the first task before the rendering process.\" class=\"image\" />\nExample 3:  In this example, we can see exactly the same two tasks as in Example 2. The difference is that the first task finished quickly\nenough, so the browser decided that it had enough time to perform the second task before the render.</p>\n\n<h3 id=\"2-costly-style-recalculations\">2. Costly style recalculations</h3>\n\n<p>Some style recalculations can be very costly. Among other things, it may be because one change in styles causes a change in many other elements.\nSuch a situation occurred in one of our interactions: opening a sidebar element (an element that slides out from the side, containing, for example,\ninformation about delivery). The operation that caused costly style recalculation was the addition of a special CSS class to the <code class=\"language-plaintext highlighter-rouge\">body</code> element,\nwhich blocked the ability to scroll the content under the sidebar. This significantly increased the total processing time for opening the sidebar,\neven though blocking the ability to scroll the content below was not critical and not the most important. The solution was to simply postpone\nthe operation of attaching CSS class to the body element until after the next frame had been rendered. This way, the user received the most\nimportant visual effect of this interaction faster — opening the sidebar with important information.</p>\n\n<p><img src=\"/img/articles/2024-07-01-INP-new-core-web-vitals/example-sidebar.png\" alt=\"The sidebar component in Allegro\" class=\"small-image\" />\nThe sidebar component at Allegro</p>\n\n<p><img src=\"/img/articles/2024-07-01-INP-new-core-web-vitals/devtools-styles-recalculation.png\" alt=\"Chrome developer tools styles recalculation information\" class=\"small-image\" />\nInformation about how many elements were affected by style recalculation can be found in developer tools in the „Performance” tab.</p>\n\n<h3 id=\"3-attaching-global-event-listeners-too-early\">3. Attaching global event listeners too early</h3>\n\n<p>Global event listeners (e.g. on the global <code class=\"language-plaintext highlighter-rouge\">window</code> / <code class=\"language-plaintext highlighter-rouge\">document</code> object or <code class=\"language-plaintext highlighter-rouge\">body</code> element) should be attached only if necessary.\nDue to the event propagation in JavaScript, such listeners can be fired on any user interaction with the page. In many cases such\nlisteners are unnecessary or are enabled too early, e.g. as soon as the page loads.</p>\n\n<p>An example of this behavior can be a modal element and the global event listener responsible for closing the modal when users\ninteract with the overlay outside its boundaries. Such listeners should be registered just after opening the modal and removed\njust after the modal is closed. Then such a listener doesn’t interrupt the others and doesn’t extend them.</p>\n\n<h2 id=\"does-it-change-a-lot\">Does it change a lot?</h2>\n\n<p>I think it does. Definitely, the introduction of INP has changed a lot in working with WebPerf. The new metric differs strongly from the FID it replaces.\nIt forces a focus on all interactions, not just making the site interactive as quickly as possible. This requires digging in and understanding how interactions are processed by the browser.\nIt also requires thinking about how other operations can affect the interactivity of the website.</p>\n\n<p>We are still learning how to work in the new reality, so we would be excited if you share your own experiences with us!</p>\n\n<p>Special thanks to <a href=\"(/authors/kamil.borzym/)\">Kamil Borzym</a>, <a href=\"/authors/pawel.lesiecki/\">Paweł Lesiecki</a> and <a href=\"https://github.com/virzen\">Wiktor Czajkowski</a> for their help with creating this post.</p>\n","contentSnippet":"Site performance is very important, first of all, from the perspective of users, who expect a good experience when visiting the site.\nThe user should not wait too long for the page to load. We all know how annoying it can be when we want to press an element\nand it jumps to another place on the page or when we click on a button and then nothing happens for a very long time. The state of a\nsite’s performance in these aspects is measured by Web Vitals performance metrics and most importantly by a set of three major\nCore Web Vitals metrics (LCP — Largest Contentful Paint, CLS — Cumulative Layout Shift, INP — Interaction to Next Paint). They are\nresponsible for measuring the 3 things: loading time, visual stability and interactivity. These metrics are also important for the\nwebsites themselves because, in addition to the user experience, they are also taken into account in terms of the website’s positioning\nin search engines (SEO), which is crucial for most websites on the Internet, Allegro included.\nIn this post, you can read about INP — the new Core Web Vitals metric assessing overall responsiveness of the page which replaced\nFID (First Input Delay) as of March 12, 2024 (source).\nWhat is INP?\nINP (Interaction to Next Paint) – is a new WebPerf metric that measures the overall responsiveness of the website to user\ninteractions throughout the user’s visit to the page. INP value is the measured time from registering a user event to rendering a new frame\nin the browser. It uses Event Timing API under the hood. Good responsiveness\nof the website means that the browser presents “visual feedback” of the interaction as quickly as possible\n(more about the meaning of “visual feedback” in the context of the INP metric in the next section ;)) .\nAn interaction can be a single mouse click event or a group of events like a tap interaction (pointerup, pointerdown, and click).\nAt this point, INP only observes:\nMouse clicks\nTapping on the screen (on touchscreen devices)\nKeyboard interactions (physical or on-screen)\nHow is INP measured?\n\nINP measures the time from detecting user input to presenting a new frame in the browser.\nThis process has three phases:\nInput delay – delay from detecting user’s interaction to calling event callback\nProcessing time – calling code with event handlers\nPresentation delay – presenting new frame by the browser (render, paint, compositing)\nWhere can you look for improvements? First of all, in phases one and two.\nInput delay phase – the interaction can happen anytime during the user’s visit. The main thread in the browser\nmay be busy at this time because of some already ongoing task. This situation can increase how long\nthis phase lasts. Blocked main thread = longer time to call the event callback.\n\nProcessing time – it is the time when event callbacks with the engineer’s code that handles user interaction are executed\n(onClick, onKey). It is crucial not to block the main thread for too long with the code that handles interactions.\n\nHow is the final INP value of the visit calculated?\nUp to this point the article was focused only on INP values for single interactions. As mentioned INP is measured for the entire\nuser visit. It is possible to find various information on how the final INP value is calculated.\nWeb.dev informs:\nFor visits with few interactions (<=50): INP is the highest measured value during the visit\nFor visits with large numbers of interactions (>50): the highest value for every 50 interactions is ignored. Next INP is the highest value from the remaining measurements.\nDebugBear.com informs that INP is reporting 98 percentile of all measured interactions.\nExample 1: if the visit had 100 interactions with 50ms and two with 300ms: 50 ms will be reported\n3 interactions with 300ms then it will report 300ms\nImportant!\nAn important aspect to understand is that “presenting visual feedback” does not have to mean a noticeable visual effect\nfor the user. Some interactions do not give the user any visual feedback of the interaction and such interactions also report\nits INP value. The INP metric only measures the time to completion of the rendering (presenting a new frame) process\n(even if visually nothing has changed for the user)! For example, a button element that triggers an HTTP request may not display any visual feedback, such as a spinner animation, but the browser will still report the INP as soon as the next frame is rendered.\nWhat about long animations? – For example: if an animation, which is the visual effect of some interaction, lasts 400ms,\nit does not mean that our INP value will be increased by the duration of the animation. CSS-based animations, and Web Animations\n(in the browser that supports the API) are handled on a thread known as the “compositor thread” and do not block the main thread.\nIf the interaction handling requires fetching/requesting some external resources (like executing an HTTP request), then the\ntime of handling such operation is not included in the INP value. It is because operations like this are asynchronous\nand handling the result of such operations is being performed in other tasks.\nWhat is a good INP value?\nThe sum of Input Delay time, Processing Time and Presentation Delay phases is the final INP value for the interaction.\nGoogle set three threshold ranges (source):\nGood: <= 200ms\nNeeds Improvement: > 200ms and <= 500ms\nPoor: > 500ms\n\nWhy is it important to stay below recommended thresholds?\nCore Web Vitals is a set of the most important performance metrics that determine overall evaluation of\n“Page Experience” on three different criteria:\nLoading — Largest Contentful Paint metric (LCP)\nVisual stability — Cumulative Layout Shift metric (CLS)\nInteractivity — Interaction to Next Paint (INP) — On March 12, 2024 INP officially replaced FID and took\nover the role of the Interactivity metric in the Core Web Vitals (CWV) set\nAll Core Web Vitals are scored based on their performance in the field at the 75th percentile of all\npage loads. Google collects data from real users (Real User Monitoring – RUM).\nIn search ranking, sites are evaluated as individual URLs. For example, this means that in this aspect\nthe two addresses allegro.pl/oferta/offer-1 and allegro.pl/oferta/offer-2 are rated separately.\nGoogle doesn’t share the exact data on how their ranking algorithm works, but what is clear is that the overall\n“Page Experience” determined by Core Web Vitals has an important impact on how each website URL is ranked in\nsearch results. Because of that it is best to stay in the “good” rating thresholds for all the\nCore Web Vitals metrics not to be affected in any negative way.\nINP vs FID\nPreviously (until March 12, 2024) the role of the metric that determined a page’s responsiveness to user’s\ninteractions in the Core Web Vitals set was the FID metric. Both metrics evaluate the user’s\nperception of an application’s responsiveness. As the name suggests, FID (First Input Delay) measures the delay of\nprocessing only for the first user interaction (input). It is not the only difference because FID does it in a different way.\nUnlike INP, it measures the time from detecting a user interaction to the start of its processing.\nFID relates only to the first of the three phases described above (Input delay).\n\nKey information summary:\nFID\n      INP\n    \nOnly first interaction\n      All users’ interactions during the visit\n    \nDelay from registering an event to start of processing (input delay)\n      Time from registering an event to rendering visual effect (input delay + processing + presenting)\n    \nResult is defined in milliseconds (ms)  \n      Result is defined in milliseconds (ms) \n    \nDetermines the speed at which the site is ready for interaction \n      Determines overall page responsiveness  \n    \nINP — debugging\n1. Using RUM data to find slow interactions\nIf there is such a possibility, the best way to start a debugging journey is to analyze data collected\ndirectly from users (known as RUM – Real User Monitoring). For INP, such data can provide information\nabout which element was interacted with and the INP time values in all three phases.\nThis can be crucial for finding specific elements on a page that are most frequently interacted with by\nusers and which interactions are reported to be long (>200ms). Data like this may differ from those\ncollected manually or collected during synthetic testing, due to hardware differences in users’ end devices.\n2. Measuring time of a single interaction with Google Chrome extension — web-vitals.\nIn addition to other helpful information about Web Vitals, this extension gives us measurement results\nfor single interactions with a distinction for all 3 phases. After turning on the right option in the extension\nsettings, you can find the metric logs in developer tools in the “Console” tab.\n\n\nWeb-vitals Chrome extension can be found HERE.\n3. JavaScript snippet\nIf you can’t use web-vitals Chrome extension, you can use this JS snippet:\n\nlet worstInp = 0;\n\nconst observer = new PerformanceObserver((list, obs, options) => {\n  for (let entry of list.getEntries()) {\n    if (!entry.interactionId) continue;\n\n    entry.renderTime = entry.startTime + entry.duration;\n    worstInp = Math.max(entry.duration, worstInp);\n\n    console.log('[Interaction]', entry.duration, `type: ${entry.name} interactionCount: ${performance.interactionCount}, worstInp: ${worstInp}`, entry, options);\n  }\n});\n\nobserver.observe({\n  type: 'event',\n  durationThreshold: 0, // 16 milliseconds minimum by the spec\n  buffered: true\n});\n\n\n4. “Performance” section in developer tools in the browser\nThe “performance” section with its recording option can provide all the necessary information about\nwhat is happening in the browser and in the main thread. It also allows you to detect long tasks, check the exact call stack in any recorded moment,\nrendered frames, cyclic and synchronous style recalculations and more. It can be your best friend during\ndebugging a slow interaction :)\n\n\n\n5. Synthetic tests tools\nPageSpeed Insights (Web App tool): https://pagespeed.web.dev/\nINP debugger (Web App tool): https://www.debugbear.com/inp-debugger\n6. Other helpful tips\nUse CPU throttling during debugging the interaction - some INP issues can be noticeable only on slower devices.\nYou can turn it on in the developers tools → “Performance” tab settings → CPU\nLocal overrides - you can override script locally (more info: https://developer.chrome.com/docs/devtools/overrides)\nBlocking scripts locally\n\nRemote debug on physical devices\n    \nAndroid: https://developer.chrome.com/docs/devtools/remote-debugging\niOS: https://developer.apple.com/documentation/safari-developer-tools/inspecting-ios\nOptimizing INP\n1. Splitting long tasks into smaller ones\nSome operations causing long tasks can be broken up into smaller ones. It helps the browser to perform other\ncritical operations like rerendering, handling event handlers etc. One of the methods to break up such\nlong tasks is using setTimeout. Using this, you can move part of the code to be done in another task.\nMore information: https://web.dev/articles/optimize-long-tasks#use_asyncawait_to_create_yield_points\n2. Optimizing of event handling\nFor long and complex operations handling the interaction, it is worth considering what is most critical\nto display to the user. All non-critical operations can be postponed for execution after the browser has\nrendered the next frame. This can be done using a combination of requestAnimationFrame and setTimeout functions.\nThis combination gives us the assurance that the given callback will execute no sooner than in the next frame.\n\nelement.addEventListener('click', () => {\n  criticalOperations();\n\n  requestAnimationFrame(() => {\n    setTimeout(() => {\n      nonCriticalOperations();\n    }, 0);\n  });\n});\n\n\nShort explanation about what is happening in the above code snippet:\ncriticalOperations() is run synchronously when the event fires. Then, requestAnimationFrame (rAF) is called, which\nschedules the given callback to the moment right before the next frame is rendered, meaning right before layout/paint/commit cycle.\nIf there is any other synchronous code, it is run now. Then comes the time to run the rAF, but the only operation is\nsetTimeout(..., 0), which adds it’s callback to the next event loop cycle, which is after the layout/paint/commit, which at\nthis point has already been scheduled.\nThe final order looks like this:\nclick event → criticalOperations() → requestAnimationFrame call → synchronous operations finished, browser schedules rendering →\nrAF callback is run, schedules nonCriticalOperations using setTimeout → layout/paint/commit → frame is drawn on screen → nonCriticalOperations()\nSo, in combination, requestAnimationFrame + setTimeout ensures that nonCriticalOperations() run after the frame is rendered.\nThey need to be used in tandem to achieve that, none of them achieves it separately.\n3. Be aware of “Layout thrashing”\nSome operations from JavaScript code can force layout style recalculation in order for the browser to calculate, for example, the new position of elements.\nSometimes, suppose an operation like this appears in the wrong place in the code. In that case, it may be necessary for the browser to perform style recalculation\nin the middle of the task (synchronously), making it much longer. Especially if the recalculation affects many elements. Such situations occur most\noften when the styles of an element are changed and then immediately the values of those styles are requested in JavaScript. Avoid mixing read and\nupdate DOM operations in the same task.\n\n// Example: BAD\nfunction changeBoxSize(box) {\n  box.classList.add('big');\n\n  // Log box height\n  console.log(box.offsetHeight);\n}\n\n\n\n// Example: BETTER\nfunction changeBoxSize(box) {\n    // Log box height\n    console.log(box.offsetHeight);\n\n    box.classList.add('big');\n}\n\n\nIn the first (BAD) example the browser has to run a styles recalculation process synchronously to calculate the new height of the box element(“Forced reflow” in the browser).\nIn the second (BETTER) example there is no such problem. We can log the height value calculated during the latest rendering process.\nAfter that there is a changing element styles operation. It’s fine in this example because it’s not going to force the browser to run styles\nrecalculation synchronously during the currently running task.\n4. Using CSS content-visibility\nYou can optimize rendering offscreen content by using the proper value of the content-visibility option. It can help the browser to specify\nrender priority (higher for content in the viewport and lower for out of viewport elements).\nRead more: https://developer.mozilla.org/en-US/docs/Web/CSS/content-visibility\n5. Minimizing DOM size\nIn Lighthouse reports you can find recommendations for pages to contain fewer than ~1400 elements and the tree should not be deeper than 32 levels.\nKeeping the number of elements in the DOM as small as possible is important because large DOM can slow the page down in multiple ways, such as:\nIncreased time of the first render due to network efficiency and load performance.\nRuntime performance — The browser must constantly recompute the position and styling of nodes.\nLarge DOM can cause long styles recalculations that block the main thread for a long time.\nRead more: https://web.dev/articles/dom-size-and-interactivity\n6. Web Workers\nIf some very long operations are hard to optimize, you can use Web Workers to run your JavaScript code in a dedicated thread. It allows\nyou to not block the main thread during, for example, complicated calculations. However, there are some limitations to this solution.\nThe code executed in the worker has its own global context (it does not have access to the window object). In addition, it is not possible to\nperform direct operations on the DOM.\nYou can find more information here: https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers\nINP in Allegro — a few examples\n1. Slow interactions — long tasks\nAt Allegro, we have taken many actions and attempts to improve the INP score. By far, the most effective were attempts to diagnose\nlong interactions based on RUM data and optimize them. This is crucial because one long interaction can spoil the INP results of the\nentire website (for visits with a small number of interactions, the time of the longest interaction is reported as the final INP result of the visit).\nAfter locating and examining the troublesome interactions, it turns out to be crucial to divide long tasks into smaller ones and to defer non-critical\noperations until the next frame is rendered. This way, we let the browser decide how many of these tasks it can run before needing to perform another action,\nsuch as style recalculation, rendering the next frame, etc. Otherwise, if we put the entire complex interaction handling into a single long task,\nwe do not give the browser any space to maneuver. In this scenario, the next frame can be rendered only after this long task is completed, as\nit will block the main thread for too long.\nBelow you can find an example of optimizing a long interaction on the offer page, which was opening and closing full-screen mode in a photo gallery,\nat the top of an offer page. In this case, the long task was split into two smaller ones using the setTimeout function with a delay parameter value set to 0.\n\nExample 1: All interaction handling is contained in one single task, which the browser reports as a “Long task”.\n\nExample 2: The same interaction handling after being split into two tasks. The entire non-critical part has been separated into the next task,\nwhich can be started by the browser at a time suitable for it. In this case, you can see that a new frame was rendered between the two tasks,\nand then the rest of the interaction handling was executed.\n\nExample 3:  In this example, we can see exactly the same two tasks as in Example 2. The difference is that the first task finished quickly\nenough, so the browser decided that it had enough time to perform the second task before the render.\n2. Costly style recalculations\nSome style recalculations can be very costly. Among other things, it may be because one change in styles causes a change in many other elements.\nSuch a situation occurred in one of our interactions: opening a sidebar element (an element that slides out from the side, containing, for example,\ninformation about delivery). The operation that caused costly style recalculation was the addition of a special CSS class to the body element,\nwhich blocked the ability to scroll the content under the sidebar. This significantly increased the total processing time for opening the sidebar,\neven though blocking the ability to scroll the content below was not critical and not the most important. The solution was to simply postpone\nthe operation of attaching CSS class to the body element until after the next frame had been rendered. This way, the user received the most\nimportant visual effect of this interaction faster — opening the sidebar with important information.\n\nThe sidebar component at Allegro\n\nInformation about how many elements were affected by style recalculation can be found in developer tools in the „Performance” tab.\n3. Attaching global event listeners too early\nGlobal event listeners (e.g. on the global window / document object or body element) should be attached only if necessary.\nDue to the event propagation in JavaScript, such listeners can be fired on any user interaction with the page. In many cases such\nlisteners are unnecessary or are enabled too early, e.g. as soon as the page loads.\nAn example of this behavior can be a modal element and the global event listener responsible for closing the modal when users\ninteract with the overlay outside its boundaries. Such listeners should be registered just after opening the modal and removed\njust after the modal is closed. Then such a listener doesn’t interrupt the others and doesn’t extend them.\nDoes it change a lot?\nI think it does. Definitely, the introduction of INP has changed a lot in working with WebPerf. The new metric differs strongly from the FID it replaces.\nIt forces a focus on all interactions, not just making the site interactive as quickly as possible. This requires digging in and understanding how interactions are processed by the browser.\nIt also requires thinking about how other operations can affect the interactivity of the website.\nWe are still learning how to work in the new reality, so we would be excited if you share your own experiences with us!\nSpecial thanks to Kamil Borzym, Paweł Lesiecki and Wiktor Czajkowski for their help with creating this post.","guid":"https://blog.allegro.tech/2024/07/INP-new-core-web-vitals.html","categories":["tech","frontend","performance","inp","webperf"],"isoDate":"2024-06-30T22:00:00.000Z"},{"title":"A Mission to Cost-Effectiveness: Reducing the cost of a single Google Cloud Dataflow Pipeline by Over 60%","link":"https://blog.allegro.tech/2024/06/cost-optimization-data-pipeline-gcp.html","pubDate":"Thu, 20 Jun 2024 00:00:00 +0200","authors":{"author":[{"name":["Jakub Demianowski"],"photo":["https://blog.allegro.tech/img/authors/jakub.demianowski.jpg"],"url":["https://blog.allegro.tech/authors/jakub.demianowski"]}]},"content":"<p>In this article we’ll present methods for efficiently optimizing physical resources and fine-tuning the configuration of a Google Cloud Platform (GCP)\nDataflow pipeline in order to achieve cost reductions.\nOptimization will be presented as a real-life scenario, which will be performed in stages.</p>\n\n<p>Before we start, it’s time to introduce several avenues through which the cost of Big Data pipelines can be significantly reduced.\nThese include:</p>\n\n<ol>\n  <li>Careful optimization of consumed physical resources, like choosing VM types with optimal CPU to memory ratio and a cost-effective CPU type.</li>\n  <li>Enhancing the configuration of the data processing engine to maximize its efficiency.</li>\n  <li>Optimizing input and output datasets. Not all data may need processing or perhaps, altering their structure could reduce the processing time.</li>\n  <li>Refining storage strategies for input and output datasets. This is particularly beneficial if reading or writing speeds are suboptimal and demand improvements.</li>\n  <li>Streamlining of our pipeline code and utilizing built-in optimization functionalities (for example broadcast joins and repartitioning in Apache Spark).</li>\n</ol>\n\n<p>Throughout this article we will focus solely on optimizing consumed physical resources (1st point) and enhancing configuration of the data processing engine (2nd point).</p>\n\n<h2 id=\"about-the-data-pipeline-being-optimized\">About the data pipeline being optimized</h2>\n\n<p>The data pipeline which will serve us as an example throughout this article is written in Apache Beam using Python SDK.\nThe pipeline runs on Google Cloud Dataflow processing engine.\nThe goal of the pipeline is to join a couple of tables (most of them are a terabyte+ in size), apply some transformations and produce a unified output table.</p>\n\n<p>Overall processing cost of the full dataset is around $350 per day.\nIt results in roughly $10,500 per month, and $127,000 per year.</p>\n\n<h2 id=\"approach-to-cost-optimization\">Approach to cost optimization</h2>\n\n<p>At the beginning of the cost optimization let’s draft a couple of hypotheses:</p>\n\n<ul>\n  <li>Physical resources are underutilized.</li>\n  <li>Physical resources have not the best price-to-performance ratio.</li>\n  <li>Configuration of the Dataflow job is suboptimal and could be optimized.</li>\n</ul>\n\n<p>My goal will be to check those hypotheses.</p>\n\n<p>During the testing phase I’ll use a 3% subsample of input datasets. As a result I will be running tests with input size at ~100 GB level.\nThus, I’ll limit the cost of tests and significantly reduce their time. Final tests will be made on the full dataset, not on a limited subsample.</p>\n\n<p>In order to save time and resources I’ve made some speculative choices regarding what I should test during optimization.\nIn addition, I’ve decided not to test all the possible combinations of machine families, disk types and configuration options to save time.\nI will try to stick with the most promising choices and omit testing unpromising configurations.</p>\n\n<h2 id=\"hypothesis-testing-physical-resources-are-underutilized\">Hypothesis testing: physical resources are underutilized</h2>\n\n<p>In our initial configuration we used the following type of worker machines:</p>\n\n<ul>\n  <li>Machine type: <a href=\"https://cloud.google.com/compute/docs/general-purpose-machines#n2_series\">n2-standard-4</a> (4 vCPU, 16 GB of memory)</li>\n  <li>Disk size: 100 GB</li>\n  <li>Disk type: HDD</li>\n  <li>Max. worker nodes: 500</li>\n  <li>Autoscaling algorithm: throughput based</li>\n</ul>\n\n<p>I made a decision to focus on CPU and memory utilization first.</p>\n\n<h3 id=\"cpu-utilization\">CPU utilization</h3>\n<p>I checked if CPU utilization was on an acceptable level, and it was.</p>\n\n<p>The following diagram from Dataflow UI presents CPU utilization on All Workers in terms of the CPU utilization\nfor all cores on a single App Engine flexible instance.\nSo it gives us an idea of how the CPU is utilized on each virtual machine.</p>\n\n<p><img src=\"/img/articles/2024-06-20-cost-optimization-data-pipeline-gcp/01_cpu_utilization_all_workers.png\" alt=\"CPU utilization on all worker nodes\" class=\"image-with-frame\" /></p>\n\n<p>We could also take a look at the same data presented in terms of statistical metrics.</p>\n\n<p><img src=\"/img/articles/2024-06-20-cost-optimization-data-pipeline-gcp/02_cpu_utilization_stats.png\" alt=\"CPU utilization statistics\" class=\"image-with-frame\" /></p>\n\n<p>From the given graph I could see that mean utilization of the CPU was around 85%, which is a good score.\nThe result is affected by two shuffle stages, when we need to send data around the cluster (usually network is a small bottleneck here).\nCPU tends to be idle while shuffling data using Dataflow <a href=\"https://cloud.google.com/dataflow/docs/shuffle-for-batch\">Shuffle Service</a>.</p>\n\n<p>So CPU resources are not underutilized. We use almost all of what we pay for.</p>\n\n<h3 id=\"memory-utilization\">Memory utilization</h3>\n\n<p>In the end I checked memory usage. I saw that we did not use all the memory which we were paying for.\nLet’s take a look at the following two graphs.\nThe first one shows maximal memory utilization among all the workers.\n<img src=\"/img/articles/2024-06-20-cost-optimization-data-pipeline-gcp/03_memory_utilization_max_usage.png\" alt=\"Memory utilization max usage\" class=\"image-with-frame\" /></p>\n\n<p>The second one shows memory utilization statistics among all the worker nodes.\n<img src=\"/img/articles/2024-06-20-cost-optimization-data-pipeline-gcp/04_memory_utilization_summary.png\" alt=\"Memory utilization summary\" class=\"image-with-frame\" /></p>\n\n<p>The first one presents average memory usage on a worker node, the second one presents overall memory usage among the whole cluster.\nWe clearly see that we only use around 50% of the memory. Bingo, we pay for memory that we do not use.</p>\n\n<h3 id=\"improving-memory-utilization\">Improving memory utilization</h3>\n\n<p>Usually there are two ways of improving memory utilization:</p>\n\n<ul>\n  <li>Change CPU to memory ratio on worker nodes.</li>\n  <li>Decrease the amount of worker nodes.</li>\n</ul>\n\n<p>I’ve decided to change the CPU to memory ratio rather than decrease the number of worker nodes.\nI did not want to compromise on scalability and time needed to perform a job.</p>\n\n<p>Test on a 3% subsample of input data has given the following cost of data processing:</p>\n\n<ul>\n  <li>n2-standard-4: $9.48</li>\n  <li>n2-highcpu-8: $8.52 (~ 10% less than original price)</li>\n  <li>n2d-highcpu-8: $8.57 (~ 10% less than original price)</li>\n</ul>\n\n<p>We saved 10% on adjusting CPU and memory ratio.\nIt results in around $12,700 of estimated savings per year (10% of $127,000 annual cost).</p>\n\n<table>\n  <tr>\n    <th>Hypothesis</th>\n    <th>Savings<span><sup id=\"fnref:1\" role=\"doc-noteref\"><a href=\"#fn:1\" class=\"footnote\" rel=\"footnote\">1</a></sup></span></th>\n  </tr>\n  <tr>\n    <td>[1] Physical resources are underutilized</td>\n    <td>$12,700</td>\n  </tr>\n</table>\n\n<h2 id=\"hypothesis-testing-physical-resources-has-not-the-best-price-to-performance-ratio\">Hypothesis testing: physical resources has not the best price-to-performance ratio</h2>\n\n<p>I assumed that the current virtual machine type (n2-standard-4) has not the best price-to-performance ratio.\nTo check performance of different virtual machine types I used <a href=\"https://cloud.google.com/compute/docs/benchmarks-linux\">CoreMark scores provided by Google Cloud itself</a>.</p>\n\n<p>Based on CoreMark scores and official Google Cloud VM pricing, I prepared a table which would help me choose the VM type with the best price-to-performance ratio.\nThe most important column is “price per 1 mln points” — how much I need to pay on average to score 1 mln points.\nI used <a href=\"https://cloud.google.com/compute/vm-instance-pricing\">official VM instance prices from Google Cloud site</a> from region europe-west1.</p>\n\n<table>\n  <tr>\n    <th>Virtual Machine Type</th>\n    <th>Points in ScoreMark<span><sup id=\"fnref:2\" role=\"doc-noteref\"><a href=\"#fn:2\" class=\"footnote\" rel=\"footnote\">2</a></sup></span></th>\n    <th>Price per hour<span><sup id=\"fnref:3\" role=\"doc-noteref\"><a href=\"#fn:3\" class=\"footnote\" rel=\"footnote\">3</a></sup></span></th>\n    <th>Price per 1 mln points</th>\n  </tr>\n  <tr>\n    <td>n2-standard-4</td>\n    <td>66 833 pts</td>\n    <td>$0.21</td>\n    <td>$3.20</td>\n  </tr>\n  <tr>\n    <td>n2-standard-8</td>\n    <td>138 657 pts</td>\n    <td>$0.43</td>\n    <td>$3.08</td>\n  </tr>\n  <tr>\n    <td>n2d-standard-8</td>\n    <td>164 539 pts</td>\n    <td>$0.37</td>\n    <td>$2.26</td>\n  </tr>\n  <tr>\n    <td>e2-standard-8</td>\n    <td>103 808 pts</td>\n    <td>$0.29</td>\n    <td>$2.84</td>\n  </tr>\n  <tr>\n    <td>t2d-standard-8</td>\n    <td>237 411 pts</td>\n    <td>$0.37</td>\n    <td>$1.57</td>\n  </tr>\n</table>\n\n<p>As we see, another hypothesis proved to be true. We’re not using the virtual machine type with the best price-to-performance ratio - T2D.\nWe’re using N2 machine type.</p>\n\n<p>Unfortunately, at the time of writing, T2D machines do not provide CPU to memory ratios other than 3 GB per 1 vCPU.\nIt’s still better than 4 GB per 1 vCPU, but far from 1 or 2 GB per 1 vCPU.\nWe will check if T2D virtual machine type with 4 GB of memory per 1 CPU is cheaper than its counterparts.</p>\n\n<h3 id=\"moving-to-a-virtual-machine-type-with-better-price-to-performance-ratio\">Moving to a virtual machine type with better price-to-performance ratio</h3>\n\n<p>I performed several tests on a small scale (3% subsample of input data) with T2D machine types. Let’s take a look at them.</p>\n\n<ul>\n  <li>n2-standard-4 + HDD: $9.48</li>\n  <li>n2-highcpu-8 + HDD: $8.52 (~ 10% less than original price)</li>\n  <li>n2d-highcpu-8 + HDD: $8.57 (~ 10% less than original price)</li>\n  <li>t2d-standard-8 + HDD: $6.65 (~ 32% less than original price)</li>\n</ul>\n\n<p>This way we decreased the estimated processing cost from $127,000 by $40,640 per year to $86,360 (by 32%)<sup id=\"fnref:1:1\" role=\"doc-noteref\"><a href=\"#fn:1\" class=\"footnote\" rel=\"footnote\">1</a></sup>.\nUnfortunately, we also introduced some possible underutilized resources (memory) by changing CPU to memory ratio.</p>\n\n<table>\n  <tr>\n    <th>Hypothesis</th>\n    <th>Savings<span><sup id=\"fnref:1:2\" role=\"doc-noteref\"><a href=\"#fn:1\" class=\"footnote\" rel=\"footnote\">1</a></sup></span></th>\n  </tr>\n  <tr>\n    <td>[1] Physical resources are underutilized</td>\n    <td>$12,700</td>\n  </tr>\n  <tr>\n    <td>[2] Moving to a more cost-effective VM type</td>\n    <td>$27,940</td>\n  </tr>\n</table>\n\n<p>Total: $40,640 of estimated savings<sup id=\"fnref:1:3\" role=\"doc-noteref\"><a href=\"#fn:1\" class=\"footnote\" rel=\"footnote\">1</a></sup></p>\n\n<h3 id=\"coming-back-to-optimization-of-virtual-machine-storage-type\">Coming back to optimization of virtual machine storage type</h3>\n\n<p>As I found the most suitable virtual machine type, I was able to focus on choosing between SSD and HDD disk types.\nAs we all know, HDDs are much slower than SSDs, especially in terms of random read/write.\nFor processes where we do not heavily use storage I/O operations there’s no need to move to more expensive SSDs.</p>\n\n<p>I decided to check if we should use cheaper and slower HDDs or more expensive and faster SSDs.\nI run the pipeline (3% of input data size) with HDD and SSD disks.\nHere are the results for different VM families:</p>\n\n<ul>\n  <li>n2-standard-4 + HDD: $9.48</li>\n  <li>n2-highcpu-8 + HDD: $8.52 (~ 10% less than original price)</li>\n  <li>n2d-highcpu-8 + HDD: $8.57 (~ 10% less than original price)</li>\n  <li>t2d-standard-8 + HDD: $6.65 (~ 32% less than original price)</li>\n  <li>t2d-standard-8 + SSD: $5.64 (~ 41% less than original price)</li>\n</ul>\n\n<p>This way we decreased the estimated processing cost from $127,000 by $52,070 per year to $74,930 (by 41%)<sup id=\"fnref:1:4\" role=\"doc-noteref\"><a href=\"#fn:1\" class=\"footnote\" rel=\"footnote\">1</a></sup>.</p>\n\n<table>\n  <tr>\n    <th>Hypothesis</th>\n    <th>Savings<span><sup id=\"fnref:1:5\" role=\"doc-noteref\"><a href=\"#fn:1\" class=\"footnote\" rel=\"footnote\">1</a></sup></span></th>\n  </tr>\n  <tr>\n    <td>[1] Physical resources are underutilized</td>\n    <td>$12,700</td>\n  </tr>\n  <tr>\n    <td>[2] Moving to a more cost-effective VM type</td>\n    <td>$27,940</td>\n  </tr>\n  <tr>\n    <td>[3] Changing VM disk type to SSD</td>\n    <td>$11,430</td>\n  </tr>\n</table>\n\n<p>Total: $52,070 of estimated savings<sup id=\"fnref:1:6\" role=\"doc-noteref\"><a href=\"#fn:1\" class=\"footnote\" rel=\"footnote\">1</a></sup></p>\n\n<h2 id=\"hypothesis-testing-configuration-of-the-dataflow-job-is-not-optimal\">Hypothesis testing: configuration of the Dataflow job is not optimal</h2>\n\n<p>Dataflow, in comparison to Apache Spark, leaves us with almost no configuration options to be changed.\nIt’s good because in Dataflow you get very decent out-of-the-box settings.\nThe single option which I wanted to tune was if we should use Shuffle Service.\nShuffle Service is a serverless tool that facilitates data shuffling around the cluster, thus relieving worker nodes from this task.\nAlso, node preemption is not so painful because Shuffle Service stores data in external storage independent of worker nodes.\nBut it comes at a price.</p>\n\n<p>Cost breakdown of processing 3% input dataset using virtual machine t2d-standard-8 with SSD disk is presented below<sup id=\"fnref:3:1\" role=\"doc-noteref\"><a href=\"#fn:3\" class=\"footnote\" rel=\"footnote\">3</a></sup>:</p>\n\n<ul>\n  <li>Cost of CPU: $2.47</li>\n  <li>Cost of memory: $0.70</li>\n  <li>Cost of SSD disk: $0.16</li>\n  <li>Cost of shuffle service: $2.32</li>\n  <li>Overall cost: $5.64</li>\n</ul>\n\n<p>Thus, we see that the cost of the shuffle service plays an important role - it’s more than 40% of the overall cost. Let’s do an experiment and turn Shuffle Service off.</p>\n\n<ul>\n  <li>n2-standard-4 + HDD: $9.48 (original configuration)</li>\n  <li>t2d-standard-8 + SSD: $5.64 (~ 41% less than original configuration)</li>\n  <li>t2d-standard-8 + SSD + no Shuffle Service: $3.95 (~ 58% less than original configuration)</li>\n</ul>\n\n<p>By turning off Shuffle Service we achieved a much lower cost.\nAs a bonus, our memory utilization increased to almost 100%, because we use worker nodes to perform a shuffle.\nSo we eliminated an underutilized T2D issue connected with a CPU to memory ratio.\nNode preemption is not a problem since we’re not utilizing preemptible VMs.</p>\n\n<p>I must also add that turning off external shuffle service may not always result in lower cost.\nIt depends on many factors, and you should test it on your own data pipeline.\nAlso, you need to take into consideration that the job will usually require more resources (CPU, memory) once you turn off external shuffle service.</p>\n\n<p>This way we decreased the estimated processing cost from $127,000 by $73,660 per year to $53,340 (by 58%)<sup id=\"fnref:1:7\" role=\"doc-noteref\"><a href=\"#fn:1\" class=\"footnote\" rel=\"footnote\">1</a></sup>.\nSo it’s now less than half of the initial cost<sup id=\"fnref:1:8\" role=\"doc-noteref\"><a href=\"#fn:1\" class=\"footnote\" rel=\"footnote\">1</a></sup>.</p>\n\n<table>\n  <tr>\n    <th>Hypothesis</th>\n    <th>Savings<span><sup id=\"fnref:1:9\" role=\"doc-noteref\"><a href=\"#fn:1\" class=\"footnote\" rel=\"footnote\">1</a></sup></span></th>\n  </tr>\n  <tr>\n    <td>[1] Physical resources are underutilized</td>\n    <td>$12,700</td>\n  </tr>\n  <tr>\n    <td>[2] Moving to a more cost-effective VM type</td>\n    <td>$27,940</td>\n  </tr>\n  <tr>\n    <td>[3] Changing VM disk type to SSD</td>\n    <td>$11,430</td>\n  </tr>\n  <tr>\n    <td>[4] Turning off Shuffle Service</td>\n    <td>$21,590</td>\n  </tr>\n</table>\n\n<p>Total: $73,660 of estimated savings<sup id=\"fnref:1:10\" role=\"doc-noteref\"><a href=\"#fn:1\" class=\"footnote\" rel=\"footnote\">1</a></sup></p>\n\n<p>Note: Why did we not use Dataflow <a href=\"https://cloud.google.com/dataflow/docs/guides/flexrs\">FlexRS</a> which could lower the processing price by combining preemptible and regular VMs?</p>\n\n<p>We did not test it due to how scheduling in FlexRS works.\nWhen you schedule a Dataflow FlexRS job you do not know the exact start time,\nthe only one promise from FlexRS is that the job will start within 6 hours (<a href=\"https://cloud.google.com/dataflow/docs/guides/flexrs\">documentation notes from Google Cloud website on that</a>).\nOur data pipeline must start at specified time and having a 6 hour delay is not acceptable.</p>\n\n<h2 id=\"final-test-on-a-full-dataset\">Final test on a full dataset</h2>\n\n<p>My last task was to test findings from subsampled input dataset (3%) tests on the full dataset (without subsampling).\nHere are the costs of processing a full dataset for a single day:</p>\n\n<table>\n  <tr>\n    <th>Configuration</th>\n    <th>Processing cost for one day on a full dataset</th>\n  </tr>\n  <tr>\n    <td>n2-standard-4 + HDD</td>\n    <td>$350.02</td>\n  </tr>\n  <tr>\n    <td>t2d-standard-8 + SSD + shuffle service turned off</td>\n    <td>$134.14 (~ 62% less than original price)</td>\n  </tr>\n</table>\n\n<p>As we see, the predicted gain from subsampling was achieved, and savings are even 3 pp higher than estimated.\nFor reference: we estimated, based on runs with 3% of input size, that we will achieve a roughly 58% cost reduction.</p>\n\n<ul>\n  <li>Initial annual cost: $127,000</li>\n  <li>Estimated annual cost after optimization: $48,260</li>\n  <li>Total estimated annual savings: $78,740</li>\n</ul>\n\n<p>Presented figures are only estimates based on a single run and extrapolated to the whole year.\nTo know the exact savings we will need to run the processing pipeline over a year, which hasn’t been done yet.</p>\n\n<h2 id=\"summary\">Summary</h2>\n\n<p>We achieved excellent outcome without even touching the processing code.\nSpeculative approach provided good results.\nThere may still be some space for optimization, but within the timeframe I was given, I treat these results as first-rate and do not find any more reasons to further\noptimize the environment and configuration of the Dataflow job.</p>\n\n<p>Also, specified strategies do not have to lead to cost optimizations in other pipelines.\nAs every data pipeline is different, some changes which brought cost reduction in this example may result in increased processing cost in different data pipelines.\nWhat is most important in this article: how to approach cost optimization of a data pipeline, not which type of resources to choose.</p>\n\n<div class=\"footnotes\" role=\"doc-endnotes\">\n  <ol>\n    <li id=\"fn:1\" role=\"doc-endnote\">\n      <p>Presented figures are only estimates based on a single run (with only 3% of input data) and extrapolated to the whole year with the assumption that processing the whole dataset will result in the same relative savings as processing 3% of source data. <a href=\"#fnref:1\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;</a> <a href=\"#fnref:1:1\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;<sup>2</sup></a> <a href=\"#fnref:1:2\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;<sup>3</sup></a> <a href=\"#fnref:1:3\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;<sup>4</sup></a> <a href=\"#fnref:1:4\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;<sup>5</sup></a> <a href=\"#fnref:1:5\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;<sup>6</sup></a> <a href=\"#fnref:1:6\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;<sup>7</sup></a> <a href=\"#fnref:1:7\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;<sup>8</sup></a> <a href=\"#fnref:1:8\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;<sup>9</sup></a> <a href=\"#fnref:1:9\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;<sup>10</sup></a> <a href=\"#fnref:1:10\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;<sup>11</sup></a></p>\n    </li>\n    <li id=\"fn:2\" role=\"doc-endnote\">\n      <p>CoreMark results from <a href=\"https://cloud.google.com/compute/docs/benchmarks-linux\">CoreMark scores provided by Google Cloud itself</a>, retrieved on 04/05/2024. <a href=\"#fnref:2\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;</a></p>\n    </li>\n    <li id=\"fn:3\" role=\"doc-endnote\">\n      <p>Official prices taken from Google Cloud site, VM instance pricing in region europe-west1, retrieved on 04/05/2024. <a href=\"#fnref:3\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;</a> <a href=\"#fnref:3:1\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;<sup>2</sup></a></p>\n    </li>\n  </ol>\n</div>\n","contentSnippet":"In this article we’ll present methods for efficiently optimizing physical resources and fine-tuning the configuration of a Google Cloud Platform (GCP)\nDataflow pipeline in order to achieve cost reductions.\nOptimization will be presented as a real-life scenario, which will be performed in stages.\nBefore we start, it’s time to introduce several avenues through which the cost of Big Data pipelines can be significantly reduced.\nThese include:\nCareful optimization of consumed physical resources, like choosing VM types with optimal CPU to memory ratio and a cost-effective CPU type.\nEnhancing the configuration of the data processing engine to maximize its efficiency.\nOptimizing input and output datasets. Not all data may need processing or perhaps, altering their structure could reduce the processing time.\nRefining storage strategies for input and output datasets. This is particularly beneficial if reading or writing speeds are suboptimal and demand improvements.\nStreamlining of our pipeline code and utilizing built-in optimization functionalities (for example broadcast joins and repartitioning in Apache Spark).\nThroughout this article we will focus solely on optimizing consumed physical resources (1st point) and enhancing configuration of the data processing engine (2nd point).\nAbout the data pipeline being optimized\nThe data pipeline which will serve us as an example throughout this article is written in Apache Beam using Python SDK.\nThe pipeline runs on Google Cloud Dataflow processing engine.\nThe goal of the pipeline is to join a couple of tables (most of them are a terabyte+ in size), apply some transformations and produce a unified output table.\nOverall processing cost of the full dataset is around $350 per day.\nIt results in roughly $10,500 per month, and $127,000 per year.\nApproach to cost optimization\nAt the beginning of the cost optimization let’s draft a couple of hypotheses:\nPhysical resources are underutilized.\nPhysical resources have not the best price-to-performance ratio.\nConfiguration of the Dataflow job is suboptimal and could be optimized.\nMy goal will be to check those hypotheses.\nDuring the testing phase I’ll use a 3% subsample of input datasets. As a result I will be running tests with input size at ~100 GB level.\nThus, I’ll limit the cost of tests and significantly reduce their time. Final tests will be made on the full dataset, not on a limited subsample.\nIn order to save time and resources I’ve made some speculative choices regarding what I should test during optimization.\nIn addition, I’ve decided not to test all the possible combinations of machine families, disk types and configuration options to save time.\nI will try to stick with the most promising choices and omit testing unpromising configurations.\nHypothesis testing: physical resources are underutilized\nIn our initial configuration we used the following type of worker machines:\nMachine type: n2-standard-4 (4 vCPU, 16 GB of memory)\nDisk size: 100 GB\nDisk type: HDD\nMax. worker nodes: 500\nAutoscaling algorithm: throughput based\nI made a decision to focus on CPU and memory utilization first.\nCPU utilization\nI checked if CPU utilization was on an acceptable level, and it was.\nThe following diagram from Dataflow UI presents CPU utilization on All Workers in terms of the CPU utilization\nfor all cores on a single App Engine flexible instance.\nSo it gives us an idea of how the CPU is utilized on each virtual machine.\n\nWe could also take a look at the same data presented in terms of statistical metrics.\n\nFrom the given graph I could see that mean utilization of the CPU was around 85%, which is a good score.\nThe result is affected by two shuffle stages, when we need to send data around the cluster (usually network is a small bottleneck here).\nCPU tends to be idle while shuffling data using Dataflow Shuffle Service.\nSo CPU resources are not underutilized. We use almost all of what we pay for.\nMemory utilization\nIn the end I checked memory usage. I saw that we did not use all the memory which we were paying for.\nLet’s take a look at the following two graphs.\nThe first one shows maximal memory utilization among all the workers.\n\nThe second one shows memory utilization statistics among all the worker nodes.\n\nThe first one presents average memory usage on a worker node, the second one presents overall memory usage among the whole cluster.\nWe clearly see that we only use around 50% of the memory. Bingo, we pay for memory that we do not use.\nImproving memory utilization\nUsually there are two ways of improving memory utilization:\nChange CPU to memory ratio on worker nodes.\nDecrease the amount of worker nodes.\nI’ve decided to change the CPU to memory ratio rather than decrease the number of worker nodes.\nI did not want to compromise on scalability and time needed to perform a job.\nTest on a 3% subsample of input data has given the following cost of data processing:\nn2-standard-4: $9.48\nn2-highcpu-8: $8.52 (~ 10% less than original price)\nn2d-highcpu-8: $8.57 (~ 10% less than original price)\nWe saved 10% on adjusting CPU and memory ratio.\nIt results in around $12,700 of estimated savings per year (10% of $127,000 annual cost).\nHypothesis\n    Savings1\n  \n[1] Physical resources are underutilized\n    $12,700\n  \nHypothesis testing: physical resources has not the best price-to-performance ratio\nI assumed that the current virtual machine type (n2-standard-4) has not the best price-to-performance ratio.\nTo check performance of different virtual machine types I used CoreMark scores provided by Google Cloud itself.\nBased on CoreMark scores and official Google Cloud VM pricing, I prepared a table which would help me choose the VM type with the best price-to-performance ratio.\nThe most important column is “price per 1 mln points” — how much I need to pay on average to score 1 mln points.\nI used official VM instance prices from Google Cloud site from region europe-west1.\nVirtual Machine Type\n    Points in ScoreMark2\n    Price per hour3\n    Price per 1 mln points\n  \nn2-standard-4\n    66 833 pts\n    $0.21\n    $3.20\n  \nn2-standard-8\n    138 657 pts\n    $0.43\n    $3.08\n  \nn2d-standard-8\n    164 539 pts\n    $0.37\n    $2.26\n  \ne2-standard-8\n    103 808 pts\n    $0.29\n    $2.84\n  \nt2d-standard-8\n    237 411 pts\n    $0.37\n    $1.57\n  \nAs we see, another hypothesis proved to be true. We’re not using the virtual machine type with the best price-to-performance ratio - T2D.\nWe’re using N2 machine type.\nUnfortunately, at the time of writing, T2D machines do not provide CPU to memory ratios other than 3 GB per 1 vCPU.\nIt’s still better than 4 GB per 1 vCPU, but far from 1 or 2 GB per 1 vCPU.\nWe will check if T2D virtual machine type with 4 GB of memory per 1 CPU is cheaper than its counterparts.\nMoving to a virtual machine type with better price-to-performance ratio\nI performed several tests on a small scale (3% subsample of input data) with T2D machine types. Let’s take a look at them.\nn2-standard-4 + HDD: $9.48\nn2-highcpu-8 + HDD: $8.52 (~ 10% less than original price)\nn2d-highcpu-8 + HDD: $8.57 (~ 10% less than original price)\nt2d-standard-8 + HDD: $6.65 (~ 32% less than original price)\nThis way we decreased the estimated processing cost from $127,000 by $40,640 per year to $86,360 (by 32%)1.\nUnfortunately, we also introduced some possible underutilized resources (memory) by changing CPU to memory ratio.\nHypothesis\n    Savings1\n  \n[1] Physical resources are underutilized\n    $12,700\n  \n[2] Moving to a more cost-effective VM type\n    $27,940\n  \nTotal: $40,640 of estimated savings1\nComing back to optimization of virtual machine storage type\nAs I found the most suitable virtual machine type, I was able to focus on choosing between SSD and HDD disk types.\nAs we all know, HDDs are much slower than SSDs, especially in terms of random read/write.\nFor processes where we do not heavily use storage I/O operations there’s no need to move to more expensive SSDs.\nI decided to check if we should use cheaper and slower HDDs or more expensive and faster SSDs.\nI run the pipeline (3% of input data size) with HDD and SSD disks.\nHere are the results for different VM families:\nn2-standard-4 + HDD: $9.48\nn2-highcpu-8 + HDD: $8.52 (~ 10% less than original price)\nn2d-highcpu-8 + HDD: $8.57 (~ 10% less than original price)\nt2d-standard-8 + HDD: $6.65 (~ 32% less than original price)\nt2d-standard-8 + SSD: $5.64 (~ 41% less than original price)\nThis way we decreased the estimated processing cost from $127,000 by $52,070 per year to $74,930 (by 41%)1.\nHypothesis\n    Savings1\n  \n[1] Physical resources are underutilized\n    $12,700\n  \n[2] Moving to a more cost-effective VM type\n    $27,940\n  \n[3] Changing VM disk type to SSD\n    $11,430\n  \nTotal: $52,070 of estimated savings1\nHypothesis testing: configuration of the Dataflow job is not optimal\nDataflow, in comparison to Apache Spark, leaves us with almost no configuration options to be changed.\nIt’s good because in Dataflow you get very decent out-of-the-box settings.\nThe single option which I wanted to tune was if we should use Shuffle Service.\nShuffle Service is a serverless tool that facilitates data shuffling around the cluster, thus relieving worker nodes from this task.\nAlso, node preemption is not so painful because Shuffle Service stores data in external storage independent of worker nodes.\nBut it comes at a price.\nCost breakdown of processing 3% input dataset using virtual machine t2d-standard-8 with SSD disk is presented below3:\nCost of CPU: $2.47\nCost of memory: $0.70\nCost of SSD disk: $0.16\nCost of shuffle service: $2.32\nOverall cost: $5.64\nThus, we see that the cost of the shuffle service plays an important role - it’s more than 40% of the overall cost. Let’s do an experiment and turn Shuffle Service off.\nn2-standard-4 + HDD: $9.48 (original configuration)\nt2d-standard-8 + SSD: $5.64 (~ 41% less than original configuration)\nt2d-standard-8 + SSD + no Shuffle Service: $3.95 (~ 58% less than original configuration)\nBy turning off Shuffle Service we achieved a much lower cost.\nAs a bonus, our memory utilization increased to almost 100%, because we use worker nodes to perform a shuffle.\nSo we eliminated an underutilized T2D issue connected with a CPU to memory ratio.\nNode preemption is not a problem since we’re not utilizing preemptible VMs.\nI must also add that turning off external shuffle service may not always result in lower cost.\nIt depends on many factors, and you should test it on your own data pipeline.\nAlso, you need to take into consideration that the job will usually require more resources (CPU, memory) once you turn off external shuffle service.\nThis way we decreased the estimated processing cost from $127,000 by $73,660 per year to $53,340 (by 58%)1.\nSo it’s now less than half of the initial cost1.\nHypothesis\n    Savings1\n  \n[1] Physical resources are underutilized\n    $12,700\n  \n[2] Moving to a more cost-effective VM type\n    $27,940\n  \n[3] Changing VM disk type to SSD\n    $11,430\n  \n[4] Turning off Shuffle Service\n    $21,590\n  \nTotal: $73,660 of estimated savings1\nNote: Why did we not use Dataflow FlexRS which could lower the processing price by combining preemptible and regular VMs?\nWe did not test it due to how scheduling in FlexRS works.\nWhen you schedule a Dataflow FlexRS job you do not know the exact start time,\nthe only one promise from FlexRS is that the job will start within 6 hours (documentation notes from Google Cloud website on that).\nOur data pipeline must start at specified time and having a 6 hour delay is not acceptable.\nFinal test on a full dataset\nMy last task was to test findings from subsampled input dataset (3%) tests on the full dataset (without subsampling).\nHere are the costs of processing a full dataset for a single day:\nConfiguration\n    Processing cost for one day on a full dataset\n  \nn2-standard-4 + HDD\n    $350.02\n  \nt2d-standard-8 + SSD + shuffle service turned off\n    $134.14 (~ 62% less than original price)\n  \nAs we see, the predicted gain from subsampling was achieved, and savings are even 3 pp higher than estimated.\nFor reference: we estimated, based on runs with 3% of input size, that we will achieve a roughly 58% cost reduction.\nInitial annual cost: $127,000\nEstimated annual cost after optimization: $48,260\nTotal estimated annual savings: $78,740\nPresented figures are only estimates based on a single run and extrapolated to the whole year.\nTo know the exact savings we will need to run the processing pipeline over a year, which hasn’t been done yet.\nSummary\nWe achieved excellent outcome without even touching the processing code.\nSpeculative approach provided good results.\nThere may still be some space for optimization, but within the timeframe I was given, I treat these results as first-rate and do not find any more reasons to further\noptimize the environment and configuration of the Dataflow job.\nAlso, specified strategies do not have to lead to cost optimizations in other pipelines.\nAs every data pipeline is different, some changes which brought cost reduction in this example may result in increased processing cost in different data pipelines.\nWhat is most important in this article: how to approach cost optimization of a data pipeline, not which type of resources to choose.\nPresented figures are only estimates based on a single run (with only 3% of input data) and extrapolated to the whole year with the assumption that processing the whole dataset will result in the same relative savings as processing 3% of source data. ↩ ↩2 ↩3 ↩4 ↩5 ↩6 ↩7 ↩8 ↩9 ↩10 ↩11\nCoreMark results from CoreMark scores provided by Google Cloud itself, retrieved on 04/05/2024. ↩\nOfficial prices taken from Google Cloud site, VM instance pricing in region europe-west1, retrieved on 04/05/2024. ↩ ↩2","guid":"https://blog.allegro.tech/2024/06/cost-optimization-data-pipeline-gcp.html","categories":["tech","big data"],"isoDate":"2024-06-19T22:00:00.000Z"},{"title":"Engineering culture of Allegro & Allegro Pay: Pragmatic Engineer Score","link":"https://blog.allegro.tech/2024/06/pragmatic-engineer-score.html","pubDate":"Tue, 11 Jun 2024 00:00:00 +0200","authors":{"author":[{"name":["Jakub Dropia"],"photo":["https://blog.allegro.tech/img/authors/jakub.dropia.jpg"],"url":["https://blog.allegro.tech/authors/jakub.dropia"]}]},"content":"<p>One tech blog/newsletter gained traction and popularity for a couple of years now: <a href=\"https://blog.pragmaticengineer.com/\">Pragmatic Engineer</a>.</p>\n\n<p>Quoting author:</p>\n\n<p><em>The #1 technology newsletter on Substack. Highly relevant for software engineers and engineering managers, useful for those working in tech.\nWritten by engineering manager and software engineer Gergely Orosz who was previously at Uber, Skype/Microsoft, and at startups.</em></p>\n\n<p>In practice, you will find a huge amount of information and internal insights on how big tech works in many companies.\nThere are many deep dives into engineering culture, best practices, and what goes on behind the scenes.</p>\n\n<p>There is one particular entry in the blog that I would like to share and talk about:</p>\n\n<p><a href=\"https://blog.pragmaticengineer.com/pragmatic-engineer-test/\">The Pragmatic Engineer Test</a></p>\n\n<p>What is it?</p>\n\n<p>It is a checklist of 12 questions, and answering them can “measure” the company’s engineering maturity.</p>\n\n<p>Working in Allegro Pay for four years, I saw a lot of these practices over the years. Hell, I had the opportunity to build some of them, which\nis a valuable thing here. Everyone is open-minded and you can influence your workplace.</p>\n\n<p>But when I came upon this article - it was natural to try to evaluate my current workplace against it.</p>\n\n<p>I did it, and I would like to share the results with you without further ado.</p>\n\n<h1 id=\"disclaimer\">Disclaimer</h1>\n\n<p>I work at Allegro Pay, a company of Allegro Group responsible for Allegro Pay, Care, and Cash products.\nWhat I write further is heavily grounded in the Allegro Pay context, as we have different tech stacks, environments, and technical platforms.\nHowever, all practices are present both at Allegro and at Allegro Pay. The execution may differ, but engineering maturity is very similar in the end.</p>\n\n<h1 id=\"tldr\">TL;DR</h1>\n\n<p>In short - Allegro &amp; Allegro Pay scored 11 points out of 12.</p>\n\n<p>If you want to stop here - the takeaway is:</p>\n\n<p><em>this is a great place for software engineers</em></p>\n\n<p>We have JAVA, .NET, cloud, our own data centers, a mobile-first approach and modern web, a good microservices ecosystem,\na great internal developer platform (or even two!), data engineering and ML, and a product that makes money.</p>\n\n<p>Would you like to hear nice, sweet, and bitter details?</p>\n\n<p>Continue reading 🙂</p>\n\n<p><a href=\"https://blog.pragmaticengineer.com/pragmatic-engineer-test/\">12 Questions</a> and my answers to them.</p>\n\n<h1 id=\"equity-or-profit-sharing\">Equity or profit sharing</h1>\n\n<p>Half Yes. Not all engineers.</p>\n\n<p>Allegro Group is a <a href=\"https://www.gpw.pl/company-factsheet?isin=LU2237380790\">public trading company</a> in Poland. Our engineers can gain stocks as a part of their total compensation package. How does this work?</p>\n\n<p>Well, each senior level and above engineer gains a stocks package yearly as a part of the end-year review. The package is vested over 3 years with (25%, 25% and 50%) proportions.\nVested parts of each package are transferred to your broker account each year and can overlap. The final amount depends on company and individual results.\nIn Poland, these stocks are 19% taxed (if you decide to sell them).</p>\n\n<p>In addition, all employees receive a yearly bonus, which, of course, also depends on the company and individual results.</p>\n\n<p>Both are a significant addition to our overall compensation package.</p>\n\n<p>Caveats?</p>\n\n<p>Stocks are still not part of the offer for newcomers, which I think could contribute to attracting more great engineers.</p>\n\n<h1 id=\"roadmapbacklog-that-engineers-contribute-to\">Roadmap/backlog that engineers contribute to</h1>\n\n<p>Yes.</p>\n\n<p>Each team usually has its backlog. The product manager assigned to that team, the engineering manager, and the team itself are responsible for building\nand maintaining this backlog around functionalities and domains that they own. The backlog is a mix of business features, some maintenance, and technical stories.\nHow it is built and tracked, if teams work in Scrum, Kanban, or some custom approach - is primarily up to the team. In the end, we have some processes that try\nto gather “bigger” deliverables and compose a roadmap and plans for the whole organization at the same root.</p>\n\n<p>It works great and allows teams huge flexibility and freedom in their work. As a trade-off, extra work is needed to map these backlogs into\nthe organizational level processes - which, usually, are in Google Sheets or a custom tool.</p>\n\n<h1 id=\"engineers-directly-working-with-other-ics-individual-contributors\">Engineers directly working with other ICs (Individual Contributors)</h1>\n\n<p>Yes.</p>\n\n<p>We collaborate with each other, regardless of role and career level. Even if other ICs are in different teams, the expectation is to communicate with them directly.\nYou can just write to anyone, and can expect to get an answer. There are some protections to prevent this from turning into complete chaos, like quarterly\nplanning of dependencies between teams, help channels, and so on, but if everyone works on the same page, we are just working together without unnecessary barriers.</p>\n\n<h1 id=\"code-reviews-and-testing\">Code reviews and testing</h1>\n\n<p>Yes.</p>\n\n<p>We have a test platform for automatic E2E tests. Manual testers are available for complex functionalities spanning multiple services.\nTo protect quality, we have code review policies for each repository. In CI/CD, the advanced build system protects us and validates many things\n(unit/integration tests, outdated / beta packages, code formats, etc.) before they go to the main branch.</p>\n\n<p>All of that is part of everyday workflow. Sometimes, it slows you down, but it is done smartly and, most of the time, helps. As always, everything is under your control, and in the end, it is your responsibility to use these tools properly.</p>\n\n<h1 id=\"ci-and-engineers-pushing-to-prod\">CI and engineers pushing to prod</h1>\n\n<p>Yes.</p>\n\n<p>At Allegro Pay, every commit on the main branch triggers a pipeline that goes through the entire CI/CD process, is automatically deployed to the DEV and TEST environment,\nand stops with manual approval before releasing to PROD. Approval needs the acceptance of another engineer than the one who changes the triggered pipeline.\nEach team is responsible for its changes and deployments. We build it, we run it, and we own it.</p>\n\n<p>Of course, that can also vary. Sometimes, additional security measurements need to be applied depending on the context and product.\nBut in the end - we have continuous delivery with dozens of deployments daily.</p>\n\n<h1 id=\"internal-open-source\">Internal open source</h1>\n\n<p>Yes.</p>\n\n<p>Each developer is welcome to issue a PR in components that do not belong to him or his team. We have common internal libraries which are developed and maintained across teams.\nOn the other hand, each repository has only one owner. It works well; people are open-minded and will always consider your contribution.</p>\n\n<p>In practice, this doesn’t happen that often. Most of the work is focused on components that your team owns, and sometimes differences between “services”\n(different technologies, architecture, etc.), and lack of proper documentation are barriers to quick contribution - because you need to understand the service\nand domain first before you will be able to change something that you don’t own.</p>\n\n<p>Additionally, we have a <a href=\"https://github.com/allegro\">catalog</a> of external open-sourced repositories. You can find many great tools and libraries, some of which you may can even know, like\n<a href=\"https://github.com/allegro/bigcache\">bigcache</a>, <a href=\"https://github.com/allegro/hermes\">hermes</a> or <a href=\"https://github.com/allegro/ralph\">ralph</a>. For Allegro Pay itself we also do have <a href=\"https://github.com/topics/allegropay\">some</a>.</p>\n\n<p>What is truly unique and I think fits into this position, is internal tourism. Anyone can request to join any team, and as a regular member work up to a couple of months (usually a quarter), contributing to other teams’ work.</p>\n\n<h1 id=\"healthy-on-call-as-a-priority\">Healthy on-call as a priority.</h1>\n\n<p>Yes.</p>\n\n<p>We do have on-call duty. This is a part of “we own it”.</p>\n\n<p>How this is implemented may vary depending on the area or teams, but in the end, there are some streams of on-duty calls where people\nperform 24-hour on-duty shifts cyclically. These duties are extra paid (for being “ready”). If something happens during duty - your intervention outside working hours is\npaid according to the Polish overtime hours policy (150% or 200% hour rate depends on when this occurs), or you can exchange them for vacation at another time.</p>\n\n<p>We have generic alerts, but each stream also has specific rules. There is a common practice where teams improve and change them to remove noise, false positives,\nor simplify on-duty shifts. In the end - SLA must be met - and how teams will approach this - is up to them.</p>\n\n<h1 id=\"technical-managers\">Technical managers.</h1>\n\n<p>Yes.</p>\n\n<p>Most of our engineering managers have a background in software engineering. They were seniors once and were promoted to manager, taking a step aside from pure IC.\nEven if hiring from outside, they must complete all the technical workshops. It is expected that they will still be experts in the field.</p>\n\n<p>They are deeply rooted in technology. They perform system designs, code reviews, consultancy, and sometimes coding. Proportion varies depending on the team and\nthe manager themselves. Besides people management, they are expected to have ownership of technical decisions and project management of the part which the team is responsible for.</p>\n\n<h1 id=\"career-ladder-when-above-10-engineers--parallel-ic-and-manager-tracks-when-above-30-engineers\">Career ladder (when above 10 engineers) &amp; Parallel IC and manager tracks (when above 30 engineers).</h1>\n\n<p>Yes &amp; half yes</p>\n\n<p>We have a career level for Software Engineer Job Family, which starts from a junior position, goes through mid to senior level, and then splits into two tracks - Individual Contributor and Manager.\nThis split is fairly fresh, as there was only a Manager track before. Because of that, this one is pretty mature, with career progression starting from\nEngineering Manager, going through Senior Engineering Manager, Director, VP or CTO.</p>\n\n<p>If we are talking about the IC path - here we have right now the Principal Software Engineer, whose scope of the work is at least an area or even the whole organization,\nand the Senior Principal Software Engineer is one person for the whole organization.</p>\n\n<p>As you can see, ladders are missing in the IC track; from what I know, this is still in progress. The organization is trying to figure out what IC ladder fits its needs.</p>\n\n<p>There are few opportunities for Individual Contributors above the Senior level. This can be improved, and it will likely be.</p>\n\n<h1 id=\"feedback-culture\">Feedback culture.</h1>\n\n<p>Yes.</p>\n\n<p>I think it is everywhere.</p>\n\n<p>We have continuous feedback - 360, peer-to-peer, promotion, employee engagement surveys and during each half-year performance review. At each significant meeting, a space for Q&amp;A.\nFeedback is deeply rooted in our daily work. You can see polls, surveys, requests for feedback and opinions, post-mortems, and so on everywhere.\nIt is hard to imagine what else we could do to cover this topic, one of our culture’s strongest traits.</p>\n\n<h1 id=\"investing-in-professional-growth\">Investing in professional growth.</h1>\n\n<p>Yes.</p>\n\n<p>This is realized in multiple ways. Each team/individual has a “training budget” - this is money you can spend on external training, courses, and conferences.\nIt differs from team to team, and used to be much better in past.\nAdditionally, we have an internal learning platform with many great workshops - especially in the soft skills area. They are great! You can upskill yourself well.</p>\n\n<p>Also, in some areas and teams, there is a time dedicated to your self-development. You can spend it on contributions to open-source, reading a book,\nlearning from the course, or, for example, writing a PoC of new technology with your team. In Allegro Pay - it is 10%. How you spend it - is up to you,\nor the team, it just should stick to our profession.</p>\n\n<p>There are many internal and external communities (guilds), each with its own meeting calendar and interesting presentations and workshops taking a different kind of forms.\nThere are also many internal events, hackathons, and initiatives. Opportunities to learn are almost infinite.</p>\n\n<p>Landing here was my biggest personal and professional progression so far.</p>\n\n<h1 id=\"the-bitter-or-not\">The bitter (or not?)</h1>\n\n<p>Sounds sweet, right? Where is the bitter here? Well, I am not sure.</p>\n\n<p>This is a rapid-growth product and company. We are focused on delivering value to clients and maximizing profit from our products.\nEverything we do must contribute to overall success, and there is little space to “breathe”. You must often balance delivering functionalities,\npaying back technical debt, and growing scale. Taking shortcuts. Making trade-offs. Asking difficult questions. Our roadmaps often change\nbecause of the economics, law, or maybe data we gathered and told us that our actions do not convert in the way we assumed.\nIn Allegro Pay itself - the financial domain also does not help — a huge amount of our work is dedicated to legal matters. New laws pop up, and we must follow them.</p>\n\n<p>I can imagine that it can’t be for everyone.</p>\n\n<p>But for me, this introduces an entirely new layer of engineering, where you need to be smart, cautious, value impact, and make the right choices.</p>\n\n<p>We strive to be the best in the market, which is why we succeed.</p>\n\n<p>Another thing can be the corporation itself. But this is very likely something that you will not notice until you become a manager.</p>\n\n<p>Allegro is a big company that has shifted to a more centralized and structured approach over the years. Everything needs to be aligned with the process.\nTo picture this, here are a few examples:</p>\n\n<ul>\n  <li>\n    <p>Instead of ordering any accessories required within the budget - the budget was removed, and you can order only specific, pre-selected accessories</p>\n  </li>\n  <li>\n    <p>Want to hire someone? There is budgeting once per year, and you need to come prepared to justify another full-time equivalent.</p>\n  </li>\n  <li>\n    <p>Do you want to give someone a raise? Well, you don’t have to worry about this. Process, one per year, will do that for you.\nYou need to provide a performance review of your directs. Based on that you will get the budget, recommendations, and ability to slightly change proportions.</p>\n  </li>\n  <li>\n    <p>Want to pursue external training? You have a budget. It would be best if you fit it in. You need to raise a request and process it through several layers of acceptance.</p>\n  </li>\n</ul>\n\n<p>As you can imagine, all of that can take time and be annoying. It is very frequent that your “request” is stuck somewhere, and you need to “push” it.\nBut on the other end of the process, there are helpful people whom you can always talk to.</p>\n\n<p>Sometimes, this leads to funny absurdities - you find an old monitor in the office that is not assigned to anyone (or a person who is not already in the company),\nand you would like to order a docking station for it. “Procedures” will not allow you to do that. The dock must have existed before; if lost,\nonly the owner can “order” a new one with a good justification. But you are not the owner. It is no man’s land - thus - no dock for it ;)</p>\n\n<p>But I think most big corporations work like that. The past few years were also difficult for the industry. I understand why this is happening.\nIf you are an individual contributor, most of these things will not affect you. And those which do - you need to get used to it, and if you focus on the rest - hell - this is a great place to work.</p>\n\n<h1 id=\"is-there-more\">Is there more?</h1>\n\n<p>A score of 11 tells that you will find much good stuff in software engineering here.</p>\n\n<p>But this is not all. There are plenty of other great features of engineering culture at Allegro &amp; Allegro Pay. You have great products, a big scale and\na data-driven approach which leads to many challenges; amazing, intelligent people; modern technology and approach to software engineering;\nrich off-topic communities (board games, sports, FIFA league, etc.), and many more.</p>\n\n<p>Overall, #DobrzeTuByć (#GoodToBeHere)</p>\n","contentSnippet":"One tech blog/newsletter gained traction and popularity for a couple of years now: Pragmatic Engineer.\nQuoting author:\nThe #1 technology newsletter on Substack. Highly relevant for software engineers and engineering managers, useful for those working in tech.\nWritten by engineering manager and software engineer Gergely Orosz who was previously at Uber, Skype/Microsoft, and at startups.\nIn practice, you will find a huge amount of information and internal insights on how big tech works in many companies.\nThere are many deep dives into engineering culture, best practices, and what goes on behind the scenes.\nThere is one particular entry in the blog that I would like to share and talk about:\nThe Pragmatic Engineer Test\nWhat is it?\nIt is a checklist of 12 questions, and answering them can “measure” the company’s engineering maturity.\nWorking in Allegro Pay for four years, I saw a lot of these practices over the years. Hell, I had the opportunity to build some of them, which\nis a valuable thing here. Everyone is open-minded and you can influence your workplace.\nBut when I came upon this article - it was natural to try to evaluate my current workplace against it.\nI did it, and I would like to share the results with you without further ado.\nDisclaimer\nI work at Allegro Pay, a company of Allegro Group responsible for Allegro Pay, Care, and Cash products.\nWhat I write further is heavily grounded in the Allegro Pay context, as we have different tech stacks, environments, and technical platforms.\nHowever, all practices are present both at Allegro and at Allegro Pay. The execution may differ, but engineering maturity is very similar in the end.\nTL;DR\nIn short - Allegro & Allegro Pay scored 11 points out of 12.\nIf you want to stop here - the takeaway is:\nthis is a great place for software engineers\nWe have JAVA, .NET, cloud, our own data centers, a mobile-first approach and modern web, a good microservices ecosystem,\na great internal developer platform (or even two!), data engineering and ML, and a product that makes money.\nWould you like to hear nice, sweet, and bitter details?\nContinue reading 🙂\n12 Questions and my answers to them.\nEquity or profit sharing\nHalf Yes. Not all engineers.\nAllegro Group is a public trading company in Poland. Our engineers can gain stocks as a part of their total compensation package. How does this work?\nWell, each senior level and above engineer gains a stocks package yearly as a part of the end-year review. The package is vested over 3 years with (25%, 25% and 50%) proportions.\nVested parts of each package are transferred to your broker account each year and can overlap. The final amount depends on company and individual results.\nIn Poland, these stocks are 19% taxed (if you decide to sell them).\nIn addition, all employees receive a yearly bonus, which, of course, also depends on the company and individual results.\nBoth are a significant addition to our overall compensation package.\nCaveats?\nStocks are still not part of the offer for newcomers, which I think could contribute to attracting more great engineers.\nRoadmap/backlog that engineers contribute to\nYes.\nEach team usually has its backlog. The product manager assigned to that team, the engineering manager, and the team itself are responsible for building\nand maintaining this backlog around functionalities and domains that they own. The backlog is a mix of business features, some maintenance, and technical stories.\nHow it is built and tracked, if teams work in Scrum, Kanban, or some custom approach - is primarily up to the team. In the end, we have some processes that try\nto gather “bigger” deliverables and compose a roadmap and plans for the whole organization at the same root.\nIt works great and allows teams huge flexibility and freedom in their work. As a trade-off, extra work is needed to map these backlogs into\nthe organizational level processes - which, usually, are in Google Sheets or a custom tool.\nEngineers directly working with other ICs (Individual Contributors)\nYes.\nWe collaborate with each other, regardless of role and career level. Even if other ICs are in different teams, the expectation is to communicate with them directly.\nYou can just write to anyone, and can expect to get an answer. There are some protections to prevent this from turning into complete chaos, like quarterly\nplanning of dependencies between teams, help channels, and so on, but if everyone works on the same page, we are just working together without unnecessary barriers.\nCode reviews and testing\nYes.\nWe have a test platform for automatic E2E tests. Manual testers are available for complex functionalities spanning multiple services.\nTo protect quality, we have code review policies for each repository. In CI/CD, the advanced build system protects us and validates many things\n(unit/integration tests, outdated / beta packages, code formats, etc.) before they go to the main branch.\nAll of that is part of everyday workflow. Sometimes, it slows you down, but it is done smartly and, most of the time, helps. As always, everything is under your control, and in the end, it is your responsibility to use these tools properly.\nCI and engineers pushing to prod\nYes.\nAt Allegro Pay, every commit on the main branch triggers a pipeline that goes through the entire CI/CD process, is automatically deployed to the DEV and TEST environment,\nand stops with manual approval before releasing to PROD. Approval needs the acceptance of another engineer than the one who changes the triggered pipeline.\nEach team is responsible for its changes and deployments. We build it, we run it, and we own it.\nOf course, that can also vary. Sometimes, additional security measurements need to be applied depending on the context and product.\nBut in the end - we have continuous delivery with dozens of deployments daily.\nInternal open source\nYes.\nEach developer is welcome to issue a PR in components that do not belong to him or his team. We have common internal libraries which are developed and maintained across teams.\nOn the other hand, each repository has only one owner. It works well; people are open-minded and will always consider your contribution.\nIn practice, this doesn’t happen that often. Most of the work is focused on components that your team owns, and sometimes differences between “services”\n(different technologies, architecture, etc.), and lack of proper documentation are barriers to quick contribution - because you need to understand the service\nand domain first before you will be able to change something that you don’t own.\nAdditionally, we have a catalog of external open-sourced repositories. You can find many great tools and libraries, some of which you may can even know, like\nbigcache, hermes or ralph. For Allegro Pay itself we also do have some.\nWhat is truly unique and I think fits into this position, is internal tourism. Anyone can request to join any team, and as a regular member work up to a couple of months (usually a quarter), contributing to other teams’ work.\nHealthy on-call as a priority.\nYes.\nWe do have on-call duty. This is a part of “we own it”.\nHow this is implemented may vary depending on the area or teams, but in the end, there are some streams of on-duty calls where people\nperform 24-hour on-duty shifts cyclically. These duties are extra paid (for being “ready”). If something happens during duty - your intervention outside working hours is\npaid according to the Polish overtime hours policy (150% or 200% hour rate depends on when this occurs), or you can exchange them for vacation at another time.\nWe have generic alerts, but each stream also has specific rules. There is a common practice where teams improve and change them to remove noise, false positives,\nor simplify on-duty shifts. In the end - SLA must be met - and how teams will approach this - is up to them.\nTechnical managers.\nYes.\nMost of our engineering managers have a background in software engineering. They were seniors once and were promoted to manager, taking a step aside from pure IC.\nEven if hiring from outside, they must complete all the technical workshops. It is expected that they will still be experts in the field.\nThey are deeply rooted in technology. They perform system designs, code reviews, consultancy, and sometimes coding. Proportion varies depending on the team and\nthe manager themselves. Besides people management, they are expected to have ownership of technical decisions and project management of the part which the team is responsible for.\nCareer ladder (when above 10 engineers) & Parallel IC and manager tracks (when above 30 engineers).\nYes & half yes\nWe have a career level for Software Engineer Job Family, which starts from a junior position, goes through mid to senior level, and then splits into two tracks - Individual Contributor and Manager.\nThis split is fairly fresh, as there was only a Manager track before. Because of that, this one is pretty mature, with career progression starting from\nEngineering Manager, going through Senior Engineering Manager, Director, VP or CTO.\nIf we are talking about the IC path - here we have right now the Principal Software Engineer, whose scope of the work is at least an area or even the whole organization,\nand the Senior Principal Software Engineer is one person for the whole organization.\nAs you can see, ladders are missing in the IC track; from what I know, this is still in progress. The organization is trying to figure out what IC ladder fits its needs.\nThere are few opportunities for Individual Contributors above the Senior level. This can be improved, and it will likely be.\nFeedback culture.\nYes.\nI think it is everywhere.\nWe have continuous feedback - 360, peer-to-peer, promotion, employee engagement surveys and during each half-year performance review. At each significant meeting, a space for Q&A.\nFeedback is deeply rooted in our daily work. You can see polls, surveys, requests for feedback and opinions, post-mortems, and so on everywhere.\nIt is hard to imagine what else we could do to cover this topic, one of our culture’s strongest traits.\nInvesting in professional growth.\nYes.\nThis is realized in multiple ways. Each team/individual has a “training budget” - this is money you can spend on external training, courses, and conferences.\nIt differs from team to team, and used to be much better in past.\nAdditionally, we have an internal learning platform with many great workshops - especially in the soft skills area. They are great! You can upskill yourself well.\nAlso, in some areas and teams, there is a time dedicated to your self-development. You can spend it on contributions to open-source, reading a book,\nlearning from the course, or, for example, writing a PoC of new technology with your team. In Allegro Pay - it is 10%. How you spend it - is up to you,\nor the team, it just should stick to our profession.\nThere are many internal and external communities (guilds), each with its own meeting calendar and interesting presentations and workshops taking a different kind of forms.\nThere are also many internal events, hackathons, and initiatives. Opportunities to learn are almost infinite.\nLanding here was my biggest personal and professional progression so far.\nThe bitter (or not?)\nSounds sweet, right? Where is the bitter here? Well, I am not sure.\nThis is a rapid-growth product and company. We are focused on delivering value to clients and maximizing profit from our products.\nEverything we do must contribute to overall success, and there is little space to “breathe”. You must often balance delivering functionalities,\npaying back technical debt, and growing scale. Taking shortcuts. Making trade-offs. Asking difficult questions. Our roadmaps often change\nbecause of the economics, law, or maybe data we gathered and told us that our actions do not convert in the way we assumed.\nIn Allegro Pay itself - the financial domain also does not help — a huge amount of our work is dedicated to legal matters. New laws pop up, and we must follow them.\nI can imagine that it can’t be for everyone.\nBut for me, this introduces an entirely new layer of engineering, where you need to be smart, cautious, value impact, and make the right choices.\nWe strive to be the best in the market, which is why we succeed.\nAnother thing can be the corporation itself. But this is very likely something that you will not notice until you become a manager.\nAllegro is a big company that has shifted to a more centralized and structured approach over the years. Everything needs to be aligned with the process.\nTo picture this, here are a few examples:\nInstead of ordering any accessories required within the budget - the budget was removed, and you can order only specific, pre-selected accessories\nWant to hire someone? There is budgeting once per year, and you need to come prepared to justify another full-time equivalent.\nDo you want to give someone a raise? Well, you don’t have to worry about this. Process, one per year, will do that for you.\nYou need to provide a performance review of your directs. Based on that you will get the budget, recommendations, and ability to slightly change proportions.\nWant to pursue external training? You have a budget. It would be best if you fit it in. You need to raise a request and process it through several layers of acceptance.\nAs you can imagine, all of that can take time and be annoying. It is very frequent that your “request” is stuck somewhere, and you need to “push” it.\nBut on the other end of the process, there are helpful people whom you can always talk to.\nSometimes, this leads to funny absurdities - you find an old monitor in the office that is not assigned to anyone (or a person who is not already in the company),\nand you would like to order a docking station for it. “Procedures” will not allow you to do that. The dock must have existed before; if lost,\nonly the owner can “order” a new one with a good justification. But you are not the owner. It is no man’s land - thus - no dock for it ;)\nBut I think most big corporations work like that. The past few years were also difficult for the industry. I understand why this is happening.\nIf you are an individual contributor, most of these things will not affect you. And those which do - you need to get used to it, and if you focus on the rest - hell - this is a great place to work.\nIs there more?\nA score of 11 tells that you will find much good stuff in software engineering here.\nBut this is not all. There are plenty of other great features of engineering culture at Allegro & Allegro Pay. You have great products, a big scale and\na data-driven approach which leads to many challenges; amazing, intelligent people; modern technology and approach to software engineering;\nrich off-topic communities (board games, sports, FIFA league, etc.), and many more.\nOverall, #DobrzeTuByć (#GoodToBeHere)","guid":"https://blog.allegro.tech/2024/06/pragmatic-engineer-score.html","categories":["tech","engineering culture","pragmatic engineer"],"isoDate":"2024-06-10T22:00:00.000Z"},{"title":"REST service client: design, testing, monitoring","link":"https://blog.allegro.tech/2024/06/rest-service-client-design-testing-monitoring.html","pubDate":"Tue, 04 Jun 2024 00:00:00 +0200","authors":{"author":[{"name":["Piotr Klimiec"],"photo":["https://blog.allegro.tech/img/authors/piotr.klimiec.jpg"],"url":["https://blog.allegro.tech/authors/piotr.klimiec"]}]},"content":"<p>The purpose of this article is to present how to design, test, and monitor a REST service client.\nThe article includes a <a href=\"https://github.com/Klimiec/webclients\">repository</a> with clients written in Kotlin using various technologies such as <a href=\"https://docs.spring.io/spring-framework/reference/web/webflux-webclient.html\">WebClient</a>,\n<a href=\"https://docs.spring.io/spring-framework/reference/integration/rest-clients.html#rest-restclient\">RestClient</a>,\n<a href=\"https://ktor.io/docs/getting-started-ktor-client.html\">Ktor Client</a>,\n<a href=\"https://square.github.io/retrofit/\">Retrofit</a>.\nIt demonstrates how to send and retrieve data from an external service, add a cache layer, and parse the received response into domain objects.</p>\n\n<h2 id=\"motivation\">Motivation</h2>\n<p>Why do we need objects in the project that encapsulate the HTTP clients we use?\nTo begin with, we want to separate the domain from technical details.\nThe way we retrieve/send data and handle errors, which can be quite complex in the case of HTTP clients, should not clutter business logic.\nNext, testability. Even if we do not use <a href=\"/2020/05/hexagonal-architecture-by-example.html\">hexagonal architecture</a> in our applications,\nit’s beneficial to separate the infrastructure from the service layer, as it improves testability.\nVerifying an HTTP service client is not a simple task and requires consideration of many cases — mainly at the integration level.\nHaving a separate “building block“ that encapsulates communication with the outside world makes testing much easier.\nFinally, reusability. A service client that has been written once can be successfully used in other projects.</p>\n\n<h2 id=\"client-design\">Client Design</h2>\n<p>As a case study, I will use an example implementation that utilizes WebClient for retrieving data from the Order Management Service,\nan example service that might appear in an e-commerce site such as <a href=\"https://allegro.tech/\">Allegro</a>.\nThe heart of our client is the <code class=\"language-plaintext highlighter-rouge\">executeHttpRequest</code> method, which is responsible for executing the provided HTTP request, logging, and error handling.\nIt is not part of the WebClient library.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kd\">class</span> <span class=\"nc\">OrderManagementServiceClient</span><span class=\"p\">(</span>\n    <span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">orderManagementServiceApi</span><span class=\"p\">:</span> <span class=\"nc\">OrderManagementServiceApi</span><span class=\"p\">,</span>\n    <span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">clientName</span><span class=\"p\">:</span> <span class=\"nc\">String</span>\n<span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"k\">suspend</span> <span class=\"k\">fun</span> <span class=\"nf\">getOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">:</span> <span class=\"nc\">ClientId</span><span class=\"p\">):</span> <span class=\"nc\">OrdersDto</span> <span class=\"p\">{</span>\n        <span class=\"k\">return</span> <span class=\"nf\">executeHttpRequest</span><span class=\"p\">(</span>\n            <span class=\"n\">initialLog</span> <span class=\"p\">=</span> <span class=\"s\">\"[$clientName] Get orders for a clientId= $clientId\"</span><span class=\"p\">,</span>\n            <span class=\"n\">request</span> <span class=\"p\">=</span> <span class=\"p\">{</span> <span class=\"n\">orderManagementServiceApi</span><span class=\"p\">.</span><span class=\"nf\">getOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">)</span> <span class=\"p\">},</span>\n            <span class=\"n\">successLog</span> <span class=\"p\">=</span> <span class=\"s\">\"[$clientName] Returned orders for a clientId= $clientId\"</span><span class=\"p\">,</span>\n            <span class=\"n\">failureMessage</span> <span class=\"p\">=</span> <span class=\"s\">\"[$clientName] Failed to get orders for clientId= $clientId\"</span>\n        <span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n</code></pre></div></div>\n\n<p>Full working example can be found <a href=\"https://github.com/Klimiec/webclients/tree/main/httpclient-webclientinterface\">here</a>.</p>\n\n<h3 id=\"client-name\">Client name</h3>\n<p>I like to name clients using the convention: name of the service we integrate with, plus the suffix <strong>Client</strong>.\nIn the case of integration with the Order Management Service, such a class will be named <code class=\"language-plaintext highlighter-rouge\">OrderManagementServiceClient</code>.</p>\n\n<p>If the technology we use employs an interface to describe the called REST API (RestClient, WebClient, Retrofit),\nwe can name such an interface <code class=\"language-plaintext highlighter-rouge\">OrderManagementServiceApi</code> — following the general pattern of the service name with the suffix <strong>Api</strong>.</p>\n\n<p>These names may seem intuitive and obvious, but without an established naming convention, we might end up with a project where\ndifferent integrations have the following suffixes: <strong>HttpClient</strong>, <strong>Facade</strong>, <strong>WebClient</strong>, <strong>Adapter</strong>, and <strong>Service</strong>.\nIt’s important to have a consistent convention and adhere to it throughout the project.</p>\n\n<h3 id=\"api\">API</h3>\n<p>Methods of our clients should have names that reflect the communicative intention behind them.\nTo capture this intention, it is necessary to use a verb in the method’s name.\nTypically, the correct name will have a structure of verb + resource name, for example, <code class=\"language-plaintext highlighter-rouge\">getOrders</code>  —  for methods that retrieve resources.\nIf we want to narrow down the number of returned resources using filters or return a particular resource, I recommend adding the suffix “For” before the list of parameters.\nTechnically, these parameters will be part of the query or path parameters.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>fun getOrdersFor(clientId: ClientId): OrdersDto\n</code></pre></div></div>\n\n<p>For methods responsible for creating resources, simply using the verb in the method name is enough,\nas the resource being passed as a parameter effectively conveys the intention of the method.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>fun publish(event: InvoiceCreatedEventDto)\n</code></pre></div></div>\n\n<h3 id=\"logging\">Logging</h3>\n<p>When communicating with external service we’d like to log the beginning of the interaction, indicating our intention to fetch or send a resource,\nas well as its outcome. The outcome can be either a success, meaning receiving a response with a 2xx status code, or a failure.</p>\n\n<p>Failure can be signaled by status codes (3xx, 4xx, 5xx), resulting from the inability to deserialize the received response into an object,\nexceeding the response time, etc. Generally, <a href=\"/2015/07/testing-server-faults-with-Wiremock.html\">many things can go wrong</a>.\nDepending on the cause of failure, we may want to log the interaction result at different levels (warn/error).\nThere are critical errors that are worth distinguishing (error), and those that will occasionally occur (warn) and don’t require urgent intervention.</p>\n\n<p>To filter logs related to a specific service while browsing through them, I like to include the client’s name within curly braces at the beginning of the logs.\nFor logging technical aspects of the communication, such as the URL called, HTTP method used, and response code,\nwe use filters (logRequestInfo, logResponseInfo) that are plugged in at the client configuration level in the <code class=\"language-plaintext highlighter-rouge\">createExternalServiceApi</code> method.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">inline</span> <span class=\"k\">fun</span> <span class=\"p\">&lt;</span><span class=\"k\">reified</span> <span class=\"nc\">T</span><span class=\"p\">&gt;</span> <span class=\"nf\">createExternalServiceApi</span><span class=\"p\">(</span>\n    <span class=\"n\">webClientBuilder</span><span class=\"p\">:</span> <span class=\"nc\">WebClient</span><span class=\"p\">.</span><span class=\"nc\">Builder</span><span class=\"p\">,</span>\n    <span class=\"n\">properties</span><span class=\"p\">:</span> <span class=\"nc\">ConnectionProperties</span>\n<span class=\"p\">):</span> <span class=\"nc\">T</span> <span class=\"p\">=</span>\n    <span class=\"n\">webClientBuilder</span>\n        <span class=\"p\">.</span><span class=\"nf\">clientConnector</span><span class=\"p\">(</span><span class=\"nf\">httpClient</span><span class=\"p\">(</span><span class=\"n\">properties</span><span class=\"p\">))</span>\n        <span class=\"p\">.</span><span class=\"nf\">baseUrl</span><span class=\"p\">(</span><span class=\"n\">properties</span><span class=\"p\">.</span><span class=\"n\">baseUrl</span><span class=\"p\">)</span>\n        <span class=\"p\">.</span><span class=\"nf\">defaultRequest</span> <span class=\"p\">{</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"nf\">attribute</span><span class=\"p\">(</span><span class=\"nc\">SERVICE_NAME</span><span class=\"p\">,</span> <span class=\"n\">properties</span><span class=\"p\">.</span><span class=\"n\">clientName</span><span class=\"p\">)</span> <span class=\"p\">}</span>\n        <span class=\"p\">.</span><span class=\"nf\">filter</span><span class=\"p\">(</span><span class=\"nf\">logRequestInfo</span><span class=\"p\">(</span><span class=\"n\">properties</span><span class=\"p\">.</span><span class=\"n\">clientName</span><span class=\"p\">))</span>\n        <span class=\"p\">.</span><span class=\"nf\">filter</span><span class=\"p\">(</span><span class=\"nf\">logResponseInfo</span><span class=\"p\">(</span><span class=\"n\">properties</span><span class=\"p\">.</span><span class=\"n\">clientName</span><span class=\"p\">))</span>\n        <span class=\"p\">.</span><span class=\"nf\">build</span><span class=\"p\">()</span>\n        <span class=\"p\">.</span><span class=\"nf\">let</span> <span class=\"p\">{</span> <span class=\"nc\">WebClientAdapter</span><span class=\"p\">.</span><span class=\"nf\">create</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">)</span> <span class=\"p\">}</span>\n        <span class=\"p\">.</span><span class=\"nf\">let</span> <span class=\"p\">{</span> <span class=\"nc\">HttpServiceProxyFactory</span><span class=\"p\">.</span><span class=\"nf\">builderFor</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">).</span><span class=\"nf\">build</span><span class=\"p\">()</span> <span class=\"p\">}</span>\n        <span class=\"p\">.</span><span class=\"nf\">createClient</span><span class=\"p\">(</span><span class=\"nc\">T</span><span class=\"o\">::</span><span class=\"k\">class</span><span class=\"p\">.</span><span class=\"n\">java</span><span class=\"p\">)</span>\n\n<span class=\"k\">fun</span> <span class=\"nf\">logRequestInfo</span><span class=\"p\">(</span><span class=\"n\">clientName</span><span class=\"p\">:</span> <span class=\"nc\">String</span><span class=\"p\">)</span> <span class=\"p\">=</span> <span class=\"nc\">ExchangeFilterFunction</span><span class=\"p\">.</span><span class=\"nf\">ofRequestProcessor</span> <span class=\"p\">{</span> <span class=\"n\">request</span> <span class=\"p\">-&gt;</span>\n    <span class=\"n\">logger</span><span class=\"p\">.</span><span class=\"nf\">info</span> <span class=\"p\">{</span>\n        <span class=\"s\">\"[$clientName] method=[${request.method().name()}] url=${request.url()}}\"</span>\n    <span class=\"p\">}</span>\n    <span class=\"nc\">Mono</span><span class=\"p\">.</span><span class=\"nf\">just</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">fun</span> <span class=\"nf\">logResponseInfo</span><span class=\"p\">(</span><span class=\"n\">clientName</span><span class=\"p\">:</span> <span class=\"nc\">String</span><span class=\"p\">)</span> <span class=\"p\">=</span> <span class=\"nc\">ExchangeFilterFunction</span><span class=\"p\">.</span><span class=\"nf\">ofResponseProcessor</span> <span class=\"p\">{</span> <span class=\"n\">response</span> <span class=\"p\">-&gt;</span>\n    <span class=\"n\">logger</span><span class=\"p\">.</span><span class=\"nf\">info</span> <span class=\"p\">{</span> <span class=\"s\">\"[$clientName] service responded with a status code= ${response.statusCode()}\"</span> <span class=\"p\">}</span>\n    <span class=\"nc\">Mono</span><span class=\"p\">.</span><span class=\"nf\">just</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>Here’s an example of logged interaction for successfully fetching a resource.</p>\n\n<p><img alt=\"Properly logged interaction\" src=\"/img/articles/2024-06-04-rest-service-client-design-testing-monitoring/logs.png\" /></p>\n\n<p>To prevent redundancy in logging code across multiple clients, it is centralized inside <code class=\"language-plaintext highlighter-rouge\">executeHttpRequest</code> method.\nThe only thing the developer needs to do is to provide a business-oriented description for the beginning of the interaction and its outcome (parameters: <code class=\"language-plaintext highlighter-rouge\">initialLog</code>, <code class=\"language-plaintext highlighter-rouge\">successLog</code>, <code class=\"language-plaintext highlighter-rouge\">failureMessage</code>).</p>\n\n<p>Why do I emphasize logging so much?\nIsn’t it enough to log only errors?\nAfter all, we have metrics that inform us about the performance of our clients.\nMetrics won’t provide us with the details of the communication, but logs will.\nThese details can turn out to be crucial in the analysis of incidents, which may reveal, for example, incorrect data produced by our service.</p>\n\n<p>Logs are like backups. We find out if we have them and how valuable they are only when they are needed,\neither because the business team requests an analysis of a particular case or when resolving an incident.</p>\n\n<h3 id=\"error-handling\">Error handling</h3>\n<p>When writing client code, we aim to highlight maximally how we send/retrieve data and hide the “noise“ that comes from error handling.\nIn the case of HTTP clients, error handling is quite extensive but generic enough that the resulting code can be written once and reused across all clients.\nIn our example, error handling mechanism is hidden inside <code class=\"language-plaintext highlighter-rouge\">executeHttpRequest</code> method.\nIt consists of two things: logging and throwing custom exceptions that encapsulate technical exceptions thrown by the underlying HTTP client.</p>\n\n<p>What are the benefits of using custom exceptions? The very name of such a custom exception tells us exactly what went wrong.\nFor comparison, <code class=\"language-plaintext highlighter-rouge\">ExternalServiceIncorrectResponseBodyException</code> seems to be more descriptive than <code class=\"language-plaintext highlighter-rouge\">DecodingException</code>.\nThey also help group various technical exceptions that lead to the same cause, for example, an incorrect response object structure.\nAdditionally, based on these exceptions, visualizations can be created to show the state of our integration.\nFor example, we can create a table that will show how many exceptions of any given type were thrown by our clients within a specified period.\nHaving custom exceptions, we are 100% certain that these exceptions were thrown only by our clients.</p>\n\n<h3 id=\"testing\">Testing</h3>\n<h4 id=\"stubs\">Stubs</h4>\n<p>To verify different scenarios of our HTTP client, it is necessary to appropriately stub the called endpoints in tests.\nFor this purpose, we will use the <a href=\"https://wiremock.org/\">WireMock</a> library.</p>\n\n<p>It is quite important that the technical details of created stubs do not leak into the tests.\nThe test should describe the behavior being tested and encapsulate technical details.\nFor example, changing the accept/content-type header or making minor modifications to the called URL should not affect the test itself.\nTo achieve this, for each service for which we write a service client, we create an object of type <code class=\"language-plaintext highlighter-rouge\">StubBuilder</code>.\nThe <code class=\"language-plaintext highlighter-rouge\">StubBuilder</code> allows hiding the details of stubbing and verification behind a readable API.\nIt takes on the impact of changes to the called API, protecting our test from modification.\nIt fulfills a similar role to the <a href=\"https://martinfowler.com/bliki/PageObject.html\">Page Object Pattern</a> in end-to-end tests for web apps.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">orderManagementServiceStub</span><span class=\"p\">.</span><span class=\"nf\">willReturnOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">,</span> <span class=\"n\">response</span> <span class=\"p\">=</span> <span class=\"nf\">ordersPlacedBySomeCustomer</span><span class=\"p\">())</span>\n</code></pre></div></div>\n\n<p>StubBuilders for services that return data come in two flavors - <a href=\"https://github.com/Klimiec/webclients/tree/591dddd1e61ea5d922f0402534d9a96a513f59b4/httpclient-webclientinterface/src/integration/kotlin/com/dev/sandbox/httpclientwebclientinterface/order/infrastructure/ordermanagementservice/stub/internal\">internal</a> and <a href=\"https://github.com/Klimiec/webclients/tree/591dddd1e61ea5d922f0402534d9a96a513f59b4/httpclient-webclientinterface/src/integration/kotlin/com/dev/sandbox/httpclientwebclientinterface/order/infrastructure/ordermanagementservice/stub/external\">external</a>.</p>\n\n<p><img alt=\"StubBuilder packages\" src=\"/img/articles/2024-06-04-rest-service-client-design-testing-monitoring/packages.png\" /></p>\n\n<p>When testing a service client, we want to have great flexibility in simulating responses.\nTherefore, <code class=\"language-plaintext highlighter-rouge\">StubBuilders</code> from the internal package will model response objects as a string. This allows us to simulate any scenario.\nIn end-to-end tests, where a given service is part of the bigger process, such flexibility is not necessary; in fact, it is not even recommended.\nTherefore, StubBuilders from the external package model responses using real objects.\nAll StubBuilders from the external packages are declared in the class <code class=\"language-plaintext highlighter-rouge\">ExternalServiceStubs</code>, to which a reference is located in the base class for\nall integration tests, <code class=\"language-plaintext highlighter-rouge\">BaseIntegrationTest</code>. This allows us to have very easy access to all external service stubs in our integration tests.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">stub</span><span class=\"p\">.</span><span class=\"nf\">orderManagementService</span><span class=\"p\">().</span><span class=\"nf\">willReturnOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">,</span> <span class=\"n\">response</span> <span class=\"p\">=</span> <span class=\"nf\">ordersPlacedBySomeCustomer</span><span class=\"p\">())</span>\n</code></pre></div></div>\n\n<p>Reading the code above, we immediately know <strong>which</strong> service is being interacted with (Order Management Service) and what will be returned from it (Orders).\nThe technical details of the stubbed endpoint have been hidden inside the StubBuilder object.\nTests should emphasize “what” and encapsulate “how.” This way, they can serve as documentation.</p>\n\n<h4 id=\"test-data\">Test Data</h4>\n\n<p>The data returned by our stubs can be prepared in three ways:</p>\n<ol type=\"a\">\n  <li>Read the entire response from a file/string.</li>\n  <li>Prepare the response using real objects used in the service for deserializing responses from called services.</li>\n  <li>Create a set of separate objects modeling the returned response from the service for testing purposes and use them to prepare the returned data.</li>\n</ol>\n\n<p>Which option to choose?\nTo answer this question, we should analyze the advantages and disadvantages of each approach.</p>\n\n<p>Option A — read response from a file/string. Response creation is very fast and simple.\nIt allows <strong>verifying the contract</strong> between the client and the supplier (at least at the time of writing the test).\nImagine that during refactoring, one of the fields in the response object accidentally changes.\nIn such a case, client tests using this approach will detect the defect before the code reaches production.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nd\">@Test</span>\n<span class=\"k\">fun</span> <span class=\"nf\">`should</span> <span class=\"k\">return</span> <span class=\"n\">orders</span> <span class=\"k\">for</span> <span class=\"n\">a</span> <span class=\"n\">given</span> <span class=\"nf\">clientId`</span><span class=\"p\">():</span> <span class=\"nc\">Unit</span> <span class=\"p\">=</span> <span class=\"nf\">runBlocking</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// given</span>\n        <span class=\"kd\">val</span> <span class=\"py\">clientId</span> <span class=\"p\">=</span> <span class=\"nf\">anyClientId</span><span class=\"p\">()</span>\n        <span class=\"n\">orderManagementServiceStub</span><span class=\"p\">.</span><span class=\"nf\">willReturnOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">,</span> <span class=\"n\">response</span> <span class=\"p\">=</span> <span class=\"nf\">ordersPlacedBySomeCustomer</span><span class=\"p\">())</span>\n\n        <span class=\"c1\">// when</span>\n        <span class=\"kd\">val</span> <span class=\"py\">response</span><span class=\"p\">:</span> <span class=\"nc\">OrdersDto</span> <span class=\"p\">=</span> <span class=\"n\">orderManagementServiceClient</span><span class=\"p\">.</span><span class=\"nf\">getOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">)</span>\n\n        <span class=\"c1\">// then</span>\n        <span class=\"n\">response</span> <span class=\"n\">shouldBe</span> <span class=\"nc\">OrdersDto</span><span class=\"p\">(</span><span class=\"nf\">listOf</span><span class=\"p\">(</span><span class=\"nc\">OrderDto</span><span class=\"p\">(</span><span class=\"s\">\"7952a9ab-503c-4483-beca-32d081cc2446\"</span><span class=\"p\">)))</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>On the other hand, keeping data in files/strings is difficult to maintain and reuse.\nProgrammers often copy entire files for new tests, introducing only minimal changes.\nThere is a problem with naming these files and refactoring them when the called service introduces an incompatible change.</p>\n\n<p>Option B — Use real response objects.\nIt allows writing one-line, readable assertions and maximally reusing already created data, especially using <a href=\"https://www.natpryce.com/articles/000714.html\">test data builders</a>.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    <span class=\"nd\">@Test</span>\n    <span class=\"k\">fun</span> <span class=\"nf\">`should</span> <span class=\"k\">return</span> <span class=\"n\">orders</span> <span class=\"k\">for</span> <span class=\"n\">a</span> <span class=\"n\">given</span> <span class=\"nf\">clientId`</span><span class=\"p\">():</span> <span class=\"nc\">Unit</span> <span class=\"p\">=</span> <span class=\"nf\">runBlocking</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// given</span>\n        <span class=\"kd\">val</span> <span class=\"py\">clientId</span> <span class=\"p\">=</span> <span class=\"nf\">anyClientId</span><span class=\"p\">()</span>\n        <span class=\"kd\">val</span> <span class=\"py\">clientOrders</span> <span class=\"p\">=</span> <span class=\"nc\">OrderManagementServiceFixture</span><span class=\"p\">.</span><span class=\"nf\">ordersPlacedBySomeCustomer</span><span class=\"p\">()</span>\n        <span class=\"n\">orderManagementServiceStub</span><span class=\"p\">.</span><span class=\"nf\">willReturnOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">,</span> <span class=\"n\">response</span> <span class=\"p\">=</span> <span class=\"n\">clientOrders</span><span class=\"p\">)</span>\n\n        <span class=\"c1\">// when</span>\n        <span class=\"kd\">val</span> <span class=\"py\">response</span><span class=\"p\">:</span> <span class=\"nc\">OrdersDto</span> <span class=\"p\">=</span> <span class=\"n\">orderManagementServiceClient</span><span class=\"p\">.</span><span class=\"nf\">getOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">)</span>\n\n        <span class=\"c1\">// then</span>\n        <span class=\"n\">response</span> <span class=\"n\">shouldBe</span> <span class=\"n\">clientOrders</span>\n    <span class=\"p\">}</span>\n</code></pre></div></div>\n<p>However, accidental change of field name which results in the  <strong>contract violation</strong> between the client and supplier won’t be caught.\nAs a result, we might have perfectly tested communication in integration tests that will not work in production.</p>\n\n<p>Option C — create a set of separate response objects. It has all the advantages of options A and B, including maintainability, reusability, and\nverification of the contract between the client and the supplier. Unfortunately, maintaining a separate model for testing purposes comes with some overhead\nand requires discipline on the developers’ side, which can be challenging to maintain.</p>\n\n<p>Which option to choose? Personally, I prefer a hybrid of options A and B.\nFor the purpose of testing the “happy path“ in client tests, I return a response that is entirely stored as a string (alternatively, it can be read from a file).\nSuch a test allows not only to verify the contract but also the correctness of deserializing the received response into a response object.\nIn other tests (cache, adapter, end-to-end), I create responses returned by the stubbed endpoint using production response objects.</p>\n\n<p>It’s worthwhile to keep sample test data in dedicated classes, such as a Fixture class, for each integration (for example <code class=\"language-plaintext highlighter-rouge\">OrderManagementServiceFixture</code>).\nThis allows the reuse of test data and enhances the readability of the tests themselves.</p>\n\n<h3 id=\"test-scenarios\">Test Scenarios</h3>\n<h4 id=\"happy-path\">Happy Path</h4>\n<p><strong>Fetching a resource</strong> — verification whether the client can retrieve data from the previously stubbed endpoint and deserialize it into a response object.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nd\">@Test</span>\n<span class=\"k\">fun</span> <span class=\"nf\">`should</span> <span class=\"k\">return</span> <span class=\"n\">orders</span> <span class=\"k\">for</span> <span class=\"n\">a</span> <span class=\"n\">given</span> <span class=\"nf\">clientId`</span><span class=\"p\">():</span> <span class=\"nc\">Unit</span> <span class=\"p\">=</span> <span class=\"nf\">runBlocking</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// given</span>\n        <span class=\"kd\">val</span> <span class=\"py\">clientId</span> <span class=\"p\">=</span> <span class=\"nf\">anyClientId</span><span class=\"p\">()</span>\n        <span class=\"n\">orderManagementServiceStub</span><span class=\"p\">.</span><span class=\"nf\">willReturnOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">,</span> <span class=\"n\">response</span> <span class=\"p\">=</span> <span class=\"nf\">ordersPlacedBySomeCustomer</span><span class=\"p\">())</span>\n\n        <span class=\"c1\">// when</span>\n        <span class=\"kd\">val</span> <span class=\"py\">response</span><span class=\"p\">:</span> <span class=\"nc\">OrdersDto</span> <span class=\"p\">=</span> <span class=\"n\">orderManagementServiceClient</span><span class=\"p\">.</span><span class=\"nf\">getOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">)</span>\n\n        <span class=\"c1\">// then</span>\n        <span class=\"n\">response</span> <span class=\"n\">shouldBe</span> <span class=\"nc\">OrdersDto</span><span class=\"p\">(</span><span class=\"nf\">listOf</span><span class=\"p\">(</span><span class=\"nc\">OrderDto</span><span class=\"p\">(</span><span class=\"s\">\"7952a9ab-503c-4483-beca-32d081cc2446\"</span><span class=\"p\">)))</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n<p>An essential part of the test for the “happy path“ is verification of the contract between the client and the supplier.\nThe <code class=\"language-plaintext highlighter-rouge\">ordersPlacedBySomeCustomer</code> method returns a sample response guaranteed by the supplier (Order Management Service).\nOn the client side, in the assertion section, we check if this message has been correctly deserialized into a response object.\nInstead of comparing individual fields with the expected value, I highly recommend comparing entire objects (returned and expected).\nIt gives us confidence that all fields have been compared. In the case of regression, modern IDEs such as IntelliJ indicate exactly where the problem is.</p>\n\n<p><img alt=\"Test regression\" src=\"/img/articles/2024-06-04-rest-service-client-design-testing-monitoring/regression.png\" /></p>\n\n<p><strong>Sending a resource</strong> — verification whether the client sends data to the specified URL in a format acceptable by the previously stubbed endpoint.\nIn the following example, I test publishing an event to <a href=\"https://hermes.allegro.tech/\">Hermes</a>, a message broker built on top of Kafka widely used at Allegro.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nd\">@Test</span>\n<span class=\"k\">fun</span> <span class=\"nf\">`should</span> <span class=\"n\">successfully</span> <span class=\"n\">publish</span> <span class=\"nc\">InvoiceCreatedEvent`</span><span class=\"p\">():</span> <span class=\"nc\">Unit</span> <span class=\"p\">=</span> <span class=\"nf\">runBlocking</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// given</span>\n        <span class=\"kd\">val</span> <span class=\"py\">invoiceCreatedEvent</span> <span class=\"p\">=</span> <span class=\"nc\">HermesFixture</span><span class=\"p\">.</span><span class=\"nf\">invoiceCreatedEvent</span><span class=\"p\">()</span>\n        <span class=\"n\">stub</span><span class=\"p\">.</span><span class=\"nf\">hermes</span><span class=\"p\">().</span><span class=\"nf\">willAcceptInvoiceCreatedEvent</span><span class=\"p\">()</span>\n\n        <span class=\"c1\">// when</span>\n        <span class=\"n\">hermesClient</span><span class=\"p\">.</span><span class=\"nf\">publish</span><span class=\"p\">(</span><span class=\"n\">invoiceCreatedEvent</span><span class=\"p\">)</span>\n\n        <span class=\"c1\">// then</span>\n        <span class=\"n\">stub</span><span class=\"p\">.</span><span class=\"nf\">hermes</span><span class=\"p\">().</span><span class=\"nf\">verifyInvoiceCreatedEventPublished</span><span class=\"p\">(</span><span class=\"n\">event</span> <span class=\"p\">=</span> <span class=\"n\">invoiceCreatedEvent</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>Stubbed endpoints for methods accepting request bodies (e.g., POST, PUT) should not verify the values of the received request body but only its <ins>structure</ins>.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">fun</span> <span class=\"nf\">willAcceptInvoiceCreatedEvent</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">stubFor</span><span class=\"p\">(</span>\n        <span class=\"nf\">invoiceCreatedEventTopic</span><span class=\"p\">()</span>\n            <span class=\"p\">.</span><span class=\"nf\">withRequestBody</span><span class=\"p\">(</span><span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">matchingJsonPath</span><span class=\"p\">(</span><span class=\"s\">\"$.invoiceId\"</span><span class=\"p\">))</span>\n            <span class=\"p\">.</span><span class=\"nf\">withRequestBody</span><span class=\"p\">(</span><span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">matchingJsonPath</span><span class=\"p\">(</span><span class=\"s\">\"$.orderId\"</span><span class=\"p\">))</span>\n            <span class=\"p\">.</span><span class=\"nf\">withRequestBody</span><span class=\"p\">(</span><span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">matchingJsonPath</span><span class=\"p\">(</span><span class=\"s\">\"$.timestamp\"</span><span class=\"p\">))</span>\n            <span class=\"p\">.</span><span class=\"nf\">willReturn</span><span class=\"p\">(</span>\n                <span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">aResponse</span><span class=\"p\">()</span>\n                    <span class=\"p\">.</span><span class=\"nf\">withFixedDelay</span><span class=\"p\">(</span><span class=\"n\">responseTime</span><span class=\"p\">)</span>\n                    <span class=\"p\">.</span><span class=\"nf\">withStatus</span><span class=\"p\">(</span><span class=\"nc\">HttpStatus</span><span class=\"p\">.</span><span class=\"nc\">OK</span><span class=\"p\">.</span><span class=\"nf\">value</span><span class=\"p\">())</span>\n            <span class=\"p\">)</span>\n    <span class=\"p\">)</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>We verify the content of the request body in the assertion section.\nHere, we also want to hide the technical aspects of assertions behind a method.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">stubs</span><span class=\"p\">.</span><span class=\"nf\">hermes</span><span class=\"p\">().</span><span class=\"nf\">verifyInvoiceCreatedEventPublished</span><span class=\"p\">(</span><span class=\"n\">event</span> <span class=\"p\">=</span> <span class=\"n\">invoiceCreatedEvent</span><span class=\"p\">)</span>\n\n\n<span class=\"k\">fun</span> <span class=\"nf\">verifyInvoiceCreatedEventPublished</span><span class=\"p\">(</span><span class=\"n\">event</span><span class=\"p\">:</span> <span class=\"nc\">InvoiceCreatedEventDto</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">verify</span><span class=\"p\">(</span>\n        <span class=\"mi\">1</span><span class=\"p\">,</span>\n        <span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">postRequestedFor</span><span class=\"p\">(</span><span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">urlPathEqualTo</span><span class=\"p\">(</span><span class=\"nc\">INVOICE_CREATED_URL</span><span class=\"p\">))</span>\n            <span class=\"p\">.</span><span class=\"nf\">withRequestBody</span><span class=\"p\">(</span><span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">matchingJsonPath</span><span class=\"p\">(</span><span class=\"s\">\"$.invoiceId\"</span><span class=\"p\">,</span> <span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">equalTo</span><span class=\"p\">(</span><span class=\"n\">event</span><span class=\"p\">.</span><span class=\"n\">invoiceId</span><span class=\"p\">)))</span>\n            <span class=\"p\">.</span><span class=\"nf\">withRequestBody</span><span class=\"p\">(</span><span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">matchingJsonPath</span><span class=\"p\">(</span><span class=\"s\">\"$.orderId\"</span><span class=\"p\">,</span> <span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">equalTo</span><span class=\"p\">(</span><span class=\"n\">event</span><span class=\"p\">.</span><span class=\"n\">orderId</span><span class=\"p\">)))</span>\n            <span class=\"p\">.</span><span class=\"nf\">withRequestBody</span><span class=\"p\">(</span><span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">matchingJsonPath</span><span class=\"p\">(</span><span class=\"s\">\"$.timestamp\"</span><span class=\"p\">,</span> <span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">equalTo</span><span class=\"p\">(</span><span class=\"n\">event</span><span class=\"p\">.</span><span class=\"n\">timestamp</span><span class=\"p\">)))</span>\n    <span class=\"p\">)</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>Combining stubbing and request verification in one method is not recommended.\nCreating stubs in this way makes their usage less convenient since not every test requires detailed verification of what is being sent in the request body.\nThe vast majority of tests will stub the endpoint based on the principle:\naccept a given request as long as its structure is preserved and will verify hypotheses other than the content of the request body (mainly end-to-end tests).</p>\n\n<h4 id=\"client-side-errors\">Client-side errors</h4>\n\n<p>For 4xx type errors, we want to verify the following cases:</p>\n<ul>\n  <li>The absence of the requested resource signaled by the response code 404 and a custom exception <code class=\"language-plaintext highlighter-rouge\">ExternalServiceResourceNotFoundException</code></li>\n  <li>Validation error signaled by the response code 422 and a custom exception <code class=\"language-plaintext highlighter-rouge\">ExternalServiceRequestValidationException</code></li>\n  <li>Any other 4xx type errors  should be cast to an <code class=\"language-plaintext highlighter-rouge\">ExternalServiceClientException</code></li>\n</ul>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nd\">@ParameterizedTest</span><span class=\"p\">(</span><span class=\"n\">name</span> <span class=\"p\">=</span> <span class=\"s\">\"{index}) http status code: {0}\"</span><span class=\"p\">)</span>\n<span class=\"nd\">@MethodSource</span><span class=\"p\">(</span><span class=\"s\">\"clientErrors\"</span><span class=\"p\">)</span>\n<span class=\"k\">fun</span> <span class=\"nf\">`when</span> <span class=\"n\">receive</span> <span class=\"n\">response</span> <span class=\"n\">with</span> <span class=\"mi\">4</span><span class=\"n\">xx</span> <span class=\"n\">status</span> <span class=\"n\">code</span> <span class=\"n\">then</span> <span class=\"k\">throw</span> <span class=\"nf\">exception`</span><span class=\"p\">(</span>\n    <span class=\"n\">exceptionClass</span><span class=\"p\">:</span> <span class=\"nc\">Class</span><span class=\"p\">&lt;</span><span class=\"nc\">Exception</span><span class=\"p\">&gt;,</span>\n    <span class=\"n\">statusCode</span><span class=\"p\">:</span> <span class=\"nc\">Int</span><span class=\"p\">,</span>\n    <span class=\"n\">responseBody</span><span class=\"p\">:</span> <span class=\"nc\">String</span><span class=\"p\">?</span>\n<span class=\"p\">):</span> <span class=\"nc\">Unit</span> <span class=\"p\">=</span> <span class=\"nf\">runBlocking</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// given</span>\n        <span class=\"kd\">val</span> <span class=\"py\">clientId</span> <span class=\"p\">=</span> <span class=\"nf\">anyClientId</span><span class=\"p\">()</span>\n        <span class=\"n\">orderManagementServiceStub</span><span class=\"p\">.</span><span class=\"nf\">willReturnOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">,</span> <span class=\"n\">status</span> <span class=\"p\">=</span> <span class=\"n\">statusCode</span><span class=\"p\">,</span> <span class=\"n\">response</span> <span class=\"p\">=</span> <span class=\"n\">responseBody</span><span class=\"p\">)</span>\n\n        <span class=\"c1\">// when</span>\n        <span class=\"kd\">val</span> <span class=\"py\">exception</span> <span class=\"p\">=</span> <span class=\"nf\">shouldThrowAny</span> <span class=\"p\">{</span>\n            <span class=\"n\">orderManagementServiceClient</span><span class=\"p\">.</span><span class=\"nf\">getOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">)</span>\n        <span class=\"p\">}</span>\n\n        <span class=\"c1\">// then</span>\n        <span class=\"n\">exception</span><span class=\"p\">.</span><span class=\"n\">javaClass</span> <span class=\"n\">shouldBeSameInstanceAs</span> <span class=\"n\">exceptionClass</span>\n        <span class=\"n\">exception</span><span class=\"p\">.</span><span class=\"n\">message</span> <span class=\"n\">shouldContain</span> <span class=\"n\">clientId</span><span class=\"p\">.</span><span class=\"n\">clientId</span><span class=\"p\">.</span><span class=\"nf\">toString</span><span class=\"p\">()</span>\n        <span class=\"n\">exception</span><span class=\"p\">.</span><span class=\"n\">message</span> <span class=\"n\">shouldContain</span> <span class=\"n\">properties</span><span class=\"p\">.</span><span class=\"n\">clientName</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>In distributed systems, a <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404\">404</a> response code is quite common and may result from temporary inconsistency across the entire system.\nIts occurrence is signaled by the <code class=\"language-plaintext highlighter-rouge\">ExternalServiceResourceNotFoundException</code> and a warning-level log.\nHere, we are more interested in the scale of occurrences, which is why we use metrics, than analyzing individual cases, hence we log such cases at the warning level.</p>\n\n<p>The situation looks a bit different in the case of responses with a code of <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/422\">422</a>.\nIf the request is rejected due to validation errors, either our service has a defect and produces incorrect data,\nor we receive incorrect data from external services (which is why it’s crucial to log what we receive from external services).\nAlternatively, the error may be on the recipient side in the logic validating the received request. It’s worth analyzing each such case, which is why\nerrors of this type are logged at the error level and signaled by the <code class=\"language-plaintext highlighter-rouge\">ExternalServiceRequestValidationException</code>.</p>\n\n<p>Other errors from the 4xx family occur less frequently.\nThey are all marked by the <code class=\"language-plaintext highlighter-rouge\">ExternalServiceClientException</code> exception and logged at the error level.</p>\n\n<h4 id=\"server-side-errors\">Server-side errors</h4>\n<p>Regardless of the reason for a 5xx error, all of them are logged at the warn level because we have no control over them.\nThey are signaled by the <code class=\"language-plaintext highlighter-rouge\">ExternalServiceServerException</code> exception. Similar to 404 errors, we are more interested in aggregate information\nabout the number of such errors rather than analyzing each case individually, hence the warn log level.</p>\n\n<p>In tests, we consider two cases because the response from the service may or may not have a body.\nIf the response has a body, we want to log it.</p>\n\n<h4 id=\"read-timeout\">Read Timeout</h4>\n<p>Our HTTP client should have a finite response timeout configured, so it’s worthwhile to write an integration test that verifies the client’s configuration.\nSimulating the delay of the stubbed endpoint can be achieved using the <code class=\"language-plaintext highlighter-rouge\">withFixedDelay</code> method from wiremock.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nd\">@Test</span>\n<span class=\"k\">fun</span> <span class=\"nf\">`when</span> <span class=\"n\">service</span> <span class=\"n\">returns</span> <span class=\"n\">above</span> <span class=\"n\">timeout</span> <span class=\"n\">threshold</span> <span class=\"n\">then</span> <span class=\"k\">throw</span> <span class=\"nf\">exception`</span><span class=\"p\">():</span> <span class=\"nc\">Unit</span> <span class=\"p\">=</span> <span class=\"nf\">runBlocking</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// given</span>\n        <span class=\"kd\">val</span> <span class=\"py\">clientId</span> <span class=\"p\">=</span> <span class=\"nf\">anyClientId</span><span class=\"p\">()</span>\n\n        <span class=\"n\">orderManagementServiceStub</span>\n            <span class=\"p\">.</span><span class=\"nf\">withDelay</span><span class=\"p\">(</span><span class=\"n\">properties</span><span class=\"p\">.</span><span class=\"n\">readTimeout</span><span class=\"p\">.</span><span class=\"nf\">toInt</span><span class=\"p\">())</span>\n            <span class=\"p\">.</span><span class=\"nf\">willReturnOrdersFor</span><span class=\"p\">(</span>\n                <span class=\"n\">clientId</span><span class=\"p\">,</span>\n                <span class=\"n\">response</span> <span class=\"p\">=</span> <span class=\"nf\">ordersPlacedBySomeCustomer</span><span class=\"p\">()</span>\n            <span class=\"p\">)</span>\n\n        <span class=\"c1\">// when</span>\n        <span class=\"kd\">val</span> <span class=\"py\">exception</span> <span class=\"p\">=</span> <span class=\"n\">shouldThrow</span><span class=\"p\">&lt;</span><span class=\"nc\">ExternalServiceReadTimeoutException</span><span class=\"p\">&gt;</span> <span class=\"p\">{</span>\n            <span class=\"n\">orderManagementServiceClient</span><span class=\"p\">.</span><span class=\"nf\">getOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">)</span>\n        <span class=\"p\">}</span>\n        <span class=\"c1\">// then</span>\n        <span class=\"n\">exception</span><span class=\"p\">.</span><span class=\"n\">message</span> <span class=\"n\">shouldContain</span> <span class=\"n\">clientId</span><span class=\"p\">.</span><span class=\"n\">clientId</span><span class=\"p\">.</span><span class=\"nf\">toString</span><span class=\"p\">()</span>\n        <span class=\"n\">exception</span><span class=\"p\">.</span><span class=\"n\">message</span> <span class=\"n\">shouldContain</span> <span class=\"n\">properties</span><span class=\"p\">.</span><span class=\"n\">clientName</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>No, this is not testing properties in tests.\nThis test ensures that the configuration derived from properties has indeed been applied to the given client.\nEnsuring a response within a specified time frame might be part of non-functional requirements and requires verification.</p>\n\n<h4 id=\"invalid-response-body\">Invalid Response Body</h4>\n<p>Considered cases:</p>\n<ul>\n  <li>Response body does not contain required field.</li>\n  <li>Response body is empty.</li>\n  <li>Response has an incorrect format.</li>\n</ul>\n\n<p>Errors of this type are signaled through <code class=\"language-plaintext highlighter-rouge\">ExternalServiceIncorrectResponseBodyException</code> and logged at the error level.</p>\n\n<h3 id=\"metrics\">Metrics</h3>\n<p>When dealing with HTTP clients, it’s essential to monitor several aspects: response times, throughput, and error rates.\nTo differentiate metrics generated by different clients easily, it’s advisable to include a <code class=\"language-plaintext highlighter-rouge\">service.name</code> tag with the respective client’s name.</p>\n\n<p>In HTTP clients offered by the Spring framework (WebClient, RestClient),\nmetrics are enabled out-of-the-box if we create them using predefined builders (WebClient.Builder, RestClient.Builder).\nHowever, for other technologies, third-party solutions must be employed. In Allegro, we have a set of libraries that allows us to quickly create new\nHTTP clients in the most popular technologies that provide support for our infrastructure.\nAs a result, all clients generate consistent metrics by default tailored to our dashboards.</p>\n\n<h4 id=\"response-time\">Response Time</h4>\n<p>Measuring the response time of HTTP clients allows us to identify bottlenecks.\nAt which percentile should we set such a metric?\nGenerally, the more requests a client generates, the higher the percentile we should aim for.\nSometimes, issues become visible only at high percentiles (P99, P99.9) for a very high volume of requests.</p>\n\n<p><img alt=\"Response Time\" src=\"/img/articles/2024-06-04-rest-service-client-design-testing-monitoring/response_time.png\" /></p>\n\n<h4 id=\"throughput\">Throughput</h4>\n<p>Number of requests that our application sends to external services per second (RPS).\nAn auxiliary metric for the response time metric, where response time is always considered in the context of the generated traffic.</p>\n\n<p><img alt=\"Throughput\" src=\"/img/articles/2024-06-04-rest-service-client-design-testing-monitoring/rps.png\" /></p>\n\n<h4 id=\"error-rate\">Error Rate</h4>\n<p>Counting responses with codes 4xx/5xx.\nHere, we are interested in visualizing how many such errors occurred within a specific timeframe.\nThe number of errors we analyze depends on the overall traffic, therefore, both metrics should be expressed in the same units, usually requests per second.\nFor high traffic and a small number of errors, we can expect that the presented values will be on the order of thousandths.</p>\n\n<p><img alt=\"Error Rate\" src=\"/img/articles/2024-06-04-rest-service-client-design-testing-monitoring/errors.png\" /></p>\n\n<h2 id=\"summary\">Summary</h2>\n<p><a href=\"https://martinfowler.com/articles/microservices.html\">Microservices Architecture</a> relies heavily on network communication.\nThe most common method of communication is REST API calls between different services.\nWriting integration code involves more than just invoking a URL and parsing a response.\nLogs, error handling, and metrics are crucial for creating a stable and fault-tolerant microservices environment.\nDevelopers should have tools that take care of these aspects, enabling fast and reliable development of such integrations.\nHowever, tools alone are insufficient. We also need established rules and guidelines that allow us to write readable and maintainable code,\nboth in production and tests.</p>\n\n<h2 id=\"code-examples\">Code examples</h2>\n<p>To explore comprehensive examples, including the usage of WebClient and other HTTP clients, check out the GitHub <a href=\"https://github.com/Klimiec/webclients\">repository</a>.</p>\n","contentSnippet":"The purpose of this article is to present how to design, test, and monitor a REST service client.\nThe article includes a repository with clients written in Kotlin using various technologies such as WebClient,\nRestClient,\nKtor Client,\nRetrofit.\nIt demonstrates how to send and retrieve data from an external service, add a cache layer, and parse the received response into domain objects.\nMotivation\nWhy do we need objects in the project that encapsulate the HTTP clients we use?\nTo begin with, we want to separate the domain from technical details.\nThe way we retrieve/send data and handle errors, which can be quite complex in the case of HTTP clients, should not clutter business logic.\nNext, testability. Even if we do not use hexagonal architecture in our applications,\nit’s beneficial to separate the infrastructure from the service layer, as it improves testability.\nVerifying an HTTP service client is not a simple task and requires consideration of many cases — mainly at the integration level.\nHaving a separate “building block“ that encapsulates communication with the outside world makes testing much easier.\nFinally, reusability. A service client that has been written once can be successfully used in other projects.\nClient Design\nAs a case study, I will use an example implementation that utilizes WebClient for retrieving data from the Order Management Service,\nan example service that might appear in an e-commerce site such as Allegro.\nThe heart of our client is the executeHttpRequest method, which is responsible for executing the provided HTTP request, logging, and error handling.\nIt is not part of the WebClient library.\n\nclass OrderManagementServiceClient(\n    private val orderManagementServiceApi: OrderManagementServiceApi,\n    private val clientName: String\n) {\n    suspend fun getOrdersFor(clientId: ClientId): OrdersDto {\n        return executeHttpRequest(\n            initialLog = \"[$clientName] Get orders for a clientId= $clientId\",\n            request = { orderManagementServiceApi.getOrdersFor(clientId) },\n            successLog = \"[$clientName] Returned orders for a clientId= $clientId\",\n            failureMessage = \"[$clientName] Failed to get orders for clientId= $clientId\"\n        )\n    }\n}\n\n\n\nFull working example can be found here.\nClient name\nI like to name clients using the convention: name of the service we integrate with, plus the suffix Client.\nIn the case of integration with the Order Management Service, such a class will be named OrderManagementServiceClient.\nIf the technology we use employs an interface to describe the called REST API (RestClient, WebClient, Retrofit),\nwe can name such an interface OrderManagementServiceApi — following the general pattern of the service name with the suffix Api.\nThese names may seem intuitive and obvious, but without an established naming convention, we might end up with a project where\ndifferent integrations have the following suffixes: HttpClient, Facade, WebClient, Adapter, and Service.\nIt’s important to have a consistent convention and adhere to it throughout the project.\nAPI\nMethods of our clients should have names that reflect the communicative intention behind them.\nTo capture this intention, it is necessary to use a verb in the method’s name.\nTypically, the correct name will have a structure of verb + resource name, for example, getOrders  —  for methods that retrieve resources.\nIf we want to narrow down the number of returned resources using filters or return a particular resource, I recommend adding the suffix “For” before the list of parameters.\nTechnically, these parameters will be part of the query or path parameters.\n\nfun getOrdersFor(clientId: ClientId): OrdersDto\n\n\nFor methods responsible for creating resources, simply using the verb in the method name is enough,\nas the resource being passed as a parameter effectively conveys the intention of the method.\n\nfun publish(event: InvoiceCreatedEventDto)\n\n\nLogging\nWhen communicating with external service we’d like to log the beginning of the interaction, indicating our intention to fetch or send a resource,\nas well as its outcome. The outcome can be either a success, meaning receiving a response with a 2xx status code, or a failure.\nFailure can be signaled by status codes (3xx, 4xx, 5xx), resulting from the inability to deserialize the received response into an object,\nexceeding the response time, etc. Generally, many things can go wrong.\nDepending on the cause of failure, we may want to log the interaction result at different levels (warn/error).\nThere are critical errors that are worth distinguishing (error), and those that will occasionally occur (warn) and don’t require urgent intervention.\nTo filter logs related to a specific service while browsing through them, I like to include the client’s name within curly braces at the beginning of the logs.\nFor logging technical aspects of the communication, such as the URL called, HTTP method used, and response code,\nwe use filters (logRequestInfo, logResponseInfo) that are plugged in at the client configuration level in the createExternalServiceApi method.\n\ninline fun <reified T> createExternalServiceApi(\n    webClientBuilder: WebClient.Builder,\n    properties: ConnectionProperties\n): T =\n    webClientBuilder\n        .clientConnector(httpClient(properties))\n        .baseUrl(properties.baseUrl)\n        .defaultRequest { it.attribute(SERVICE_NAME, properties.clientName) }\n        .filter(logRequestInfo(properties.clientName))\n        .filter(logResponseInfo(properties.clientName))\n        .build()\n        .let { WebClientAdapter.create(it) }\n        .let { HttpServiceProxyFactory.builderFor(it).build() }\n        .createClient(T::class.java)\n\nfun logRequestInfo(clientName: String) = ExchangeFilterFunction.ofRequestProcessor { request ->\n    logger.info {\n        \"[$clientName] method=[${request.method().name()}] url=${request.url()}}\"\n    }\n    Mono.just(request)\n}\n\nfun logResponseInfo(clientName: String) = ExchangeFilterFunction.ofResponseProcessor { response ->\n    logger.info { \"[$clientName] service responded with a status code= ${response.statusCode()}\" }\n    Mono.just(response)\n}\n\n\nHere’s an example of logged interaction for successfully fetching a resource.\n\nTo prevent redundancy in logging code across multiple clients, it is centralized inside executeHttpRequest method.\nThe only thing the developer needs to do is to provide a business-oriented description for the beginning of the interaction and its outcome (parameters: initialLog, successLog, failureMessage).\nWhy do I emphasize logging so much?\nIsn’t it enough to log only errors?\nAfter all, we have metrics that inform us about the performance of our clients.\nMetrics won’t provide us with the details of the communication, but logs will.\nThese details can turn out to be crucial in the analysis of incidents, which may reveal, for example, incorrect data produced by our service.\nLogs are like backups. We find out if we have them and how valuable they are only when they are needed,\neither because the business team requests an analysis of a particular case or when resolving an incident.\nError handling\nWhen writing client code, we aim to highlight maximally how we send/retrieve data and hide the “noise“ that comes from error handling.\nIn the case of HTTP clients, error handling is quite extensive but generic enough that the resulting code can be written once and reused across all clients.\nIn our example, error handling mechanism is hidden inside executeHttpRequest method.\nIt consists of two things: logging and throwing custom exceptions that encapsulate technical exceptions thrown by the underlying HTTP client.\nWhat are the benefits of using custom exceptions? The very name of such a custom exception tells us exactly what went wrong.\nFor comparison, ExternalServiceIncorrectResponseBodyException seems to be more descriptive than DecodingException.\nThey also help group various technical exceptions that lead to the same cause, for example, an incorrect response object structure.\nAdditionally, based on these exceptions, visualizations can be created to show the state of our integration.\nFor example, we can create a table that will show how many exceptions of any given type were thrown by our clients within a specified period.\nHaving custom exceptions, we are 100% certain that these exceptions were thrown only by our clients.\nTesting\nStubs\nTo verify different scenarios of our HTTP client, it is necessary to appropriately stub the called endpoints in tests.\nFor this purpose, we will use the WireMock library.\nIt is quite important that the technical details of created stubs do not leak into the tests.\nThe test should describe the behavior being tested and encapsulate technical details.\nFor example, changing the accept/content-type header or making minor modifications to the called URL should not affect the test itself.\nTo achieve this, for each service for which we write a service client, we create an object of type StubBuilder.\nThe StubBuilder allows hiding the details of stubbing and verification behind a readable API.\nIt takes on the impact of changes to the called API, protecting our test from modification.\nIt fulfills a similar role to the Page Object Pattern in end-to-end tests for web apps.\n\norderManagementServiceStub.willReturnOrdersFor(clientId, response = ordersPlacedBySomeCustomer())\n\n\nStubBuilders for services that return data come in two flavors - internal and external.\n\nWhen testing a service client, we want to have great flexibility in simulating responses.\nTherefore, StubBuilders from the internal package will model response objects as a string. This allows us to simulate any scenario.\nIn end-to-end tests, where a given service is part of the bigger process, such flexibility is not necessary; in fact, it is not even recommended.\nTherefore, StubBuilders from the external package model responses using real objects.\nAll StubBuilders from the external packages are declared in the class ExternalServiceStubs, to which a reference is located in the base class for\nall integration tests, BaseIntegrationTest. This allows us to have very easy access to all external service stubs in our integration tests.\n\nstub.orderManagementService().willReturnOrdersFor(clientId, response = ordersPlacedBySomeCustomer())\n\n\nReading the code above, we immediately know which service is being interacted with (Order Management Service) and what will be returned from it (Orders).\nThe technical details of the stubbed endpoint have been hidden inside the StubBuilder object.\nTests should emphasize “what” and encapsulate “how.” This way, they can serve as documentation.\nTest Data\nThe data returned by our stubs can be prepared in three ways:\nRead the entire response from a file/string.\nPrepare the response using real objects used in the service for deserializing responses from called services.\nCreate a set of separate objects modeling the returned response from the service for testing purposes and use them to prepare the returned data.\nWhich option to choose?\nTo answer this question, we should analyze the advantages and disadvantages of each approach.\nOption A — read response from a file/string. Response creation is very fast and simple.\nIt allows verifying the contract between the client and the supplier (at least at the time of writing the test).\nImagine that during refactoring, one of the fields in the response object accidentally changes.\nIn such a case, client tests using this approach will detect the defect before the code reaches production.\n\n@Test\nfun `should return orders for a given clientId`(): Unit = runBlocking {\n        // given\n        val clientId = anyClientId()\n        orderManagementServiceStub.willReturnOrdersFor(clientId, response = ordersPlacedBySomeCustomer())\n\n        // when\n        val response: OrdersDto = orderManagementServiceClient.getOrdersFor(clientId)\n\n        // then\n        response shouldBe OrdersDto(listOf(OrderDto(\"7952a9ab-503c-4483-beca-32d081cc2446\")))\n}\n\n\nOn the other hand, keeping data in files/strings is difficult to maintain and reuse.\nProgrammers often copy entire files for new tests, introducing only minimal changes.\nThere is a problem with naming these files and refactoring them when the called service introduces an incompatible change.\nOption B — Use real response objects.\nIt allows writing one-line, readable assertions and maximally reusing already created data, especially using test data builders.\n\n    @Test\n    fun `should return orders for a given clientId`(): Unit = runBlocking {\n        // given\n        val clientId = anyClientId()\n        val clientOrders = OrderManagementServiceFixture.ordersPlacedBySomeCustomer()\n        orderManagementServiceStub.willReturnOrdersFor(clientId, response = clientOrders)\n\n        // when\n        val response: OrdersDto = orderManagementServiceClient.getOrdersFor(clientId)\n\n        // then\n        response shouldBe clientOrders\n    }\n\n\nHowever, accidental change of field name which results in the  contract violation between the client and supplier won’t be caught.\nAs a result, we might have perfectly tested communication in integration tests that will not work in production.\nOption C — create a set of separate response objects. It has all the advantages of options A and B, including maintainability, reusability, and\nverification of the contract between the client and the supplier. Unfortunately, maintaining a separate model for testing purposes comes with some overhead\nand requires discipline on the developers’ side, which can be challenging to maintain.\nWhich option to choose? Personally, I prefer a hybrid of options A and B.\nFor the purpose of testing the “happy path“ in client tests, I return a response that is entirely stored as a string (alternatively, it can be read from a file).\nSuch a test allows not only to verify the contract but also the correctness of deserializing the received response into a response object.\nIn other tests (cache, adapter, end-to-end), I create responses returned by the stubbed endpoint using production response objects.\nIt’s worthwhile to keep sample test data in dedicated classes, such as a Fixture class, for each integration (for example OrderManagementServiceFixture).\nThis allows the reuse of test data and enhances the readability of the tests themselves.\nTest Scenarios\nHappy Path\nFetching a resource — verification whether the client can retrieve data from the previously stubbed endpoint and deserialize it into a response object.\n\n@Test\nfun `should return orders for a given clientId`(): Unit = runBlocking {\n        // given\n        val clientId = anyClientId()\n        orderManagementServiceStub.willReturnOrdersFor(clientId, response = ordersPlacedBySomeCustomer())\n\n        // when\n        val response: OrdersDto = orderManagementServiceClient.getOrdersFor(clientId)\n\n        // then\n        response shouldBe OrdersDto(listOf(OrderDto(\"7952a9ab-503c-4483-beca-32d081cc2446\")))\n}\n\n\nAn essential part of the test for the “happy path“ is verification of the contract between the client and the supplier.\nThe ordersPlacedBySomeCustomer method returns a sample response guaranteed by the supplier (Order Management Service).\nOn the client side, in the assertion section, we check if this message has been correctly deserialized into a response object.\nInstead of comparing individual fields with the expected value, I highly recommend comparing entire objects (returned and expected).\nIt gives us confidence that all fields have been compared. In the case of regression, modern IDEs such as IntelliJ indicate exactly where the problem is.\n\nSending a resource — verification whether the client sends data to the specified URL in a format acceptable by the previously stubbed endpoint.\nIn the following example, I test publishing an event to Hermes, a message broker built on top of Kafka widely used at Allegro.\n\n@Test\nfun `should successfully publish InvoiceCreatedEvent`(): Unit = runBlocking {\n        // given\n        val invoiceCreatedEvent = HermesFixture.invoiceCreatedEvent()\n        stub.hermes().willAcceptInvoiceCreatedEvent()\n\n        // when\n        hermesClient.publish(invoiceCreatedEvent)\n\n        // then\n        stub.hermes().verifyInvoiceCreatedEventPublished(event = invoiceCreatedEvent)\n}\n\n\nStubbed endpoints for methods accepting request bodies (e.g., POST, PUT) should not verify the values of the received request body but only its structure.\n\nfun willAcceptInvoiceCreatedEvent() {\n    WireMock.stubFor(\n        invoiceCreatedEventTopic()\n            .withRequestBody(WireMock.matchingJsonPath(\"$.invoiceId\"))\n            .withRequestBody(WireMock.matchingJsonPath(\"$.orderId\"))\n            .withRequestBody(WireMock.matchingJsonPath(\"$.timestamp\"))\n            .willReturn(\n                WireMock.aResponse()\n                    .withFixedDelay(responseTime)\n                    .withStatus(HttpStatus.OK.value())\n            )\n    )\n}\n\n\nWe verify the content of the request body in the assertion section.\nHere, we also want to hide the technical aspects of assertions behind a method.\n\nstubs.hermes().verifyInvoiceCreatedEventPublished(event = invoiceCreatedEvent)\n\n\nfun verifyInvoiceCreatedEventPublished(event: InvoiceCreatedEventDto) {\n    WireMock.verify(\n        1,\n        WireMock.postRequestedFor(WireMock.urlPathEqualTo(INVOICE_CREATED_URL))\n            .withRequestBody(WireMock.matchingJsonPath(\"$.invoiceId\", WireMock.equalTo(event.invoiceId)))\n            .withRequestBody(WireMock.matchingJsonPath(\"$.orderId\", WireMock.equalTo(event.orderId)))\n            .withRequestBody(WireMock.matchingJsonPath(\"$.timestamp\", WireMock.equalTo(event.timestamp)))\n    )\n}\n\n\nCombining stubbing and request verification in one method is not recommended.\nCreating stubs in this way makes their usage less convenient since not every test requires detailed verification of what is being sent in the request body.\nThe vast majority of tests will stub the endpoint based on the principle:\naccept a given request as long as its structure is preserved and will verify hypotheses other than the content of the request body (mainly end-to-end tests).\nClient-side errors\nFor 4xx type errors, we want to verify the following cases:\nThe absence of the requested resource signaled by the response code 404 and a custom exception ExternalServiceResourceNotFoundException\nValidation error signaled by the response code 422 and a custom exception ExternalServiceRequestValidationException\nAny other 4xx type errors  should be cast to an ExternalServiceClientException\n\n@ParameterizedTest(name = \"{index}) http status code: {0}\")\n@MethodSource(\"clientErrors\")\nfun `when receive response with 4xx status code then throw exception`(\n    exceptionClass: Class<Exception>,\n    statusCode: Int,\n    responseBody: String?\n): Unit = runBlocking {\n        // given\n        val clientId = anyClientId()\n        orderManagementServiceStub.willReturnOrdersFor(clientId, status = statusCode, response = responseBody)\n\n        // when\n        val exception = shouldThrowAny {\n            orderManagementServiceClient.getOrdersFor(clientId)\n        }\n\n        // then\n        exception.javaClass shouldBeSameInstanceAs exceptionClass\n        exception.message shouldContain clientId.clientId.toString()\n        exception.message shouldContain properties.clientName\n}\n\n\nIn distributed systems, a 404 response code is quite common and may result from temporary inconsistency across the entire system.\nIts occurrence is signaled by the ExternalServiceResourceNotFoundException and a warning-level log.\nHere, we are more interested in the scale of occurrences, which is why we use metrics, than analyzing individual cases, hence we log such cases at the warning level.\nThe situation looks a bit different in the case of responses with a code of 422.\nIf the request is rejected due to validation errors, either our service has a defect and produces incorrect data,\nor we receive incorrect data from external services (which is why it’s crucial to log what we receive from external services).\nAlternatively, the error may be on the recipient side in the logic validating the received request. It’s worth analyzing each such case, which is why\nerrors of this type are logged at the error level and signaled by the ExternalServiceRequestValidationException.\nOther errors from the 4xx family occur less frequently.\nThey are all marked by the ExternalServiceClientException exception and logged at the error level.\nServer-side errors\nRegardless of the reason for a 5xx error, all of them are logged at the warn level because we have no control over them.\nThey are signaled by the ExternalServiceServerException exception. Similar to 404 errors, we are more interested in aggregate information\nabout the number of such errors rather than analyzing each case individually, hence the warn log level.\nIn tests, we consider two cases because the response from the service may or may not have a body.\nIf the response has a body, we want to log it.\nRead Timeout\nOur HTTP client should have a finite response timeout configured, so it’s worthwhile to write an integration test that verifies the client’s configuration.\nSimulating the delay of the stubbed endpoint can be achieved using the withFixedDelay method from wiremock.\n\n@Test\nfun `when service returns above timeout threshold then throw exception`(): Unit = runBlocking {\n        // given\n        val clientId = anyClientId()\n\n        orderManagementServiceStub\n            .withDelay(properties.readTimeout.toInt())\n            .willReturnOrdersFor(\n                clientId,\n                response = ordersPlacedBySomeCustomer()\n            )\n\n        // when\n        val exception = shouldThrow<ExternalServiceReadTimeoutException> {\n            orderManagementServiceClient.getOrdersFor(clientId)\n        }\n        // then\n        exception.message shouldContain clientId.clientId.toString()\n        exception.message shouldContain properties.clientName\n}\n\n\nNo, this is not testing properties in tests.\nThis test ensures that the configuration derived from properties has indeed been applied to the given client.\nEnsuring a response within a specified time frame might be part of non-functional requirements and requires verification.\nInvalid Response Body\nConsidered cases:\nResponse body does not contain required field.\nResponse body is empty.\nResponse has an incorrect format.\nErrors of this type are signaled through ExternalServiceIncorrectResponseBodyException and logged at the error level.\nMetrics\nWhen dealing with HTTP clients, it’s essential to monitor several aspects: response times, throughput, and error rates.\nTo differentiate metrics generated by different clients easily, it’s advisable to include a service.name tag with the respective client’s name.\nIn HTTP clients offered by the Spring framework (WebClient, RestClient),\nmetrics are enabled out-of-the-box if we create them using predefined builders (WebClient.Builder, RestClient.Builder).\nHowever, for other technologies, third-party solutions must be employed. In Allegro, we have a set of libraries that allows us to quickly create new\nHTTP clients in the most popular technologies that provide support for our infrastructure.\nAs a result, all clients generate consistent metrics by default tailored to our dashboards.\nResponse Time\nMeasuring the response time of HTTP clients allows us to identify bottlenecks.\nAt which percentile should we set such a metric?\nGenerally, the more requests a client generates, the higher the percentile we should aim for.\nSometimes, issues become visible only at high percentiles (P99, P99.9) for a very high volume of requests.\n\nThroughput\nNumber of requests that our application sends to external services per second (RPS).\nAn auxiliary metric for the response time metric, where response time is always considered in the context of the generated traffic.\n\nError Rate\nCounting responses with codes 4xx/5xx.\nHere, we are interested in visualizing how many such errors occurred within a specific timeframe.\nThe number of errors we analyze depends on the overall traffic, therefore, both metrics should be expressed in the same units, usually requests per second.\nFor high traffic and a small number of errors, we can expect that the presented values will be on the order of thousandths.\n\nSummary\nMicroservices Architecture relies heavily on network communication.\nThe most common method of communication is REST API calls between different services.\nWriting integration code involves more than just invoking a URL and parsing a response.\nLogs, error handling, and metrics are crucial for creating a stable and fault-tolerant microservices environment.\nDevelopers should have tools that take care of these aspects, enabling fast and reliable development of such integrations.\nHowever, tools alone are insufficient. We also need established rules and guidelines that allow us to write readable and maintainable code,\nboth in production and tests.\nCode examples\nTo explore comprehensive examples, including the usage of WebClient and other HTTP clients, check out the GitHub repository.","guid":"https://blog.allegro.tech/2024/06/rest-service-client-design-testing-monitoring.html","categories":["kotlin","testing","integration tests","rest","wiremock"],"isoDate":"2024-06-03T22:00:00.000Z"}],"jobs":[{"id":"743999999349931","name":"Software Engineer (.NET) - Allegro Pay","uuid":"b2ee7d94-5131-4197-8bf6-9a64a41d4106","jobAdId":"1098f20d-0b14-41de-a388-1799601b2074","defaultJobAd":true,"refNumber":"REF4748E","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2024-07-09T08:58:10.718Z","location":{"city":"Warsaw","region":"Masovian Voivodeship","country":"pl","remote":false,"latitude":"52.2296756","longitude":"21.0122287"},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572770","label":"IT - Software Development"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"id":"permanent","label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"61583054f15cea434e0be36f","fieldLabel":"Career Level","valueId":"3c97f53f-19c2-4a25-9eb1-513f9fb38b80","valueLabel":"3-5"},{"fieldId":"61582f70e72a6b6d239c9857","fieldLabel":"Area","valueId":"76599a72-f283-4550-9303-52e2e0eb6e32","valueLabel":"Technology"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Recruitment Process","valueId":"b3da614a-1ddb-441b-a557-5acfdb6fcb90","valueLabel":"NEW Technology CL 1-6"},{"fieldId":"6406f92e638cbb2f415a94a9","fieldLabel":"Job Area","valueId":"e8731ea4-48a9-476d-ab1d-9a40eb3426f1","valueLabel":"Technology"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572770","valueLabel":"IT - Software Development"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"9c8396d4-11a6-443c-897c-15f29221a3fd","valueLabel":"Allegro Pay sp. z o.o."}],"visibility":"PUBLIC","ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999999349931","creator":{"name":"Martyna Stafa"},"language":{"code":"en","label":"English","labelNative":"English (US)"}},{"id":"743999999160035","name":"Software Engineer 1 (Java/Kotlin)","uuid":"412d9096-bc5b-453e-bfe0-9bee10f8e391","jobAdId":"bba75edc-0e2c-4e24-a115-17a75ce435ec","defaultJobAd":false,"refNumber":"REF4072X","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2024-07-08T12:51:23.441Z","location":{"city":"Poznań","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572770","label":"IT - Software Development"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"id":"permanent","label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"61583054f15cea434e0be36f","fieldLabel":"Career Level","valueId":"3c97f53f-19c2-4a25-9eb1-513f9fb38b80","valueLabel":"3-5"},{"fieldId":"61582f70e72a6b6d239c9857","fieldLabel":"Area","valueId":"76599a72-f283-4550-9303-52e2e0eb6e32","valueLabel":"Technology"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Recruitment Process","valueId":"ed4682c7-33c9-41c2-8d13-428ed39046f5","valueLabel":"Tech. Engineer - IC"},{"fieldId":"6406f92e638cbb2f415a94a9","fieldLabel":"Job Area","valueId":"e8731ea4-48a9-476d-ab1d-9a40eb3426f1","valueLabel":"Technology"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572770","valueLabel":"IT - Software Development"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro sp. z o.o."}],"visibility":"PUBLIC","ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999999160035","language":{"code":"en","label":"English","labelNative":"English (US)"}},{"id":"743999999139951","name":"Mobile Software Engineer 2 (iOS) - Consumer","uuid":"7ac3e476-238a-492a-932f-7e1afcecbf25","jobAdId":"135e9d05-ab38-4249-8833-476904d552d1","defaultJobAd":true,"refNumber":"REF5103J","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2024-07-08T11:29:05.537Z","location":{"city":"Warsaw","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572770","label":"IT - Software Development"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"id":"permanent","label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"61583054f15cea434e0be36f","fieldLabel":"Career Level","valueId":"3976147c-fe25-42a8-8c97-78273250960b","valueLabel":"4"},{"fieldId":"61582f70e72a6b6d239c9857","fieldLabel":"Area","valueId":"76599a72-f283-4550-9303-52e2e0eb6e32","valueLabel":"Technology"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Recruitment Process","valueId":"b3da614a-1ddb-441b-a557-5acfdb6fcb90","valueLabel":"NEW Technology CL 1-6"},{"fieldId":"6406f92e638cbb2f415a94a9","fieldLabel":"Job Area","valueId":"e8731ea4-48a9-476d-ab1d-9a40eb3426f1","valueLabel":"Technology"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572770","valueLabel":"IT - Software Development"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro sp. z o.o."}],"visibility":"PUBLIC","ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999999139951","creator":{"name":"Monika Walaszek"},"language":{"code":"en","label":"English","labelNative":"English (US)"}},{"id":"743999999125636","name":"Senior Mobile Software Engineer (Android) - Consumer","uuid":"89fb91ab-dc96-4b64-ba58-df7990951492","jobAdId":"88cffe88-6630-4e9a-bc16-0c9c7ebb29a1","defaultJobAd":true,"refNumber":"REF5100F","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2024-07-08T10:42:38.789Z","location":{"city":"Warsaw","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572770","label":"IT - Software Development"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"id":"permanent","label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"61583054f15cea434e0be36f","fieldLabel":"Career Level","valueId":"26b58095-3c5f-4596-937f-27547fb80b07","valueLabel":"5"},{"fieldId":"61582f70e72a6b6d239c9857","fieldLabel":"Area","valueId":"76599a72-f283-4550-9303-52e2e0eb6e32","valueLabel":"Technology"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Recruitment Process","valueId":"b3da614a-1ddb-441b-a557-5acfdb6fcb90","valueLabel":"NEW Technology CL 1-6"},{"fieldId":"6406f92e638cbb2f415a94a9","fieldLabel":"Job Area","valueId":"e8731ea4-48a9-476d-ab1d-9a40eb3426f1","valueLabel":"Technology"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572770","valueLabel":"IT - Software Development"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro sp. z o.o."}],"visibility":"PUBLIC","ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999999125636","creator":{"name":"Monika Walaszek"},"language":{"code":"en","label":"English","labelNative":"English (US)"}},{"id":"743999998791780","name":"Software Engineer 2 (Java/Kotlin) - Search&Personalization","uuid":"c468eba1-10fd-4134-88c2-05e44b784bf5","jobAdId":"550d9f6e-b309-45a7-9da0-e77dbb85e8a3","defaultJobAd":false,"refNumber":"REF4072X","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2024-07-05T10:42:28.875Z","location":{"city":"Poznań, Warsaw","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572770","label":"IT - Software Development"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"id":"permanent","label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"61583054f15cea434e0be36f","fieldLabel":"Career Level","valueId":"3c97f53f-19c2-4a25-9eb1-513f9fb38b80","valueLabel":"3-5"},{"fieldId":"61582f70e72a6b6d239c9857","fieldLabel":"Area","valueId":"76599a72-f283-4550-9303-52e2e0eb6e32","valueLabel":"Technology"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Recruitment Process","valueId":"ed4682c7-33c9-41c2-8d13-428ed39046f5","valueLabel":"Tech. Engineer - IC"},{"fieldId":"6406f92e638cbb2f415a94a9","fieldLabel":"Job Area","valueId":"e8731ea4-48a9-476d-ab1d-9a40eb3426f1","valueLabel":"Technology"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572770","valueLabel":"IT - Software Development"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro sp. z o.o."}],"visibility":"PUBLIC","ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999998791780","language":{"code":"en","label":"English","labelNative":"English (US)"}}],"events":[{"created":1715716710000,"duration":7200000,"id":"301022703","name":"Allegro Tech Talks #43 - Wszystko o programie e-Xperience","date_in_series_pattern":false,"status":"past","time":1716393600000,"local_date":"2024-05-22","local_time":"18:00","updated":1716406648000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":14,"venue":{"id":27570147,"name":"Allegro Office - Poznań (Nowy Rynek)","lat":52.40021514892578,"lon":16.92083168029785,"repinned":false,"address_1":"Wierzbięcice 1B - budynek D","city":"Poznań","country":"pl","localized_country_name":"Poland"},"is_online_event":false,"eventType":"PHYSICAL","group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/301022703/","description":"**➡ Rejestracja:** [https://app.evenea.pl/event/allegro-tech-talk-43/](https://app.evenea.pl/event/allegro-tech-talk-43/) Zapraszamy Was na #43 wydarzenie z serii Allegro Tech Talk, podczas których dzielimy się wiedzą, wzajemnie inspirujemy oraz integrujemy przy dobrej kawie☕, napojach🥤…","how_to_find_us":"Biuro Allegro znajduje się w kompleksie Nowy Rynek. Szukaj budynku D i kieruj się do wejścia od ul. Wierzbięcice. Komunikacja miejska: najbliższy przystanek to Wierzbięcice i kursują tu linie tramwajowe numer 2, 5, 6, 10, 12, 18 Spacerem - z dworca Poznań Główny przejście zajmie Ci około 5 minut.","visibility":"public","member_pay_fee":false},{"created":1702979844000,"duration":187200000,"id":"298027809","name":"UX Research Confetti - IV edycja","date_in_series_pattern":false,"status":"past","time":1716202800000,"local_date":"2024-05-20","local_time":"13:00","updated":1716392955000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":82,"venue":{"id":27549223,"name":"Allegro Warsaw Office","lat":52.23224639892578,"lon":20.992111206054688,"repinned":true,"address_1":"ul. Żelazna 51/53","city":"Warszawa","country":"pl","localized_country_name":"Poland"},"is_online_event":false,"eventType":"PHYSICAL","group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/298027809/","description":"**🎉 Przedstawiamy 4. edycję UX Research Confetti - bezpłatną, polską konferencję poświęconą badaniom UX, organizowaną przez zespół badaczy z Allegro.** ✨ Konferencja odbędzie się w…","visibility":"public","member_pay_fee":false},{"created":1712583756000,"duration":14400000,"id":"300288303","name":"DDD & EventStorming na luzie - unconference na 2 lata gildii w Allegro","date_in_series_pattern":false,"status":"past","time":1714129200000,"local_date":"2024-04-26","local_time":"13:00","updated":1714146607000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":103,"venue":{"id":27549223,"name":"Allegro Warsaw Office","lat":52.23224639892578,"lon":20.992111206054688,"repinned":true,"address_1":"ul. Żelazna 51/53","city":"Warszawa","country":"pl","localized_country_name":"Poland"},"is_online_event":false,"eventType":"PHYSICAL","group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/300288303/","description":"**➡ Rejestracja:** **[https://app.evenea.pl/event/allegro-tech-talk-ddd/](https://app.evenea.pl/event/allegro-tech-talk-ddd/)** Dobrze Was widzieć! Allegro Tech to miejsce, w którym dzielimy się wiedzą, dobrymi praktykami i case study z różnych projektów prowadzonych w…","how_to_find_us":"Biuro Allegro znajduje się w kompleksie Fabryki Norblina. Szukaj wejścia Plater 3, od ul. Żelaznej. \n\nKomunikacja miejska: najbliższe przystanki to Norblin 05 i 06 z liniami: 109, 178, 157. Dojedziecie do nas również tramwajami numer 10 i 11 oraz metrem (Rondo ONZ lub Rondo Daszyńskiego).","visibility":"public","member_pay_fee":false},{"created":1712756447000,"duration":7200000,"id":"300327359","name":"Allegro Tech Talks #42 - Kariera Product Managera","date_in_series_pattern":false,"status":"past","time":1713888000000,"local_date":"2024-04-23","local_time":"18:00","updated":1713900030000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":37,"venue":{"id":27549223,"name":"Allegro Warsaw Office","lat":52.23224639892578,"lon":20.992111206054688,"repinned":true,"address_1":"ul. Żelazna 51/53","city":"Warszawa","country":"pl","localized_country_name":"Poland"},"is_online_event":false,"eventType":"PHYSICAL","group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/300327359/","description":"**➡ Rejestracja:** [https://app.evenea.pl/event/allegro-tech-talk-42/ ](https://app.evenea.pl/event/allegro-tech-talk-42/) Zapraszamy Was na #42 wydarzenie z serii Allegro Tech Talk, podczas których dzielimy się wiedzą, wzajemnie inspirujemy oraz integrujemy przy dobrej…","how_to_find_us":"Biuro Allegro znajduje się w kompleksie Fabryki Norblina. Szukaj wejścia Plater 3, od ul. Żelaznej. \n\nKomunikacja miejska: najbliższe przystanki to Norblin 05 i 06 z liniami: 109, 178, 157. Dojedziesz do nas również tramwajami numer 10 i 11 oraz metrem (Rondo ONZ lub Rondo Daszyńskiego).","visibility":"public","member_pay_fee":false}],"podcasts":[{"title":"O pracy analityków w obszarze technologii i przetwarzaniu danych w dużej skali","link":"https://podcast.allegro.tech/o-pracy-analitykow-w-obszarze-technologii-i-przetwarzaniu-danych-w-duzej-skali/","pubDate":"Thu, 29 Feb 2024 00:00:00 GMT","content":"Na czym polega praca analityków w obszarze technologii w Allegro? Jakich narzędzi i technologii na co dzień używają osoby pracujące na tych stanowiskach? Jak efekty pracy analityków wpływają na naszą platformę, produkty i funkcjonalności? Czym zajmuje się Data Product Manager w Allegro Pay? Dlaczego monety są ważnym elementem ekosystemu Allegro? Posłuchajcie kolejnego odcinka Allegro Tech Podcast tym razem z udziałem Adrianny Napiórkowskiej - Data Product Managerki w Allegro Pay oraz Kaya Akcelikli - Senior Managera w obszarze Data w Allegro.","contentSnippet":"Na czym polega praca analityków w obszarze technologii w Allegro? Jakich narzędzi i technologii na co dzień używają osoby pracujące na tych stanowiskach? Jak efekty pracy analityków wpływają na naszą platformę, produkty i funkcjonalności? Czym zajmuje się Data Product Manager w Allegro Pay? Dlaczego monety są ważnym elementem ekosystemu Allegro? Posłuchajcie kolejnego odcinka Allegro Tech Podcast tym razem z udziałem Adrianny Napiórkowskiej - Data Product Managerki w Allegro Pay oraz Kaya Akcelikli - Senior Managera w obszarze Data w Allegro.","guid":"https://podcast.allegro.tech/o-pracy-analitykow-w-obszarze-technologii-i-przetwarzaniu-danych-w-duzej-skali/","isoDate":"2024-02-29T00:00:00.000Z"},{"title":"Programowanie - co liczy się w nim najbardziej?","link":"https://podcast.allegro.tech/programowanie-co-liczy-sie-w-nim-najbardziej/","pubDate":"Thu, 01 Feb 2024 00:00:00 GMT","content":"Jaką ścieżkę trzeba przejść, aby dobrze programować? Gdzie zdobywać wiedzę, doświadczenie i szlifować swoje umiejętności? Ile czasu potrzeba aby nabrać doświadczenia i jak zadbać o swój dalszy rozwój? Na czym w praktyce polegają role (Senior) Software Engineer oraz Engineering Manager w Allegro i kto najlepiej sprawdza się w naszych zespołach? Posłuchajcie nowego odcinka Allegro Tech Podcast z udziałem Rafała Schmidta (Senior Software Engineer) i Waldemara Panasa (Manager, Engineering) z Allegro.","contentSnippet":"Jaką ścieżkę trzeba przejść, aby dobrze programować? Gdzie zdobywać wiedzę, doświadczenie i szlifować swoje umiejętności? Ile czasu potrzeba aby nabrać doświadczenia i jak zadbać o swój dalszy rozwój? Na czym w praktyce polegają role (Senior) Software Engineer oraz Engineering Manager w Allegro i kto najlepiej sprawdza się w naszych zespołach? Posłuchajcie nowego odcinka Allegro Tech Podcast z udziałem Rafała Schmidta (Senior Software Engineer) i Waldemara Panasa (Manager, Engineering) z Allegro.","guid":"https://podcast.allegro.tech/programowanie-co-liczy-sie-w-nim-najbardziej/","isoDate":"2024-02-01T00:00:00.000Z"},{"title":"MBox: server-driven UI dla aplikacji mobilnych","link":"https://podcast.allegro.tech/mbox-server-driven-ui-dla-aplikacji-mobilnych/","pubDate":"Thu, 16 Nov 2023 00:00:00 GMT","content":"Czym jest i jak powstał MBox: wewnętrzna platforma server-driven UI dla aplikacji mobilnych w Allegro? Skąd wziął się pomysł na to rozwiązanie i na jakie bolączki odpowiada? Dlaczego zdecydowaliśmy się na budowanie tego typu rozwiązania in-house i z jakimi wyzwaniami mierzyliśmy się w procesie tworzenia? Co wyróżnia zespoły pracujące nad tym narzędziem i jak pracuje im się bez Product Ownera? Posłuchajcie siódmego odcinka Allegro Tech Podcast z udziałem Pauliny Sadowskiej i Tomasza Gębarowskiego - Managerów w obszarze Technical Platform Services w Allegro.","contentSnippet":"Czym jest i jak powstał MBox: wewnętrzna platforma server-driven UI dla aplikacji mobilnych w Allegro? Skąd wziął się pomysł na to rozwiązanie i na jakie bolączki odpowiada? Dlaczego zdecydowaliśmy się na budowanie tego typu rozwiązania in-house i z jakimi wyzwaniami mierzyliśmy się w procesie tworzenia? Co wyróżnia zespoły pracujące nad tym narzędziem i jak pracuje im się bez Product Ownera? Posłuchajcie siódmego odcinka Allegro Tech Podcast z udziałem Pauliny Sadowskiej i Tomasza Gębarowskiego - Managerów w obszarze Technical Platform Services w Allegro.","guid":"https://podcast.allegro.tech/mbox-server-driven-ui-dla-aplikacji-mobilnych/","isoDate":"2023-11-16T00:00:00.000Z"},{"title":"O chatbotach i ich wpływie na Allegro","link":"https://podcast.allegro.tech/o-chatbotach-i-ich-wplywie-na-allegro/","pubDate":"Wed, 11 Oct 2023 00:00:00 GMT","content":"Jakie procesy automatyzujemy w Allegro i co warto o nich wiedzieć w kontekście obszaru Customer Experience? W czym pomagają nam chatboty, jak je rozwijamy i dbamy o ich jakość? Kim są Allina oraz Albert i co mają wspólnego z automatyzacją? Za jakie rozwiązania otrzymaliśmy nagrodę hiperautomatyzacji? O tym wszystkim posłuchacie w odcinku z udziałem Rafała Gajewskiego - Managera w obszarze IT Services w Allegro.","contentSnippet":"Jakie procesy automatyzujemy w Allegro i co warto o nich wiedzieć w kontekście obszaru Customer Experience? W czym pomagają nam chatboty, jak je rozwijamy i dbamy o ich jakość? Kim są Allina oraz Albert i co mają wspólnego z automatyzacją? Za jakie rozwiązania otrzymaliśmy nagrodę hiperautomatyzacji? O tym wszystkim posłuchacie w odcinku z udziałem Rafała Gajewskiego - Managera w obszarze IT Services w Allegro.","guid":"https://podcast.allegro.tech/o-chatbotach-i-ich-wplywie-na-allegro/","isoDate":"2023-10-11T00:00:00.000Z"}]},"__N_SSG":true}