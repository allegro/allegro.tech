{"pageProps":{"posts":[{"title":"How do coroutines work internally in Python?","link":"https://blog.allegro.tech/2022/01/how-do-coroutines-work-internally-in-python.html","pubDate":"Mon, 24 Jan 2022 00:00:00 +0100","authors":{"author":[{"name":["Tomasz Szewczyk"],"photo":["https://blog.allegro.tech/img/authors/tomasz.szewczyk.jpg"],"url":["https://blog.allegro.tech/authors/tomasz.szewczyk"]}]},"content":"<p>Most of applications we create are basically loops. An average program waits\nfor an event, then processes it following some business logic. Afterwards it\nbegins waiting for another event to arrive. Java Servlets work this way too.\nPopular frameworks such as Spring allow us to only care about the business logic,\nwhile the framework takes care of the application main loop.</p>\n\n<h3 id=\"the-problem-with-blocking-operations\">The problem with blocking operations</h3>\n<p>Imagine a very simple web application whose task is to calculate currency\nexchange rates. It uses no framework, only operating system API or methods from\nyour favourite language standard library. It waits for a request with the amount,\nbase and target currencies and responds with a calculated output. In its simplest\nform it could have all the exchange rates hardcoded, so the operation is very\nfast and efficient. We can assume that such an application uses all the\navailable processing power when handling requests.</p>\n\n<p>But in the next iteration we want our app to query another service for current\nrates instead of relying on hardcoded values. We will soon discover our app is\nspending most of its time waiting for a response from the other service.</p>\n\n<p>Network communication is very slow after all. Let’s assume that a simple request\ntakes at least 1ms to complete. Modern processors have clock frequencies up to\n5GHz and, provided the data and code are already cached, they are capable of\nat least one simple operation per cycle. This means we could have done at least\n5 million simple operations while waiting for the request to complete! What a\nwaste of resources!</p>\n\n<h3 id=\"classic-approach-with-threads\">Classic approach with threads</h3>\n<p>The most obvious solution to this issue are threads. We could refactor our\napplication so that when it receives the request it passes it to a separate\nthread. This way we don’t have to worry about blocking operations in the\nbusiness logic. It is the operating system’s responsibility to allocate CPU to\nsomething meaningful while our thread is blocked waiting for the other service.\nFrom my experience this is how most of the applications work.</p>\n\n<p>Unfortunately this approach has some drawbacks as well. Threads consume a lot of\nresources and you can only create a limited number of them. Very soon you\ndiscover threads are a precious resource on their own and you can hardly afford\nthem sitting and waiting for a request to complete. You need to consider your\nthread pool allocation policy in order not to starve some part of your\napplication. Add race conditions and other concurrency related issues and it\nsuddenly gets overcomplicated.</p>\n\n<h3 id=\"how-about-we-dont-block\">How about we don’t block</h3>\n<p>Let’s assume you decide threads are too expensive, too cumbersome or they are\nsimply not available on your platform, because for example you are writing bare\nmetal applications and there is no operating system. When we decide not to use\nthreading we have to keep in mind we cannot afford having any blocking operations\nin our application, because they are wasting our resources. Having no threads\nmeans there is no way to use time when something blocks.</p>\n\n<p>The new idea for the program architecture is as follows:</p>\n<ul>\n  <li>Wait for an event to happen.</li>\n  <li>If the event is a new request arriving to an endpoint, then we only setup\nthe request to another service and return.</li>\n  <li>If the event is a response from the other service, then\nwe consume the received data and we setup a response to the original request.</li>\n</ul>\n\n<p>This way we don’t have any blocking operation in our application, hence it is\nvery efficient.</p>\n\n<h2 id=\"low-level-async-api\">Low level async API</h2>\n<p>Linux and similar operating systems provide us with a convenient API for many\nblocking operations. For example, the <code class=\"language-plaintext highlighter-rouge\">accept</code> system call is used to get an\nincoming TCP connection from a queue of pending connections or wait for one\nto show up. You can read more about <code class=\"language-plaintext highlighter-rouge\">accept</code> in <a href=\"https://man7.org/linux/man-pages/man2/accept.2.html\">the Linux manual</a>.</p>\n\n<p>Similarly <code class=\"language-plaintext highlighter-rouge\">write</code> and <code class=\"language-plaintext highlighter-rouge\">read</code> functions, defined by POSIX standard, are used\nto send and receive data over the created connection. Both can also block\nwaiting for the I/O operation to become possible. You can read more about these\nfunctions in the Linux manual: <a href=\"https://man7.org/linux/man-pages/man2/read.2.html\">read</a>,\n<a href=\"https://man7.org/linux/man-pages/man3/write.3p.html\">write</a>.</p>\n\n<p>As you may have already noticed, our asynchronous application only makes sense\nwhen there is only one blocking operation in the whole program. Earlier we\ncalled it “waiting for an event to happen”. In Linux we can achieve such a\nbehaviour using <code class=\"language-plaintext highlighter-rouge\">select</code> or <code class=\"language-plaintext highlighter-rouge\">poll</code> system calls. <code class=\"language-plaintext highlighter-rouge\">poll</code> is basically a more modern\nversion of <code class=\"language-plaintext highlighter-rouge\">select</code>. In practice we can provide them with a set of event\ndescriptors and they will block until one of expected events occurs. You can\nread more about these calls in the Linux manual: <a href=\"https://man7.org/linux/man-pages/man2/select.2.html\">select</a>,\n<a href=\"https://man7.org/linux/man-pages/man2/poll.2.html\">poll</a>.</p>\n\n<h2 id=\"select-in-python\">Select in Python</h2>\n<p>This API can be accessed in Python with a convenient wrapper provided by the\nPython standard library. It hides some complicated low level aspects of the\noperating system API which is good for this article. Read more about\n<code class=\"language-plaintext highlighter-rouge\">selectors</code> module in <a href=\"https://docs.python.org/3/library/selectors.html#module-selectors\">the Python documentation</a>.</p>\n\n<p>Firstly we can register an event we want to wait for using the <code class=\"language-plaintext highlighter-rouge\">register</code>\nmethod, then we wait for any registered event to happen using the <code class=\"language-plaintext highlighter-rouge\">select</code>\nmethod. Python standard library provides us with <code class=\"language-plaintext highlighter-rouge\">DefaultSelector</code> which is an\nalias for the most efficient implementation on the current platform, so that we\ndon’t have to dive into low level details if we don’t want to.</p>\n\n<h3 id=\"the-simplest-async-application\">The simplest async application</h3>\n<p>For the sake of simplicity of the examples I won’t use <code class=\"language-plaintext highlighter-rouge\">Selector</code> and I won’t\ntry to create an async http client from scratch. There are plainly too many\nunrelated low level details. Surprisingly, event the most common GET request consists\nof numerous blocking operations. Instead, I propose the most basic and most easily\ncontrollable blocking operation there is: waiting for user input.</p>\n\n<p>Let’s replace the complicated <code class=\"language-plaintext highlighter-rouge\">selector</code> with a simple <code class=\"language-plaintext highlighter-rouge\">input</code> function and\nmodel events with letters. Here is how such an app could look like:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">def</span> <span class=\"nf\">process_a</span><span class=\"p\">():</span>\n    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"Processing event A\"</span><span class=\"p\">)</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">process_b</span><span class=\"p\">():</span>\n    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"Processing event B\"</span><span class=\"p\">)</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">process_c</span><span class=\"p\">():</span>\n    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"Processing event C\"</span><span class=\"p\">)</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">app</span><span class=\"p\">():</span>\n    <span class=\"k\">while</span> <span class=\"bp\">True</span><span class=\"p\">:</span>\n        <span class=\"n\">event</span> <span class=\"o\">=</span> <span class=\"nb\">input</span><span class=\"p\">(</span><span class=\"s\">\"&gt; \"</span><span class=\"p\">).</span><span class=\"n\">strip</span><span class=\"p\">()</span>\n\n        <span class=\"k\">if</span> <span class=\"n\">event</span> <span class=\"o\">==</span> <span class=\"s\">\"A\"</span><span class=\"p\">:</span>\n            <span class=\"n\">process_a</span><span class=\"p\">()</span>\n        <span class=\"k\">elif</span> <span class=\"n\">event</span> <span class=\"o\">==</span> <span class=\"s\">\"B\"</span><span class=\"p\">:</span>\n            <span class=\"n\">process_b</span><span class=\"p\">()</span>\n        <span class=\"k\">elif</span> <span class=\"n\">event</span> <span class=\"o\">==</span> <span class=\"s\">\"C\"</span><span class=\"p\">:</span>\n            <span class=\"n\">process_c</span><span class=\"p\">()</span>\n\n\n<span class=\"k\">if</span> <span class=\"n\">__name__</span> <span class=\"o\">==</span> <span class=\"s\">\"__main__\"</span><span class=\"p\">:</span>\n    <span class=\"n\">app</span><span class=\"p\">()</span>\n</code></pre></div></div>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>$ python manual_async_simple.py\n&gt; A\nProcessing event A\n&gt; B\nProcessing event B\n&gt; C\nProcessing event C\n</code></pre></div></div>\n\n<p>As you can see we created an event loop listening for events (user input),\nthen it dispatches the event to the relevant handler. Note how the <code class=\"language-plaintext highlighter-rouge\">input</code>\nfunction inside the event loop is the only blocking operation in the whole\nprogram.</p>\n\n<h3 id=\"more-complex-flow-of-execution\">More complex flow of execution</h3>\n<p>As I already mentioned, creating asynchronous applications is easy as long as\nthere is no blocking operation while processing events. The aforementioned\nexample was so simple because there weren’t any. When there is some blocking\noperation we have to split our processing logic into parts, each one ending\nwhen there is a need for some blocking operation.</p>\n\n<p>For example imagine a <code class=\"language-plaintext highlighter-rouge\">Task</code> which is triggered with event A, but then it has\nto wait for events B and C in order to complete. You need separate chunks of\ncode to process each event and some way to hold the <code class=\"language-plaintext highlighter-rouge\">Task</code> state. One could\ncode it that way:</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">class</span> <span class=\"nc\">Task</span><span class=\"p\">:</span>\n    <span class=\"n\">COUNTER</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">state</span> <span class=\"o\">=</span> <span class=\"s\">\"AWAITING A\"</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"nb\">id</span> <span class=\"o\">=</span> <span class=\"n\">Task</span><span class=\"p\">.</span><span class=\"n\">COUNTER</span>\n        <span class=\"n\">Task</span><span class=\"p\">.</span><span class=\"n\">COUNTER</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">process_a</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s\">\"</span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"nb\">id</span><span class=\"si\">}</span><span class=\"s\"> Processing event A, blocking on B\"</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">state</span> <span class=\"o\">=</span> <span class=\"s\">\"AWAITING B\"</span>\n        <span class=\"k\">return</span> <span class=\"bp\">True</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">process_b</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s\">\"</span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"nb\">id</span><span class=\"si\">}</span><span class=\"s\"> Processing event B, blocking on C\"</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">state</span> <span class=\"o\">=</span> <span class=\"s\">\"AWAITING C\"</span>\n        <span class=\"k\">return</span> <span class=\"bp\">True</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">process_c</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s\">\"</span><span class=\"si\">{</span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"nb\">id</span><span class=\"si\">}</span><span class=\"s\"> Processing event C, task done\"</span><span class=\"p\">)</span>\n        <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">state</span> <span class=\"o\">=</span> <span class=\"s\">\"DONE\"</span>\n        <span class=\"k\">return</span> <span class=\"bp\">True</span>\n\n    <span class=\"k\">def</span> <span class=\"nf\">process_new_event</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">event</span><span class=\"p\">):</span>\n        <span class=\"k\">if</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">state</span> <span class=\"o\">==</span> <span class=\"s\">\"AWAITING A\"</span> <span class=\"ow\">and</span> <span class=\"n\">event</span> <span class=\"o\">==</span> <span class=\"s\">\"A\"</span><span class=\"p\">:</span>\n            <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">process_a</span><span class=\"p\">()</span>\n\n        <span class=\"k\">if</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">state</span> <span class=\"o\">==</span> <span class=\"s\">\"AWAITING B\"</span> <span class=\"ow\">and</span> <span class=\"n\">event</span> <span class=\"o\">==</span> <span class=\"s\">\"B\"</span><span class=\"p\">:</span>\n            <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">process_b</span><span class=\"p\">()</span>\n\n        <span class=\"k\">if</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">state</span> <span class=\"o\">==</span> <span class=\"s\">\"AWAITING C\"</span> <span class=\"ow\">and</span> <span class=\"n\">event</span> <span class=\"o\">==</span> <span class=\"s\">\"C\"</span><span class=\"p\">:</span>\n            <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">process_c</span><span class=\"p\">()</span>\n\n        <span class=\"k\">return</span> <span class=\"bp\">False</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">app</span><span class=\"p\">():</span>\n    <span class=\"n\">tasks</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n    <span class=\"k\">while</span> <span class=\"bp\">True</span><span class=\"p\">:</span>\n        <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s\">\"Task queue size </span><span class=\"si\">{</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">tasks</span><span class=\"p\">)</span><span class=\"si\">}</span><span class=\"s\">\"</span><span class=\"p\">)</span>\n        <span class=\"n\">event</span> <span class=\"o\">=</span> <span class=\"nb\">input</span><span class=\"p\">(</span><span class=\"s\">\"&gt; \"</span><span class=\"p\">).</span><span class=\"n\">strip</span><span class=\"p\">()</span>\n\n        <span class=\"k\">if</span> <span class=\"n\">event</span> <span class=\"o\">==</span> <span class=\"s\">\"A\"</span><span class=\"p\">:</span>\n            <span class=\"n\">tasks</span><span class=\"p\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">Task</span><span class=\"p\">())</span>\n\n        <span class=\"k\">for</span> <span class=\"n\">task</span> <span class=\"ow\">in</span> <span class=\"n\">tasks</span><span class=\"p\">:</span>\n            <span class=\"k\">if</span> <span class=\"n\">task</span><span class=\"p\">.</span><span class=\"n\">process_new_event</span><span class=\"p\">(</span><span class=\"n\">event</span><span class=\"p\">):</span>\n                <span class=\"k\">if</span> <span class=\"n\">task</span><span class=\"p\">.</span><span class=\"n\">state</span> <span class=\"o\">==</span> <span class=\"s\">\"DONE\"</span><span class=\"p\">:</span>\n                    <span class=\"n\">tasks</span><span class=\"p\">.</span><span class=\"n\">remove</span><span class=\"p\">(</span><span class=\"n\">task</span><span class=\"p\">)</span>\n                <span class=\"k\">break</span>\n\n\n<span class=\"k\">if</span> <span class=\"n\">__name__</span> <span class=\"o\">==</span> <span class=\"s\">\"__main__\"</span><span class=\"p\">:</span>\n    <span class=\"n\">app</span><span class=\"p\">()</span>\n</code></pre></div></div>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>$ python manual_async_with_state.py\nTask queue size 0\n&gt; A\n0 Processing event A, blocking on B\nTask queue size 1\n&gt; A\n1 Processing event A, blocking on B\nTask queue size 2\n&gt; A\n2 Processing event A, blocking on B\nTask queue size 3\n&gt; B\n0 Processing event B, blocking on C\nTask queue size 3\n&gt; C\n0 Processing event C, task done\nTask queue size 2\n&gt; B\n1 Processing event B, blocking on C\nTask queue size 2\n&gt; C\n1 Processing event C, task done\nTask queue size 1\n&gt; B\n2 Processing event B, blocking on C\nTask queue size 1\n&gt; C\n2 Processing event C, task done\nTask queue size 0\n</code></pre></div></div>\n\n<p>Pay attention to how hard it is to extract the actual flow of the <code class=\"language-plaintext highlighter-rouge\">Task</code> from\nthe example. The <code class=\"language-plaintext highlighter-rouge\">Task</code> is split into three separate methods, each one\nresponsible for a part of the process. There is also a state persisted through\nconsecutive events.</p>\n\n<p>The bright side is the code actually works. You can go through a <code class=\"language-plaintext highlighter-rouge\">Task</code>\ntriggering events A, B and C, but you can also start a number of <em>Tasks</em> in\nparallel by sending a lot of A events in a row. You can then advance these\n<em>Tasks</em> by sending events they are waiting for.</p>\n\n<p>With classic threaded approach it would be most likely easy to saturate thread\npool even by hand. With our asynchronous example you can have a ton of <em>Tasks</em>\nin progress without any overhead, so the main goal is accomplished.</p>\n\n<h2 id=\"disadvantages-of-asynchronous-approach\">Disadvantages of asynchronous approach</h2>\n<p>We learned that asynchronous approach results in an efficient application, but\nalso has some drawbacks. For starters, your code does not reflect your program\nlogic directly. Instead, you have to manually control the flow, maintain state\nand pass requests’ context around which is cumbersome and error prone.</p>\n\n<p>Your application business logic is hidden under implementation details and the\narchitecture of your solution is determined by the way you decided to deal with\nasynchronous operations. You have to stick to a set of complicated rules when\ndeveloping new features.</p>\n\n<p>If only there were functions that could be easily suspended! We then could\ncreate our business logic in a convenient way and achieve asynchronous\nbehaviour at the same time. Instead of passing context around fragments of our\nprogram, we could just suspend the execution of a function while there is some\nblocking operation going on. That would be great, wouldn’t it?</p>\n\n<h2 id=\"generators\">Generators</h2>\n<p>According to the glossary of Python official documentation a generator is a\nfunction which contains <code class=\"language-plaintext highlighter-rouge\">yield</code> expressions. Each <code class=\"language-plaintext highlighter-rouge\">yield</code> temporarily suspends\nprocessing, remembering the location execution state. When the generator\nresumes, it picks up where it left off. It seems generators are indeed\nfunctions that can be easily suspended. That is exactly what we were looking\nfor!</p>\n\n<h3 id=\"a-closer-look-at-generators\">A closer look at generators</h3>\n<p>Let’s take a closer look at generators. How do they work and what is their\npurpose? First let’s write a function that prints Fibonacci numbers.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">def</span> <span class=\"nf\">print_fibonacci</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">):</span>\n    <span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span>\n    <span class=\"k\">for</span> <span class=\"n\">_</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">):</span>\n        <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span>\n        <span class=\"n\">b</span><span class=\"p\">,</span> <span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"n\">a</span> <span class=\"o\">+</span> <span class=\"n\">b</span><span class=\"p\">,</span> <span class=\"n\">b</span>\n\n\n<span class=\"k\">if</span> <span class=\"n\">__name__</span> <span class=\"o\">==</span> <span class=\"s\">\"__main__\"</span><span class=\"p\">:</span>\n    <span class=\"n\">print_fibonacci</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>$ python print_fibonnaci.py\n1\n1\n2\n3\n5\n</code></pre></div></div>\n\n<p>Next, replace the call to print function with <code class=\"language-plaintext highlighter-rouge\">yield</code> expressions and use our\nfunction as an iterable.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">def</span> <span class=\"nf\">yield_fibonacci</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">):</span>\n    <span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span>\n    <span class=\"k\">for</span> <span class=\"n\">_</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">i</span><span class=\"p\">):</span>\n        <span class=\"k\">yield</span> <span class=\"n\">a</span>\n        <span class=\"n\">b</span><span class=\"p\">,</span> <span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"n\">a</span> <span class=\"o\">+</span> <span class=\"n\">b</span><span class=\"p\">,</span> <span class=\"n\">b</span>\n\n\n<span class=\"k\">if</span> <span class=\"n\">__name__</span> <span class=\"o\">==</span> <span class=\"s\">\"__main__\"</span><span class=\"p\">:</span>\n    <span class=\"k\">for</span> <span class=\"n\">f</span> <span class=\"ow\">in</span> <span class=\"n\">yield_fibonacci</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">):</span>\n        <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">f</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>$ python yield_fibonnaci.py\n1\n1\n2\n3\n5\n</code></pre></div></div>\n\n<p>As you can see, the function became a generator when we used <code class=\"language-plaintext highlighter-rouge\">yield</code> expression\ninside it. When the program reaches <code class=\"language-plaintext highlighter-rouge\">yield</code> expression, the execution is suspended\nand a value is used as an output. From the outside, the generator behaves like\nan iterable or even like a stream, because the values we iterate over are not\nstored in memory. They are generated when needed.</p>\n\n<p>There can be multiple <code class=\"language-plaintext highlighter-rouge\">yield</code> expressions in the generator. When execution reaches\nthe end of the generator, the <code class=\"language-plaintext highlighter-rouge\">StopIteration</code> exception is thrown, just like\nwith iterators.</p>\n\n<h3 id=\"yield-from-and-return\">Yield from and return</h3>\n<p>You can embed one generator inside another with <code class=\"language-plaintext highlighter-rouge\">yield from</code> expression. In the\nfollowing example there is a generator using another generator twice to\ngenerate increasing and decreasing numbers.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">def</span> <span class=\"nf\">step_generator</span><span class=\"p\">(</span><span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"n\">stop</span><span class=\"p\">,</span> <span class=\"n\">step</span><span class=\"p\">):</span>\n    <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n    <span class=\"k\">while</span> <span class=\"n\">start</span> <span class=\"o\">+</span> <span class=\"n\">step</span> <span class=\"o\">*</span> <span class=\"n\">i</span> <span class=\"o\">!=</span> <span class=\"n\">stop</span><span class=\"p\">:</span>\n        <span class=\"k\">yield</span> <span class=\"n\">start</span> <span class=\"o\">+</span> <span class=\"n\">step</span> <span class=\"o\">*</span> <span class=\"n\">i</span>\n        <span class=\"n\">i</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">wrapper_generator</span><span class=\"p\">(</span><span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"n\">stop</span><span class=\"p\">):</span>\n    <span class=\"k\">yield</span> <span class=\"k\">from</span> <span class=\"n\">step_generator</span><span class=\"p\">(</span><span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"n\">stop</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n    <span class=\"k\">yield</span> <span class=\"k\">from</span> <span class=\"n\">step_generator</span><span class=\"p\">(</span><span class=\"n\">stop</span><span class=\"p\">,</span> <span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n\n<span class=\"k\">if</span> <span class=\"n\">__name__</span> <span class=\"o\">==</span> <span class=\"s\">\"__main__\"</span><span class=\"p\">:</span>\n    <span class=\"k\">for</span> <span class=\"n\">f</span> <span class=\"ow\">in</span> <span class=\"n\">wrapper_generator</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">):</span>\n        <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">f</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>$ python yield_twice.py\n0\n1\n2\n3\n4\n5\n4\n3\n2\n1\n</code></pre></div></div>\n\n<p>What is more, a generator can also have a return statement. The returned value\nwill be used as a payload to <code class=\"language-plaintext highlighter-rouge\">StopIteration</code> exception raised when the iteration\nis over or (much more usefully) it can be used as a result of <code class=\"language-plaintext highlighter-rouge\">yield from</code>\nexpression.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">def</span> <span class=\"nf\">step_generator</span><span class=\"p\">(</span><span class=\"n\">start</span><span class=\"p\">,</span> <span class=\"n\">stop</span><span class=\"p\">,</span> <span class=\"n\">step</span><span class=\"p\">):</span>\n    <span class=\"n\">i</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n    <span class=\"k\">while</span> <span class=\"n\">start</span> <span class=\"o\">+</span> <span class=\"n\">step</span> <span class=\"o\">*</span> <span class=\"n\">i</span> <span class=\"o\">!=</span> <span class=\"n\">stop</span><span class=\"p\">:</span>\n        <span class=\"k\">yield</span> <span class=\"n\">start</span> <span class=\"o\">+</span> <span class=\"n\">step</span> <span class=\"o\">*</span> <span class=\"n\">i</span>\n        <span class=\"n\">i</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span>\n    <span class=\"k\">return</span> <span class=\"n\">i</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">wrapper_generator</span><span class=\"p\">():</span>\n    <span class=\"n\">count</span> <span class=\"o\">=</span> <span class=\"k\">yield</span> <span class=\"k\">from</span> <span class=\"n\">step_generator</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">)</span>\n    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s\">\"Generated </span><span class=\"si\">{</span><span class=\"n\">count</span><span class=\"si\">}</span><span class=\"s\"> numbers\"</span><span class=\"p\">)</span>\n\n\n<span class=\"k\">if</span> <span class=\"n\">__name__</span> <span class=\"o\">==</span> <span class=\"s\">\"__main__\"</span><span class=\"p\">:</span>\n    <span class=\"k\">for</span> <span class=\"n\">f</span> <span class=\"ow\">in</span> <span class=\"n\">wrapper_generator</span><span class=\"p\">():</span>\n        <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">f</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>$ python returning_generator.py\n0\n2\n4\n6\n8\nGenerated 5 numbers\n</code></pre></div></div>\n\n<h3 id=\"exceptions-inside-generators\">Exceptions inside generators</h3>\n<p>If an exception is raised within the generator it can be caught using the\nregular try/except statement in the wrapping generator.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">def</span> <span class=\"nf\">failing_generator</span><span class=\"p\">():</span>\n    <span class=\"k\">yield</span> <span class=\"mi\">0</span>\n    <span class=\"k\">raise</span> <span class=\"nb\">Exception</span><span class=\"p\">(</span><span class=\"s\">\"Generator error\"</span><span class=\"p\">)</span>\n    <span class=\"k\">yield</span> <span class=\"mi\">1</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">wrapper_generator</span><span class=\"p\">():</span>\n    <span class=\"k\">try</span><span class=\"p\">:</span>\n        <span class=\"k\">yield</span> <span class=\"k\">from</span> <span class=\"n\">failing_generator</span><span class=\"p\">()</span>\n    <span class=\"k\">except</span><span class=\"p\">:</span>\n        <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"s\">\"Something went wrong\"</span><span class=\"p\">)</span>\n\n\n<span class=\"k\">if</span> <span class=\"n\">__name__</span> <span class=\"o\">==</span> <span class=\"s\">\"__main__\"</span><span class=\"p\">:</span>\n    <span class=\"k\">for</span> <span class=\"n\">f</span> <span class=\"ow\">in</span> <span class=\"n\">wrapper_generator</span><span class=\"p\">():</span>\n        <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"n\">f</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>$ python failing_generator.py\n0\nSomething went wrong\n</code></pre></div></div>\n\n<p>You can read more about generators in the <a href=\"https://docs.python.org/3/howto/functional.html#generators\">Python documentation</a>.</p>\n\n<h2 id=\"async-code-using-generators\">Async code using generators</h2>\n<p>So we know that generators superficially behave like a stream of values.\nOn the inside they look very similar to regular functions. Their execution\nflow is easy to understand, because they work just like our standard imperative\ncode. And we know they can be easily suspended. What if we model asynchronous\noperations as generators of events to be waited for? We could <code class=\"language-plaintext highlighter-rouge\">yield</code> all the\nevents from generators and still have readable and maintainable logic inside.</p>\n\n<p>Our generators could be kept in a map, connecting the generator to the event it\nis waiting for. When the event occurs we can simply take the next event from\nthe generator and again wait for it to happen.</p>\n\n<p>Inside the generator we can have any amount of logic among <code class=\"language-plaintext highlighter-rouge\">yield</code> expressions as\nlong as there are no blocking operations. Basically, we write our logic as if it\nwas synchronous code but instead of blocking on some operation we <em>yield</em> what we\nare waiting for.</p>\n\n<p>Let’s rewrite the example with tasks waiting for user input using the new\napproach.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">counter</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">wait_for_b</span><span class=\"p\">():</span>\n    <span class=\"k\">yield</span> <span class=\"s\">\"B\"</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">wait_for_c</span><span class=\"p\">():</span>\n    <span class=\"k\">yield</span> <span class=\"s\">\"C\"</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">task_generator</span><span class=\"p\">():</span>\n    <span class=\"k\">global</span> <span class=\"n\">counter</span>\n    <span class=\"nb\">id</span> <span class=\"o\">=</span> <span class=\"n\">counter</span>\n    <span class=\"n\">counter</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span>\n\n    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s\">\"</span><span class=\"si\">{</span><span class=\"nb\">id</span><span class=\"si\">}</span><span class=\"s\"> Processing event A, blocking on B\"</span><span class=\"p\">)</span>\n    <span class=\"k\">yield</span> <span class=\"k\">from</span> <span class=\"n\">wait_for_b</span><span class=\"p\">()</span>\n    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s\">\"</span><span class=\"si\">{</span><span class=\"nb\">id</span><span class=\"si\">}</span><span class=\"s\"> Processing event B, blocking on C\"</span><span class=\"p\">)</span>\n    <span class=\"k\">yield</span> <span class=\"k\">from</span> <span class=\"n\">wait_for_c</span><span class=\"p\">()</span>\n    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s\">\"</span><span class=\"si\">{</span><span class=\"nb\">id</span><span class=\"si\">}</span><span class=\"s\"> Processing event C, task done\"</span><span class=\"p\">)</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">app</span><span class=\"p\">():</span>\n    <span class=\"n\">tasks</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s\">\"A\"</span><span class=\"p\">:</span> <span class=\"p\">[],</span> <span class=\"s\">\"B\"</span><span class=\"p\">:</span> <span class=\"p\">[],</span> <span class=\"s\">\"C\"</span><span class=\"p\">:</span> <span class=\"p\">[]}</span>\n    <span class=\"k\">while</span> <span class=\"bp\">True</span><span class=\"p\">:</span>\n        <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s\">\"Task queue size </span><span class=\"si\">{</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">tasks</span><span class=\"p\">[</span><span class=\"s\">'A'</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">tasks</span><span class=\"p\">[</span><span class=\"s\">'B'</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">tasks</span><span class=\"p\">[</span><span class=\"s\">'C'</span><span class=\"p\">])</span><span class=\"si\">}</span><span class=\"s\">\"</span><span class=\"p\">)</span>\n        <span class=\"n\">event</span> <span class=\"o\">=</span> <span class=\"nb\">input</span><span class=\"p\">(</span><span class=\"s\">\"&gt; \"</span><span class=\"p\">).</span><span class=\"n\">strip</span><span class=\"p\">()</span>\n\n        <span class=\"k\">if</span> <span class=\"n\">event</span> <span class=\"o\">==</span> <span class=\"s\">\"A\"</span><span class=\"p\">:</span>\n            <span class=\"n\">new_task</span> <span class=\"o\">=</span> <span class=\"n\">task_generator</span><span class=\"p\">()</span>\n            <span class=\"n\">waiting_for</span> <span class=\"o\">=</span> <span class=\"n\">new_task</span><span class=\"p\">.</span><span class=\"n\">send</span><span class=\"p\">(</span><span class=\"bp\">None</span><span class=\"p\">)</span>\n            <span class=\"n\">tasks</span><span class=\"p\">[</span><span class=\"n\">waiting_for</span><span class=\"p\">].</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">new_task</span><span class=\"p\">)</span>\n\n        <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">tasks</span><span class=\"p\">[</span><span class=\"n\">event</span><span class=\"p\">]):</span>\n            <span class=\"n\">task</span> <span class=\"o\">=</span> <span class=\"n\">tasks</span><span class=\"p\">[</span><span class=\"n\">event</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n            <span class=\"n\">tasks</span><span class=\"p\">[</span><span class=\"n\">event</span><span class=\"p\">].</span><span class=\"n\">remove</span><span class=\"p\">(</span><span class=\"n\">task</span><span class=\"p\">)</span>\n            <span class=\"k\">try</span><span class=\"p\">:</span>\n                <span class=\"n\">waiting_for</span> <span class=\"o\">=</span> <span class=\"n\">task</span><span class=\"p\">.</span><span class=\"n\">send</span><span class=\"p\">(</span><span class=\"bp\">None</span><span class=\"p\">)</span>\n                <span class=\"n\">tasks</span><span class=\"p\">[</span><span class=\"n\">waiting_for</span><span class=\"p\">].</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">task</span><span class=\"p\">)</span>\n            <span class=\"k\">except</span> <span class=\"nb\">StopIteration</span><span class=\"p\">:</span>\n                <span class=\"k\">pass</span>\n\n\n<span class=\"k\">if</span> <span class=\"n\">__name__</span> <span class=\"o\">==</span> <span class=\"s\">\"__main__\"</span><span class=\"p\">:</span>\n    <span class=\"n\">app</span><span class=\"p\">()</span>\n</code></pre></div></div>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>$ python yield_based_coroutines.py\nTask queue size 0\n&gt; A\n0 Processing event A, blocking on B\nTask queue size 1\n&gt; A\n1 Processing event A, blocking on B\nTask queue size 2\n&gt; A\n2 Processing event A, blocking on B\nTask queue size 3\n&gt; B\n0 Processing event B, blocking on C\nTask queue size 3\n&gt; B\n1 Processing event B, blocking on C\nTask queue size 3\n&gt; C\n0 Processing event C, task done\nTask queue size 2\n&gt; C\n1 Processing event C, task done\nTask queue size 1\n&gt; B\n2 Processing event B, blocking on C\nTask queue size 1\n&gt; C\n2 Processing event C, task done\nTask queue size 0\n</code></pre></div></div>\n\n<p>By simply replacing our complicated <code class=\"language-plaintext highlighter-rouge\">Task</code> class with a short generator\nfunction and queue of tasks with a map of generators and their previously\nyielded values we manage to get very convenient, yet still very efficient\nasynchronous code. Actually, these are called coroutines!</p>\n\n<h2 id=\"replace-yield-with-await\">Replace yield with await</h2>\n<p>Do you think I’m stretching reality a little bit by calling generators\ncoroutines? Let’s see. First replace all <code class=\"language-plaintext highlighter-rouge\">yield from</code> expressions with <code class=\"language-plaintext highlighter-rouge\">await</code>.\nNext add an <code class=\"language-plaintext highlighter-rouge\">async</code> keyword to the generator definition. Finally wrap the\nevents we await into classes with the <code class=\"language-plaintext highlighter-rouge\">__await__</code> operator method.</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">counter</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">WaitB</span><span class=\"p\">:</span>\n    <span class=\"k\">def</span> <span class=\"nf\">__await__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">yield</span> <span class=\"s\">\"B\"</span>\n\n\n<span class=\"k\">class</span> <span class=\"nc\">WaitC</span><span class=\"p\">:</span>\n    <span class=\"k\">def</span> <span class=\"nf\">__await__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"k\">yield</span> <span class=\"s\">\"C\"</span>\n\n\n<span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">coroutine</span><span class=\"p\">():</span>\n    <span class=\"k\">global</span> <span class=\"n\">counter</span>\n    <span class=\"nb\">id</span> <span class=\"o\">=</span> <span class=\"n\">counter</span>\n    <span class=\"n\">counter</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span>\n\n    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s\">\"</span><span class=\"si\">{</span><span class=\"nb\">id</span><span class=\"si\">}</span><span class=\"s\"> Processing event A, blocking on B\"</span><span class=\"p\">)</span>\n    <span class=\"k\">await</span> <span class=\"n\">WaitB</span><span class=\"p\">()</span>\n    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s\">\"</span><span class=\"si\">{</span><span class=\"nb\">id</span><span class=\"si\">}</span><span class=\"s\"> Processing event B, blocking on C\"</span><span class=\"p\">)</span>\n    <span class=\"k\">await</span> <span class=\"n\">WaitC</span><span class=\"p\">()</span>\n    <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s\">\"</span><span class=\"si\">{</span><span class=\"nb\">id</span><span class=\"si\">}</span><span class=\"s\"> Processing event C, task done\"</span><span class=\"p\">)</span>\n\n\n<span class=\"k\">def</span> <span class=\"nf\">app</span><span class=\"p\">():</span>\n    <span class=\"n\">tasks</span> <span class=\"o\">=</span> <span class=\"p\">{</span><span class=\"s\">\"A\"</span><span class=\"p\">:</span> <span class=\"p\">[],</span> <span class=\"s\">\"B\"</span><span class=\"p\">:</span> <span class=\"p\">[],</span> <span class=\"s\">\"C\"</span><span class=\"p\">:</span> <span class=\"p\">[]}</span>\n    <span class=\"k\">while</span> <span class=\"bp\">True</span><span class=\"p\">:</span>\n        <span class=\"k\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s\">\"Task queue size </span><span class=\"si\">{</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">tasks</span><span class=\"p\">[</span><span class=\"s\">'A'</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">tasks</span><span class=\"p\">[</span><span class=\"s\">'B'</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">tasks</span><span class=\"p\">[</span><span class=\"s\">'C'</span><span class=\"p\">])</span><span class=\"si\">}</span><span class=\"s\">\"</span><span class=\"p\">)</span>\n        <span class=\"n\">event</span> <span class=\"o\">=</span> <span class=\"nb\">input</span><span class=\"p\">(</span><span class=\"s\">\"&gt; \"</span><span class=\"p\">).</span><span class=\"n\">strip</span><span class=\"p\">()</span>\n\n        <span class=\"k\">if</span> <span class=\"n\">event</span> <span class=\"o\">==</span> <span class=\"s\">\"A\"</span><span class=\"p\">:</span>\n            <span class=\"n\">new_task</span> <span class=\"o\">=</span> <span class=\"n\">coroutine</span><span class=\"p\">()</span>\n            <span class=\"n\">waiting_for</span> <span class=\"o\">=</span> <span class=\"n\">new_task</span><span class=\"p\">.</span><span class=\"n\">send</span><span class=\"p\">(</span><span class=\"bp\">None</span><span class=\"p\">)</span>\n            <span class=\"n\">tasks</span><span class=\"p\">[</span><span class=\"n\">waiting_for</span><span class=\"p\">].</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">new_task</span><span class=\"p\">)</span>\n\n        <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">tasks</span><span class=\"p\">[</span><span class=\"n\">event</span><span class=\"p\">]):</span>\n            <span class=\"n\">task</span> <span class=\"o\">=</span> <span class=\"n\">tasks</span><span class=\"p\">[</span><span class=\"n\">event</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n            <span class=\"n\">tasks</span><span class=\"p\">[</span><span class=\"n\">event</span><span class=\"p\">].</span><span class=\"n\">remove</span><span class=\"p\">(</span><span class=\"n\">task</span><span class=\"p\">)</span>\n            <span class=\"k\">try</span><span class=\"p\">:</span>\n                <span class=\"n\">waiting_for</span> <span class=\"o\">=</span> <span class=\"n\">task</span><span class=\"p\">.</span><span class=\"n\">send</span><span class=\"p\">(</span><span class=\"bp\">None</span><span class=\"p\">)</span>\n                <span class=\"n\">tasks</span><span class=\"p\">[</span><span class=\"n\">waiting_for</span><span class=\"p\">].</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">task</span><span class=\"p\">)</span>\n            <span class=\"k\">except</span> <span class=\"nb\">StopIteration</span><span class=\"p\">:</span>\n                <span class=\"k\">pass</span>\n\n\n<span class=\"k\">if</span> <span class=\"n\">__name__</span> <span class=\"o\">==</span> <span class=\"s\">\"__main__\"</span><span class=\"p\">:</span>\n    <span class=\"n\">app</span><span class=\"p\">()</span>\n</code></pre></div></div>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>$ python yield_based_coroutines.py\nTask queue size 0\n&gt; A\n0 Processing event A, blocking on B\nTask queue size 1\n&gt; A\n1 Processing event A, blocking on B\nTask queue size 2\n&gt; A\n2 Processing event A, blocking on B\nTask queue size 3\n&gt; B\n0 Processing event B, blocking on C\nTask queue size 3\n&gt; B\n1 Processing event B, blocking on C\nTask queue size 3\n&gt; C\n0 Processing event C, task done\nTask queue size 2\n&gt; C\n1 Processing event C, task done\nTask queue size 1\n&gt; B\n2 Processing event B, blocking on C\nTask queue size 1\n&gt; C\n2 Processing event C, task done\nTask queue size 0\n</code></pre></div></div>\n\n<p>This code still runs OK! We can have a ton of opened tasks and we won’t\nsaturate any precious resource. What is more, you wouldn’t guess that\nwe had implemented this ourselves by looking at the actual coroutine.</p>\n\n<p>Now you can just replace <code class=\"language-plaintext highlighter-rouge\">input</code> with <code class=\"language-plaintext highlighter-rouge\">select</code> and <code class=\"language-plaintext highlighter-rouge\">yield</code> descriptors of\nactual blocking operations like reading from socket and you can create your own\nasynchronous HTTP application.</p>\n\n<h2 id=\"python-asyncio\">Python asyncio</h2>\n<p>In fact, the async/await syntax is present only since Python 3.7. Prior to 3.7\ncoroutines were actually written as generators with special annotation attached\nto them.</p>\n\n<p>Python standard library provides us with a ready-to-use event loop to run our\ncoroutines as well as a set of convenient awaitable operations covering all the\nlowest level blocking operations we usually deal with. If you want to learn more\nabout low level async API in Python,\n<a href=\"https://www.python.org/dev/peps/pep-3156/\">PEP3156</a> is a great place to start.</p>\n\n<p>Furthermore, there is a huge number of libraries making use of this low level\nAPI. They implement HTTP clients, web frameworks, database drivers and many\nothers. My favourite asynchronous libraries in Python are:\nasynchronous HTTP client <a href=\"https://docs.aiohttp.org/en/stable/\">aiohttp</a>,\nweb framework <a href=\"https://fastapi.tiangolo.com/\">FastAPI</a> and\nMongoDB driver <a href=\"https://motor.readthedocs.io/en/stable/\">Motor</a>.</p>\n\n<p>In reality, the Python event loop runs on futures, also known as promises\nin other languages. Coroutines are implemented with tasks which rely on\nfutures. Our implementation is actually simplified as it bypasses some abstraction\nlayers. You should remember that when looking into Python sources, \nso you don’t get confused!</p>\n\n<p>When I first started learning coroutines I had hard times trying to figure out\nall the strange behaviours myself. It was only the understanding of how things\nwork inside that helped me finally feel it. I hope my explanation will help you\nnot only understand how to use coroutines, but also let you gain\nconfidence and intuition about how asynchronous programming works.</p>\n\n<p>Happy coding!</p>\n","contentSnippet":"Most of applications we create are basically loops. An average program waits\nfor an event, then processes it following some business logic. Afterwards it\nbegins waiting for another event to arrive. Java Servlets work this way too.\nPopular frameworks such as Spring allow us to only care about the business logic,\nwhile the framework takes care of the application main loop.\nThe problem with blocking operations\nImagine a very simple web application whose task is to calculate currency\nexchange rates. It uses no framework, only operating system API or methods from\nyour favourite language standard library. It waits for a request with the amount,\nbase and target currencies and responds with a calculated output. In its simplest\nform it could have all the exchange rates hardcoded, so the operation is very\nfast and efficient. We can assume that such an application uses all the\navailable processing power when handling requests.\nBut in the next iteration we want our app to query another service for current\nrates instead of relying on hardcoded values. We will soon discover our app is\nspending most of its time waiting for a response from the other service.\nNetwork communication is very slow after all. Let’s assume that a simple request\ntakes at least 1ms to complete. Modern processors have clock frequencies up to\n5GHz and, provided the data and code are already cached, they are capable of\nat least one simple operation per cycle. This means we could have done at least\n5 million simple operations while waiting for the request to complete! What a\nwaste of resources!\nClassic approach with threads\nThe most obvious solution to this issue are threads. We could refactor our\napplication so that when it receives the request it passes it to a separate\nthread. This way we don’t have to worry about blocking operations in the\nbusiness logic. It is the operating system’s responsibility to allocate CPU to\nsomething meaningful while our thread is blocked waiting for the other service.\nFrom my experience this is how most of the applications work.\nUnfortunately this approach has some drawbacks as well. Threads consume a lot of\nresources and you can only create a limited number of them. Very soon you\ndiscover threads are a precious resource on their own and you can hardly afford\nthem sitting and waiting for a request to complete. You need to consider your\nthread pool allocation policy in order not to starve some part of your\napplication. Add race conditions and other concurrency related issues and it\nsuddenly gets overcomplicated.\nHow about we don’t block\nLet’s assume you decide threads are too expensive, too cumbersome or they are\nsimply not available on your platform, because for example you are writing bare\nmetal applications and there is no operating system. When we decide not to use\nthreading we have to keep in mind we cannot afford having any blocking operations\nin our application, because they are wasting our resources. Having no threads\nmeans there is no way to use time when something blocks.\nThe new idea for the program architecture is as follows:\nWait for an event to happen.\nIf the event is a new request arriving to an endpoint, then we only setup\nthe request to another service and return.\nIf the event is a response from the other service, then\nwe consume the received data and we setup a response to the original request.\nThis way we don’t have any blocking operation in our application, hence it is\nvery efficient.\nLow level async API\nLinux and similar operating systems provide us with a convenient API for many\nblocking operations. For example, the accept system call is used to get an\nincoming TCP connection from a queue of pending connections or wait for one\nto show up. You can read more about accept in the Linux manual.\nSimilarly write and read functions, defined by POSIX standard, are used\nto send and receive data over the created connection. Both can also block\nwaiting for the I/O operation to become possible. You can read more about these\nfunctions in the Linux manual: read,\nwrite.\nAs you may have already noticed, our asynchronous application only makes sense\nwhen there is only one blocking operation in the whole program. Earlier we\ncalled it “waiting for an event to happen”. In Linux we can achieve such a\nbehaviour using select or poll system calls. poll is basically a more modern\nversion of select. In practice we can provide them with a set of event\ndescriptors and they will block until one of expected events occurs. You can\nread more about these calls in the Linux manual: select,\npoll.\nSelect in Python\nThis API can be accessed in Python with a convenient wrapper provided by the\nPython standard library. It hides some complicated low level aspects of the\noperating system API which is good for this article. Read more about\nselectors module in the Python documentation.\nFirstly we can register an event we want to wait for using the register\nmethod, then we wait for any registered event to happen using the select\nmethod. Python standard library provides us with DefaultSelector which is an\nalias for the most efficient implementation on the current platform, so that we\ndon’t have to dive into low level details if we don’t want to.\nThe simplest async application\nFor the sake of simplicity of the examples I won’t use Selector and I won’t\ntry to create an async http client from scratch. There are plainly too many\nunrelated low level details. Surprisingly, event the most common GET request consists\nof numerous blocking operations. Instead, I propose the most basic and most easily\ncontrollable blocking operation there is: waiting for user input.\nLet’s replace the complicated selector with a simple input function and\nmodel events with letters. Here is how such an app could look like:\n\ndef process_a():\n    print(\"Processing event A\")\n\n\ndef process_b():\n    print(\"Processing event B\")\n\n\ndef process_c():\n    print(\"Processing event C\")\n\n\ndef app():\n    while True:\n        event = input(\"> \").strip()\n\n        if event == \"A\":\n            process_a()\n        elif event == \"B\":\n            process_b()\n        elif event == \"C\":\n            process_c()\n\n\nif __name__ == \"__main__\":\n    app()\n\n\n\n$ python manual_async_simple.py\n> A\nProcessing event A\n> B\nProcessing event B\n> C\nProcessing event C\n\n\nAs you can see we created an event loop listening for events (user input),\nthen it dispatches the event to the relevant handler. Note how the input\nfunction inside the event loop is the only blocking operation in the whole\nprogram.\nMore complex flow of execution\nAs I already mentioned, creating asynchronous applications is easy as long as\nthere is no blocking operation while processing events. The aforementioned\nexample was so simple because there weren’t any. When there is some blocking\noperation we have to split our processing logic into parts, each one ending\nwhen there is a need for some blocking operation.\nFor example imagine a Task which is triggered with event A, but then it has\nto wait for events B and C in order to complete. You need separate chunks of\ncode to process each event and some way to hold the Task state. One could\ncode it that way:\n\nclass Task:\n    COUNTER = 0\n\n    def __init__(self):\n        self.state = \"AWAITING A\"\n        self.id = Task.COUNTER\n        Task.COUNTER += 1\n\n    def process_a(self):\n        print(f\"{self.id} Processing event A, blocking on B\")\n        self.state = \"AWAITING B\"\n        return True\n\n    def process_b(self):\n        print(f\"{self.id} Processing event B, blocking on C\")\n        self.state = \"AWAITING C\"\n        return True\n\n    def process_c(self):\n        print(f\"{self.id} Processing event C, task done\")\n        self.state = \"DONE\"\n        return True\n\n    def process_new_event(self, event):\n        if self.state == \"AWAITING A\" and event == \"A\":\n            return self.process_a()\n\n        if self.state == \"AWAITING B\" and event == \"B\":\n            return self.process_b()\n\n        if self.state == \"AWAITING C\" and event == \"C\":\n            return self.process_c()\n\n        return False\n\n\ndef app():\n    tasks = []\n    while True:\n        print(f\"Task queue size {len(tasks)}\")\n        event = input(\"> \").strip()\n\n        if event == \"A\":\n            tasks.append(Task())\n\n        for task in tasks:\n            if task.process_new_event(event):\n                if task.state == \"DONE\":\n                    tasks.remove(task)\n                break\n\n\nif __name__ == \"__main__\":\n    app()\n\n\n\n$ python manual_async_with_state.py\nTask queue size 0\n> A\n0 Processing event A, blocking on B\nTask queue size 1\n> A\n1 Processing event A, blocking on B\nTask queue size 2\n> A\n2 Processing event A, blocking on B\nTask queue size 3\n> B\n0 Processing event B, blocking on C\nTask queue size 3\n> C\n0 Processing event C, task done\nTask queue size 2\n> B\n1 Processing event B, blocking on C\nTask queue size 2\n> C\n1 Processing event C, task done\nTask queue size 1\n> B\n2 Processing event B, blocking on C\nTask queue size 1\n> C\n2 Processing event C, task done\nTask queue size 0\n\n\nPay attention to how hard it is to extract the actual flow of the Task from\nthe example. The Task is split into three separate methods, each one\nresponsible for a part of the process. There is also a state persisted through\nconsecutive events.\nThe bright side is the code actually works. You can go through a Task\ntriggering events A, B and C, but you can also start a number of Tasks in\nparallel by sending a lot of A events in a row. You can then advance these\nTasks by sending events they are waiting for.\nWith classic threaded approach it would be most likely easy to saturate thread\npool even by hand. With our asynchronous example you can have a ton of Tasks\nin progress without any overhead, so the main goal is accomplished.\nDisadvantages of asynchronous approach\nWe learned that asynchronous approach results in an efficient application, but\nalso has some drawbacks. For starters, your code does not reflect your program\nlogic directly. Instead, you have to manually control the flow, maintain state\nand pass requests’ context around which is cumbersome and error prone.\nYour application business logic is hidden under implementation details and the\narchitecture of your solution is determined by the way you decided to deal with\nasynchronous operations. You have to stick to a set of complicated rules when\ndeveloping new features.\nIf only there were functions that could be easily suspended! We then could\ncreate our business logic in a convenient way and achieve asynchronous\nbehaviour at the same time. Instead of passing context around fragments of our\nprogram, we could just suspend the execution of a function while there is some\nblocking operation going on. That would be great, wouldn’t it?\nGenerators\nAccording to the glossary of Python official documentation a generator is a\nfunction which contains yield expressions. Each yield temporarily suspends\nprocessing, remembering the location execution state. When the generator\nresumes, it picks up where it left off. It seems generators are indeed\nfunctions that can be easily suspended. That is exactly what we were looking\nfor!\nA closer look at generators\nLet’s take a closer look at generators. How do they work and what is their\npurpose? First let’s write a function that prints Fibonacci numbers.\n\ndef print_fibonacci(i):\n    a, b = 1, 1\n    for _ in range(i):\n        print(a)\n        b, a = a + b, b\n\n\nif __name__ == \"__main__\":\n    print_fibonacci(5)\n\n\n\n$ python print_fibonnaci.py\n1\n1\n2\n3\n5\n\n\nNext, replace the call to print function with yield expressions and use our\nfunction as an iterable.\n\ndef yield_fibonacci(i):\n    a, b = 1, 1\n    for _ in range(i):\n        yield a\n        b, a = a + b, b\n\n\nif __name__ == \"__main__\":\n    for f in yield_fibonacci(5):\n        print(f)\n\n\n\n$ python yield_fibonnaci.py\n1\n1\n2\n3\n5\n\n\nAs you can see, the function became a generator when we used yield expression\ninside it. When the program reaches yield expression, the execution is suspended\nand a value is used as an output. From the outside, the generator behaves like\nan iterable or even like a stream, because the values we iterate over are not\nstored in memory. They are generated when needed.\nThere can be multiple yield expressions in the generator. When execution reaches\nthe end of the generator, the StopIteration exception is thrown, just like\nwith iterators.\nYield from and return\nYou can embed one generator inside another with yield from expression. In the\nfollowing example there is a generator using another generator twice to\ngenerate increasing and decreasing numbers.\n\ndef step_generator(start, stop, step):\n    i = 0\n    while start + step * i != stop:\n        yield start + step * i\n        i += 1\n\n\ndef wrapper_generator(start, stop):\n    yield from step_generator(start, stop, 1)\n    yield from step_generator(stop, start, -1)\n\n\nif __name__ == \"__main__\":\n    for f in wrapper_generator(0, 5):\n        print(f)\n\n\n\n$ python yield_twice.py\n0\n1\n2\n3\n4\n5\n4\n3\n2\n1\n\n\nWhat is more, a generator can also have a return statement. The returned value\nwill be used as a payload to StopIteration exception raised when the iteration\nis over or (much more usefully) it can be used as a result of yield from\nexpression.\n\ndef step_generator(start, stop, step):\n    i = 0\n    while start + step * i != stop:\n        yield start + step * i\n        i += 1\n    return i\n\n\ndef wrapper_generator():\n    count = yield from step_generator(0, 10, 2)\n    print(f\"Generated {count} numbers\")\n\n\nif __name__ == \"__main__\":\n    for f in wrapper_generator():\n        print(f)\n\n\n\n$ python returning_generator.py\n0\n2\n4\n6\n8\nGenerated 5 numbers\n\n\nExceptions inside generators\nIf an exception is raised within the generator it can be caught using the\nregular try/except statement in the wrapping generator.\n\ndef failing_generator():\n    yield 0\n    raise Exception(\"Generator error\")\n    yield 1\n\n\ndef wrapper_generator():\n    try:\n        yield from failing_generator()\n    except:\n        print(\"Something went wrong\")\n\n\nif __name__ == \"__main__\":\n    for f in wrapper_generator():\n        print(f)\n\n\n\n$ python failing_generator.py\n0\nSomething went wrong\n\n\nYou can read more about generators in the Python documentation.\nAsync code using generators\nSo we know that generators superficially behave like a stream of values.\nOn the inside they look very similar to regular functions. Their execution\nflow is easy to understand, because they work just like our standard imperative\ncode. And we know they can be easily suspended. What if we model asynchronous\noperations as generators of events to be waited for? We could yield all the\nevents from generators and still have readable and maintainable logic inside.\nOur generators could be kept in a map, connecting the generator to the event it\nis waiting for. When the event occurs we can simply take the next event from\nthe generator and again wait for it to happen.\nInside the generator we can have any amount of logic among yield expressions as\nlong as there are no blocking operations. Basically, we write our logic as if it\nwas synchronous code but instead of blocking on some operation we yield what we\nare waiting for.\nLet’s rewrite the example with tasks waiting for user input using the new\napproach.\n\ncounter = 0\n\n\ndef wait_for_b():\n    yield \"B\"\n\n\ndef wait_for_c():\n    yield \"C\"\n\n\ndef task_generator():\n    global counter\n    id = counter\n    counter += 1\n\n    print(f\"{id} Processing event A, blocking on B\")\n    yield from wait_for_b()\n    print(f\"{id} Processing event B, blocking on C\")\n    yield from wait_for_c()\n    print(f\"{id} Processing event C, task done\")\n\n\ndef app():\n    tasks = {\"A\": [], \"B\": [], \"C\": []}\n    while True:\n        print(f\"Task queue size {len(tasks['A'] + tasks['B'] + tasks['C'])}\")\n        event = input(\"> \").strip()\n\n        if event == \"A\":\n            new_task = task_generator()\n            waiting_for = new_task.send(None)\n            tasks[waiting_for].append(new_task)\n\n        if len(tasks[event]):\n            task = tasks[event][0]\n            tasks[event].remove(task)\n            try:\n                waiting_for = task.send(None)\n                tasks[waiting_for].append(task)\n            except StopIteration:\n                pass\n\n\nif __name__ == \"__main__\":\n    app()\n\n\n\n$ python yield_based_coroutines.py\nTask queue size 0\n> A\n0 Processing event A, blocking on B\nTask queue size 1\n> A\n1 Processing event A, blocking on B\nTask queue size 2\n> A\n2 Processing event A, blocking on B\nTask queue size 3\n> B\n0 Processing event B, blocking on C\nTask queue size 3\n> B\n1 Processing event B, blocking on C\nTask queue size 3\n> C\n0 Processing event C, task done\nTask queue size 2\n> C\n1 Processing event C, task done\nTask queue size 1\n> B\n2 Processing event B, blocking on C\nTask queue size 1\n> C\n2 Processing event C, task done\nTask queue size 0\n\n\nBy simply replacing our complicated Task class with a short generator\nfunction and queue of tasks with a map of generators and their previously\nyielded values we manage to get very convenient, yet still very efficient\nasynchronous code. Actually, these are called coroutines!\nReplace yield with await\nDo you think I’m stretching reality a little bit by calling generators\ncoroutines? Let’s see. First replace all yield from expressions with await.\nNext add an async keyword to the generator definition. Finally wrap the\nevents we await into classes with the __await__ operator method.\n\ncounter = 0\n\n\nclass WaitB:\n    def __await__(self):\n        yield \"B\"\n\n\nclass WaitC:\n    def __await__(self):\n        yield \"C\"\n\n\nasync def coroutine():\n    global counter\n    id = counter\n    counter += 1\n\n    print(f\"{id} Processing event A, blocking on B\")\n    await WaitB()\n    print(f\"{id} Processing event B, blocking on C\")\n    await WaitC()\n    print(f\"{id} Processing event C, task done\")\n\n\ndef app():\n    tasks = {\"A\": [], \"B\": [], \"C\": []}\n    while True:\n        print(f\"Task queue size {len(tasks['A'] + tasks['B'] + tasks['C'])}\")\n        event = input(\"> \").strip()\n\n        if event == \"A\":\n            new_task = coroutine()\n            waiting_for = new_task.send(None)\n            tasks[waiting_for].append(new_task)\n\n        if len(tasks[event]):\n            task = tasks[event][0]\n            tasks[event].remove(task)\n            try:\n                waiting_for = task.send(None)\n                tasks[waiting_for].append(task)\n            except StopIteration:\n                pass\n\n\nif __name__ == \"__main__\":\n    app()\n\n\n\n$ python yield_based_coroutines.py\nTask queue size 0\n> A\n0 Processing event A, blocking on B\nTask queue size 1\n> A\n1 Processing event A, blocking on B\nTask queue size 2\n> A\n2 Processing event A, blocking on B\nTask queue size 3\n> B\n0 Processing event B, blocking on C\nTask queue size 3\n> B\n1 Processing event B, blocking on C\nTask queue size 3\n> C\n0 Processing event C, task done\nTask queue size 2\n> C\n1 Processing event C, task done\nTask queue size 1\n> B\n2 Processing event B, blocking on C\nTask queue size 1\n> C\n2 Processing event C, task done\nTask queue size 0\n\n\nThis code still runs OK! We can have a ton of opened tasks and we won’t\nsaturate any precious resource. What is more, you wouldn’t guess that\nwe had implemented this ourselves by looking at the actual coroutine.\nNow you can just replace input with select and yield descriptors of\nactual blocking operations like reading from socket and you can create your own\nasynchronous HTTP application.\nPython asyncio\nIn fact, the async/await syntax is present only since Python 3.7. Prior to 3.7\ncoroutines were actually written as generators with special annotation attached\nto them.\nPython standard library provides us with a ready-to-use event loop to run our\ncoroutines as well as a set of convenient awaitable operations covering all the\nlowest level blocking operations we usually deal with. If you want to learn more\nabout low level async API in Python,\nPEP3156 is a great place to start.\nFurthermore, there is a huge number of libraries making use of this low level\nAPI. They implement HTTP clients, web frameworks, database drivers and many\nothers. My favourite asynchronous libraries in Python are:\nasynchronous HTTP client aiohttp,\nweb framework FastAPI and\nMongoDB driver Motor.\nIn reality, the Python event loop runs on futures, also known as promises\nin other languages. Coroutines are implemented with tasks which rely on\nfutures. Our implementation is actually simplified as it bypasses some abstraction\nlayers. You should remember that when looking into Python sources, \nso you don’t get confused!\nWhen I first started learning coroutines I had hard times trying to figure out\nall the strange behaviours myself. It was only the understanding of how things\nwork inside that helped me finally feel it. I hope my explanation will help you\nnot only understand how to use coroutines, but also let you gain\nconfidence and intuition about how asynchronous programming works.\nHappy coding!","guid":"https://blog.allegro.tech/2022/01/how-do-coroutines-work-internally-in-python.html","categories":["tech","python","async","coroutines"],"isoDate":"2022-01-23T23:00:00.000Z","thumbnail":"images/post-headers/python.png"},{"title":"Shrinking the size of a monorepo","link":"https://blog.allegro.tech/2022/01/shrinking-size-of-monorepo.html","pubDate":"Wed, 12 Jan 2022 00:00:00 +0100","authors":{"author":[{"name":["Maciej Piotrowski"],"photo":["https://blog.allegro.tech/img/authors/maciej.piotrowski.jpg"],"url":["https://blog.allegro.tech/authors/maciej.piotrowski"]}]},"content":"<p>The source code of Allegro iOS app for buyers used to be divided into separate modules hosted in multiple repositories\n(polyrepo). The\nsource code was migrated to a monorepo a few years back along with the history of all repos that constituted the app.\nUpdating source code of a module on one repository could affect another module hosted on a separate repository.\nVersioning modules and propagation of dependency update led to long release process of the entire application.\nOur main\nrepository for the iOS application thus became our monorepo. After 9 years of development of the app the repo size has\ngrown\nenormously and the <code class=\"language-plaintext highlighter-rouge\">git clone</code> command became a nightmare taking too much time. We had a possibility to shrink the\nproject size during the\nmigration from an on-premise to an external git repo hosting provider.</p>\n\n<h2 id=\"monorepo-scale\">Monorepo scale</h2>\n\n<h3 id=\"general-repo-scale\">General repo scale</h3>\n\n<p>The General scale of our old repository was as follows:</p>\n\n<ul>\n  <li>almost 9 years of history with <strong>91k +</strong> commits</li>\n  <li><strong>440k</strong> <a href=\"https://en.wikipedia.org/wiki/Binary_large_object\">BLOBs</a> were stored in the repo: multiple <code class=\"language-plaintext highlighter-rouge\">.png</code> and\n<code class=\"language-plaintext highlighter-rouge\">.jpeg</code> files, 3rd-party frameworks and toolset binaries. The unpacked size of the BLOBs would add up to <strong>36 GB</strong> and\nthe biggest BLOB stored was <strong>100+ MB</strong></li>\n  <li><strong>680k</strong> git <em>tree</em> objects</li>\n  <li>the unpacked repo size on the main development branch was <strong>8+ GB</strong> where the <code class=\"language-plaintext highlighter-rouge\">.git</code> dir size after a clone was\n<strong>7+ GB</strong>. The <code class=\"language-plaintext highlighter-rouge\">.git</code> directory contained compressed <code class=\"language-plaintext highlighter-rouge\">.png</code> (<strong>4.5+ GB</strong> 🤯) and <code class=\"language-plaintext highlighter-rouge\">.pbxproj</code> (<strong>600+ MB</strong>) files</li>\n</ul>\n\n<h3 id=\"new-repo-scale\">New repo scale</h3>\n\n<p>After the migration and history rewrite we shrank the repo size to:</p>\n\n<ul>\n  <li><strong>71k +</strong> commits</li>\n  <li><strong>230k</strong> <a href=\"https://en.wikipedia.org/wiki/Binary_large_object\">BLOBs</a>, where all BLOBs unpacked would add up to\n<strong>1.6 GB</strong> - this\nnumber also includes size of source code files, whereas assets and binaries were migrated to an external storage</li>\n  <li><strong>455k+</strong> git <em>tree</em> objects</li>\n</ul>\n\n<h2 id=\"how-did-we-do-it\">How did we do it?</h2>\n\n<p>The history-rewrite process required proper planning and a few steps:</p>\n<ol>\n  <li>Analysis of the old repo contents and its history</li>\n  <li>Creating a reproducible procedure for the history rewrite</li>\n  <li>Dry running the procedure to test out the process</li>\n  <li>Planning and scheduling activities necessary to migrate the repo</li>\n  <li>Proper communication about the process to stakeholders (a.k.a. developers 👩‍💻👨‍💻)</li>\n  <li>The actual migration</li>\n</ol>\n\n<h3 id=\"the-repo-analysis\">The repo analysis</h3>\n\n<p>Goals:</p>\n<ul>\n  <li>find items that can be removed from the history</li>\n  <li>select items that can be migrated to an external storage</li>\n</ul>\n\n<p>We used tools such as <a href=\"https://github.com/github/git-sizer\">git-sizer</a> and\n<a href=\"https://github.com/newren/git-filter-repo\">git-filter-repo tool</a> to\nget information about types of files stored in the repository. If you wanted to do the same the workshops from\n<a href=\"https://githubuniverse.com/professional-services-workshop-2-how-to-keep-git-monorepos-manageable/\">GitHub Universe</a> and\n<a href=\"https://github.com/githubuniverseworkshops/grafting-monorepos/issues/2\">the scripts introduced there</a> might be a good\nstarting point.</p>\n\n<p>From the analysis we were able to select the following items for complete removal from the history:</p>\n\n<ul>\n  <li>deleted dirs and files</li>\n  <li>unwanted paths: e.g. <code class=\"language-plaintext highlighter-rouge\">Pods/</code>, invalid symlinks causing deep nesting of paths</li>\n  <li>unwanted history of paths: e.g. <code class=\"language-plaintext highlighter-rouge\">Vendor</code> for storing 3rd party dependencies or <code class=\"language-plaintext highlighter-rouge\">Toolset</code> with binaries</li>\n  <li>unwanted files: .e.g <code class=\"language-plaintext highlighter-rouge\">.pbxproj</code> that can be generated by <a href=\"https://github.com/yonaskolb/XcodeGen\">XcodeGen</a> and their\nhistory is meaningless (<strong>600+ MB</strong> savings in our case), history of BLOB files such as <code class=\"language-plaintext highlighter-rouge\">.jpg</code>, <code class=\"language-plaintext highlighter-rouge\">.png</code>, <code class=\"language-plaintext highlighter-rouge\">.a</code>,\n<code class=\"language-plaintext highlighter-rouge\">.dylib</code>, <code class=\"language-plaintext highlighter-rouge\">.pdf</code>, <code class=\"language-plaintext highlighter-rouge\">.zip</code>, <code class=\"language-plaintext highlighter-rouge\">.mp4</code>, <code class=\"language-plaintext highlighter-rouge\">.json</code></li>\n</ul>\n\n<p>We decided to track BLOBs using <a href=\"https://git-lfs.github.com/\">Git LFS (Large File Storage)</a>. In our case the\nfollowing were a good use case for it:</p>\n<ul>\n  <li>large binary files <code class=\"language-plaintext highlighter-rouge\">.jpg</code>, <code class=\"language-plaintext highlighter-rouge\">.png</code>, <code class=\"language-plaintext highlighter-rouge\">.a</code>, <code class=\"language-plaintext highlighter-rouge\">.dylib</code>, <code class=\"language-plaintext highlighter-rouge\">.pdf</code>, <code class=\"language-plaintext highlighter-rouge\">.zip</code>, <code class=\"language-plaintext highlighter-rouge\">.mp4</code>, <code class=\"language-plaintext highlighter-rouge\">.json</code></li>\n  <li>framework binaries</li>\n  <li>toolset binaries</li>\n</ul>\n\n<h3 id=\"reproducible-procedure-and-dry-runs\">Reproducible procedure and dry runs</h3>\n\n<p>We created a script that contained all commands that removed redundant items from the history. To remove items we used\n<a href=\"https://github.com/newren/git-filter-repo\">git filter-repo</a> - it‘s much more performant than git‘s built-in\n <code class=\"language-plaintext highlighter-rouge\">git filter-branch</code> (do not use it!). Some examples of usage:</p>\n\n<div class=\"language-shell highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>git filter-repo <span class=\"nt\">--invert-paths</span> <span class=\"nt\">--path</span> Pods/ <span class=\"nt\">--force</span>\ngit filter-repo <span class=\"nt\">--invert-paths</span> <span class=\"nt\">--paths-from-file</span> remove.txt <span class=\"nt\">--force</span>\ngit filter-repo <span class=\"nt\">--invert-paths</span> <span class=\"nt\">--path-glob</span> <span class=\"s1\">'*.pbxproj'</span> <span class=\"nt\">--force</span>\n\n</code></pre></div></div>\n\n<p>After the removal we restored the most-recent version of binaries, frameworks and BLOBs to the repo and we tracked them\nwith Git LFS:</p>\n\n<div class=\"language-shell highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>git lfs track <span class=\"s2\">\"*.png\"</span>\ngit lfs track <span class=\"s2\">\"Vendor/SomeSDK/SomeSDK.framework/SomeSDK\"</span>\n\n</code></pre></div></div>\n\n<p>We ran the script a few times to verify the output size of the repo. One crucial aspect after the run was to verify\nthat <strong>all plans</strong> on the CI (Continuous Integration) pass - we did it to check that the app still compiles, tests pass\nand no more files that the ones we had wanted were actually deleted.</p>\n\n<h3 id=\"communication\">Communication</h3>\n\n<p>The crucial aspect of introducing any change is communication. It‘s good to prepare it in advance, have team members\nreview it. We used a few channels so that our devs would get important info about the migration and history rewrite\nthrough the channel that suited their working habits best (e-mails, instant messaging tool, dev forums).</p>\n\n<h2 id=\"some-final-thoughts\">Some final thoughts</h2>\n\n<p>It took a large amount of time to prepare the migration, understand the history of the repository and select proper\nitems and\nstrategies for the migration. The links here might be a good starting point if you wanted to rewrite histories of your\noverweight repos:</p>\n\n<ul>\n  <li><a href=\"https://www.youtube.com/watch?v=bk7akV8nyAM\">GitHub Universe Workshops</a> and corresponding\n<a href=\"https://github.com/githubuniverseworkshops/grafting-monorepos\">repository</a></li>\n  <li><a href=\"https://github.com/github/git-sizer\">git-sizer</a></li>\n  <li><a href=\"https://github.com/newren/git-filter-repo\">git filter-repo</a></li>\n</ul>\n\n<p>When creating a plan for the rewrite, remember to have a checklist that you can use to verify outcomes and to remember\nall the steps involved in the process. If the repository migration from one provider to another hosting provider is\nrequired execute it together with the history rewrite. Plan the rewrite for a time that folks would not want to\npush code to the repo. We used Friday evening, and yes, we had to fix some issues over the weekend - not everything\nwent smoothly.</p>\n\n<p>You can have a copy of your old repository in READ-ONLY mode on the servers - it will serve as a <strong>backup</strong> and will\ncontain the actual history.</p>\n","contentSnippet":"The source code of Allegro iOS app for buyers used to be divided into separate modules hosted in multiple repositories\n(polyrepo). The\nsource code was migrated to a monorepo a few years back along with the history of all repos that constituted the app.\nUpdating source code of a module on one repository could affect another module hosted on a separate repository.\nVersioning modules and propagation of dependency update led to long release process of the entire application.\nOur main\nrepository for the iOS application thus became our monorepo. After 9 years of development of the app the repo size has\ngrown\nenormously and the git clone command became a nightmare taking too much time. We had a possibility to shrink the\nproject size during the\nmigration from an on-premise to an external git repo hosting provider.\nMonorepo scale\nGeneral repo scale\nThe General scale of our old repository was as follows:\nalmost 9 years of history with 91k + commits\n440k BLOBs were stored in the repo: multiple .png and\n.jpeg files, 3rd-party frameworks and toolset binaries. The unpacked size of the BLOBs would add up to 36 GB and\nthe biggest BLOB stored was 100+ MB\n680k git tree objects\nthe unpacked repo size on the main development branch was 8+ GB where the .git dir size after a clone was\n7+ GB. The .git directory contained compressed .png (4.5+ GB 🤯) and .pbxproj (600+ MB) files\nNew repo scale\nAfter the migration and history rewrite we shrank the repo size to:\n71k + commits\n230k BLOBs, where all BLOBs unpacked would add up to\n1.6 GB - this\nnumber also includes size of source code files, whereas assets and binaries were migrated to an external storage\n455k+ git tree objects\nHow did we do it?\nThe history-rewrite process required proper planning and a few steps:\nAnalysis of the old repo contents and its history\nCreating a reproducible procedure for the history rewrite\nDry running the procedure to test out the process\nPlanning and scheduling activities necessary to migrate the repo\nProper communication about the process to stakeholders (a.k.a. developers 👩‍💻👨‍💻)\nThe actual migration\nThe repo analysis\nGoals:\nfind items that can be removed from the history\nselect items that can be migrated to an external storage\nWe used tools such as git-sizer and\ngit-filter-repo tool to\nget information about types of files stored in the repository. If you wanted to do the same the workshops from\nGitHub Universe and\nthe scripts introduced there might be a good\nstarting point.\nFrom the analysis we were able to select the following items for complete removal from the history:\ndeleted dirs and files\nunwanted paths: e.g. Pods/, invalid symlinks causing deep nesting of paths\nunwanted history of paths: e.g. Vendor for storing 3rd party dependencies or Toolset with binaries\nunwanted files: .e.g .pbxproj that can be generated by XcodeGen and their\nhistory is meaningless (600+ MB savings in our case), history of BLOB files such as .jpg, .png, .a,\n.dylib, .pdf, .zip, .mp4, .json\nWe decided to track BLOBs using Git LFS (Large File Storage). In our case the\nfollowing were a good use case for it:\nlarge binary files .jpg, .png, .a, .dylib, .pdf, .zip, .mp4, .json\nframework binaries\ntoolset binaries\nReproducible procedure and dry runs\nWe created a script that contained all commands that removed redundant items from the history. To remove items we used\ngit filter-repo - it‘s much more performant than git‘s built-in\n git filter-branch (do not use it!). Some examples of usage:\n\ngit filter-repo --invert-paths --path Pods/ --force\ngit filter-repo --invert-paths --paths-from-file remove.txt --force\ngit filter-repo --invert-paths --path-glob '*.pbxproj' --force\n\n\n\nAfter the removal we restored the most-recent version of binaries, frameworks and BLOBs to the repo and we tracked them\nwith Git LFS:\n\ngit lfs track \"*.png\"\ngit lfs track \"Vendor/SomeSDK/SomeSDK.framework/SomeSDK\"\n\n\n\nWe ran the script a few times to verify the output size of the repo. One crucial aspect after the run was to verify\nthat all plans on the CI (Continuous Integration) pass - we did it to check that the app still compiles, tests pass\nand no more files that the ones we had wanted were actually deleted.\nCommunication\nThe crucial aspect of introducing any change is communication. It‘s good to prepare it in advance, have team members\nreview it. We used a few channels so that our devs would get important info about the migration and history rewrite\nthrough the channel that suited their working habits best (e-mails, instant messaging tool, dev forums).\nSome final thoughts\nIt took a large amount of time to prepare the migration, understand the history of the repository and select proper\nitems and\nstrategies for the migration. The links here might be a good starting point if you wanted to rewrite histories of your\noverweight repos:\nGitHub Universe Workshops and corresponding\nrepository\ngit-sizer\ngit filter-repo\nWhen creating a plan for the rewrite, remember to have a checklist that you can use to verify outcomes and to remember\nall the steps involved in the process. If the repository migration from one provider to another hosting provider is\nrequired execute it together with the history rewrite. Plan the rewrite for a time that folks would not want to\npush code to the repo. We used Friday evening, and yes, we had to fix some issues over the weekend - not everything\nwent smoothly.\nYou can have a copy of your old repository in READ-ONLY mode on the servers - it will serve as a backup and will\ncontain the actual history.","guid":"https://blog.allegro.tech/2022/01/shrinking-size-of-monorepo.html","categories":["tech","ios","git","mobile","swift","objectivec"],"isoDate":"2022-01-11T23:00:00.000Z","thumbnail":"images/post-headers/ios.png"},{"title":"Evaluating performance of time series collections","link":"https://blog.allegro.tech/2021/12/performance-evaluation-of-timeseries.html","pubDate":"Mon, 20 Dec 2021 00:00:00 +0100","authors":{"author":[{"name":["Michał Knasiecki"],"photo":["https://blog.allegro.tech/img/authors/michal.knasiecki.jpg"],"url":["https://blog.allegro.tech/authors/michal.knasiecki"]}]},"content":"<p>A few years ago, I was working on a new version of <a href=\"https://allegro.tech\">Allegro</a> purchase ratings.\nIt was a time of a pretty large revolution in the rating system when we moved this product away from our monolith, also\nintroducing quite significant changes to the concept of purchase rating itself. Replacing the system of positive, neutral\nor negative rating, we introduced an approach based on “thumbs up” and “thumbs down” as well as the option to rate several\nelements of the purchase separately: the time and cost of delivery, or products’ conformity with its description. The\nproduct-related revolution was accompanied by a major change in technology. Apart from transitioning towards the\nmicroservices architecture, we also decided to migrate data from a large relational database to MongoDB. There were many\nreasons for this decision: from the non-relational nature of our model, through the need for easier scaling, to the wish\nfor cost reduction. Upon completion of the works, we were for the most part content with the decision that we made. The\nnew solution was more user-friendly, easier to maintain and worked smoothly. The sole exception was aggregation queries,\nspecifically: determining the average of seller ratings in a specified period of time. While at the level of the 99th\npercentile times were very low, some queries were much slower. We spent a lot of time optimising both queries and the\ncode, and had to use some programming tricks to achieve satisfactory results. While we were able to solve our problems in\nthe end, the final conclusion was that the aggregation of data in large MongoDB collections is quite challenging.</p>\n\n<h2 id=\"to-the-rescue-time-series\">To the rescue: Time series</h2>\n<p>A new version of MongoDB, 5.0, has been recently launched. The list of changes included one that I found particularly\ninteresting: the time series collections. It is a method of effective storing and processing of time-ordered value series.\nA classic example for this case is measuring the temperature of air. These measurements are taken\nperiodically (for instance every hour), and their sequence forms time series. We then often review such data in an\nappropriate order, as well as calculate the maximum and minimum values, or the arithmetic mean. Therefore, in the said\ncase of use, a database must be highly efficient when saving the data, store records in a compact manner due to the\nlarge number thereof, and must quickly calculate aggregates. Although in the case of temperature readings database write\noperations are made on a regular basis, it turns out that in the case of time series it is not mandatory, and the only\nthing that truly matters is the presence of time. While reading about this topic, I instantly remembered my countless\nlate nights struggling with slow ratings aggregations. Therefore, I decided to explore this topic and see how the\nsolution works in practice.</p>\n\n<p>Before the release of MongoDB 5.0, the only way to efficiently process time series was to store pre-calculated\naggregates, or use a <a href=\"https://www.mongodb.com/blog/post/building-with-patterns-the-bucket-pattern\">bucket pattern</a>,\nwhich was obviously associated with additional work and complexity of the\ncode. Now, things have been made much easier as this additional complexity is covered by a convenient abstraction. In\nMongoDB, time series are not actual collections, but materialised views that cover physical collections. This\nabstraction is intended to simplify complicated operations based on “buckets” of documents. You can read more about the\nconcept of storing data in the new kind of collection on the MongoDB <a href=\"https://www.mongodb.com/developer/how-to/new-time-series-collections/\">official blog</a>.\nEveryone who is interested in using this solution should take a look at it. In my article, on the other hand, I would\nlike to verify whether the processing of time series is really as fast as promised by the authors.</p>\n\n<h2 id=\"data-preparation\">Data preparation</h2>\n<p>For the purposes of our considerations I will use a simple document describing the rating in the form of:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>{\n    \"timestamp\" : ISODate(\"2021-10-22T00:00:00.000Z\"),\n    \"rating\" : 2.0\n}\n</code></pre></div></div>\n\n<p>Attentive readers will immediately notice the absence of the field containing the ID of the seller whom the rating\nconcerns. It was done intentionally, otherwise I would have to\ncreate an additional index covering this field. However, I did not want to introduce any additional elements in my\nexperiment that could have any impact on the results. Let’s assume for this experiment that we are rating a\nrestaurant, not Allegro sellers, therefore all ratings in the collection concern the restaurant only.</p>\n\n<p>Now we can create two collections storing an identical set of data. One will be a standard collection, and the other will\nbe a time series. The time series collection has to be created manually by indicating the field specifying the time label:</p>\n\n<div class=\"language-javascript highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nx\">db</span><span class=\"p\">.</span><span class=\"nx\">createCollection</span><span class=\"p\">(</span><span class=\"dl\">\"</span><span class=\"s2\">coll-ts</span><span class=\"dl\">\"</span><span class=\"p\">,</span> <span class=\"p\">{</span> <span class=\"na\">timeseries</span><span class=\"p\">:</span> <span class=\"p\">{</span> <span class=\"na\">timeField</span><span class=\"p\">:</span> <span class=\"dl\">\"</span><span class=\"s2\">timestamp</span><span class=\"dl\">\"</span> <span class=\"p\">}</span> <span class=\"p\">}</span> <span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>If you did not install Mongo 5.0 from scratch, but updated its previous version, you should make sure that\nit is set to an adequate level of compatibility. Otherwise, the above command will not create a time series collection.\nYou can check it with this command:</p>\n\n<div class=\"language-javascript highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nx\">db</span><span class=\"p\">.</span><span class=\"nx\">adminCommand</span><span class=\"p\">(</span> <span class=\"p\">{</span> <span class=\"na\">getParameter</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"na\">featureCompatibilityVersion</span><span class=\"p\">:</span> <span class=\"mi\">1</span> <span class=\"p\">}</span> <span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>If the returned value is less than 5.0, you need to issue:</p>\n\n<div class=\"language-javascript highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nx\">db</span><span class=\"p\">.</span><span class=\"nx\">adminCommand</span><span class=\"p\">(</span> <span class=\"p\">{</span> <span class=\"na\">setFeatureCompatibilityVersion</span><span class=\"p\">:</span> <span class=\"dl\">\"</span><span class=\"s2\">5.0</span><span class=\"dl\">\"</span> <span class=\"p\">}</span> <span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>Upon creating a collection, it is also worth checking that a time series has actually been created:</p>\n\n<div class=\"language-javascript highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nx\">db</span><span class=\"p\">.</span><span class=\"nx\">runCommand</span><span class=\"p\">(</span> <span class=\"p\">{</span> <span class=\"na\">listCollections</span><span class=\"p\">:</span> <span class=\"mf\">1.0</span> <span class=\"p\">}</span> <span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>We look for <code class=\"language-plaintext highlighter-rouge\">\"type\" : \"timeseries\"</code> entry:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>{\n    \"name\" : \"coll-ts\",\n    \"type\" : \"timeseries\",\n    \"options\" : {\n        \"timeseries\" : {\n            \"timeField\" : \"timestamp\",\n            \"granularity\" : \"seconds\",\n            \"bucketMaxSpanSeconds\" : 3600\n        }\n    },\n    \"info\" : {\n        \"readOnly\" : false\n    }\n}\n</code></pre></div></div>\n\n<p>We will also create the second collection manually (although it is not necessary, because it would be created with the\nfirst INSERT command). We will want to check the speed of data search based on time field, so we will create a unique index:</p>\n\n<div class=\"language-javascript highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nx\">db</span><span class=\"p\">.</span><span class=\"nx\">createCollection</span><span class=\"p\">(</span><span class=\"dl\">\"</span><span class=\"s2\">coll-ord</span><span class=\"dl\">\"</span><span class=\"p\">)</span>\n<span class=\"nx\">db</span><span class=\"p\">.</span><span class=\"nx\">getCollection</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">coll-ord</span><span class=\"dl\">'</span><span class=\"p\">).</span><span class=\"nx\">createIndex</span><span class=\"p\">({</span><span class=\"na\">timestamp</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">},</span> <span class=\"p\">{</span><span class=\"na\">unique</span><span class=\"p\">:</span> <span class=\"kc\">true</span><span class=\"p\">})</span>\n</code></pre></div></div>\n\n<p>Let’s use the following scripts to fill both collections with 10 million documents:</p>\n\n<div class=\"language-javascript highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// Save as fill-ts.js</span>\n<span class=\"kd\">var</span> <span class=\"nx\">bulk</span> <span class=\"o\">=</span> <span class=\"nx\">db</span><span class=\"p\">.</span><span class=\"nx\">getCollection</span><span class=\"p\">(</span><span class=\"dl\">\"</span><span class=\"s2\">coll-ts</span><span class=\"dl\">\"</span><span class=\"p\">).</span><span class=\"nx\">initializeUnorderedBulkOp</span><span class=\"p\">();</span>\n<span class=\"kd\">var</span> <span class=\"nx\">startTime</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"nb\">Date</span><span class=\"p\">(</span><span class=\"dl\">\"</span><span class=\"s2\">2021-10-22T00:00:00.000Z</span><span class=\"dl\">\"</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kd\">let</span> <span class=\"nx\">i</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"nx\">i</span> <span class=\"o\">&lt;</span> <span class=\"mi\">10000000</span><span class=\"p\">;</span> <span class=\"nx\">i</span><span class=\"o\">++</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"nx\">bulk</span><span class=\"p\">.</span><span class=\"nx\">insert</span><span class=\"p\">({</span>\n       <span class=\"dl\">\"</span><span class=\"s2\">timestamp</span><span class=\"dl\">\"</span><span class=\"p\">:</span> <span class=\"k\">new</span> <span class=\"nb\">Date</span><span class=\"p\">(</span><span class=\"nx\">startTime</span><span class=\"p\">.</span><span class=\"nx\">getTime</span><span class=\"p\">()</span> <span class=\"o\">+</span> <span class=\"nx\">i</span> <span class=\"o\">*</span> <span class=\"mi\">60000</span><span class=\"p\">),</span>\n       <span class=\"dl\">\"</span><span class=\"s2\">rating</span><span class=\"dl\">\"</span><span class=\"p\">:</span> <span class=\"nb\">Math</span><span class=\"p\">.</span><span class=\"nx\">floor</span><span class=\"p\">(</span><span class=\"mi\">1</span> <span class=\"o\">+</span> <span class=\"nb\">Math</span><span class=\"p\">.</span><span class=\"nx\">random</span><span class=\"p\">()</span> <span class=\"o\">*</span> <span class=\"mi\">4</span><span class=\"p\">)</span>\n    <span class=\"p\">})</span>\n<span class=\"p\">}</span>\n<span class=\"nx\">bulk</span><span class=\"p\">.</span><span class=\"nx\">execute</span><span class=\"p\">();</span>\n</code></pre></div></div>\n\n<div class=\"language-javascript highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// Save as fill-ord.js</span>\n<span class=\"kd\">var</span> <span class=\"nx\">bulk</span> <span class=\"o\">=</span> <span class=\"nx\">db</span><span class=\"p\">.</span><span class=\"nx\">getCollection</span><span class=\"p\">(</span><span class=\"dl\">\"</span><span class=\"s2\">coll-ord</span><span class=\"dl\">\"</span><span class=\"p\">).</span><span class=\"nx\">initializeUnorderedBulkOp</span><span class=\"p\">();</span>\n<span class=\"kd\">var</span> <span class=\"nx\">startTime</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"nb\">Date</span><span class=\"p\">(</span><span class=\"dl\">\"</span><span class=\"s2\">2021-10-22T00:00:00.000Z</span><span class=\"dl\">\"</span><span class=\"p\">)</span>\n<span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"kd\">let</span> <span class=\"nx\">i</span> <span class=\"o\">=</span> <span class=\"mi\">0</span><span class=\"p\">;</span> <span class=\"nx\">i</span> <span class=\"o\">&lt;</span> <span class=\"mi\">10000000</span><span class=\"p\">;</span> <span class=\"nx\">i</span><span class=\"o\">++</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"nx\">bulk</span><span class=\"p\">.</span><span class=\"nx\">insert</span><span class=\"p\">({</span>\n       <span class=\"dl\">\"</span><span class=\"s2\">timestamp</span><span class=\"dl\">\"</span><span class=\"p\">:</span> <span class=\"k\">new</span> <span class=\"nb\">Date</span><span class=\"p\">(</span><span class=\"nx\">startTime</span><span class=\"p\">.</span><span class=\"nx\">getTime</span><span class=\"p\">()</span> <span class=\"o\">+</span> <span class=\"nx\">i</span> <span class=\"o\">*</span> <span class=\"mi\">60000</span><span class=\"p\">),</span>\n       <span class=\"dl\">\"</span><span class=\"s2\">rating</span><span class=\"dl\">\"</span><span class=\"p\">:</span> <span class=\"nb\">Math</span><span class=\"p\">.</span><span class=\"nx\">floor</span><span class=\"p\">(</span><span class=\"mi\">1</span> <span class=\"o\">+</span> <span class=\"nb\">Math</span><span class=\"p\">.</span><span class=\"nx\">random</span><span class=\"p\">()</span> <span class=\"o\">*</span> <span class=\"mi\">4</span><span class=\"p\">)</span>\n    <span class=\"p\">})</span>\n<span class=\"p\">}</span>\n<span class=\"nx\">bulk</span><span class=\"p\">.</span><span class=\"nx\">execute</span><span class=\"p\">();</span>\n</code></pre></div></div>\n\n<p>It is worth to measure the execution time of scripts to compare write times to both collections. For this purpose I use\n<code class=\"language-plaintext highlighter-rouge\">time</code> command and <code class=\"language-plaintext highlighter-rouge\">mongo</code> command-line client, <code class=\"language-plaintext highlighter-rouge\">test</code> is the name of my database.\nTo avoid network latency I perform the measurements on my laptop with a local instance of MongoDB version 5.0.3 running.</p>\n\n<div class=\"language-shell highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">time </span>mongo <span class=\"nb\">test </span>fill-ts.js\n</code></pre></div></div>\n\n<div class=\"language-shell highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">time </span>mongo <span class=\"nb\">test </span>fill-ord.js\n</code></pre></div></div>\n\n<p>As expected, the filling of the time series collection was faster: 3:30,11 vs 4:39,48. Such a difference can be essential\nif our system performs many write operations in a short period of time. At the very beginning of our experiments\ncollection of a new type comes to the forefront.</p>\n\n<p>Now when our collections already contain data, we can take a look at the size of files. On the\n<a href=\"https://docs.mongodb.com/manual/core/timeseries-collections/\">manual page</a> we can read that:</p>\n\n<blockquote>\n  <p>Compared to normal collections, storing time series data in time series collections improves query efficiency and\nreduces the disk usage</p>\n</blockquote>\n\n<p>Let’s find out how true that is.</p>\n\n<h2 id=\"a-closer-look-at-the-data\">A closer look at the data</h2>\n\n<p>In the first place, it is worth making sure that documents in both collections look the same:</p>\n\n<div class=\"language-javascript highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nx\">db</span><span class=\"p\">.</span><span class=\"nx\">getCollection</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">coll-ts</span><span class=\"dl\">'</span><span class=\"p\">).</span><span class=\"nx\">find</span><span class=\"p\">({}).</span><span class=\"nx\">limit</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n<span class=\"nx\">db</span><span class=\"p\">.</span><span class=\"nx\">getCollection</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">coll-ord</span><span class=\"dl\">'</span><span class=\"p\">).</span><span class=\"nx\">find</span><span class=\"p\">({}).</span><span class=\"nx\">limit</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>Both documents should be similar to this one:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>{\n    \"timestamp\" : ISODate(\"2021-10-22T00:00:00.000Z\"),\n    \"_id\" : ObjectId(\"6184126fc42d1ab73d5208e4\"),\n    \"rating\" : 2.0\n}\n</code></pre></div></div>\n\n<p>The documents have the same schema. In addition, the <code class=\"language-plaintext highlighter-rouge\">_id</code> key was automatically generated in both cases, although our\nfilling script did not contain them.</p>\n\n<p>Let’s move on to indexes now and use the commands: <code class=\"language-plaintext highlighter-rouge\">db.getCollection('coll-ord').getIndexes()</code> and <code class=\"language-plaintext highlighter-rouge\">db.getCollection('coll-ts').getIndexes()</code>\nto get the indexes of both collections.</p>\n\n<p>The normal collection has two indexes, one that was created automatically for the <code class=\"language-plaintext highlighter-rouge\">_id</code> key and the one that we created manually:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>// coll-ord:\n[\n    {\n        \"v\" : 2,\n        \"key\" : {\n            \"_id\" : 1\n        },\n        \"name\" : \"_id_\"\n    },\n    {\n        \"v\" : 2,\n        \"key\" : {\n            \"timestamp\" : 1.0\n        },\n        \"name\" : \"timestamp_1\",\n        \"unique\" : true\n    }\n]\n</code></pre></div></div>\n\n<p>What is interesting is that the time series collection has no index at all:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>// coll-ts:\n[]\n</code></pre></div></div>\n\n<p>The lack of the index for the <code class=\"language-plaintext highlighter-rouge\">_id</code> key of\ncourse means that, by default, the time series collection will have to perform the <code class=\"language-plaintext highlighter-rouge\">COLLSCAN</code> operation if we want to\nsearch documents based on <code class=\"language-plaintext highlighter-rouge\">_id</code>. The index is probably missing simply to save disc space and storage time,\nstemming from the assumption that the time series collections are mainly used to search based on time. The lack of\nthe index for the timestamp field is much more surprising. Does it mean that time-based searches in time series will\nalso cause <code class=\"language-plaintext highlighter-rouge\">COLLCSAN</code> and work slowly? The answer to this question can be found in the documentation:</p>\n<blockquote>\n  <p>The internal index for a time series collection is not displayed</p>\n</blockquote>\n\n<p>So, there actually is an index, but it is different from those created manually, and even from indexes created\nautomatically for the <code class=\"language-plaintext highlighter-rouge\">_id</code> key.\nAs I wrote in another <a href=\"/2021/10/comparing-mongodb-composite-indexes.html\">post</a>, indexes are not all the\nsame, so it’s worth taking a closer look at this one. Let’s check the query execution plans:</p>\n\n<div class=\"language-javascript highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nx\">db</span><span class=\"p\">.</span><span class=\"nx\">getCollection</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">coll-ord</span><span class=\"dl\">'</span><span class=\"p\">).</span><span class=\"nx\">find</span><span class=\"p\">({</span><span class=\"dl\">\"</span><span class=\"s2\">timestamp</span><span class=\"dl\">\"</span> <span class=\"p\">:</span> <span class=\"nx\">ISODate</span><span class=\"p\">(</span><span class=\"dl\">\"</span><span class=\"s2\">2021-10-22T00:00:00.000Z</span><span class=\"dl\">\"</span><span class=\"p\">)}).</span><span class=\"nx\">explain</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">executionStats</span><span class=\"dl\">'</span><span class=\"p\">)</span>\n<span class=\"nx\">db</span><span class=\"p\">.</span><span class=\"nx\">getCollection</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">coll-ts</span><span class=\"dl\">'</span><span class=\"p\">).</span><span class=\"nx\">find</span><span class=\"p\">({</span><span class=\"dl\">\"</span><span class=\"s2\">timestamp</span><span class=\"dl\">\"</span> <span class=\"p\">:</span> <span class=\"nx\">ISODate</span><span class=\"p\">(</span><span class=\"dl\">\"</span><span class=\"s2\">2021-10-22T00:00:00.000Z</span><span class=\"dl\">\"</span><span class=\"p\">)}).</span><span class=\"nx\">explain</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">executionStats</span><span class=\"dl\">'</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>//coll-ord\n\"winningPlan\" : {\n    \"stage\" : \"FETCH\",\n    \"inputStage\" : {\n        \"stage\" : \"IXSCAN\",\n        \"keyPattern\" : {\n            \"timestamp\" : 1.0\n        }\n    },\n    \"indexName\" : \"timestamp_1\",\n}\n</code></pre></div></div>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>//coll-ts\n\"winningPlan\" : {\n    \"stage\" : \"COLLSCAN\",\n    \"filter\" : {\n        \"$and\" : [\n            {\n                \"_id\" : {\n                    \"$lte\" : ObjectId(\"6171ff00ffffffffffffffff\")\n                }\n            },\n            {\n                \"_id\" : {\n                    \"$gte\" : ObjectId(\"6171f0f00000000000000000\")\n                }\n            },\n            {\n                \"control.max.timestamp\" : {\n                    \"$_internalExprGte\" : ISODate(\"2021-10-22T00:00:00.000Z\")\n                }\n            },\n            {\n                \"control.min.timestamp\" : {\n                    \"$_internalExprLte\" : ISODate(\"2021-10-22T00:00:00.000Z\")\n                }\n            }\n        ]\n    },\n}\n</code></pre></div></div>\n\n<p>It turns out that while in the case of the regular collection the plan shows the use of the index, in the time series\ncollection we see the <code class=\"language-plaintext highlighter-rouge\">COLLSCAN</code> operation. It doesn’t mean that this operation is slow, though. The execution times of\nboth operations were similar. We will move on to a more detailed time comparison in a moment; for now we should only\nnote that the hidden index in the time series collection follows specific rules, it is not only invisible, but it also\ncannot be seen in the execution plan, although it clearly affects the speed of the search.</p>\n\n<p>And what happens if we add sorting?</p>\n\n<div class=\"language-javascript highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nx\">db</span><span class=\"p\">.</span><span class=\"nx\">getCollection</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">coll-ts</span><span class=\"dl\">'</span><span class=\"p\">).</span><span class=\"nx\">find</span><span class=\"p\">({}).</span><span class=\"nx\">sort</span><span class=\"p\">({</span><span class=\"na\">timestamp</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">})</span>\n</code></pre></div></div>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>{\n \"ok\" : 0,\n \"errmsg\" : \"PlanExecutor error during aggregation :: caused by :: Sort exceeded memory limit of 104857600 bytes,\n but did not opt in to external sorting.\",\n \"code\" : 292,\n \"codeName\" : \"QueryExceededMemoryLimitNoDiskUseAllowed\"\n}\n</code></pre></div></div>\n\n<p>Surprise! The internal index for the time series collection does not have a sorting feature. This means that if we add\nthe sort clause to our query, the operation will take very long, or even fail because of exceeding the memory\nlimit. It is surprising because I did not find any information on this in the documentation. Therefore, if we plan to\nsort our data based on the field with time, we will need to index this field manually. It means, of\ncourse, that the benefits stemming from a lower disc usage and faster saving times will unfortunately diminish.</p>\n\n<p>Since we are talking about the use of disc space, let’s check the data size:</p>\n\n<div class=\"language-javascript highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nx\">db</span><span class=\"p\">.</span><span class=\"nx\">getCollection</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">coll-ts</span><span class=\"dl\">'</span><span class=\"p\">).</span><span class=\"nx\">stats</span><span class=\"p\">()</span>\n<span class=\"nx\">db</span><span class=\"p\">.</span><span class=\"nx\">getCollection</span><span class=\"p\">(</span><span class=\"dl\">'</span><span class=\"s1\">coll-ord</span><span class=\"dl\">'</span><span class=\"p\">).</span><span class=\"nx\">stats</span><span class=\"p\">()</span>\n</code></pre></div></div>\n\n<p>We will compare several fields:</p>\n\n<ul>\n  <li><code class=\"language-plaintext highlighter-rouge\">size</code>: data size before the compression,</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">storageSize</code>: size of data after the compression,</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">totalIndexSize</code>: size of indexes,</li>\n  <li><code class=\"language-plaintext highlighter-rouge\">totalSize</code>: total size of data and indexes.</li>\n</ul>\n\n<p>Results are gathered in the table below (in bytes, space is thousand separator):</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>Field</th>\n      <th style=\"text-align: right\">Normal collection</th>\n      <th style=\"text-align: right\">Time series collection</th>\n      <th style=\"text-align: center\">Diff</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>size</td>\n      <td style=\"text-align: right\">570 000 000</td>\n      <td style=\"text-align: right\">747 855 228</td>\n      <td style=\"text-align: center\">+ 31%</td>\n    </tr>\n    <tr>\n      <td>storageSize</td>\n      <td style=\"text-align: right\">175 407 104</td>\n      <td style=\"text-align: right\">119 410 688</td>\n      <td style=\"text-align: center\">-31%</td>\n    </tr>\n    <tr>\n      <td>totalIndexSize</td>\n      <td style=\"text-align: right\">232 701 952</td>\n      <td style=\"text-align: right\">0</td>\n      <td style=\"text-align: center\">-100%</td>\n    </tr>\n    <tr>\n      <td>totalSize</td>\n      <td style=\"text-align: right\">408 109 056</td>\n      <td style=\"text-align: right\">119 410 688</td>\n      <td style=\"text-align: center\">-70%</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>As you can see, raw data of the time series collection may take up more space, but after their compression the new-type\ncollection turns out to be the winner in the size-on-disc category. After adding the size of indexes created in the\nregular collection, the difference will be even greater. Therefore, we must admit that the way time series data are\npacked on the disc is impressive.</p>\n\n<p>Now it’s time to compare query execution times for both collections.</p>\n\n<h2 id=\"speed-is-all-that-matters\">Speed is all that matters</h2>\n\n<p>Using the script below (saved as <code class=\"language-plaintext highlighter-rouge\">gen-find.sh</code> file), I generated two files containing commands getting documents from\nboth collections based on the\ntime label:</p>\n\n<div class=\"language-shell highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\">#!/bin/bash</span>\n<span class=\"nv\">RANDOM</span><span class=\"o\">=</span>42\n<span class=\"k\">for</span> <span class=\"o\">((</span>i <span class=\"o\">=</span> 1<span class=\"p\">;</span> i &lt;<span class=\"o\">=</span> <span class=\"nv\">$1</span><span class=\"p\">;</span> i++ <span class=\"o\">))</span><span class=\"p\">;</span>\n<span class=\"k\">do\n  </span><span class=\"nv\">x</span><span class=\"o\">=</span><span class=\"k\">$((</span> <span class=\"nv\">$RANDOM</span> <span class=\"o\">%</span> <span class=\"m\">10000000</span><span class=\"k\">))</span>\n  <span class=\"nv\">t</span><span class=\"o\">=</span><span class=\"si\">$(</span><span class=\"nb\">date</span> <span class=\"nt\">-jv</span> +<span class=\"k\">${</span><span class=\"nv\">x</span><span class=\"k\">}</span>M <span class=\"nt\">-f</span> <span class=\"s2\">\"%Y-%m-%d %H:%M:%S\"</span> <span class=\"s2\">\"2021-10-22 0:00:00\"</span> +%Y-%m-%dT%H:%M:%S<span class=\"si\">)</span>\n  <span class=\"nb\">echo</span> <span class=\"s2\">\"db.getCollection('</span><span class=\"nv\">$2</span><span class=\"s2\">').find({'timestamp' : new ISODate('</span><span class=\"nv\">$t</span><span class=\"s2\">')})\"</span>\n<span class=\"k\">done</span> <span class=\"o\">&gt;&gt;</span> find-<span class=\"nv\">$2</span>.js\n</code></pre></div></div>\n\n<p>The script takes as parameters: the number of queries, and the name of the collection that we want to search. I\ngenerated a million queries (it may take some time depending on your hardware, so you can start with a lower amount of\nqueries):</p>\n\n<div class=\"language-shell highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>./gen-find.sh 1000000 coll-ts\n./gen-find.sh 1000000 coll-ord\n</code></pre></div></div>\n\n<p>Then I checked the time of the execution of both query sequences using the command:</p>\n\n<div class=\"language-shell highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">time </span>mongo <span class=\"nb\">test </span>find-coll-ts.js\n<span class=\"nb\">time </span>mongo <span class=\"nb\">test </span>find-coll-ord.js\n</code></pre></div></div>\n\n<p>The standard collection was a bit slower: 16,854 for <code class=\"language-plaintext highlighter-rouge\">coll-ord</code> vs 16,038 for <code class=\"language-plaintext highlighter-rouge\">coll-ts</code>. Although the difference is small,\nanother point goes to time series: simple search is slightly faster than in the case of the regular collection.</p>\n\n<p>But we’re yet to discuss the most interesting part. Time series is primarily used for quick aggregate counting. Let’s\nsee what the comparison looks like when calculating the arithmetic mean in a given time interval.</p>\n\n<p>The script below (saved as <code class=\"language-plaintext highlighter-rouge\">gen-aggregate.sh</code>) creates a list of queries calculating the arithmetic mean of ratings for\na randomly selected six-hour interval:</p>\n\n<div class=\"language-shell highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\">#!/bin/bash</span>\n<span class=\"nv\">RANDOM</span><span class=\"o\">=</span>42\n<span class=\"k\">for</span> <span class=\"o\">((</span>i <span class=\"o\">=</span> 1<span class=\"p\">;</span> i &lt;<span class=\"o\">=</span> <span class=\"nv\">$1</span><span class=\"p\">;</span> i++ <span class=\"o\">))</span><span class=\"p\">;</span>\n<span class=\"k\">do\n  </span><span class=\"nv\">x1</span><span class=\"o\">=</span><span class=\"k\">$((</span> <span class=\"nv\">$RANDOM</span> <span class=\"o\">%</span> <span class=\"m\">10000000</span><span class=\"k\">))</span>\n  <span class=\"nv\">x2</span><span class=\"o\">=</span><span class=\"k\">$((</span> x1 <span class=\"o\">+</span> <span class=\"m\">360</span><span class=\"k\">))</span>\n  <span class=\"nv\">t1</span><span class=\"o\">=</span><span class=\"si\">$(</span><span class=\"nb\">date</span> <span class=\"nt\">-jv</span> +<span class=\"k\">${</span><span class=\"nv\">x1</span><span class=\"k\">}</span>M <span class=\"nt\">-f</span> <span class=\"s2\">\"%Y-%m-%d %H:%M:%S\"</span> <span class=\"s2\">\"2021-10-22 0:00:00\"</span> +%Y-%m-%dT%H:%M:%S<span class=\"si\">)</span>\n  <span class=\"nv\">t2</span><span class=\"o\">=</span><span class=\"si\">$(</span><span class=\"nb\">date</span> <span class=\"nt\">-jv</span> +<span class=\"k\">${</span><span class=\"nv\">x2</span><span class=\"k\">}</span>M <span class=\"nt\">-f</span> <span class=\"s2\">\"%Y-%m-%d %H:%M:%S\"</span> <span class=\"s2\">\"2021-10-22 0:00:00\"</span> +%Y-%m-%dT%H:%M:%S<span class=\"si\">)</span>\n  <span class=\"nb\">echo</span> <span class=\"s2\">\"db.getCollection('</span><span class=\"nv\">$2</span><span class=\"s2\">').aggregate([{ </span><span class=\"se\">\\$</span><span class=\"s2\">match: { \"</span>timestamp<span class=\"s2\">\" : \"</span> <span class=\"se\">\\</span>\n    <span class=\"s2\">\"{</span><span class=\"se\">\\$</span><span class=\"s2\">gte:new ISODate('</span><span class=\"nv\">$t1</span><span class=\"s2\">'),</span><span class=\"se\">\\$</span><span class=\"s2\">lt:new ISODate('</span><span class=\"nv\">$t2</span><span class=\"s2\">')} } },\"</span> <span class=\"se\">\\</span>\n    <span class=\"s2\">\"{ </span><span class=\"se\">\\$</span><span class=\"s2\">group: { _id: null, avg: { </span><span class=\"se\">\\$</span><span class=\"s2\">avg: </span><span class=\"se\">\\\"\\$</span><span class=\"s2\">rating</span><span class=\"se\">\\\"</span><span class=\"s2\"> } } }])\"</span>\n<span class=\"k\">done</span> <span class=\"o\">&gt;&gt;</span> aggregate-<span class=\"nv\">$2</span>-<span class=\"nv\">$1</span>.js\n</code></pre></div></div>\n\n<p>I prepared three script sets with: 10K, 50K and 100K queries for both collections:</p>\n\n<div class=\"language-shell highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>./gen-aggregate.sh 10000 coll-ts\n./gen-aggregate.sh 50000 coll-ts\n./gen-aggregate.sh 100000 coll-ts\n\n./gen-aggregate.sh 10000 coll-ord\n./gen-aggregate.sh 50000 coll-ord\n./gen-aggregate.sh 100000 coll-ord\n</code></pre></div></div>\n\n<p>I made the measurements using following commands:</p>\n\n<div class=\"language-shell highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nb\">time </span>mongo <span class=\"nb\">test </span>aggregate-coll-ts-10000.js\n<span class=\"nb\">time </span>mongo <span class=\"nb\">test </span>aggregate-coll-ord-10000.js\n\n<span class=\"nb\">time </span>mongo <span class=\"nb\">test </span>aggregate-coll-ts-50000.js\n<span class=\"nb\">time </span>mongo <span class=\"nb\">test </span>aggregate-coll-ord-50000.js\n\n<span class=\"nb\">time </span>mongo <span class=\"nb\">test </span>aggregate-coll-ts-100000.js\n<span class=\"nb\">time </span>mongo <span class=\"nb\">test </span>aggregate-coll-ord-100000.js\n\n</code></pre></div></div>\n\n<p>The results are shown in the table below:</p>\n\n<table>\n  <thead>\n    <tr>\n      <th style=\"text-align: center\">Number of queries</th>\n      <th style=\"text-align: right\">Normal collection [min:sec]</th>\n      <th style=\"text-align: right\">Time series [min:sec]</th>\n      <th style=\"text-align: center\">Diff</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td style=\"text-align: center\">10000</td>\n      <td style=\"text-align: right\">0:21,947</td>\n      <td style=\"text-align: right\">0:16,835</td>\n      <td style=\"text-align: center\">-23%</td>\n    </tr>\n    <tr>\n      <td style=\"text-align: center\">50000</td>\n      <td style=\"text-align: right\">1:37,02</td>\n      <td style=\"text-align: right\">1:11,18</td>\n      <td style=\"text-align: center\">-26%</td>\n    </tr>\n    <tr>\n      <td style=\"text-align: center\">100000</td>\n      <td style=\"text-align: right\">4:33,29</td>\n      <td style=\"text-align: right\">2:21,37</td>\n      <td style=\"text-align: center\">-48%</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>Although there are far fewer queries this time than in the previous experiment, the differences in times are much\ngreater. It clearly proves that time series collections are indeed spreading their wings when we want to use aggregation\nqueries and have been developed mainly for this purpose. The reason is probably the sequential way of writing data,\nwhich shows a noticeable improvement when running ranged queries. The results clearly show also how much of an impact\nquery performance can have on an element that often doesn’t get the adequate attention: proper modelling the data.</p>\n\n<h2 id=\"limitations\">Limitations</h2>\n\n<p>Of course, time series collections also have their limitations and should not be used as a golden hammer.\nWe have already mentioned the first one — the lack of the primary key index. It stems from the assumption\nthat searches will be primarily based on time, so there is no point in creating an index that will be useful for very\nfew people. Of course, we can create this index ourselves.</p>\n\n<p>It is also not possible to sort by time field, which is another inconvenience. If we want to have\nsorting queries, we have to create an additional index.</p>\n\n<p>Although these two missing indexes may seem to be an easy thing to fix, we must remember that it involves additional use\nof disc space as well as longer indexing time during the saving of the document, which means that the benefits\nstemming from the use of time series will be somewhat reduced.</p>\n\n<p>The third, and perhaps most import limitation is the immutability of the document. Once saved, documents cannot be\nupdated or deleted. The only way to delete data is to use <code class=\"language-plaintext highlighter-rouge\">drop()</code> command or to define retention for the collection\nusing the <code class=\"language-plaintext highlighter-rouge\">expireAfterSeconds</code> parameter, which, like TTL indexes, will automatically delete documents certain time\nafter creation.</p>\n\n<p>The lack of possibility to manipulate the saved documents will probably be the main reason why programmers will be\nhesitant to use time series. We should mention, however, that the authors of MongoDB will probably add the possibility\nto edit and delete documents in the future:</p>\n\n<blockquote>\n  <p>While we know some of these limitations may be impactful to your current use case, we promise we’re working on this\nright now and would love for you to provide your feedback!</p>\n</blockquote>\n\n<h2 id=\"summary\">Summary</h2>\n<p>Adding the ability to store time series in MongoDB is a step in the right direction. First tests show that in certain\ncases the new type of collections really does work better than the regular ones. They use less disc space, are faster at\nsaving and searching by the time. But high performance always comes at a cost, in this case: the cost of reduced flexibility.\nTherefore, the final decision to use time series should be preceded by an analysis of\nadvantages and disadvantages of both in particular cases. We should also hope that the authors of the database are\nworking on improving it and will soon eliminate most limitations.</p>\n","contentSnippet":"A few years ago, I was working on a new version of Allegro purchase ratings.\nIt was a time of a pretty large revolution in the rating system when we moved this product away from our monolith, also\nintroducing quite significant changes to the concept of purchase rating itself. Replacing the system of positive, neutral\nor negative rating, we introduced an approach based on “thumbs up” and “thumbs down” as well as the option to rate several\nelements of the purchase separately: the time and cost of delivery, or products’ conformity with its description. The\nproduct-related revolution was accompanied by a major change in technology. Apart from transitioning towards the\nmicroservices architecture, we also decided to migrate data from a large relational database to MongoDB. There were many\nreasons for this decision: from the non-relational nature of our model, through the need for easier scaling, to the wish\nfor cost reduction. Upon completion of the works, we were for the most part content with the decision that we made. The\nnew solution was more user-friendly, easier to maintain and worked smoothly. The sole exception was aggregation queries,\nspecifically: determining the average of seller ratings in a specified period of time. While at the level of the 99th\npercentile times were very low, some queries were much slower. We spent a lot of time optimising both queries and the\ncode, and had to use some programming tricks to achieve satisfactory results. While we were able to solve our problems in\nthe end, the final conclusion was that the aggregation of data in large MongoDB collections is quite challenging.\nTo the rescue: Time series\nA new version of MongoDB, 5.0, has been recently launched. The list of changes included one that I found particularly\ninteresting: the time series collections. It is a method of effective storing and processing of time-ordered value series.\nA classic example for this case is measuring the temperature of air. These measurements are taken\nperiodically (for instance every hour), and their sequence forms time series. We then often review such data in an\nappropriate order, as well as calculate the maximum and minimum values, or the arithmetic mean. Therefore, in the said\ncase of use, a database must be highly efficient when saving the data, store records in a compact manner due to the\nlarge number thereof, and must quickly calculate aggregates. Although in the case of temperature readings database write\noperations are made on a regular basis, it turns out that in the case of time series it is not mandatory, and the only\nthing that truly matters is the presence of time. While reading about this topic, I instantly remembered my countless\nlate nights struggling with slow ratings aggregations. Therefore, I decided to explore this topic and see how the\nsolution works in practice.\nBefore the release of MongoDB 5.0, the only way to efficiently process time series was to store pre-calculated\naggregates, or use a bucket pattern,\nwhich was obviously associated with additional work and complexity of the\ncode. Now, things have been made much easier as this additional complexity is covered by a convenient abstraction. In\nMongoDB, time series are not actual collections, but materialised views that cover physical collections. This\nabstraction is intended to simplify complicated operations based on “buckets” of documents. You can read more about the\nconcept of storing data in the new kind of collection on the MongoDB official blog.\nEveryone who is interested in using this solution should take a look at it. In my article, on the other hand, I would\nlike to verify whether the processing of time series is really as fast as promised by the authors.\nData preparation\nFor the purposes of our considerations I will use a simple document describing the rating in the form of:\n\n{\n    \"timestamp\" : ISODate(\"2021-10-22T00:00:00.000Z\"),\n    \"rating\" : 2.0\n}\n\n\nAttentive readers will immediately notice the absence of the field containing the ID of the seller whom the rating\nconcerns. It was done intentionally, otherwise I would have to\ncreate an additional index covering this field. However, I did not want to introduce any additional elements in my\nexperiment that could have any impact on the results. Let’s assume for this experiment that we are rating a\nrestaurant, not Allegro sellers, therefore all ratings in the collection concern the restaurant only.\nNow we can create two collections storing an identical set of data. One will be a standard collection, and the other will\nbe a time series. The time series collection has to be created manually by indicating the field specifying the time label:\n\ndb.createCollection(\"coll-ts\", { timeseries: { timeField: \"timestamp\" } } )\n\n\nIf you did not install Mongo 5.0 from scratch, but updated its previous version, you should make sure that\nit is set to an adequate level of compatibility. Otherwise, the above command will not create a time series collection.\nYou can check it with this command:\n\ndb.adminCommand( { getParameter: 1, featureCompatibilityVersion: 1 } )\n\n\nIf the returned value is less than 5.0, you need to issue:\n\ndb.adminCommand( { setFeatureCompatibilityVersion: \"5.0\" } )\n\n\nUpon creating a collection, it is also worth checking that a time series has actually been created:\n\ndb.runCommand( { listCollections: 1.0 } )\n\n\nWe look for \"type\" : \"timeseries\" entry:\n\n{\n    \"name\" : \"coll-ts\",\n    \"type\" : \"timeseries\",\n    \"options\" : {\n        \"timeseries\" : {\n            \"timeField\" : \"timestamp\",\n            \"granularity\" : \"seconds\",\n            \"bucketMaxSpanSeconds\" : 3600\n        }\n    },\n    \"info\" : {\n        \"readOnly\" : false\n    }\n}\n\n\nWe will also create the second collection manually (although it is not necessary, because it would be created with the\nfirst INSERT command). We will want to check the speed of data search based on time field, so we will create a unique index:\n\ndb.createCollection(\"coll-ord\")\ndb.getCollection('coll-ord').createIndex({timestamp: 1}, {unique: true})\n\n\nLet’s use the following scripts to fill both collections with 10 million documents:\n\n// Save as fill-ts.js\nvar bulk = db.getCollection(\"coll-ts\").initializeUnorderedBulkOp();\nvar startTime = new Date(\"2021-10-22T00:00:00.000Z\")\nfor (let i = 0; i < 10000000; i++) {\n    bulk.insert({\n       \"timestamp\": new Date(startTime.getTime() + i * 60000),\n       \"rating\": Math.floor(1 + Math.random() * 4)\n    })\n}\nbulk.execute();\n\n\n\n// Save as fill-ord.js\nvar bulk = db.getCollection(\"coll-ord\").initializeUnorderedBulkOp();\nvar startTime = new Date(\"2021-10-22T00:00:00.000Z\")\nfor (let i = 0; i < 10000000; i++) {\n    bulk.insert({\n       \"timestamp\": new Date(startTime.getTime() + i * 60000),\n       \"rating\": Math.floor(1 + Math.random() * 4)\n    })\n}\nbulk.execute();\n\n\nIt is worth to measure the execution time of scripts to compare write times to both collections. For this purpose I use\ntime command and mongo command-line client, test is the name of my database.\nTo avoid network latency I perform the measurements on my laptop with a local instance of MongoDB version 5.0.3 running.\n\ntime mongo test fill-ts.js\n\n\n\ntime mongo test fill-ord.js\n\n\nAs expected, the filling of the time series collection was faster: 3:30,11 vs 4:39,48. Such a difference can be essential\nif our system performs many write operations in a short period of time. At the very beginning of our experiments\ncollection of a new type comes to the forefront.\nNow when our collections already contain data, we can take a look at the size of files. On the\nmanual page we can read that:\nCompared to normal collections, storing time series data in time series collections improves query efficiency and\nreduces the disk usage\nLet’s find out how true that is.\nA closer look at the data\nIn the first place, it is worth making sure that documents in both collections look the same:\n\ndb.getCollection('coll-ts').find({}).limit(1)\ndb.getCollection('coll-ord').find({}).limit(1)\n\n\nBoth documents should be similar to this one:\n\n{\n    \"timestamp\" : ISODate(\"2021-10-22T00:00:00.000Z\"),\n    \"_id\" : ObjectId(\"6184126fc42d1ab73d5208e4\"),\n    \"rating\" : 2.0\n}\n\n\nThe documents have the same schema. In addition, the _id key was automatically generated in both cases, although our\nfilling script did not contain them.\nLet’s move on to indexes now and use the commands: db.getCollection('coll-ord').getIndexes() and db.getCollection('coll-ts').getIndexes()\nto get the indexes of both collections.\nThe normal collection has two indexes, one that was created automatically for the _id key and the one that we created manually:\n\n// coll-ord:\n[\n    {\n        \"v\" : 2,\n        \"key\" : {\n            \"_id\" : 1\n        },\n        \"name\" : \"_id_\"\n    },\n    {\n        \"v\" : 2,\n        \"key\" : {\n            \"timestamp\" : 1.0\n        },\n        \"name\" : \"timestamp_1\",\n        \"unique\" : true\n    }\n]\n\n\nWhat is interesting is that the time series collection has no index at all:\n\n// coll-ts:\n[]\n\n\nThe lack of the index for the _id key of\ncourse means that, by default, the time series collection will have to perform the COLLSCAN operation if we want to\nsearch documents based on _id. The index is probably missing simply to save disc space and storage time,\nstemming from the assumption that the time series collections are mainly used to search based on time. The lack of\nthe index for the timestamp field is much more surprising. Does it mean that time-based searches in time series will\nalso cause COLLCSAN and work slowly? The answer to this question can be found in the documentation:\nThe internal index for a time series collection is not displayed\nSo, there actually is an index, but it is different from those created manually, and even from indexes created\nautomatically for the _id key.\nAs I wrote in another post, indexes are not all the\nsame, so it’s worth taking a closer look at this one. Let’s check the query execution plans:\n\ndb.getCollection('coll-ord').find({\"timestamp\" : ISODate(\"2021-10-22T00:00:00.000Z\")}).explain('executionStats')\ndb.getCollection('coll-ts').find({\"timestamp\" : ISODate(\"2021-10-22T00:00:00.000Z\")}).explain('executionStats')\n\n\n\n//coll-ord\n\"winningPlan\" : {\n    \"stage\" : \"FETCH\",\n    \"inputStage\" : {\n        \"stage\" : \"IXSCAN\",\n        \"keyPattern\" : {\n            \"timestamp\" : 1.0\n        }\n    },\n    \"indexName\" : \"timestamp_1\",\n}\n\n\n\n//coll-ts\n\"winningPlan\" : {\n    \"stage\" : \"COLLSCAN\",\n    \"filter\" : {\n        \"$and\" : [\n            {\n                \"_id\" : {\n                    \"$lte\" : ObjectId(\"6171ff00ffffffffffffffff\")\n                }\n            },\n            {\n                \"_id\" : {\n                    \"$gte\" : ObjectId(\"6171f0f00000000000000000\")\n                }\n            },\n            {\n                \"control.max.timestamp\" : {\n                    \"$_internalExprGte\" : ISODate(\"2021-10-22T00:00:00.000Z\")\n                }\n            },\n            {\n                \"control.min.timestamp\" : {\n                    \"$_internalExprLte\" : ISODate(\"2021-10-22T00:00:00.000Z\")\n                }\n            }\n        ]\n    },\n}\n\n\nIt turns out that while in the case of the regular collection the plan shows the use of the index, in the time series\ncollection we see the COLLSCAN operation. It doesn’t mean that this operation is slow, though. The execution times of\nboth operations were similar. We will move on to a more detailed time comparison in a moment; for now we should only\nnote that the hidden index in the time series collection follows specific rules, it is not only invisible, but it also\ncannot be seen in the execution plan, although it clearly affects the speed of the search.\nAnd what happens if we add sorting?\n\ndb.getCollection('coll-ts').find({}).sort({timestamp: 1})\n\n\n\n{\n \"ok\" : 0,\n \"errmsg\" : \"PlanExecutor error during aggregation :: caused by :: Sort exceeded memory limit of 104857600 bytes,\n but did not opt in to external sorting.\",\n \"code\" : 292,\n \"codeName\" : \"QueryExceededMemoryLimitNoDiskUseAllowed\"\n}\n\n\nSurprise! The internal index for the time series collection does not have a sorting feature. This means that if we add\nthe sort clause to our query, the operation will take very long, or even fail because of exceeding the memory\nlimit. It is surprising because I did not find any information on this in the documentation. Therefore, if we plan to\nsort our data based on the field with time, we will need to index this field manually. It means, of\ncourse, that the benefits stemming from a lower disc usage and faster saving times will unfortunately diminish.\nSince we are talking about the use of disc space, let’s check the data size:\n\ndb.getCollection('coll-ts').stats()\ndb.getCollection('coll-ord').stats()\n\n\nWe will compare several fields:\nsize: data size before the compression,\nstorageSize: size of data after the compression,\ntotalIndexSize: size of indexes,\ntotalSize: total size of data and indexes.\nResults are gathered in the table below (in bytes, space is thousand separator):\nField\n      Normal collection\n      Time series collection\n      Diff\n    \nsize\n      570 000 000\n      747 855 228\n      + 31%\n    \nstorageSize\n      175 407 104\n      119 410 688\n      -31%\n    \ntotalIndexSize\n      232 701 952\n      0\n      -100%\n    \ntotalSize\n      408 109 056\n      119 410 688\n      -70%\n    \nAs you can see, raw data of the time series collection may take up more space, but after their compression the new-type\ncollection turns out to be the winner in the size-on-disc category. After adding the size of indexes created in the\nregular collection, the difference will be even greater. Therefore, we must admit that the way time series data are\npacked on the disc is impressive.\nNow it’s time to compare query execution times for both collections.\nSpeed is all that matters\nUsing the script below (saved as gen-find.sh file), I generated two files containing commands getting documents from\nboth collections based on the\ntime label:\n\n#!/bin/bash\nRANDOM=42\nfor ((i = 1; i <= $1; i++ ));\ndo\n  x=$(( $RANDOM % 10000000))\n  t=$(date -jv +${x}M -f \"%Y-%m-%d %H:%M:%S\" \"2021-10-22 0:00:00\" +%Y-%m-%dT%H:%M:%S)\n  echo \"db.getCollection('$2').find({'timestamp' : new ISODate('$t')})\"\ndone >> find-$2.js\n\n\nThe script takes as parameters: the number of queries, and the name of the collection that we want to search. I\ngenerated a million queries (it may take some time depending on your hardware, so you can start with a lower amount of\nqueries):\n\n./gen-find.sh 1000000 coll-ts\n./gen-find.sh 1000000 coll-ord\n\n\nThen I checked the time of the execution of both query sequences using the command:\n\ntime mongo test find-coll-ts.js\ntime mongo test find-coll-ord.js\n\n\nThe standard collection was a bit slower: 16,854 for coll-ord vs 16,038 for coll-ts. Although the difference is small,\nanother point goes to time series: simple search is slightly faster than in the case of the regular collection.\nBut we’re yet to discuss the most interesting part. Time series is primarily used for quick aggregate counting. Let’s\nsee what the comparison looks like when calculating the arithmetic mean in a given time interval.\nThe script below (saved as gen-aggregate.sh) creates a list of queries calculating the arithmetic mean of ratings for\na randomly selected six-hour interval:\n\n#!/bin/bash\nRANDOM=42\nfor ((i = 1; i <= $1; i++ ));\ndo\n  x1=$(( $RANDOM % 10000000))\n  x2=$(( x1 + 360))\n  t1=$(date -jv +${x1}M -f \"%Y-%m-%d %H:%M:%S\" \"2021-10-22 0:00:00\" +%Y-%m-%dT%H:%M:%S)\n  t2=$(date -jv +${x2}M -f \"%Y-%m-%d %H:%M:%S\" \"2021-10-22 0:00:00\" +%Y-%m-%dT%H:%M:%S)\n  echo \"db.getCollection('$2').aggregate([{ \\$match: { \"timestamp\" : \" \\\n    \"{\\$gte:new ISODate('$t1'),\\$lt:new ISODate('$t2')} } },\" \\\n    \"{ \\$group: { _id: null, avg: { \\$avg: \\\"\\$rating\\\" } } }])\"\ndone >> aggregate-$2-$1.js\n\n\nI prepared three script sets with: 10K, 50K and 100K queries for both collections:\n\n./gen-aggregate.sh 10000 coll-ts\n./gen-aggregate.sh 50000 coll-ts\n./gen-aggregate.sh 100000 coll-ts\n\n./gen-aggregate.sh 10000 coll-ord\n./gen-aggregate.sh 50000 coll-ord\n./gen-aggregate.sh 100000 coll-ord\n\n\nI made the measurements using following commands:\n\ntime mongo test aggregate-coll-ts-10000.js\ntime mongo test aggregate-coll-ord-10000.js\n\ntime mongo test aggregate-coll-ts-50000.js\ntime mongo test aggregate-coll-ord-50000.js\n\ntime mongo test aggregate-coll-ts-100000.js\ntime mongo test aggregate-coll-ord-100000.js\n\n\n\nThe results are shown in the table below:\nNumber of queries\n      Normal collection [min:sec]\n      Time series [min:sec]\n      Diff\n    \n10000\n      0:21,947\n      0:16,835\n      -23%\n    \n50000\n      1:37,02\n      1:11,18\n      -26%\n    \n100000\n      4:33,29\n      2:21,37\n      -48%\n    \nAlthough there are far fewer queries this time than in the previous experiment, the differences in times are much\ngreater. It clearly proves that time series collections are indeed spreading their wings when we want to use aggregation\nqueries and have been developed mainly for this purpose. The reason is probably the sequential way of writing data,\nwhich shows a noticeable improvement when running ranged queries. The results clearly show also how much of an impact\nquery performance can have on an element that often doesn’t get the adequate attention: proper modelling the data.\nLimitations\nOf course, time series collections also have their limitations and should not be used as a golden hammer.\nWe have already mentioned the first one — the lack of the primary key index. It stems from the assumption\nthat searches will be primarily based on time, so there is no point in creating an index that will be useful for very\nfew people. Of course, we can create this index ourselves.\nIt is also not possible to sort by time field, which is another inconvenience. If we want to have\nsorting queries, we have to create an additional index.\nAlthough these two missing indexes may seem to be an easy thing to fix, we must remember that it involves additional use\nof disc space as well as longer indexing time during the saving of the document, which means that the benefits\nstemming from the use of time series will be somewhat reduced.\nThe third, and perhaps most import limitation is the immutability of the document. Once saved, documents cannot be\nupdated or deleted. The only way to delete data is to use drop() command or to define retention for the collection\nusing the expireAfterSeconds parameter, which, like TTL indexes, will automatically delete documents certain time\nafter creation.\nThe lack of possibility to manipulate the saved documents will probably be the main reason why programmers will be\nhesitant to use time series. We should mention, however, that the authors of MongoDB will probably add the possibility\nto edit and delete documents in the future:\nWhile we know some of these limitations may be impactful to your current use case, we promise we’re working on this\nright now and would love for you to provide your feedback!\nSummary\nAdding the ability to store time series in MongoDB is a step in the right direction. First tests show that in certain\ncases the new type of collections really does work better than the regular ones. They use less disc space, are faster at\nsaving and searching by the time. But high performance always comes at a cost, in this case: the cost of reduced flexibility.\nTherefore, the final decision to use time series should be preceded by an analysis of\nadvantages and disadvantages of both in particular cases. We should also hope that the authors of the database are\nworking on improving it and will soon eliminate most limitations.","guid":"https://blog.allegro.tech/2021/12/performance-evaluation-of-timeseries.html","categories":["tech","mongodb","performance","time series"],"isoDate":"2021-12-19T23:00:00.000Z","thumbnail":"images/post-headers/mongodb.png"},{"title":"Clean Architecture Story","link":"https://blog.allegro.tech/2021/12/clean-architecture-story.html","pubDate":"Mon, 13 Dec 2021 00:00:00 +0100","authors":{"author":[{"name":["Michał Kowalcze"],"photo":["https://blog.allegro.tech/img/authors/michal.kowalcze.jpg"],"url":["https://blog.allegro.tech/authors/michal.kowalcze"]}]},"content":"<p><a href=\"https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html\">The Clean Architecture</a> concept has been\naround for some time and keeps surfacing in one place or another, yet it is not widely adopted. In this post I would\nlike to introduce this topic in a less conventional way: starting with customer’s needs and going through various\nstages to present a solution that is clean enough to satisfy concepts from the aforementioned blog (or\n<a href=\"https://www.goodreads.com/book/show/18043011-clean-architecture\">the book</a> with the same name).</p>\n\n<h2 id=\"the-perspective\">The perspective</h2>\n<p>Why do we need software architecture? What is it anyway? An extensive definition can be found in a place a bit unexpected\nfor an agile world — an enterprise-architecture definition from <a href=\"https://en.wikipedia.org/wiki/The_Open_Group_Architecture_Framework\">TOGAF</a>:</p>\n\n<ul>\n  <li>The fundamental concepts or properties of a system in its environment embodied in its elements, relationships, and\nin the principles of its design and evolution. (Source: ISO/IEC/IEEE 42010:2011)</li>\n  <li>The structure of components, their inter-relationships, and the principles and guidelines governing their design and\nevolution over time.</li>\n</ul>\n\n<p>And what do we need such a governing structure or shape for? Basically it allows us to make cost/time-efficient choices\nwhen it comes to development. And deployment. And operation. And maintenance.</p>\n\n<p>It also allows us to keep as many options open as possible, so our future choices are not limited by an overcommitment\nfrom the past.</p>\n\n<p>So — we have our perspective defined. Let’s dive into a real-world problem!</p>\n\n<h2 id=\"the-challenge\">The challenge</h2>\n<p>You are a young, promising programmer sitting in a dorm and one afternoon a stranger appears. “I run a small company\nthat delivers packages from furniture shops to customers. I need a database that will allow reservation of slots. Is it\nsomething you are able to deliver?” “Of course!” — what else could a young, promising programmer answer?</p>\n\n<h2 id=\"the-false-start\">The false start</h2>\n<p>The customer needs a database, so what can we start with? The database schema, of course! We can identify entities with\nease: a transport slot, a schedule, a user (we need some authentication, right?), a … something? Okay, perhaps it is\nnot the easiest way. So why don’t we start with something else?</p>\n\n<p>Let’s choose the technology to use! Let’s go with React frontend, Java+Spring backend, some SQL as persistence. To\npresent a clickable version to our customer we need some warm-up work to set up an environment, create a deployable\nservice version or GUI mockups, configure persistence and so on. In general: to pay attention to technical details —\ncode necessary to set up something working, of which non-devs are usually not aware. It simply has to be done before we\nstart talking about nitty-gritty for business logic.</p>\n\n<h2 id=\"the-use-case-driven-approach\">The use-case-driven approach</h2>\n<p>What if instead of starting with what we already know — how to visualize relationships, how to build a web-system — we\nstarted with what we didn’t know? Simply — by asking questions such as: How is the system going to be used? By whom?</p>\n\n<h2 id=\"use-cases\">Use cases</h2>\n<p>In other words — what are the use cases for the system? Let’s define the challenge once more using high-level actors\nand interactions: <img src=\"/img/articles/2021-12-13-clean-architecture-story/use_cases.png\" alt=\"Use cases\" /> and pick the first\nrequired interaction: shop makes a reservation. What is required to make a reservation? Hmm, I think that it would be\ngood to get the current schedule in the first place. Why am I using “get” instead of “display”? “Display” already\nsuggests a way of delivering output, when we hear “display” a computer screen comes to our minds, with a web\napplication. Single page web app, of course. “Get” is more neutral, it does not constrain our vision by a specific\npresentation method. Frankly — is there anything wrong with delivering the current schedule over the phone, for\nexample?</p>\n\n<h3 id=\"getting-the-schedule\">Getting the schedule</h3>\n<p>So, we can start thinking about our schedule model — let it be a single instance representing a day with slots inside.\nGreat, we have our entities! How to get one? Well, we need to check if there is already a stored schedule and if so\n— retrieve it from the repository. If the schedule is not available we have to create one. Based on…? Exactly — we do\nnot know yet, all we can say is that it will probably be something flexible. Something to discuss with our customer\n— but this does not prevent us from going forward with our first use case. Logic is indeed simple:</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">fun</span> <span class=\"nf\">getSchedule</span><span class=\"p\">(</span><span class=\"n\">scheduleDay</span><span class=\"p\">:</span> <span class=\"nc\">LocalDate</span><span class=\"p\">):</span> <span class=\"nc\">DaySchedule</span> <span class=\"p\">{</span>\n  <span class=\"kd\">val</span> <span class=\"py\">daySchedule</span> <span class=\"p\">=</span> <span class=\"n\">daySchedulerRepository</span><span class=\"p\">.</span><span class=\"k\">get</span><span class=\"p\">(</span><span class=\"n\">scheduleDay</span><span class=\"p\">)</span>\n  <span class=\"k\">if</span> <span class=\"p\">(</span><span class=\"n\">daySchedule</span> <span class=\"p\">!=</span> <span class=\"k\">null</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"k\">return</span> <span class=\"n\">daySchedule</span>\n  <span class=\"p\">}</span>\n\n  <span class=\"kd\">val</span> <span class=\"py\">newSchedule</span> <span class=\"p\">=</span> <span class=\"n\">dayScheduleCreator</span><span class=\"p\">.</span><span class=\"nf\">create</span><span class=\"p\">(</span><span class=\"n\">scheduleDay</span><span class=\"p\">)</span>\n  <span class=\"k\">return</span> <span class=\"n\">daySchedulerRepository</span><span class=\"p\">.</span><span class=\"nf\">save</span><span class=\"p\">(</span><span class=\"n\">newSchedule</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>(full commit: <a href=\"https://github.com/michal-kowalcze/clean-architecture-example/commit/6dfeee53554a4ccf37e81aa50a2bd24af7e02cce\">GitHub</a>)</p>\n\n<p>And even with this simple logic we identified a hidden assumption regarding the schedule definition: that there is a\nrecipe for creating a daily schedule. What is more we can test retrieval of a schedule — with definition of schedule\ncreator if required — without any irrelevant details, like database, UI, framework and so on. Test only business rules,\nwithout unnecessary details.</p>\n\n<h2 id=\"reserving-the-slot\">Reserving the slot</h2>\n<p>To finish the reservation we have to add at least one more use case — one for reservation of a free slot. Provided that\nwe re-use existing logic, the interaction is still simple:</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">fun</span> <span class=\"nf\">reserve</span><span class=\"p\">(</span><span class=\"n\">slotId</span><span class=\"p\">:</span> <span class=\"nc\">SlotId</span><span class=\"p\">):</span> <span class=\"nc\">DaySchedule</span> <span class=\"p\">{</span>\n  <span class=\"kd\">val</span> <span class=\"py\">daySchedule</span> <span class=\"p\">=</span> <span class=\"n\">getScheduleUseCase</span><span class=\"p\">.</span><span class=\"nf\">getSchedule</span><span class=\"p\">(</span><span class=\"n\">scheduleDay</span> <span class=\"p\">=</span> <span class=\"n\">slotId</span><span class=\"p\">.</span><span class=\"n\">day</span><span class=\"p\">)</span>\n\n  <span class=\"kd\">val</span> <span class=\"py\">modifiedSchedule</span> <span class=\"p\">=</span> <span class=\"n\">daySchedule</span><span class=\"p\">.</span><span class=\"nf\">reserveSlot</span><span class=\"p\">(</span><span class=\"n\">slotId</span><span class=\"p\">.</span><span class=\"n\">index</span><span class=\"p\">)</span>\n\n  <span class=\"k\">return</span> <span class=\"n\">dayScheduleRepository</span><span class=\"p\">.</span><span class=\"nf\">save</span><span class=\"p\">(</span><span class=\"n\">modifiedSchedule</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>(full commit: <a href=\"https://github.com/michal-kowalcze/clean-architecture-example/commit/7b7961b28107c3c89d40ce69a8383bf9f32337b0\">GitHub</a>)</p>\n\n<p>And, as we can see — the slot reservation business rule (and constraint) is implemented at the domain model itself — so\nwe are safe, that any other interaction, any other use case, is not going to break these rules. This approach also\nsimplifies testing, as business rules can be verified in separation from the use case interaction logic.</p>\n\n<h2 id=\"where-is-the-clean-architecture\">Where is the “Clean Architecture”?</h2>\n<p>Let‘s stop with business logic for a moment. We created quite thoughtful, extensible code for sure, but why are we\ntalking about “Clean” architecture? We already used Domain-Driven Design and Hexagonal architecture concepts. Is there\nanything more? Imagine that another person is going to help us with implementation. She is not aware of the source code\nyet and simply would like to take a look at the codebase. And she sees: <img src=\"/img/articles/2021-12-13-clean-architecture-story/use_case_classes.png\" alt=\"Use case classes\" />\nIt looks like something to her, doesn‘t it? A kind of reservation system! It is not yet another domain service with\nsome methods that have no clear connection with possible uses — the list of classes itself describes what the system\ncan do.</p>\n\n<h2 id=\"the-first-assumption\">The first assumption</h2>\n<p>We have a mocked implementation as the schedule creator. It is OK to test logic at the unit test level, but not enough\nto run a prototype.</p>\n\n<p>After a short call with our customer we know more about the daily schedule — there are six slots, two hours each,\nstarting at 8:oo a.m. We also know that this recipe for the daily schedule is very, very simple and it is going to be\nchanged soon (e.g. to accommodate for holidays, etc.). All these issues will be solved later, now we are at the\nprototype stage and our desired outcome is to have a working demo for our stranger.</p>\n\n<p>Where to put this simple implementation of the schedule creator? So far, the domain used an interface for that. Are we\ngoing to put an implementation of this interface to the infrastructure package and treat it as something outside the\ndomain? Certainly not! It is not complicated and this is part of the domain itself, we simply replace the mocked\nimplementation of the schedule creator with class specification.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">package</span> <span class=\"nn\">eu.kowalcze.michal.arch.clean.example.domain.model</span>\n\n<span class=\"kd\">class</span> <span class=\"nc\">DayScheduleCreator</span> <span class=\"p\">{</span>\n    <span class=\"k\">fun</span> <span class=\"nf\">create</span><span class=\"p\">(</span><span class=\"n\">scheduleDay</span><span class=\"p\">:</span> <span class=\"nc\">LocalDate</span><span class=\"p\">):</span> <span class=\"nc\">DaySchedule</span> <span class=\"p\">=</span> <span class=\"nc\">DaySchedule</span><span class=\"p\">(</span>\n        <span class=\"n\">scheduleDay</span><span class=\"p\">,</span>\n        <span class=\"nf\">createStandardSlots</span><span class=\"p\">()</span>\n    <span class=\"p\">)</span>\n<span class=\"c1\">//...</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>(full commit: <a href=\"https://github.com/michal-kowalcze/clean-architecture-example/commit/2792fc31e98d76a610561636f03073dee73fbb47\">GitHub</a>)</p>\n\n<h2 id=\"the-prototype\">The prototype</h2>\n<p>I will not be original here — for the first prototype version the REST API sounds like something reasonable. Do we care\nabout other infrastructure at the moment? Persistence? No! In the previous commits a map-based persistence layer is\nused for unit tests and this solution is good enough to start with. As long as the system is not restarted, of course.</p>\n\n<p>What is important at this stage? We are introducing an <strong>API</strong> — this is a separate layer, so it is crucial to ensure\nthat domain classes are not exposed to the outside world — and that we do not introduce a dependency on the API into\nthe domain.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">package</span> <span class=\"nn\">eu.kowalcze.michal.arch.clean.example.api</span>\n\n<span class=\"nd\">@Controller</span>\n<span class=\"kd\">class</span> <span class=\"nc\">GetScheduleEndpoint</span><span class=\"p\">(</span><span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">getScheduleUseCase</span><span class=\"p\">:</span> <span class=\"nc\">GetScheduleUseCase</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n\n    <span class=\"nd\">@GetMapping</span><span class=\"p\">(</span><span class=\"s\">\"/schedules/{localDate}\"</span><span class=\"p\">)</span>\n    <span class=\"k\">fun</span> <span class=\"nf\">getSchedules</span><span class=\"p\">(</span><span class=\"nd\">@PathVariable</span> <span class=\"n\">localDate</span><span class=\"p\">:</span> <span class=\"nc\">String</span><span class=\"p\">):</span> <span class=\"nc\">DayScheduleDto</span> <span class=\"p\">{</span>\n        <span class=\"kd\">val</span> <span class=\"py\">scheduleDay</span> <span class=\"p\">=</span> <span class=\"nc\">LocalDate</span><span class=\"p\">.</span><span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"n\">localDate</span><span class=\"p\">)</span>\n        <span class=\"kd\">val</span> <span class=\"py\">daySchedule</span> <span class=\"p\">=</span> <span class=\"n\">getScheduleUseCase</span><span class=\"p\">.</span><span class=\"nf\">getSchedule</span><span class=\"p\">(</span><span class=\"n\">scheduleDay</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">daySchedule</span><span class=\"p\">.</span><span class=\"nf\">toApi</span><span class=\"p\">()</span>\n    <span class=\"p\">}</span>\n\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>(full commit: <a href=\"https://github.com/michal-kowalcze/clean-architecture-example/commit/b1d1c3fe3901d9328bdfaf560331d35131f8224b\">GitHub</a>)</p>\n\n<h2 id=\"the-abstractions\">The abstractions</h2>\n<h3 id=\"use-case\">Use Case</h3>\n<p>Checking the implementation of endpoints (see comments in the code) we can see that conceptually each endpoint executes\nlogic according to the same structure: <img src=\"/img/articles/2021-12-13-clean-architecture-story/use_case_flow.png\" alt=\"Use case flow\" />\nWell, why don’t we make some abstraction for this? Sounds like a crazy idea? Let‘s check! Based on our code and the\ndiagram above we can identify the <code class=\"language-plaintext highlighter-rouge\">UseCase</code> abstraction — something that takes some input (domain input, to be precise)\nand converts it to a (domain) output.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kd\">interface</span> <span class=\"nc\">UseCase</span><span class=\"p\">&lt;</span><span class=\"nc\">INPUT</span><span class=\"p\">,</span> <span class=\"nc\">OUTPUT</span><span class=\"p\">&gt;</span> <span class=\"p\">{</span>\n    <span class=\"k\">fun</span> <span class=\"nf\">apply</span><span class=\"p\">(</span><span class=\"n\">input</span><span class=\"p\">:</span> <span class=\"nc\">INPUT</span><span class=\"p\">):</span> <span class=\"nc\">OUTPUT</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>(full commit: <a href=\"https://github.com/michal-kowalcze/clean-architecture-example/commit/006811b49ae4531b96b300c964d3a66d725183bf\">GitHub</a>)</p>\n\n<h3 id=\"use-case-executor\">Use Case Executor</h3>\n<p>Great! We have use cases and I just realized that I would like to have an email in my inbox each time an exception is\nthrown — and I do not want to depend on a spring-specific mechanism to do this. A common <code class=\"language-plaintext highlighter-rouge\">UseCaseExecutor</code> will be a\ngreat help to address this non-functional requirement.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kd\">class</span> <span class=\"nc\">UseCaseExecutor</span><span class=\"p\">(</span><span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">notificationGateway</span><span class=\"p\">:</span> <span class=\"nc\">NotificationGateway</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"k\">fun</span> <span class=\"p\">&lt;</span><span class=\"nc\">INPUT</span><span class=\"p\">,</span> <span class=\"nc\">OUTPUT</span><span class=\"p\">&gt;</span> <span class=\"nf\">execute</span><span class=\"p\">(</span><span class=\"n\">useCase</span><span class=\"p\">:</span> <span class=\"nc\">UseCase</span><span class=\"p\">&lt;</span><span class=\"nc\">INPUT</span><span class=\"p\">,</span> <span class=\"nc\">OUTPUT</span><span class=\"p\">&gt;,</span> <span class=\"n\">input</span><span class=\"p\">:</span> <span class=\"nc\">INPUT</span><span class=\"p\">):</span> <span class=\"nc\">OUTPUT</span> <span class=\"p\">{</span>\n        <span class=\"k\">try</span> <span class=\"p\">{</span>\n            <span class=\"k\">return</span> <span class=\"n\">useCase</span><span class=\"p\">.</span><span class=\"nf\">apply</span><span class=\"p\">(</span><span class=\"n\">input</span><span class=\"p\">)</span>\n        <span class=\"p\">}</span> <span class=\"k\">catch</span> <span class=\"p\">(</span><span class=\"n\">e</span><span class=\"p\">:</span> <span class=\"nc\">Exception</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n            <span class=\"n\">notificationGateway</span><span class=\"p\">.</span><span class=\"nf\">notify</span><span class=\"p\">(</span><span class=\"n\">useCase</span><span class=\"p\">,</span> <span class=\"n\">e</span><span class=\"p\">)</span>\n            <span class=\"k\">throw</span> <span class=\"n\">e</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>(full commit: <a href=\"https://github.com/michal-kowalcze/clean-architecture-example/commit/54d3187aed94427bb60af9781d0eec573c8c8db0\">GitHub</a>)</p>\n\n<h3 id=\"framework-independent-response\">Framework-independent response</h3>\n<p>In order to handle the next requirements in our plan we have to change the logic a bit — add the possibility of returning\nspring-specific response entities from the executor itself. To make our code reusable in a non-spring world (ktor,\nanyone?) we separated the plain executor from spring specific decorator, so that it is possible to use this code easily\nin other frameworks.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kd\">data class</span> <span class=\"nc\">UseCaseApiResult</span><span class=\"p\">&lt;</span><span class=\"nc\">API_OUTPUT</span><span class=\"p\">&gt;(</span>\n    <span class=\"kd\">val</span> <span class=\"py\">responseCode</span><span class=\"p\">:</span> <span class=\"nc\">Int</span><span class=\"p\">,</span>\n    <span class=\"kd\">val</span> <span class=\"py\">output</span><span class=\"p\">:</span> <span class=\"nc\">API_OUTPUT</span><span class=\"p\">,</span>\n<span class=\"p\">)</span>\n\n<span class=\"kd\">class</span> <span class=\"nc\">SpringUseCaseExecutor</span><span class=\"p\">(</span><span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">useCaseExecutor</span><span class=\"p\">:</span> <span class=\"nc\">UseCaseExecutor</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"k\">fun</span> <span class=\"p\">&lt;</span><span class=\"nc\">DOMAIN_INPUT</span><span class=\"p\">,</span> <span class=\"nc\">DOMAIN_OUTPUT</span><span class=\"p\">,</span> <span class=\"nc\">API_OUTPUT</span><span class=\"p\">&gt;</span> <span class=\"nf\">execute</span><span class=\"p\">(</span>\n        <span class=\"n\">useCase</span><span class=\"p\">:</span> <span class=\"nc\">UseCase</span><span class=\"p\">&lt;</span><span class=\"nc\">DOMAIN_INPUT</span><span class=\"p\">,</span> <span class=\"nc\">DOMAIN_OUTPUT</span><span class=\"p\">&gt;,</span>\n        <span class=\"n\">input</span><span class=\"p\">:</span> <span class=\"nc\">DOMAIN_INPUT</span><span class=\"p\">,</span>\n        <span class=\"n\">toApiConversion</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"n\">domainOutput</span><span class=\"p\">:</span> <span class=\"nc\">DOMAIN_OUTPUT</span><span class=\"p\">)</span> <span class=\"p\">-&gt;</span> <span class=\"nc\">UseCaseApiResult</span><span class=\"p\">&lt;</span><span class=\"nc\">API_OUTPUT</span><span class=\"p\">&gt;</span>\n    <span class=\"p\">):</span> <span class=\"nc\">ResponseEntity</span><span class=\"p\">&lt;</span><span class=\"nc\">API_OUTPUT</span><span class=\"p\">&gt;</span> <span class=\"p\">{</span>\n        <span class=\"k\">return</span> <span class=\"n\">useCaseExecutor</span><span class=\"p\">.</span><span class=\"nf\">execute</span><span class=\"p\">(</span><span class=\"n\">useCase</span><span class=\"p\">,</span> <span class=\"n\">input</span><span class=\"p\">,</span> <span class=\"n\">toApiConversion</span><span class=\"p\">).</span><span class=\"nf\">toSpringResponse</span><span class=\"p\">()</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">private</span> <span class=\"k\">fun</span> <span class=\"p\">&lt;</span><span class=\"nc\">API_OUTPUT</span><span class=\"p\">&gt;</span> <span class=\"nf\">UseCaseApiResult</span><span class=\"p\">&lt;</span><span class=\"nc\">API_OUTPUT</span><span class=\"p\">&gt;.</span><span class=\"nf\">toSpringResponse</span><span class=\"p\">():</span> <span class=\"nc\">ResponseEntity</span><span class=\"p\">&lt;</span><span class=\"nc\">API_OUTPUT</span><span class=\"p\">&gt;</span> <span class=\"p\">=</span>\n    <span class=\"nc\">ResponseEntity</span><span class=\"p\">.</span><span class=\"nf\">status</span><span class=\"p\">(</span><span class=\"n\">responseCode</span><span class=\"p\">).</span><span class=\"nf\">body</span><span class=\"p\">(</span><span class=\"n\">output</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>(full commit: <a href=\"https://github.com/michal-kowalcze/clean-architecture-example/commit/d44f7f993fab2e749e3048561b3ac4d3cff6fd88\">GitHub</a>)</p>\n\n<h3 id=\"handle-domain-exceptions\">Handle domain exceptions</h3>\n<p>Ooops. Our prototype is running and we observe exceptions resulting in HTTP 500 errors. It would be nice to convert\nthese to dedicated response codes in a reasonable way yet without using much of spring infrastructure, for simplified\nmaintenance (and possible future changes). This can be easily achieved by adding another parameter to use case\nexecution, like this:</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kd\">class</span> <span class=\"nc\">UseCaseExecutor</span><span class=\"p\">(</span><span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">notificationGateway</span><span class=\"p\">:</span> <span class=\"nc\">NotificationGateway</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"k\">fun</span> <span class=\"p\">&lt;</span><span class=\"nc\">DOMAIN_INPUT</span><span class=\"p\">,</span> <span class=\"nc\">DOMAIN_OUTPUT</span><span class=\"p\">&gt;</span> <span class=\"nf\">execute</span><span class=\"p\">(</span>\n        <span class=\"n\">useCase</span><span class=\"p\">:</span> <span class=\"nc\">UseCase</span><span class=\"p\">&lt;</span><span class=\"nc\">DOMAIN_INPUT</span><span class=\"p\">,</span> <span class=\"nc\">DOMAIN_OUTPUT</span><span class=\"p\">&gt;,</span>\n        <span class=\"n\">input</span><span class=\"p\">:</span> <span class=\"nc\">DOMAIN_INPUT</span><span class=\"p\">,</span>\n        <span class=\"n\">toApiConversion</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"n\">domainOutput</span><span class=\"p\">:</span> <span class=\"nc\">DOMAIN_OUTPUT</span><span class=\"p\">)</span> <span class=\"p\">-&gt;</span> <span class=\"nc\">UseCaseApiResult</span><span class=\"p\">&lt;</span><span class=\"err\">*</span><span class=\"p\">&gt;,</span>\n        <span class=\"n\">handledExceptions</span><span class=\"p\">:</span> <span class=\"p\">(</span><span class=\"nc\">ExceptionHandler</span><span class=\"p\">.()</span> <span class=\"p\">-&gt;</span> <span class=\"nc\">Any</span><span class=\"p\">)?</span> <span class=\"p\">=</span> <span class=\"k\">null</span><span class=\"p\">,</span>\n    <span class=\"p\">):</span> <span class=\"nc\">UseCaseApiResult</span><span class=\"p\">&lt;</span><span class=\"err\">*</span><span class=\"p\">&gt;</span> <span class=\"p\">{</span>\n\n        <span class=\"k\">try</span> <span class=\"p\">{</span>\n            <span class=\"kd\">val</span> <span class=\"py\">domainOutput</span> <span class=\"p\">=</span> <span class=\"n\">useCase</span><span class=\"p\">.</span><span class=\"nf\">apply</span><span class=\"p\">(</span><span class=\"n\">input</span><span class=\"p\">)</span>\n            <span class=\"k\">return</span> <span class=\"nf\">toApiConversion</span><span class=\"p\">(</span><span class=\"n\">domainOutput</span><span class=\"p\">)</span>\n        <span class=\"p\">}</span> <span class=\"k\">catch</span> <span class=\"p\">(</span><span class=\"n\">e</span><span class=\"p\">:</span> <span class=\"nc\">Exception</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n            <span class=\"c1\">// conceptual logic</span>\n            <span class=\"kd\">val</span> <span class=\"py\">exceptionHandler</span> <span class=\"p\">=</span> <span class=\"nc\">ExceptionHandler</span><span class=\"p\">(</span><span class=\"n\">e</span><span class=\"p\">)</span>\n            <span class=\"n\">handledExceptions</span><span class=\"o\">?.</span><span class=\"nf\">let</span> <span class=\"p\">{</span> <span class=\"n\">exceptionHandler</span><span class=\"p\">.</span><span class=\"nf\">handledExceptions</span><span class=\"p\">()</span> <span class=\"p\">}</span>\n            <span class=\"k\">return</span> <span class=\"nc\">UseCaseApiResult</span><span class=\"p\">(</span><span class=\"n\">responseCodeIfExceptionIsHandled</span><span class=\"p\">,</span> <span class=\"n\">exceptionHandler</span><span class=\"p\">.</span><span class=\"n\">message</span> <span class=\"o\">?:</span> <span class=\"n\">e</span><span class=\"p\">.</span><span class=\"n\">message</span><span class=\"p\">)</span>\n        <span class=\"p\">}</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>(full commit: <a href=\"https://github.com/michal-kowalcze/clean-architecture-example/commit/ac6763f19e2f3f61adc1f8b02bab6cb1e1a65c11\">GitHub</a>)</p>\n\n<h3 id=\"handle-dto-conversion-exceptions\">Handle DTO conversion exceptions</h3>\n<p>By simply replacing input with:</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">inputProvider</span><span class=\"p\">:</span> <span class=\"nc\">Any</span><span class=\"p\">.()</span> <span class=\"p\">-&gt;</span> <span class=\"nc\">DOMAIN_INPUT</span><span class=\"p\">,</span>\n</code></pre></div></div>\n\n<p>(full commit: <a href=\"https://github.com/michal-kowalcze/clean-architecture-example/commit/a9ef4bb835977a4bd4a62eb754d8563340bd3d4e\">GitHub</a>)</p>\n\n<p>we are able to handle exceptions raised during creation of input domain objects in a uniform way, without any\nadditional try/catches at the endpoint level.</p>\n\n<h2 id=\"the-outcome\">The outcome</h2>\n\n<p>What is the result of our journey across some functional requirements and a bit more non-functional requirements? By\nlooking at the definition of an endpoint we have full documentation of its behaviour, including exceptions. Our code is\neasily portable to some different API (e.g. EJB), we have fully-auditable modifications, and we can exchange layers\nquite freely. Also analysis of whole service is simplified, as possible use cases are explicitely stated.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nd\">@PutMapping</span><span class=\"p\">(</span><span class=\"s\">\"/schedules/{localDate}/{index}\"</span><span class=\"p\">,</span> <span class=\"n\">produces</span> <span class=\"p\">=</span> <span class=\"p\">[</span><span class=\"s\">\"application/json\"</span><span class=\"p\">],</span> <span class=\"n\">consumes</span> <span class=\"p\">=</span> <span class=\"p\">[</span><span class=\"s\">\"application/json\"</span><span class=\"p\">])</span>\n<span class=\"k\">fun</span> <span class=\"nf\">getSchedules</span><span class=\"p\">(</span><span class=\"nd\">@PathVariable</span> <span class=\"n\">localDate</span><span class=\"p\">:</span> <span class=\"nc\">String</span><span class=\"p\">,</span> <span class=\"nd\">@PathVariable</span> <span class=\"n\">index</span><span class=\"p\">:</span> <span class=\"nc\">Int</span><span class=\"p\">):</span> <span class=\"nc\">ResponseEntity</span><span class=\"p\">&lt;</span><span class=\"err\">*</span><span class=\"p\">&gt;</span> <span class=\"p\">=</span>\n    <span class=\"n\">useCaseExecutor</span><span class=\"p\">.</span><span class=\"nf\">execute</span><span class=\"p\">(</span>\n        <span class=\"n\">useCase</span> <span class=\"p\">=</span> <span class=\"n\">reserveSlotUseCase</span><span class=\"p\">,</span>\n        <span class=\"n\">inputProvider</span> <span class=\"p\">=</span> <span class=\"p\">{</span> <span class=\"nc\">SlotId</span><span class=\"p\">(</span><span class=\"nc\">LocalDate</span><span class=\"p\">.</span><span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"n\">localDate</span><span class=\"p\">),</span> <span class=\"n\">index</span><span class=\"p\">)</span> <span class=\"p\">},</span>\n        <span class=\"n\">toApiConversion</span> <span class=\"p\">=</span> <span class=\"p\">{</span>\n            <span class=\"kd\">val</span> <span class=\"py\">dayScheduleDto</span> <span class=\"p\">=</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"nf\">toApi</span><span class=\"p\">()</span>\n            <span class=\"nc\">UseCaseApiResult</span><span class=\"p\">(</span><span class=\"nc\">HttpServletResponse</span><span class=\"p\">.</span><span class=\"nc\">SC_ACCEPTED</span><span class=\"p\">,</span> <span class=\"n\">dayScheduleDto</span><span class=\"p\">)</span>\n        <span class=\"p\">},</span>\n        <span class=\"n\">handledExceptions</span> <span class=\"p\">=</span> <span class=\"p\">{</span>\n            <span class=\"nf\">exception</span><span class=\"p\">(</span><span class=\"nc\">InvalidSlotIndexException</span><span class=\"o\">::</span><span class=\"k\">class</span><span class=\"p\">,</span> <span class=\"nc\">UNPROCESSABLE_ENTITY</span><span class=\"p\">,</span> <span class=\"s\">\"INVALID-SLOT-ID\"</span><span class=\"p\">)</span>\n            <span class=\"nf\">exception</span><span class=\"p\">(</span><span class=\"nc\">SlotAlreadyReservedException</span><span class=\"o\">::</span><span class=\"k\">class</span><span class=\"p\">,</span> <span class=\"nc\">CONFLICT</span><span class=\"p\">,</span> <span class=\"s\">\"SLOT-ALREADY-RESERVED\"</span><span class=\"p\">)</span>\n        <span class=\"p\">},</span>\n    <span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>(repository: <a href=\"https://github.com/michal-kowalcze/clean-architecture-example\">GitHub</a>)</p>\n\n<p>A simple evaluation of our solution with measures mentioned at the beginning:</p>\n\n<table>\n  <thead>\n    <tr>\n      <th style=\"text-align: left\">Aspect</th>\n      <th style=\"text-align: left\">Evaluation</th>\n      <th style=\"text-align: center\">Has advantage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td style=\"text-align: left\">Development</td>\n      <td style=\"text-align: left\"><code class=\"language-plaintext highlighter-rouge\">UseCase</code> abstraction forces unification of approach across different teams in a more significant way than standard service approach.</td>\n      <td style=\"text-align: center\">✓</td>\n    </tr>\n    <tr>\n      <td style=\"text-align: left\">Deployment</td>\n      <td style=\"text-align: left\">We did not consider deployment in our example. It certainly is not going to be different/harder than in case of hexagonal architecture.</td>\n      <td style=\"text-align: center\"> </td>\n    </tr>\n    <tr>\n      <td style=\"text-align: left\">Operation</td>\n      <td style=\"text-align: left\">Use case-based approach reveals operation of the system, which reduces learning curve for both development and maintenance.</td>\n      <td style=\"text-align: center\">✓</td>\n    </tr>\n    <tr>\n      <td style=\"text-align: left\">Maintenance</td>\n      <td style=\"text-align: left\">Entry threshold might be lower compared to hexagonal approach, as service is separated horizontally (into layers) and vertically (into use cases with common domain model).</td>\n      <td style=\"text-align: center\">✓</td>\n    </tr>\n    <tr>\n      <td style=\"text-align: left\">Keeping options open</td>\n      <td style=\"text-align: left\">Similar to hexagonal architecture approach.</td>\n      <td style=\"text-align: center\"> </td>\n    </tr>\n  </tbody>\n</table>\n\n<h3 id=\"tldr\">TL;DR</h3>\n<p>It is like hexagonal architecture with one additional dimension, composed of use cases, giving better insight into\noperations of a system and streamlining development and maintenance. Solution that was created during this narrative\nallows for creation of a self-documenting API endpoint.</p>\n\n<h2 id=\"high-level-overview\">High-level overview</h2>\n<p>With all this read we can switch our view to the high-level perspective:</p>\n\n<p><img src=\"/img/articles/2021-12-13-clean-architecture-story/clean_architecture_diagram.png\" alt=\"The Clean Architecture Diagram\" /></p>\n\n<p>and describe abstractions. Starting from the inside we have:</p>\n<ul>\n  <li><strong>Domain Model</strong>, <strong>Services</strong> and <strong>Gateways</strong>, which are responsible for defining\nbusiness rules for the domain.</li>\n  <li><strong>UseCase</strong>, which orchestrates execution of business rules.</li>\n  <li><strong>UseCaseExecutor</strong> providing common behavior for all use cases.</li>\n  <li><strong>API</strong> connecting service with the outside world.</li>\n  <li><strong>Implementation of gateways</strong>, which connects with other services or persistence providers.</li>\n  <li><strong>Configuration</strong>, responsible for gluing all elements together.</li>\n</ul>\n\n<p>I hope that you enjoy this simple story and find the concept of\n<a href=\"https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html\">the Clean Architecture</a> useful.\nThank you for reading!</p>\n","contentSnippet":"The Clean Architecture concept has been\naround for some time and keeps surfacing in one place or another, yet it is not widely adopted. In this post I would\nlike to introduce this topic in a less conventional way: starting with customer’s needs and going through various\nstages to present a solution that is clean enough to satisfy concepts from the aforementioned blog (or\nthe book with the same name).\nThe perspective\nWhy do we need software architecture? What is it anyway? An extensive definition can be found in a place a bit unexpected\nfor an agile world — an enterprise-architecture definition from TOGAF:\nThe fundamental concepts or properties of a system in its environment embodied in its elements, relationships, and\nin the principles of its design and evolution. (Source: ISO/IEC/IEEE 42010:2011)\nThe structure of components, their inter-relationships, and the principles and guidelines governing their design and\nevolution over time.\nAnd what do we need such a governing structure or shape for? Basically it allows us to make cost/time-efficient choices\nwhen it comes to development. And deployment. And operation. And maintenance.\nIt also allows us to keep as many options open as possible, so our future choices are not limited by an overcommitment\nfrom the past.\nSo — we have our perspective defined. Let’s dive into a real-world problem!\nThe challenge\nYou are a young, promising programmer sitting in a dorm and one afternoon a stranger appears. “I run a small company\nthat delivers packages from furniture shops to customers. I need a database that will allow reservation of slots. Is it\nsomething you are able to deliver?” “Of course!” — what else could a young, promising programmer answer?\nThe false start\nThe customer needs a database, so what can we start with? The database schema, of course! We can identify entities with\nease: a transport slot, a schedule, a user (we need some authentication, right?), a … something? Okay, perhaps it is\nnot the easiest way. So why don’t we start with something else?\nLet’s choose the technology to use! Let’s go with React frontend, Java+Spring backend, some SQL as persistence. To\npresent a clickable version to our customer we need some warm-up work to set up an environment, create a deployable\nservice version or GUI mockups, configure persistence and so on. In general: to pay attention to technical details —\ncode necessary to set up something working, of which non-devs are usually not aware. It simply has to be done before we\nstart talking about nitty-gritty for business logic.\nThe use-case-driven approach\nWhat if instead of starting with what we already know — how to visualize relationships, how to build a web-system — we\nstarted with what we didn’t know? Simply — by asking questions such as: How is the system going to be used? By whom?\nUse cases\nIn other words — what are the use cases for the system? Let’s define the challenge once more using high-level actors\nand interactions:  and pick the first\nrequired interaction: shop makes a reservation. What is required to make a reservation? Hmm, I think that it would be\ngood to get the current schedule in the first place. Why am I using “get” instead of “display”? “Display” already\nsuggests a way of delivering output, when we hear “display” a computer screen comes to our minds, with a web\napplication. Single page web app, of course. “Get” is more neutral, it does not constrain our vision by a specific\npresentation method. Frankly — is there anything wrong with delivering the current schedule over the phone, for\nexample?\nGetting the schedule\nSo, we can start thinking about our schedule model — let it be a single instance representing a day with slots inside.\nGreat, we have our entities! How to get one? Well, we need to check if there is already a stored schedule and if so\n— retrieve it from the repository. If the schedule is not available we have to create one. Based on…? Exactly — we do\nnot know yet, all we can say is that it will probably be something flexible. Something to discuss with our customer\n— but this does not prevent us from going forward with our first use case. Logic is indeed simple:\n\nfun getSchedule(scheduleDay: LocalDate): DaySchedule {\n  val daySchedule = daySchedulerRepository.get(scheduleDay)\n  if (daySchedule != null) {\n    return daySchedule\n  }\n\n  val newSchedule = dayScheduleCreator.create(scheduleDay)\n  return daySchedulerRepository.save(newSchedule)\n}\n\n\n(full commit: GitHub)\nAnd even with this simple logic we identified a hidden assumption regarding the schedule definition: that there is a\nrecipe for creating a daily schedule. What is more we can test retrieval of a schedule — with definition of schedule\ncreator if required — without any irrelevant details, like database, UI, framework and so on. Test only business rules,\nwithout unnecessary details.\nReserving the slot\nTo finish the reservation we have to add at least one more use case — one for reservation of a free slot. Provided that\nwe re-use existing logic, the interaction is still simple:\n\nfun reserve(slotId: SlotId): DaySchedule {\n  val daySchedule = getScheduleUseCase.getSchedule(scheduleDay = slotId.day)\n\n  val modifiedSchedule = daySchedule.reserveSlot(slotId.index)\n\n  return dayScheduleRepository.save(modifiedSchedule)\n}\n\n\n(full commit: GitHub)\nAnd, as we can see — the slot reservation business rule (and constraint) is implemented at the domain model itself — so\nwe are safe, that any other interaction, any other use case, is not going to break these rules. This approach also\nsimplifies testing, as business rules can be verified in separation from the use case interaction logic.\nWhere is the “Clean Architecture”?\nLet‘s stop with business logic for a moment. We created quite thoughtful, extensible code for sure, but why are we\ntalking about “Clean” architecture? We already used Domain-Driven Design and Hexagonal architecture concepts. Is there\nanything more? Imagine that another person is going to help us with implementation. She is not aware of the source code\nyet and simply would like to take a look at the codebase. And she sees: \nIt looks like something to her, doesn‘t it? A kind of reservation system! It is not yet another domain service with\nsome methods that have no clear connection with possible uses — the list of classes itself describes what the system\ncan do.\nThe first assumption\nWe have a mocked implementation as the schedule creator. It is OK to test logic at the unit test level, but not enough\nto run a prototype.\nAfter a short call with our customer we know more about the daily schedule — there are six slots, two hours each,\nstarting at 8:oo a.m. We also know that this recipe for the daily schedule is very, very simple and it is going to be\nchanged soon (e.g. to accommodate for holidays, etc.). All these issues will be solved later, now we are at the\nprototype stage and our desired outcome is to have a working demo for our stranger.\nWhere to put this simple implementation of the schedule creator? So far, the domain used an interface for that. Are we\ngoing to put an implementation of this interface to the infrastructure package and treat it as something outside the\ndomain? Certainly not! It is not complicated and this is part of the domain itself, we simply replace the mocked\nimplementation of the schedule creator with class specification.\n\npackage eu.kowalcze.michal.arch.clean.example.domain.model\n\nclass DayScheduleCreator {\n    fun create(scheduleDay: LocalDate): DaySchedule = DaySchedule(\n        scheduleDay,\n        createStandardSlots()\n    )\n//...\n}\n\n\n(full commit: GitHub)\nThe prototype\nI will not be original here — for the first prototype version the REST API sounds like something reasonable. Do we care\nabout other infrastructure at the moment? Persistence? No! In the previous commits a map-based persistence layer is\nused for unit tests and this solution is good enough to start with. As long as the system is not restarted, of course.\nWhat is important at this stage? We are introducing an API — this is a separate layer, so it is crucial to ensure\nthat domain classes are not exposed to the outside world — and that we do not introduce a dependency on the API into\nthe domain.\n\npackage eu.kowalcze.michal.arch.clean.example.api\n\n@Controller\nclass GetScheduleEndpoint(private val getScheduleUseCase: GetScheduleUseCase) {\n\n    @GetMapping(\"/schedules/{localDate}\")\n    fun getSchedules(@PathVariable localDate: String): DayScheduleDto {\n        val scheduleDay = LocalDate.parse(localDate)\n        val daySchedule = getScheduleUseCase.getSchedule(scheduleDay)\n        return daySchedule.toApi()\n    }\n\n}\n\n\n(full commit: GitHub)\nThe abstractions\nUse Case\nChecking the implementation of endpoints (see comments in the code) we can see that conceptually each endpoint executes\nlogic according to the same structure: \nWell, why don’t we make some abstraction for this? Sounds like a crazy idea? Let‘s check! Based on our code and the\ndiagram above we can identify the UseCase abstraction — something that takes some input (domain input, to be precise)\nand converts it to a (domain) output.\n\ninterface UseCase<INPUT, OUTPUT> {\n    fun apply(input: INPUT): OUTPUT\n}\n\n\n(full commit: GitHub)\nUse Case Executor\nGreat! We have use cases and I just realized that I would like to have an email in my inbox each time an exception is\nthrown — and I do not want to depend on a spring-specific mechanism to do this. A common UseCaseExecutor will be a\ngreat help to address this non-functional requirement.\n\nclass UseCaseExecutor(private val notificationGateway: NotificationGateway) {\n    fun <INPUT, OUTPUT> execute(useCase: UseCase<INPUT, OUTPUT>, input: INPUT): OUTPUT {\n        try {\n            return useCase.apply(input)\n        } catch (e: Exception) {\n            notificationGateway.notify(useCase, e)\n            throw e\n        }\n    }\n}\n\n\n(full commit: GitHub)\nFramework-independent response\nIn order to handle the next requirements in our plan we have to change the logic a bit — add the possibility of returning\nspring-specific response entities from the executor itself. To make our code reusable in a non-spring world (ktor,\nanyone?) we separated the plain executor from spring specific decorator, so that it is possible to use this code easily\nin other frameworks.\n\ndata class UseCaseApiResult<API_OUTPUT>(\n    val responseCode: Int,\n    val output: API_OUTPUT,\n)\n\nclass SpringUseCaseExecutor(private val useCaseExecutor: UseCaseExecutor) {\n    fun <DOMAIN_INPUT, DOMAIN_OUTPUT, API_OUTPUT> execute(\n        useCase: UseCase<DOMAIN_INPUT, DOMAIN_OUTPUT>,\n        input: DOMAIN_INPUT,\n        toApiConversion: (domainOutput: DOMAIN_OUTPUT) -> UseCaseApiResult<API_OUTPUT>\n    ): ResponseEntity<API_OUTPUT> {\n        return useCaseExecutor.execute(useCase, input, toApiConversion).toSpringResponse()\n    }\n}\n\nprivate fun <API_OUTPUT> UseCaseApiResult<API_OUTPUT>.toSpringResponse(): ResponseEntity<API_OUTPUT> =\n    ResponseEntity.status(responseCode).body(output)\n\n\n(full commit: GitHub)\nHandle domain exceptions\nOoops. Our prototype is running and we observe exceptions resulting in HTTP 500 errors. It would be nice to convert\nthese to dedicated response codes in a reasonable way yet without using much of spring infrastructure, for simplified\nmaintenance (and possible future changes). This can be easily achieved by adding another parameter to use case\nexecution, like this:\n\nclass UseCaseExecutor(private val notificationGateway: NotificationGateway) {\n    fun <DOMAIN_INPUT, DOMAIN_OUTPUT> execute(\n        useCase: UseCase<DOMAIN_INPUT, DOMAIN_OUTPUT>,\n        input: DOMAIN_INPUT,\n        toApiConversion: (domainOutput: DOMAIN_OUTPUT) -> UseCaseApiResult<*>,\n        handledExceptions: (ExceptionHandler.() -> Any)? = null,\n    ): UseCaseApiResult<*> {\n\n        try {\n            val domainOutput = useCase.apply(input)\n            return toApiConversion(domainOutput)\n        } catch (e: Exception) {\n            // conceptual logic\n            val exceptionHandler = ExceptionHandler(e)\n            handledExceptions?.let { exceptionHandler.handledExceptions() }\n            return UseCaseApiResult(responseCodeIfExceptionIsHandled, exceptionHandler.message ?: e.message)\n        }\n    }\n}\n\n\n(full commit: GitHub)\nHandle DTO conversion exceptions\nBy simply replacing input with:\n\ninputProvider: Any.() -> DOMAIN_INPUT,\n\n\n(full commit: GitHub)\nwe are able to handle exceptions raised during creation of input domain objects in a uniform way, without any\nadditional try/catches at the endpoint level.\nThe outcome\nWhat is the result of our journey across some functional requirements and a bit more non-functional requirements? By\nlooking at the definition of an endpoint we have full documentation of its behaviour, including exceptions. Our code is\neasily portable to some different API (e.g. EJB), we have fully-auditable modifications, and we can exchange layers\nquite freely. Also analysis of whole service is simplified, as possible use cases are explicitely stated.\n\n@PutMapping(\"/schedules/{localDate}/{index}\", produces = [\"application/json\"], consumes = [\"application/json\"])\nfun getSchedules(@PathVariable localDate: String, @PathVariable index: Int): ResponseEntity<*> =\n    useCaseExecutor.execute(\n        useCase = reserveSlotUseCase,\n        inputProvider = { SlotId(LocalDate.parse(localDate), index) },\n        toApiConversion = {\n            val dayScheduleDto = it.toApi()\n            UseCaseApiResult(HttpServletResponse.SC_ACCEPTED, dayScheduleDto)\n        },\n        handledExceptions = {\n            exception(InvalidSlotIndexException::class, UNPROCESSABLE_ENTITY, \"INVALID-SLOT-ID\")\n            exception(SlotAlreadyReservedException::class, CONFLICT, \"SLOT-ALREADY-RESERVED\")\n        },\n    )\n\n\n(repository: GitHub)\nA simple evaluation of our solution with measures mentioned at the beginning:\nAspect\n      Evaluation\n      Has advantage\n    \nDevelopment\n      UseCase abstraction forces unification of approach across different teams in a more significant way than standard service approach.\n      ✓\n    \nDeployment\n      We did not consider deployment in our example. It certainly is not going to be different/harder than in case of hexagonal architecture.\n       \n    \nOperation\n      Use case-based approach reveals operation of the system, which reduces learning curve for both development and maintenance.\n      ✓\n    \nMaintenance\n      Entry threshold might be lower compared to hexagonal approach, as service is separated horizontally (into layers) and vertically (into use cases with common domain model).\n      ✓\n    \nKeeping options open\n      Similar to hexagonal architecture approach.\n       \n    \nTL;DR\nIt is like hexagonal architecture with one additional dimension, composed of use cases, giving better insight into\noperations of a system and streamlining development and maintenance. Solution that was created during this narrative\nallows for creation of a self-documenting API endpoint.\nHigh-level overview\nWith all this read we can switch our view to the high-level perspective:\n\nand describe abstractions. Starting from the inside we have:\nDomain Model, Services and Gateways, which are responsible for defining\nbusiness rules for the domain.\nUseCase, which orchestrates execution of business rules.\nUseCaseExecutor providing common behavior for all use cases.\nAPI connecting service with the outside world.\nImplementation of gateways, which connects with other services or persistence providers.\nConfiguration, responsible for gluing all elements together.\nI hope that you enjoy this simple story and find the concept of\nthe Clean Architecture useful.\nThank you for reading!","guid":"https://blog.allegro.tech/2021/12/clean-architecture-story.html","categories":["tech","architecture","clean-architecture","ddd","kotlin"],"isoDate":"2021-12-12T23:00:00.000Z","thumbnail":"images/post-headers/default.jpg"}],"jobs":[{"id":"743999785422127","name":"Research Engineer - Machine Learning (Reinforcement Learning)","uuid":"229d607a-333b-431b-9abe-78137730f5fd","refNumber":"REF2881V","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2021-11-08T09:56:17.000Z","location":{"city":"Warszawa, Kraków, Poznań, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572821","label":"IT - Machine Learning"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"606235fe248e6f5bea0815ed","fieldLabel":"Katowice","valueId":"185eb5a9-b884-4ee8-8ebc-0e5f3e852b27","valueLabel":"Tak"},{"fieldId":"58c1575ee4b01d4b19ddf797","fieldLabel":"Kraków","valueId":"2cfcfcc1-da44-43f7-8eaa-3907faf2797c","valueLabel":"Tak"},{"fieldId":"606235bcefbac7156d6a470a","fieldLabel":"Łódź","valueId":"7d33e23d-3fa7-4d7d-86ae-7d7caff54fa9","valueLabel":"Tak"},{"fieldId":"58c158e9e4b0614667d5973e","fieldLabel":"Więcej lokalizacji","valueId":"3a186e8d-a82c-4955-af81-fcef9a63928a","valueLabel":"Tak"},{"fieldId":"58c1576ee4b0614667d59732","fieldLabel":"Toruń","valueId":"987e8884-bad1-4a8f-b149-99e4184cc221","valueLabel":"Tak"},{"fieldId":"6165609ee6b46b6506c66b63","fieldLabel":"Gdańsk","valueId":"cde0f8e7-5c9d-4d78-9f5c-e1c17ee499a8","valueLabel":"Tak"},{"fieldId":"58c156e6e4b01d4b19ddf793","fieldLabel":"Warszawa","valueId":"6a428533-1586-4372-89ec-65fb45366363","valueLabel":"Tak"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Proces rekrutacji","valueId":"c807eec2-8a53-4b55-b7c5-c03180f2059b","valueLabel":"(Archive) IT Allegro"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c15788e4b0614667d59733","fieldLabel":"Błonie","valueId":"25f6cb8c-81b3-434a-93ec-6dc851d5808d","valueLabel":"Nie"},{"fieldId":"58c15798e4b01d4b19ddf79b","fieldLabel":"Wrocław","valueId":"64818201-cdba-422e-8e8c-8ec633b0d327","valueLabel":"Tak"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572821","valueLabel":"IT - Machine Learning"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro.pl sp. z o.o."},{"fieldId":"61656102a169ed164d546c31","fieldLabel":"Lublin","valueId":"02d54f00-48b9-4669-b7b3-10c16ac4bada","valueLabel":"Tak"},{"fieldId":"58c156b9e4b01d4b19ddf792","fieldLabel":"Poznań","valueId":"ac20917b-cb6a-4280-aff3-4fae2532a33e","valueLabel":"Tak"},{"fieldId":"5cdab2c84cedfd0006e7758c","fieldLabel":"Key words","valueLabel":"ML, Machine Learning, Python, Deep Learning, AI, Artificial Intelligence"}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999785422127","creator":{"name":"Maciej Matwiejczyk"},"language":{"code":"en","label":"English","labelNative":"English (US)"}},{"id":"743999785421861","name":"Research Engineer - Machine Learning (Ranking and Recommendations)","uuid":"a6b2b59e-28e3-4bfa-89ab-b13ab97f06c8","refNumber":"REF2990T","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2021-11-08T09:54:52.000Z","location":{"city":"Warszawa, Poznań, Kraków, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572821","label":"IT - Machine Learning"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"58c1575ee4b01d4b19ddf797","fieldLabel":"Kraków","valueId":"2cfcfcc1-da44-43f7-8eaa-3907faf2797c","valueLabel":"Tak"},{"fieldId":"58c158e9e4b0614667d5973e","fieldLabel":"Więcej lokalizacji","valueId":"3a186e8d-a82c-4955-af81-fcef9a63928a","valueLabel":"Tak"},{"fieldId":"58c1576ee4b0614667d59732","fieldLabel":"Toruń","valueId":"987e8884-bad1-4a8f-b149-99e4184cc221","valueLabel":"Tak"},{"fieldId":"58c156e6e4b01d4b19ddf793","fieldLabel":"Warszawa","valueId":"6a428533-1586-4372-89ec-65fb45366363","valueLabel":"Tak"},{"fieldId":"60cb31a9c87e511299a3a050","fieldLabel":"Department II","valueId":"b8a4596e-d9ce-42bb-8de5-10995e9ccf99","valueLabel":"IT - Machine Learning"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Proces rekrutacji","valueId":"c807eec2-8a53-4b55-b7c5-c03180f2059b","valueLabel":"(Archive) IT Allegro"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c15788e4b0614667d59733","fieldLabel":"Błonie","valueId":"25f6cb8c-81b3-434a-93ec-6dc851d5808d","valueLabel":"Nie"},{"fieldId":"58c15798e4b01d4b19ddf79b","fieldLabel":"Wrocław","valueId":"64818201-cdba-422e-8e8c-8ec633b0d327","valueLabel":"Tak"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572821","valueLabel":"IT - Machine Learning"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro.pl sp. z o.o."},{"fieldId":"58c156b9e4b01d4b19ddf792","fieldLabel":"Poznań","valueId":"ac20917b-cb6a-4280-aff3-4fae2532a33e","valueLabel":"Tak"},{"fieldId":"5cdab2c84cedfd0006e7758c","fieldLabel":"Key words","valueLabel":"ML, AI, Ranking, Research, Machine Learning"}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999785421861","creator":{"name":"Maciej Matwiejczyk"},"language":{"code":"en","label":"English","labelNative":"English (US)"}},{"id":"743999779448775","name":"Research Engineer - Machine Learning (Reinforcement Learning)","uuid":"c8e577cc-c93a-43e7-8e73-e430989798d7","refNumber":"REF2881V","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2021-10-14T10:29:36.000Z","location":{"city":"Warszawa, Kraków, Poznań, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572821","label":"IT - Machine Learning"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"606235fe248e6f5bea0815ed","fieldLabel":"Katowice","valueId":"185eb5a9-b884-4ee8-8ebc-0e5f3e852b27","valueLabel":"Tak"},{"fieldId":"58c1575ee4b01d4b19ddf797","fieldLabel":"Kraków","valueId":"2cfcfcc1-da44-43f7-8eaa-3907faf2797c","valueLabel":"Tak"},{"fieldId":"606235bcefbac7156d6a470a","fieldLabel":"Łódź","valueId":"7d33e23d-3fa7-4d7d-86ae-7d7caff54fa9","valueLabel":"Tak"},{"fieldId":"58c158e9e4b0614667d5973e","fieldLabel":"Więcej lokalizacji","valueId":"3a186e8d-a82c-4955-af81-fcef9a63928a","valueLabel":"Tak"},{"fieldId":"58c1576ee4b0614667d59732","fieldLabel":"Toruń","valueId":"987e8884-bad1-4a8f-b149-99e4184cc221","valueLabel":"Tak"},{"fieldId":"6165609ee6b46b6506c66b63","fieldLabel":"Gdańsk","valueId":"cde0f8e7-5c9d-4d78-9f5c-e1c17ee499a8","valueLabel":"Tak"},{"fieldId":"58c156e6e4b01d4b19ddf793","fieldLabel":"Warszawa","valueId":"6a428533-1586-4372-89ec-65fb45366363","valueLabel":"Tak"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Proces rekrutacji","valueId":"c807eec2-8a53-4b55-b7c5-c03180f2059b","valueLabel":"(Archive) IT Allegro"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c15788e4b0614667d59733","fieldLabel":"Błonie","valueId":"25f6cb8c-81b3-434a-93ec-6dc851d5808d","valueLabel":"Nie"},{"fieldId":"58c15798e4b01d4b19ddf79b","fieldLabel":"Wrocław","valueId":"64818201-cdba-422e-8e8c-8ec633b0d327","valueLabel":"Tak"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572821","valueLabel":"IT - Machine Learning"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro.pl sp. z o.o."},{"fieldId":"61656102a169ed164d546c31","fieldLabel":"Lublin","valueId":"02d54f00-48b9-4669-b7b3-10c16ac4bada","valueLabel":"Tak"},{"fieldId":"58c156b9e4b01d4b19ddf792","fieldLabel":"Poznań","valueId":"ac20917b-cb6a-4280-aff3-4fae2532a33e","valueLabel":"Tak"},{"fieldId":"5cdab2c84cedfd0006e7758c","fieldLabel":"Key words","valueLabel":"ML, Machine Learning, Python, Deep Learning, AI, Artificial Intelligence"}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999779448775","creator":{"name":"Maciej Matwiejczyk"},"language":{"code":"pl","label":"Polish","labelNative":"polski"}},{"id":"743999779448676","name":"Research Engineer - Machine Learning (Ranking and Recommendations)","uuid":"7cb35dfc-f53c-4b51-81ac-61b683060f4c","refNumber":"REF2990T","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2021-10-14T10:29:00.000Z","location":{"city":"Warszawa, Poznań, Kraków, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572821","label":"IT - Machine Learning"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"58c1575ee4b01d4b19ddf797","fieldLabel":"Kraków","valueId":"2cfcfcc1-da44-43f7-8eaa-3907faf2797c","valueLabel":"Tak"},{"fieldId":"58c158e9e4b0614667d5973e","fieldLabel":"Więcej lokalizacji","valueId":"3a186e8d-a82c-4955-af81-fcef9a63928a","valueLabel":"Tak"},{"fieldId":"58c1576ee4b0614667d59732","fieldLabel":"Toruń","valueId":"987e8884-bad1-4a8f-b149-99e4184cc221","valueLabel":"Tak"},{"fieldId":"58c156e6e4b01d4b19ddf793","fieldLabel":"Warszawa","valueId":"6a428533-1586-4372-89ec-65fb45366363","valueLabel":"Tak"},{"fieldId":"60cb31a9c87e511299a3a050","fieldLabel":"Department II","valueId":"b8a4596e-d9ce-42bb-8de5-10995e9ccf99","valueLabel":"IT - Machine Learning"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Proces rekrutacji","valueId":"c807eec2-8a53-4b55-b7c5-c03180f2059b","valueLabel":"(Archive) IT Allegro"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c15788e4b0614667d59733","fieldLabel":"Błonie","valueId":"25f6cb8c-81b3-434a-93ec-6dc851d5808d","valueLabel":"Nie"},{"fieldId":"58c15798e4b01d4b19ddf79b","fieldLabel":"Wrocław","valueId":"64818201-cdba-422e-8e8c-8ec633b0d327","valueLabel":"Tak"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572821","valueLabel":"IT - Machine Learning"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro.pl sp. z o.o."},{"fieldId":"58c156b9e4b01d4b19ddf792","fieldLabel":"Poznań","valueId":"ac20917b-cb6a-4280-aff3-4fae2532a33e","valueLabel":"Tak"},{"fieldId":"5cdab2c84cedfd0006e7758c","fieldLabel":"Key words","valueLabel":"ML, AI, Ranking, Research, Machine Learning"}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999779448676","creator":{"name":"Maciej Matwiejczyk"},"language":{"code":"pl","label":"Polish","labelNative":"polski"}},{"id":"743999777347284","name":"Team Leader (Java/Kotlin) - Consumer Technology Experience","uuid":"c9925a03-d2ab-4d63-804e-0c06f0b0e87a","refNumber":"REF2902G","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2021-10-04T08:03:28.000Z","location":{"city":"Warszawa, Kraków, Poznań","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572770","label":"IT - Software Development"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"label":"Full-time"},"experienceLevel":{"id":"executive","label":"Executive"},"customField":[{"fieldId":"58c1575ee4b01d4b19ddf797","fieldLabel":"Kraków","valueId":"2cfcfcc1-da44-43f7-8eaa-3907faf2797c","valueLabel":"Tak"},{"fieldId":"58c158e9e4b0614667d5973e","fieldLabel":"Więcej lokalizacji","valueId":"3a186e8d-a82c-4955-af81-fcef9a63928a","valueLabel":"Tak"},{"fieldId":"58c1576ee4b0614667d59732","fieldLabel":"Toruń","valueId":"a6765624-e047-4a26-9481-9621086d8b96","valueLabel":"Nie"},{"fieldId":"58c156e6e4b01d4b19ddf793","fieldLabel":"Warszawa","valueId":"6a428533-1586-4372-89ec-65fb45366363","valueLabel":"Tak"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Proces rekrutacji","valueId":"c807eec2-8a53-4b55-b7c5-c03180f2059b","valueLabel":"(Archive) IT Allegro"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c15788e4b0614667d59733","fieldLabel":"Błonie","valueId":"25f6cb8c-81b3-434a-93ec-6dc851d5808d","valueLabel":"Nie"},{"fieldId":"58c15798e4b01d4b19ddf79b","fieldLabel":"Wrocław","valueId":"31873284-1e97-427d-8918-6ce504344351","valueLabel":"Nie"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572770","valueLabel":"IT - Software Development"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro.pl sp. z o.o."},{"fieldId":"58c156b9e4b01d4b19ddf792","fieldLabel":"Poznań","valueId":"ac20917b-cb6a-4280-aff3-4fae2532a33e","valueLabel":"Tak"}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999777347284","creator":{"name":"Aleksandra Sotowska"},"language":{"code":"pl","label":"Polish","labelNative":"polski"}}],"events":[{"created":1642501324000,"duration":5400000,"id":"283335598","name":"Allegro Tech Live #24 - Automatyzacja i usługi biznesowe w Allegro","date_in_series_pattern":false,"status":"upcoming","time":1643907600000,"local_date":"2022-02-03","local_time":"18:00","updated":1642501324000,"utc_offset":3600000,"waitlist_count":0,"yes_rsvp_count":36,"venue":{"id":26906060,"name":"Online event","repinned":false,"country":"","localized_country_name":""},"is_online_event":true,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/283335598/","description":"REJESTRACJA NA WYDARZENIE ---&gt; https://app.evenea.pl/event/allegro-tech-live-24/ Allegro Tech Live to w 100% zdalna odsłona naszych stacjonarnych meetupów Allegro Tech Talks. Kiedyś spotykaliśmy się w naszych biurach,…","how_to_find_us":"https://app.evenea.pl/event/allegro-tech-live-24/","visibility":"public","member_pay_fee":false},{"created":1638356820000,"duration":7200000,"id":"282421464","name":"Allegro Tech Labs #9 Online: System design workshop","date_in_series_pattern":false,"status":"past","time":1639501200000,"local_date":"2021-12-14","local_time":"18:00","updated":1639514166000,"utc_offset":3600000,"waitlist_count":0,"yes_rsvp_count":62,"venue":{"id":26906060,"name":"Online event","repinned":false,"country":"","localized_country_name":""},"is_online_event":true,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/282421464/","description":"❗NA WYDARZENIE OBOWIĄZUJE REJESTRACJA: Liczba miejsc jest organiczona: https://app.evenea.pl/event/allegro-tech-labs-9/ ❗ To już druga edycja naszych warsztatów System Design Workshop! Czy chcesz poznać tajniki tworzenia systemów?…","how_to_find_us":"https://app.evenea.pl/event/allegro-tech-labs-9/","visibility":"public","member_pay_fee":false},{"created":1635344914000,"duration":7200000,"id":"281692274","name":"Allegro Tech Live #23 - Przygody backendowców w C#","date_in_series_pattern":false,"status":"past","time":1636045200000,"local_date":"2021-11-04","local_time":"18:00","updated":1636056125000,"utc_offset":3600000,"waitlist_count":0,"yes_rsvp_count":29,"is_online_event":false,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/281692274/","description":"------ Rejestracja: https://app.evenea.pl/event/allegro-tech-live-23/------- Allegro Tech Live to w 100% zdalna odsłona naszych stacjonarnych meetupów Allegro Tech Talks. Kiedyś spotykaliśmy się w naszych biurach, a teraz…","visibility":"public","member_pay_fee":false},{"created":1634290537000,"duration":5400000,"id":"281441586","name":"Allegro Tech Live #22 - Jak wygląda codzienność lidera w Allegro?","date_in_series_pattern":false,"status":"past","time":1634832000000,"local_date":"2021-10-21","local_time":"18:00","updated":1634841007000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":67,"venue":{"id":26906060,"name":"Online event","repinned":false,"country":"","localized_country_name":""},"is_online_event":true,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/281441586/","description":"!!!! Rejestracja: https://app.evenea.pl/event/allegro-tech-live-22/ !!!! Allegro Tech Live to w 100% zdalna odsłona naszych stacjonarnych meetupów Allegro Tech Talks. Zazwyczaj spotykaliśmy się w naszych biurach, ale…","visibility":"public","member_pay_fee":false}],"podcasts":[{"title":"S02E12 - Piotr Betkier - Rola architekta w Allegro","link":"https://podcast.allegro.tech/rola_architekta_w_allegro/","pubDate":"Wed, 16 Jun 2021 00:00:00 GMT","content":"Od kodowania do tworzenia strategii technicznej... Jak wygląda rola architekta w Allegro? Ile takich osób pracuje w naszej firmie i dlaczego ta rola jest tak różnorodna? Czym jest Andamio i jak rozwijamy naszą platformę – o tym wszystkim opowie Piotr Betkier – Inżynier, Architekt Platformy Technicznej w Allegro oraz twórca piosenek o IT :)","contentSnippet":"Od kodowania do tworzenia strategii technicznej... Jak wygląda rola architekta w Allegro? Ile takich osób pracuje w naszej firmie i dlaczego ta rola jest tak różnorodna? Czym jest Andamio i jak rozwijamy naszą platformę – o tym wszystkim opowie Piotr Betkier – Inżynier, Architekt Platformy Technicznej w Allegro oraz twórca piosenek o IT :)","guid":"https://podcast.allegro.tech/rola_architekta_w_allegro/","isoDate":"2021-06-16T00:00:00.000Z"},{"title":"S02E11 - Piotr Michoński - Infrastruktura Allegro","link":"https://podcast.allegro.tech/infrastruktura_Allegro/","pubDate":"Tue, 01 Jun 2021 00:00:00 GMT","content":"Jak jest zbudowane środowisko uruchomienia aplikacji Allegro? Jak działają serwerownie firmy i ile ich potrzeba, a które elementy Allegro działają w chmurze publicznej? Jak przebiegała transformacja w Allegro i co zmieniało się przez lata? Jak wzrost biznesu wpływa na wielkość infrastruktury i jak infrastruktura Allegro odczuła przyjście pandemii? O tym, a także o rozwoju liderów technologii w Allegro oraz o historii powstania dżingla do naszych podcastów, opowie Piotr Michoński - menadżer Zespołów tworzących infrastrukturę Allegro.","contentSnippet":"Jak jest zbudowane środowisko uruchomienia aplikacji Allegro? Jak działają serwerownie firmy i ile ich potrzeba, a które elementy Allegro działają w chmurze publicznej? Jak przebiegała transformacja w Allegro i co zmieniało się przez lata? Jak wzrost biznesu wpływa na wielkość infrastruktury i jak infrastruktura Allegro odczuła przyjście pandemii? O tym, a także o rozwoju liderów technologii w Allegro oraz o historii powstania dżingla do naszych podcastów, opowie Piotr Michoński - menadżer Zespołów tworzących infrastrukturę Allegro.","guid":"https://podcast.allegro.tech/infrastruktura_Allegro/","isoDate":"2021-06-01T00:00:00.000Z"},{"title":"S02E10 - Dariusz Eliasz - Praca architekta ekosystemu big data w Allegro","link":"https://podcast.allegro.tech/praca_architekta_ekosystemu_big_data_w_Allegro/","pubDate":"Thu, 20 May 2021 00:00:00 GMT","content":"Jak wygląda praca architekta ekosystemu big data w Allegro? Jakie zadania realizuje nasz zespół odpowiedzialny za narzędzia i infrastrukturę dla przetwarzania danych? Kiedy możemy mówić o dużych danych i ile petabajtów przetwarza Allegro? Skąd pochodzą dane Allegro i dlaczego jest ich tak dużo oraz z jakiego powodu dopiero teraz przenosimy się do chmury? O tym wszystkim opowie zdobywca statuetki Allegro Tech Hero - Dariusz Eliasz – Team Manager & Platform Architect w Allegro.","contentSnippet":"Jak wygląda praca architekta ekosystemu big data w Allegro? Jakie zadania realizuje nasz zespół odpowiedzialny za narzędzia i infrastrukturę dla przetwarzania danych? Kiedy możemy mówić o dużych danych i ile petabajtów przetwarza Allegro? Skąd pochodzą dane Allegro i dlaczego jest ich tak dużo oraz z jakiego powodu dopiero teraz przenosimy się do chmury? O tym wszystkim opowie zdobywca statuetki Allegro Tech Hero - Dariusz Eliasz – Team Manager & Platform Architect w Allegro.","guid":"https://podcast.allegro.tech/praca_architekta_ekosystemu_big_data_w_Allegro/","isoDate":"2021-05-20T00:00:00.000Z"},{"title":"S02E09 - Bartosz Gałek - Od inżyniera do lidera w Allegro","link":"https://podcast.allegro.tech/od_inzyniera_do_lidera_w_allegro/","pubDate":"Thu, 06 May 2021 00:00:00 GMT","content":"Czym jest Opbox i jakie wyzwania przed nim stoją? Jak w Allegro angażujemy się w rozwój kultury Open Source? Ile mamy projektów na GitHubie i jak świętujemy Hacktoberfest? W jaki sposób można rozwinąć się od inżyniera do lidera? Na te pytania w najnowszym Allegro Tech Podcast odpowie Bartek Gałek, Team Leader w Allegro.","contentSnippet":"Czym jest Opbox i jakie wyzwania przed nim stoją? Jak w Allegro angażujemy się w rozwój kultury Open Source? Ile mamy projektów na GitHubie i jak świętujemy Hacktoberfest? W jaki sposób można rozwinąć się od inżyniera do lidera? Na te pytania w najnowszym Allegro Tech Podcast odpowie Bartek Gałek, Team Leader w Allegro.","guid":"https://podcast.allegro.tech/od_inzyniera_do_lidera_w_allegro/","isoDate":"2021-05-06T00:00:00.000Z"}]},"__N_SSG":true}