{"pageProps":{"posts":[{"title":"Engineering culture of Allegro & Allegro Pay: Pragmatic Engineer Score","link":"https://blog.allegro.tech/2024/06/pragmatic-engineer-score.html","pubDate":"Tue, 11 Jun 2024 00:00:00 +0200","authors":{"author":[{"name":["Jakub Dropia"],"photo":["https://blog.allegro.tech/img/authors/jakub.dropia.jpg"],"url":["https://blog.allegro.tech/authors/jakub.dropia"]}]},"content":"<p>One tech blog/newsletter gained traction and popularity for a couple of years now: <a href=\"https://blog.pragmaticengineer.com/\">Pragmatic Engineer</a>.</p>\n\n<p>Quoting author:</p>\n\n<p><em>The #1 technology newsletter on Substack. Highly relevant for software engineers and engineering managers, useful for those working in tech.\nWritten by engineering manager and software engineer Gergely Orosz who was previously at Uber, Skype/Microsoft, and at startups.</em></p>\n\n<p>In practice, you will find a huge amount of information and internal insights on how big tech works in many companies.\nThere are many deep dives into engineering culture, best practices, and what goes on behind the scenes.</p>\n\n<p>There is one particular entry in the blog that I would like to share and talk about:</p>\n\n<p><a href=\"https://blog.pragmaticengineer.com/pragmatic-engineer-test/\">The Pragmatic Engineer Test</a></p>\n\n<p>What is it?</p>\n\n<p>It is a checklist of 12 questions, and answering them can ‚Äúmeasure‚Äù the company‚Äôs engineering maturity.</p>\n\n<p>Working in Allegro Pay for four years, I saw a lot of these practices over the years. Hell, I had the opportunity to build some of them, which\nis a valuable thing here. Everyone is open-minded and you can influence your workplace.</p>\n\n<p>But when I came upon this article - it was natural to try to evaluate my current workplace against it.</p>\n\n<p>I did it, and I would like to share the results with you without further ado.</p>\n\n<h1 id=\"disclaimer\">Disclaimer</h1>\n\n<p>I work at Allegro Pay, a company of Allegro Group responsible for Allegro Pay, Care, and Cash products.\nWhat I write further is heavily grounded in the Allegro Pay context, as we have different tech stacks, environments, and technical platforms.\nHowever, all practices are present both at Allegro and at Allegro Pay. The execution may differ, but engineering maturity is very similar in the end.</p>\n\n<h1 id=\"tldr\">TL;DR</h1>\n\n<p>In short - Allegro &amp; Allegro Pay scored 11 points out of 12.</p>\n\n<p>If you want to stop here - the takeaway is:</p>\n\n<p><em>this is a great place for software engineers</em></p>\n\n<p>We have JAVA, .NET, cloud, our own data centers, a mobile-first approach and modern web, a good microservices ecosystem,\na great internal developer platform (or even two!), data engineering and ML, and a product that makes money.</p>\n\n<p>Would you like to hear nice, sweet, and bitter details?</p>\n\n<p>Continue reading üôÇ</p>\n\n<p><a href=\"https://blog.pragmaticengineer.com/pragmatic-engineer-test/\">12 Questions</a> and my answers to them.</p>\n\n<h1 id=\"equity-or-profit-sharing\">Equity or profit sharing</h1>\n\n<p>Half Yes. Not all engineers.</p>\n\n<p>Allegro Group is a <a href=\"https://www.gpw.pl/company-factsheet?isin=LU2237380790\">public trading company</a> in Poland. Our engineers can gain stocks as a part of their total compensation package. How does this work?</p>\n\n<p>Well, each senior level and above engineer gains a stocks package yearly as a part of the end-year review. The package is vested over 3 years with (25%, 25% and 50%) proportions.\nVested parts of each package are transferred to your broker account each year and can overlap. The final amount depends on company and individual results.\nIn Poland, these stocks are 19% taxed (if you decide to sell them).</p>\n\n<p>In addition, all employees receive a yearly bonus, which, of course, also depends on the company and individual results.</p>\n\n<p>Both are a significant addition to our overall compensation package.</p>\n\n<p>Caveats?</p>\n\n<p>Stocks are still not part of the offer for newcomers, which I think could contribute to attracting more great engineers.</p>\n\n<h1 id=\"roadmapbacklog-that-engineers-contribute-to\">Roadmap/backlog that engineers contribute to</h1>\n\n<p>Yes.</p>\n\n<p>Each team usually has its backlog. The product manager assigned to that team, the engineering manager, and the team itself are responsible for building\nand maintaining this backlog around functionalities and domains that they own. The backlog is a mix of business features, some maintenance, and technical stories.\nHow it is built and tracked, if teams work in Scrum, Kanban, or some custom approach - is primarily up to the team. In the end, we have some processes that try\nto gather ‚Äúbigger‚Äù deliverables and compose a roadmap and plans for the whole organization at the same root.</p>\n\n<p>It works great and allows teams huge flexibility and freedom in their work. As a trade-off, extra work is needed to map these backlogs into\nthe organizational level processes - which, usually, are in Google Sheets or a custom tool.</p>\n\n<h1 id=\"engineers-directly-working-with-other-ics-individual-contributors\">Engineers directly working with other ICs (Individual Contributors)</h1>\n\n<p>Yes.</p>\n\n<p>We collaborate with each other, regardless of role and career level. Even if other ICs are in different teams, the expectation is to communicate with them directly.\nYou can just write to anyone, and can expect to get an answer. There are some protections to prevent this from turning into complete chaos, like quarterly\nplanning of dependencies between teams, help channels, and so on, but if everyone works on the same page, we are just working together without unnecessary barriers.</p>\n\n<h1 id=\"code-reviews-and-testing\">Code reviews and testing</h1>\n\n<p>Yes.</p>\n\n<p>We have a test platform for automatic E2E tests. Manual testers are available for complex functionalities spanning multiple services.\nTo protect quality, we have code review policies for each repository. In CI/CD, the advanced build system protects us and validates many things\n(unit/integration tests, outdated / beta packages, code formats, etc.) before they go to the main branch.</p>\n\n<p>All of that is part of everyday workflow. Sometimes, it slows you down, but it is done smartly and, most of the time, helps. As always, everything is under your control, and in the end, it is your responsibility to use these tools properly.</p>\n\n<h1 id=\"ci-and-engineers-pushing-to-prod\">CI and engineers pushing to prod</h1>\n\n<p>Yes.</p>\n\n<p>At Allegro Pay, every commit on the main branch triggers a pipeline that goes through the entire CI/CD process, is automatically deployed to the DEV and TEST environment,\nand stops with manual approval before releasing to PROD. Approval needs the acceptance of another engineer than the one who changes the triggered pipeline.\nEach team is responsible for its changes and deployments. We build it, we run it, and we own it.</p>\n\n<p>Of course, that can also vary. Sometimes, additional security measurements need to be applied depending on the context and product.\nBut in the end - we have continuous delivery with dozens of deployments daily.</p>\n\n<h1 id=\"internal-open-source\">Internal open source</h1>\n\n<p>Yes.</p>\n\n<p>Each developer is welcome to issue a PR in components that do not belong to him or his team. We have common internal libraries which are developed and maintained across teams.\nOn the other hand, each repository has only one owner. It works well; people are open-minded and will always consider your contribution.</p>\n\n<p>In practice, this doesn‚Äôt happen that often. Most of the work is focused on components that your team owns, and sometimes differences between ‚Äúservices‚Äù\n(different technologies, architecture, etc.), and lack of proper documentation are barriers to quick contribution - because you need to understand the service\nand domain first before you will be able to change something that you don‚Äôt own.</p>\n\n<p>Additionally, we have a <a href=\"https://github.com/allegro\">catalog</a> of external open-sourced repositories. You can find many great tools and libraries, some of which you may can even know, like\n<a href=\"https://github.com/allegro/bigcache\">bigcache</a>, <a href=\"https://github.com/allegro/hermes\">hermes</a> or <a href=\"https://github.com/allegro/ralph\">ralph</a>. For Allegro Pay itself we also do have <a href=\"https://github.com/topics/allegropay\">some</a>.</p>\n\n<p>What is truly unique and I think fits into this position, is internal tourism. Anyone can request to join any team, and as a regular member work up to a couple of months (usually a quarter), contributing to other teams‚Äô work.</p>\n\n<h1 id=\"healthy-on-call-as-a-priority\">Healthy on-call as a priority.</h1>\n\n<p>Yes.</p>\n\n<p>We do have on-call duty. This is a part of ‚Äúwe own it‚Äù.</p>\n\n<p>How this is implemented may vary depending on the area or teams, but in the end, there are some streams of on-duty calls where people\nperform 24-hour on-duty shifts cyclically. These duties are extra paid (for being ‚Äúready‚Äù). If something happens during duty - your intervention outside working hours is\npaid according to the Polish overtime hours policy (150% or 200% hour rate depends on when this occurs), or you can exchange them for vacation at another time.</p>\n\n<p>We have generic alerts, but each stream also has specific rules. There is a common practice where teams improve and change them to remove noise, false positives,\nor simplify on-duty shifts. In the end - SLA must be met - and how teams will approach this - is up to them.</p>\n\n<h1 id=\"technical-managers\">Technical managers.</h1>\n\n<p>Yes.</p>\n\n<p>Most of our engineering managers have a background in software engineering. They were seniors once and were promoted to manager, taking a step aside from pure IC.\nEven if hiring from outside, they must complete all the technical workshops. It is expected that they will still be experts in the field.</p>\n\n<p>They are deeply rooted in technology. They perform system designs, code reviews, consultancy, and sometimes coding. Proportion varies depending on the team and\nthe manager themselves. Besides people management, they are expected to have ownership of technical decisions and project management of the part which the team is responsible for.</p>\n\n<h1 id=\"career-ladder-when-above-10-engineers--parallel-ic-and-manager-tracks-when-above-30-engineers\">Career ladder (when above 10 engineers) &amp; Parallel IC and manager tracks (when above 30 engineers).</h1>\n\n<p>Yes &amp; half yes</p>\n\n<p>We have a career level for Software Engineer Job Family, which starts from a junior position, goes through mid to senior level, and then splits into two tracks - Individual Contributor and Manager.\nThis split is fairly fresh, as there was only a Manager track before. Because of that, this one is pretty mature, with career progression starting from\nEngineering Manager, going through Senior Engineering Manager, Director, VP or CTO.</p>\n\n<p>If we are talking about the IC path - here we have right now the Principal Software Engineer, whose scope of the work is at least an area or even the whole organization,\nand the Senior Principal Software Engineer is one person for the whole organization.</p>\n\n<p>As you can see, ladders are missing in the IC track; from what I know, this is still in progress. The organization is trying to figure out what IC ladder fits its needs.</p>\n\n<p>There are few opportunities for Individual Contributors above the Senior level. This can be improved, and it will likely be.</p>\n\n<h1 id=\"feedback-culture\">Feedback culture.</h1>\n\n<p>Yes.</p>\n\n<p>I think it is everywhere.</p>\n\n<p>We have continuous feedback - 360, peer-to-peer, promotion, employee engagement surveys and during each half-year performance review. At each significant meeting, a space for Q&amp;A.\nFeedback is deeply rooted in our daily work. You can see polls, surveys, requests for feedback and opinions, post-mortems, and so on everywhere.\nIt is hard to imagine what else we could do to cover this topic, one of our culture‚Äôs strongest traits.</p>\n\n<h1 id=\"investing-in-professional-growth\">Investing in professional growth.</h1>\n\n<p>Yes.</p>\n\n<p>This is realized in multiple ways. Each team/individual has a ‚Äútraining budget‚Äù - this is money you can spend on external training, courses, and conferences.\nIt differs from team to team, and used to be much better in past.\nAdditionally, we have an internal learning platform with many great workshops - especially in the soft skills area. They are great! You can upskill yourself well.</p>\n\n<p>Also, in some areas and teams, there is a time dedicated to your self-development. You can spend it on contributions to open-source, reading a book,\nlearning from the course, or, for example, writing a PoC of new technology with your team. In Allegro Pay - it is 10%. How you spend it - is up to you,\nor the team, it just should stick to our profession.</p>\n\n<p>There are many internal and external communities (guilds), each with its own meeting calendar and interesting presentations and workshops taking a different kind of forms.\nThere are also many internal events, hackathons, and initiatives. Opportunities to learn are almost infinite.</p>\n\n<p>Landing here was my biggest personal and professional progression so far.</p>\n\n<h1 id=\"the-bitter-or-not\">The bitter (or not?)</h1>\n\n<p>Sounds sweet, right? Where is the bitter here? Well, I am not sure.</p>\n\n<p>This is a rapid-growth product and company. We are focused on delivering value to clients and maximizing profit from our products.\nEverything we do must contribute to overall success, and there is little space to ‚Äúbreathe‚Äù. You must often balance delivering functionalities,\npaying back technical debt, and growing scale. Taking shortcuts. Making trade-offs. Asking difficult questions. Our roadmaps often change\nbecause of the economics, law, or maybe data we gathered and told us that our actions do not convert in the way we assumed.\nIn Allegro Pay itself - the financial domain also does not help ‚Äî a huge amount of our work is dedicated to legal matters. New laws pop up, and we must follow them.</p>\n\n<p>I can imagine that it can‚Äôt be for everyone.</p>\n\n<p>But for me, this introduces an entirely new layer of engineering, where you need to be smart, cautious, value impact, and make the right choices.</p>\n\n<p>We strive to be the best in the market, which is why we succeed.</p>\n\n<p>Another thing can be the corporation itself. But this is very likely something that you will not notice until you become a manager.</p>\n\n<p>Allegro is a big company that has shifted to a more centralized and structured approach over the years. Everything needs to be aligned with the process.\nTo picture this, here are a few examples:</p>\n\n<ul>\n  <li>\n    <p>Instead of ordering any accessories required within the budget - the budget was removed, and you can order only specific, pre-selected accessories</p>\n  </li>\n  <li>\n    <p>Want to hire someone? There is budgeting once per year, and you need to come prepared to justify another full-time equivalent.</p>\n  </li>\n  <li>\n    <p>Do you want to give someone a raise? Well, you don‚Äôt have to worry about this. Process, one per year, will do that for you.\nYou need to provide a performance review of your directs. Based on that you will get the budget, recommendations, and ability to slightly change proportions.</p>\n  </li>\n  <li>\n    <p>Want to pursue external training? You have a budget. It would be best if you fit it in. You need to raise a request and process it through several layers of acceptance.</p>\n  </li>\n</ul>\n\n<p>As you can imagine, all of that can take time and be annoying. It is very frequent that your ‚Äúrequest‚Äù is stuck somewhere, and you need to ‚Äúpush‚Äù it.\nBut on the other end of the process, there are helpful people whom you can always talk to.</p>\n\n<p>Sometimes, this leads to funny absurdities - you find an old monitor in the office that is not assigned to anyone (or a person who is not already in the company),\nand you would like to order a docking station for it. ‚ÄúProcedures‚Äù will not allow you to do that. The dock must have existed before; if lost,\nonly the owner can ‚Äúorder‚Äù a new one with a good justification. But you are not the owner. It is no man‚Äôs land - thus - no dock for it ;)</p>\n\n<p>But I think most big corporations work like that. The past few years were also difficult for the industry. I understand why this is happening.\nIf you are an individual contributor, most of these things will not affect you. And those which do - you need to get used to it, and if you focus on the rest - hell - this is a great place to work.</p>\n\n<h1 id=\"is-there-more\">Is there more?</h1>\n\n<p>A score of 11 tells that you will find much good stuff in software engineering here.</p>\n\n<p>But this is not all. There are plenty of other great features of engineering culture at Allegro &amp; Allegro Pay. You have great products, a big scale and\na data-driven approach which leads to many challenges; amazing, intelligent people; modern technology and approach to software engineering;\nrich off-topic communities (board games, sports, FIFA league, etc.), and many more.</p>\n\n<p>Overall, #DobrzeTuByƒá (#GoodToBeHere)</p>\n","contentSnippet":"One tech blog/newsletter gained traction and popularity for a couple of years now: Pragmatic Engineer.\nQuoting author:\nThe #1 technology newsletter on Substack. Highly relevant for software engineers and engineering managers, useful for those working in tech.\nWritten by engineering manager and software engineer Gergely Orosz who was previously at Uber, Skype/Microsoft, and at startups.\nIn practice, you will find a huge amount of information and internal insights on how big tech works in many companies.\nThere are many deep dives into engineering culture, best practices, and what goes on behind the scenes.\nThere is one particular entry in the blog that I would like to share and talk about:\nThe Pragmatic Engineer Test\nWhat is it?\nIt is a checklist of 12 questions, and answering them can ‚Äúmeasure‚Äù the company‚Äôs engineering maturity.\nWorking in Allegro Pay for four years, I saw a lot of these practices over the years. Hell, I had the opportunity to build some of them, which\nis a valuable thing here. Everyone is open-minded and you can influence your workplace.\nBut when I came upon this article - it was natural to try to evaluate my current workplace against it.\nI did it, and I would like to share the results with you without further ado.\nDisclaimer\nI work at Allegro Pay, a company of Allegro Group responsible for Allegro Pay, Care, and Cash products.\nWhat I write further is heavily grounded in the Allegro Pay context, as we have different tech stacks, environments, and technical platforms.\nHowever, all practices are present both at Allegro and at Allegro Pay. The execution may differ, but engineering maturity is very similar in the end.\nTL;DR\nIn short - Allegro & Allegro Pay scored 11 points out of 12.\nIf you want to stop here - the takeaway is:\nthis is a great place for software engineers\nWe have JAVA, .NET, cloud, our own data centers, a mobile-first approach and modern web, a good microservices ecosystem,\na great internal developer platform (or even two!), data engineering and ML, and a product that makes money.\nWould you like to hear nice, sweet, and bitter details?\nContinue reading üôÇ\n12 Questions and my answers to them.\nEquity or profit sharing\nHalf Yes. Not all engineers.\nAllegro Group is a public trading company in Poland. Our engineers can gain stocks as a part of their total compensation package. How does this work?\nWell, each senior level and above engineer gains a stocks package yearly as a part of the end-year review. The package is vested over 3 years with (25%, 25% and 50%) proportions.\nVested parts of each package are transferred to your broker account each year and can overlap. The final amount depends on company and individual results.\nIn Poland, these stocks are 19% taxed (if you decide to sell them).\nIn addition, all employees receive a yearly bonus, which, of course, also depends on the company and individual results.\nBoth are a significant addition to our overall compensation package.\nCaveats?\nStocks are still not part of the offer for newcomers, which I think could contribute to attracting more great engineers.\nRoadmap/backlog that engineers contribute to\nYes.\nEach team usually has its backlog. The product manager assigned to that team, the engineering manager, and the team itself are responsible for building\nand maintaining this backlog around functionalities and domains that they own. The backlog is a mix of business features, some maintenance, and technical stories.\nHow it is built and tracked, if teams work in Scrum, Kanban, or some custom approach - is primarily up to the team. In the end, we have some processes that try\nto gather ‚Äúbigger‚Äù deliverables and compose a roadmap and plans for the whole organization at the same root.\nIt works great and allows teams huge flexibility and freedom in their work. As a trade-off, extra work is needed to map these backlogs into\nthe organizational level processes - which, usually, are in Google Sheets or a custom tool.\nEngineers directly working with other ICs (Individual Contributors)\nYes.\nWe collaborate with each other, regardless of role and career level. Even if other ICs are in different teams, the expectation is to communicate with them directly.\nYou can just write to anyone, and can expect to get an answer. There are some protections to prevent this from turning into complete chaos, like quarterly\nplanning of dependencies between teams, help channels, and so on, but if everyone works on the same page, we are just working together without unnecessary barriers.\nCode reviews and testing\nYes.\nWe have a test platform for automatic E2E tests. Manual testers are available for complex functionalities spanning multiple services.\nTo protect quality, we have code review policies for each repository. In CI/CD, the advanced build system protects us and validates many things\n(unit/integration tests, outdated / beta packages, code formats, etc.) before they go to the main branch.\nAll of that is part of everyday workflow. Sometimes, it slows you down, but it is done smartly and, most of the time, helps. As always, everything is under your control, and in the end, it is your responsibility to use these tools properly.\nCI and engineers pushing to prod\nYes.\nAt Allegro Pay, every commit on the main branch triggers a pipeline that goes through the entire CI/CD process, is automatically deployed to the DEV and TEST environment,\nand stops with manual approval before releasing to PROD. Approval needs the acceptance of another engineer than the one who changes the triggered pipeline.\nEach team is responsible for its changes and deployments. We build it, we run it, and we own it.\nOf course, that can also vary. Sometimes, additional security measurements need to be applied depending on the context and product.\nBut in the end - we have continuous delivery with dozens of deployments daily.\nInternal open source\nYes.\nEach developer is welcome to issue a PR in components that do not belong to him or his team. We have common internal libraries which are developed and maintained across teams.\nOn the other hand, each repository has only one owner. It works well; people are open-minded and will always consider your contribution.\nIn practice, this doesn‚Äôt happen that often. Most of the work is focused on components that your team owns, and sometimes differences between ‚Äúservices‚Äù\n(different technologies, architecture, etc.), and lack of proper documentation are barriers to quick contribution - because you need to understand the service\nand domain first before you will be able to change something that you don‚Äôt own.\nAdditionally, we have a catalog of external open-sourced repositories. You can find many great tools and libraries, some of which you may can even know, like\nbigcache, hermes or ralph. For Allegro Pay itself we also do have some.\nWhat is truly unique and I think fits into this position, is internal tourism. Anyone can request to join any team, and as a regular member work up to a couple of months (usually a quarter), contributing to other teams‚Äô work.\nHealthy on-call as a priority.\nYes.\nWe do have on-call duty. This is a part of ‚Äúwe own it‚Äù.\nHow this is implemented may vary depending on the area or teams, but in the end, there are some streams of on-duty calls where people\nperform 24-hour on-duty shifts cyclically. These duties are extra paid (for being ‚Äúready‚Äù). If something happens during duty - your intervention outside working hours is\npaid according to the Polish overtime hours policy (150% or 200% hour rate depends on when this occurs), or you can exchange them for vacation at another time.\nWe have generic alerts, but each stream also has specific rules. There is a common practice where teams improve and change them to remove noise, false positives,\nor simplify on-duty shifts. In the end - SLA must be met - and how teams will approach this - is up to them.\nTechnical managers.\nYes.\nMost of our engineering managers have a background in software engineering. They were seniors once and were promoted to manager, taking a step aside from pure IC.\nEven if hiring from outside, they must complete all the technical workshops. It is expected that they will still be experts in the field.\nThey are deeply rooted in technology. They perform system designs, code reviews, consultancy, and sometimes coding. Proportion varies depending on the team and\nthe manager themselves. Besides people management, they are expected to have ownership of technical decisions and project management of the part which the team is responsible for.\nCareer ladder (when above 10 engineers) & Parallel IC and manager tracks (when above 30 engineers).\nYes & half yes\nWe have a career level for Software Engineer Job Family, which starts from a junior position, goes through mid to senior level, and then splits into two tracks - Individual Contributor and Manager.\nThis split is fairly fresh, as there was only a Manager track before. Because of that, this one is pretty mature, with career progression starting from\nEngineering Manager, going through Senior Engineering Manager, Director, VP or CTO.\nIf we are talking about the IC path - here we have right now the Principal Software Engineer, whose scope of the work is at least an area or even the whole organization,\nand the Senior Principal Software Engineer is one person for the whole organization.\nAs you can see, ladders are missing in the IC track; from what I know, this is still in progress. The organization is trying to figure out what IC ladder fits its needs.\nThere are few opportunities for Individual Contributors above the Senior level. This can be improved, and it will likely be.\nFeedback culture.\nYes.\nI think it is everywhere.\nWe have continuous feedback - 360, peer-to-peer, promotion, employee engagement surveys and during each half-year performance review. At each significant meeting, a space for Q&A.\nFeedback is deeply rooted in our daily work. You can see polls, surveys, requests for feedback and opinions, post-mortems, and so on everywhere.\nIt is hard to imagine what else we could do to cover this topic, one of our culture‚Äôs strongest traits.\nInvesting in professional growth.\nYes.\nThis is realized in multiple ways. Each team/individual has a ‚Äútraining budget‚Äù - this is money you can spend on external training, courses, and conferences.\nIt differs from team to team, and used to be much better in past.\nAdditionally, we have an internal learning platform with many great workshops - especially in the soft skills area. They are great! You can upskill yourself well.\nAlso, in some areas and teams, there is a time dedicated to your self-development. You can spend it on contributions to open-source, reading a book,\nlearning from the course, or, for example, writing a PoC of new technology with your team. In Allegro Pay - it is 10%. How you spend it - is up to you,\nor the team, it just should stick to our profession.\nThere are many internal and external communities (guilds), each with its own meeting calendar and interesting presentations and workshops taking a different kind of forms.\nThere are also many internal events, hackathons, and initiatives. Opportunities to learn are almost infinite.\nLanding here was my biggest personal and professional progression so far.\nThe bitter (or not?)\nSounds sweet, right? Where is the bitter here? Well, I am not sure.\nThis is a rapid-growth product and company. We are focused on delivering value to clients and maximizing profit from our products.\nEverything we do must contribute to overall success, and there is little space to ‚Äúbreathe‚Äù. You must often balance delivering functionalities,\npaying back technical debt, and growing scale. Taking shortcuts. Making trade-offs. Asking difficult questions. Our roadmaps often change\nbecause of the economics, law, or maybe data we gathered and told us that our actions do not convert in the way we assumed.\nIn Allegro Pay itself - the financial domain also does not help ‚Äî a huge amount of our work is dedicated to legal matters. New laws pop up, and we must follow them.\nI can imagine that it can‚Äôt be for everyone.\nBut for me, this introduces an entirely new layer of engineering, where you need to be smart, cautious, value impact, and make the right choices.\nWe strive to be the best in the market, which is why we succeed.\nAnother thing can be the corporation itself. But this is very likely something that you will not notice until you become a manager.\nAllegro is a big company that has shifted to a more centralized and structured approach over the years. Everything needs to be aligned with the process.\nTo picture this, here are a few examples:\nInstead of ordering any accessories required within the budget - the budget was removed, and you can order only specific, pre-selected accessories\nWant to hire someone? There is budgeting once per year, and you need to come prepared to justify another full-time equivalent.\nDo you want to give someone a raise? Well, you don‚Äôt have to worry about this. Process, one per year, will do that for you.\nYou need to provide a performance review of your directs. Based on that you will get the budget, recommendations, and ability to slightly change proportions.\nWant to pursue external training? You have a budget. It would be best if you fit it in. You need to raise a request and process it through several layers of acceptance.\nAs you can imagine, all of that can take time and be annoying. It is very frequent that your ‚Äúrequest‚Äù is stuck somewhere, and you need to ‚Äúpush‚Äù it.\nBut on the other end of the process, there are helpful people whom you can always talk to.\nSometimes, this leads to funny absurdities - you find an old monitor in the office that is not assigned to anyone (or a person who is not already in the company),\nand you would like to order a docking station for it. ‚ÄúProcedures‚Äù will not allow you to do that. The dock must have existed before; if lost,\nonly the owner can ‚Äúorder‚Äù a new one with a good justification. But you are not the owner. It is no man‚Äôs land - thus - no dock for it ;)\nBut I think most big corporations work like that. The past few years were also difficult for the industry. I understand why this is happening.\nIf you are an individual contributor, most of these things will not affect you. And those which do - you need to get used to it, and if you focus on the rest - hell - this is a great place to work.\nIs there more?\nA score of 11 tells that you will find much good stuff in software engineering here.\nBut this is not all. There are plenty of other great features of engineering culture at Allegro & Allegro Pay. You have great products, a big scale and\na data-driven approach which leads to many challenges; amazing, intelligent people; modern technology and approach to software engineering;\nrich off-topic communities (board games, sports, FIFA league, etc.), and many more.\nOverall, #DobrzeTuByƒá (#GoodToBeHere)","guid":"https://blog.allegro.tech/2024/06/pragmatic-engineer-score.html","categories":["tech","engineering culture","pragmatic engineer"],"isoDate":"2024-06-10T22:00:00.000Z"},{"title":"REST service client: design, testing, monitoring","link":"https://blog.allegro.tech/2024/06/rest-service-client-design-testing-monitoring.html","pubDate":"Tue, 04 Jun 2024 00:00:00 +0200","authors":{"author":[{"name":["Piotr Klimiec"],"photo":["https://blog.allegro.tech/img/authors/piotr.klimiec.jpg"],"url":["https://blog.allegro.tech/authors/piotr.klimiec"]}]},"content":"<p>The purpose of this article is to present how to design, test, and monitor a REST service client.\nThe article includes a <a href=\"https://github.com/Klimiec/webclients\">repository</a> with clients written in Kotlin using various technologies such as <a href=\"https://docs.spring.io/spring-framework/reference/web/webflux-webclient.html\">WebClient</a>,\n<a href=\"https://docs.spring.io/spring-framework/reference/integration/rest-clients.html#rest-restclient\">RestClient</a>,\n<a href=\"https://ktor.io/docs/getting-started-ktor-client.html\">Ktor Client</a>,\n<a href=\"https://square.github.io/retrofit/\">Retrofit</a>.\nIt demonstrates how to send and retrieve data from an external service, add a cache layer, and parse the received response into domain objects.</p>\n\n<h2 id=\"motivation\">Motivation</h2>\n<p>Why do we need objects in the project that encapsulate the HTTP clients we use?\nTo begin with, we want to separate the domain from technical details.\nThe way we retrieve/send data and handle errors, which can be quite complex in the case of HTTP clients, should not clutter business logic.\nNext, testability. Even if we do not use <a href=\"/2020/05/hexagonal-architecture-by-example.html\">hexagonal architecture</a> in our applications,\nit‚Äôs beneficial to separate the infrastructure from the service layer, as it improves testability.\nVerifying an HTTP service client is not a simple task and requires consideration of many cases ‚Äî mainly at the integration level.\nHaving a separate ‚Äúbuilding block‚Äú that encapsulates communication with the outside world makes testing much easier.\nFinally, reusability. A service client that has been written once can be successfully used in other projects.</p>\n\n<h2 id=\"client-design\">Client Design</h2>\n<p>As a case study, I will use an example implementation that utilizes WebClient for retrieving data from the Order Management Service,\nan example service that might appear in an e-commerce site such as <a href=\"https://allegro.tech/\">Allegro</a>.\nThe heart of our client is the <code class=\"language-plaintext highlighter-rouge\">executeHttpRequest</code> method, which is responsible for executing the provided HTTP request, logging, and error handling.\nIt is not part of the WebClient library.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kd\">class</span> <span class=\"nc\">OrderManagementServiceClient</span><span class=\"p\">(</span>\n    <span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">orderManagementServiceApi</span><span class=\"p\">:</span> <span class=\"nc\">OrderManagementServiceApi</span><span class=\"p\">,</span>\n    <span class=\"k\">private</span> <span class=\"kd\">val</span> <span class=\"py\">clientName</span><span class=\"p\">:</span> <span class=\"nc\">String</span>\n<span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"k\">suspend</span> <span class=\"k\">fun</span> <span class=\"nf\">getOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">:</span> <span class=\"nc\">ClientId</span><span class=\"p\">):</span> <span class=\"nc\">OrdersDto</span> <span class=\"p\">{</span>\n        <span class=\"k\">return</span> <span class=\"nf\">executeHttpRequest</span><span class=\"p\">(</span>\n            <span class=\"n\">initialLog</span> <span class=\"p\">=</span> <span class=\"s\">\"[$clientName] Get orders for a clientId= $clientId\"</span><span class=\"p\">,</span>\n            <span class=\"n\">request</span> <span class=\"p\">=</span> <span class=\"p\">{</span> <span class=\"n\">orderManagementServiceApi</span><span class=\"p\">.</span><span class=\"nf\">getOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">)</span> <span class=\"p\">},</span>\n            <span class=\"n\">successLog</span> <span class=\"p\">=</span> <span class=\"s\">\"[$clientName] Returned orders for a clientId= $clientId\"</span><span class=\"p\">,</span>\n            <span class=\"n\">failureMessage</span> <span class=\"p\">=</span> <span class=\"s\">\"[$clientName] Failed to get orders for clientId= $clientId\"</span>\n        <span class=\"p\">)</span>\n    <span class=\"p\">}</span>\n<span class=\"p\">}</span>\n\n</code></pre></div></div>\n\n<p>Full working example can be found <a href=\"https://github.com/Klimiec/webclients/tree/main/httpclient-webclientinterface\">here</a>.</p>\n\n<h3 id=\"client-name\">Client name</h3>\n<p>I like to name clients using the convention: name of the service we integrate with, plus the suffix <strong>Client</strong>.\nIn the case of integration with the Order Management Service, such a class will be named <code class=\"language-plaintext highlighter-rouge\">OrderManagementServiceClient</code>.</p>\n\n<p>If the technology we use employs an interface to describe the called REST API (RestClient, WebClient, Retrofit),\nwe can name such an interface <code class=\"language-plaintext highlighter-rouge\">OrderManagementServiceApi</code> ‚Äî following the general pattern of the service name with the suffix <strong>Api</strong>.</p>\n\n<p>These names may seem intuitive and obvious, but without an established naming convention, we might end up with a project where\ndifferent integrations have the following suffixes: <strong>HttpClient</strong>, <strong>Facade</strong>, <strong>WebClient</strong>, <strong>Adapter</strong>, and <strong>Service</strong>.\nIt‚Äôs important to have a consistent convention and adhere to it throughout the project.</p>\n\n<h3 id=\"api\">API</h3>\n<p>Methods of our clients should have names that reflect the communicative intention behind them.\nTo capture this intention, it is necessary to use a verb in the method‚Äôs name.\nTypically, the correct name will have a structure of verb + resource name, for example, <code class=\"language-plaintext highlighter-rouge\">getOrders</code>  ‚Äî  for methods that retrieve resources.\nIf we want to narrow down the number of returned resources using filters or return a particular resource, I recommend adding the suffix ‚ÄúFor‚Äù before the list of parameters.\nTechnically, these parameters will be part of the query or path parameters.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>fun getOrdersFor(clientId: ClientId): OrdersDto\n</code></pre></div></div>\n\n<p>For methods responsible for creating resources, simply using the verb in the method name is enough,\nas the resource being passed as a parameter effectively conveys the intention of the method.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>fun publish(event: InvoiceCreatedEventDto)\n</code></pre></div></div>\n\n<h3 id=\"logging\">Logging</h3>\n<p>When communicating with external service we‚Äôd like to log the beginning of the interaction, indicating our intention to fetch or send a resource,\nas well as its outcome. The outcome can be either a success, meaning receiving a response with a 2xx status code, or a failure.</p>\n\n<p>Failure can be signaled by status codes (3xx, 4xx, 5xx), resulting from the inability to deserialize the received response into an object,\nexceeding the response time, etc. Generally, <a href=\"/2015/07/testing-server-faults-with-Wiremock.html\">many things can go wrong</a>.\nDepending on the cause of failure, we may want to log the interaction result at different levels (warn/error).\nThere are critical errors that are worth distinguishing (error), and those that will occasionally occur (warn) and don‚Äôt require urgent intervention.</p>\n\n<p>To filter logs related to a specific service while browsing through them, I like to include the client‚Äôs name within curly braces at the beginning of the logs.\nFor logging technical aspects of the communication, such as the URL called, HTTP method used, and response code,\nwe use filters (logRequestInfo, logResponseInfo) that are plugged in at the client configuration level in the <code class=\"language-plaintext highlighter-rouge\">createExternalServiceApi</code> method.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">inline</span> <span class=\"k\">fun</span> <span class=\"p\">&lt;</span><span class=\"k\">reified</span> <span class=\"nc\">T</span><span class=\"p\">&gt;</span> <span class=\"nf\">createExternalServiceApi</span><span class=\"p\">(</span>\n    <span class=\"n\">webClientBuilder</span><span class=\"p\">:</span> <span class=\"nc\">WebClient</span><span class=\"p\">.</span><span class=\"nc\">Builder</span><span class=\"p\">,</span>\n    <span class=\"n\">properties</span><span class=\"p\">:</span> <span class=\"nc\">ConnectionProperties</span>\n<span class=\"p\">):</span> <span class=\"nc\">T</span> <span class=\"p\">=</span>\n    <span class=\"n\">webClientBuilder</span>\n        <span class=\"p\">.</span><span class=\"nf\">clientConnector</span><span class=\"p\">(</span><span class=\"nf\">httpClient</span><span class=\"p\">(</span><span class=\"n\">properties</span><span class=\"p\">))</span>\n        <span class=\"p\">.</span><span class=\"nf\">baseUrl</span><span class=\"p\">(</span><span class=\"n\">properties</span><span class=\"p\">.</span><span class=\"n\">baseUrl</span><span class=\"p\">)</span>\n        <span class=\"p\">.</span><span class=\"nf\">defaultRequest</span> <span class=\"p\">{</span> <span class=\"n\">it</span><span class=\"p\">.</span><span class=\"nf\">attribute</span><span class=\"p\">(</span><span class=\"nc\">SERVICE_NAME</span><span class=\"p\">,</span> <span class=\"n\">properties</span><span class=\"p\">.</span><span class=\"n\">clientName</span><span class=\"p\">)</span> <span class=\"p\">}</span>\n        <span class=\"p\">.</span><span class=\"nf\">filter</span><span class=\"p\">(</span><span class=\"nf\">logRequestInfo</span><span class=\"p\">(</span><span class=\"n\">properties</span><span class=\"p\">.</span><span class=\"n\">clientName</span><span class=\"p\">))</span>\n        <span class=\"p\">.</span><span class=\"nf\">filter</span><span class=\"p\">(</span><span class=\"nf\">logResponseInfo</span><span class=\"p\">(</span><span class=\"n\">properties</span><span class=\"p\">.</span><span class=\"n\">clientName</span><span class=\"p\">))</span>\n        <span class=\"p\">.</span><span class=\"nf\">build</span><span class=\"p\">()</span>\n        <span class=\"p\">.</span><span class=\"nf\">let</span> <span class=\"p\">{</span> <span class=\"nc\">WebClientAdapter</span><span class=\"p\">.</span><span class=\"nf\">create</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">)</span> <span class=\"p\">}</span>\n        <span class=\"p\">.</span><span class=\"nf\">let</span> <span class=\"p\">{</span> <span class=\"nc\">HttpServiceProxyFactory</span><span class=\"p\">.</span><span class=\"nf\">builderFor</span><span class=\"p\">(</span><span class=\"n\">it</span><span class=\"p\">).</span><span class=\"nf\">build</span><span class=\"p\">()</span> <span class=\"p\">}</span>\n        <span class=\"p\">.</span><span class=\"nf\">createClient</span><span class=\"p\">(</span><span class=\"nc\">T</span><span class=\"o\">::</span><span class=\"k\">class</span><span class=\"p\">.</span><span class=\"n\">java</span><span class=\"p\">)</span>\n\n<span class=\"k\">fun</span> <span class=\"nf\">logRequestInfo</span><span class=\"p\">(</span><span class=\"n\">clientName</span><span class=\"p\">:</span> <span class=\"nc\">String</span><span class=\"p\">)</span> <span class=\"p\">=</span> <span class=\"nc\">ExchangeFilterFunction</span><span class=\"p\">.</span><span class=\"nf\">ofRequestProcessor</span> <span class=\"p\">{</span> <span class=\"n\">request</span> <span class=\"p\">-&gt;</span>\n    <span class=\"n\">logger</span><span class=\"p\">.</span><span class=\"nf\">info</span> <span class=\"p\">{</span>\n        <span class=\"s\">\"[$clientName] method=[${request.method().name()}] url=${request.url()}}\"</span>\n    <span class=\"p\">}</span>\n    <span class=\"nc\">Mono</span><span class=\"p\">.</span><span class=\"nf\">just</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n\n<span class=\"k\">fun</span> <span class=\"nf\">logResponseInfo</span><span class=\"p\">(</span><span class=\"n\">clientName</span><span class=\"p\">:</span> <span class=\"nc\">String</span><span class=\"p\">)</span> <span class=\"p\">=</span> <span class=\"nc\">ExchangeFilterFunction</span><span class=\"p\">.</span><span class=\"nf\">ofResponseProcessor</span> <span class=\"p\">{</span> <span class=\"n\">response</span> <span class=\"p\">-&gt;</span>\n    <span class=\"n\">logger</span><span class=\"p\">.</span><span class=\"nf\">info</span> <span class=\"p\">{</span> <span class=\"s\">\"[$clientName] service responded with a status code= ${response.statusCode()}\"</span> <span class=\"p\">}</span>\n    <span class=\"nc\">Mono</span><span class=\"p\">.</span><span class=\"nf\">just</span><span class=\"p\">(</span><span class=\"n\">response</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>Here‚Äôs an example of logged interaction for successfully fetching a resource.</p>\n\n<p><img alt=\"Properly logged interaction\" src=\"/img/articles/2024-06-04-rest-service-client-design-testing-monitoring/logs.png\" /></p>\n\n<p>To prevent redundancy in logging code across multiple clients, it is centralized inside <code class=\"language-plaintext highlighter-rouge\">executeHttpRequest</code> method.\nThe only thing the developer needs to do is to provide a business-oriented description for the beginning of the interaction and its outcome (parameters: <code class=\"language-plaintext highlighter-rouge\">initialLog</code>, <code class=\"language-plaintext highlighter-rouge\">successLog</code>, <code class=\"language-plaintext highlighter-rouge\">failureMessage</code>).</p>\n\n<p>Why do I emphasize logging so much?\nIsn‚Äôt it enough to log only errors?\nAfter all, we have metrics that inform us about the performance of our clients.\nMetrics won‚Äôt provide us with the details of the communication, but logs will.\nThese details can turn out to be crucial in the analysis of incidents, which may reveal, for example, incorrect data produced by our service.</p>\n\n<p>Logs are like backups. We find out if we have them and how valuable they are only when they are needed,\neither because the business team requests an analysis of a particular case or when resolving an incident.</p>\n\n<h3 id=\"error-handling\">Error handling</h3>\n<p>When writing client code, we aim to highlight maximally how we send/retrieve data and hide the ‚Äúnoise‚Äú that comes from error handling.\nIn the case of HTTP clients, error handling is quite extensive but generic enough that the resulting code can be written once and reused across all clients.\nIn our example, error handling mechanism is hidden inside <code class=\"language-plaintext highlighter-rouge\">executeHttpRequest</code> method.\nIt consists of two things: logging and throwing custom exceptions that encapsulate technical exceptions thrown by the underlying HTTP client.</p>\n\n<p>What are the benefits of using custom exceptions? The very name of such a custom exception tells us exactly what went wrong.\nFor comparison, <code class=\"language-plaintext highlighter-rouge\">ExternalServiceIncorrectResponseBodyException</code> seems to be more descriptive than <code class=\"language-plaintext highlighter-rouge\">DecodingException</code>.\nThey also help group various technical exceptions that lead to the same cause, for example, an incorrect response object structure.\nAdditionally, based on these exceptions, visualizations can be created to show the state of our integration.\nFor example, we can create a table that will show how many exceptions of any given type were thrown by our clients within a specified period.\nHaving custom exceptions, we are 100% certain that these exceptions were thrown only by our clients.</p>\n\n<h3 id=\"testing\">Testing</h3>\n<h4 id=\"stubs\">Stubs</h4>\n<p>To verify different scenarios of our HTTP client, it is necessary to appropriately stub the called endpoints in tests.\nFor this purpose, we will use the <a href=\"https://wiremock.org/\">WireMock</a> library.</p>\n\n<p>It is quite important that the technical details of created stubs do not leak into the tests.\nThe test should describe the behavior being tested and encapsulate technical details.\nFor example, changing the accept/content-type header or making minor modifications to the called URL should not affect the test itself.\nTo achieve this, for each service for which we write a service client, we create an object of type <code class=\"language-plaintext highlighter-rouge\">StubBuilder</code>.\nThe <code class=\"language-plaintext highlighter-rouge\">StubBuilder</code> allows hiding the details of stubbing and verification behind a readable API.\nIt takes on the impact of changes to the called API, protecting our test from modification.\nIt fulfills a similar role to the <a href=\"https://martinfowler.com/bliki/PageObject.html\">Page Object Pattern</a> in end-to-end tests for web apps.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">orderManagementServiceStub</span><span class=\"p\">.</span><span class=\"nf\">willReturnOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">,</span> <span class=\"n\">response</span> <span class=\"p\">=</span> <span class=\"nf\">ordersPlacedBySomeCustomer</span><span class=\"p\">())</span>\n</code></pre></div></div>\n\n<p>StubBuilders for services that return data come in two flavors - <a href=\"https://github.com/Klimiec/webclients/tree/591dddd1e61ea5d922f0402534d9a96a513f59b4/httpclient-webclientinterface/src/integration/kotlin/com/dev/sandbox/httpclientwebclientinterface/order/infrastructure/ordermanagementservice/stub/internal\">internal</a> and <a href=\"https://github.com/Klimiec/webclients/tree/591dddd1e61ea5d922f0402534d9a96a513f59b4/httpclient-webclientinterface/src/integration/kotlin/com/dev/sandbox/httpclientwebclientinterface/order/infrastructure/ordermanagementservice/stub/external\">external</a>.</p>\n\n<p><img alt=\"StubBuilder packages\" src=\"/img/articles/2024-06-04-rest-service-client-design-testing-monitoring/packages.png\" /></p>\n\n<p>When testing a service client, we want to have great flexibility in simulating responses.\nTherefore, <code class=\"language-plaintext highlighter-rouge\">StubBuilders</code> from the internal package will model response objects as a string. This allows us to simulate any scenario.\nIn end-to-end tests, where a given service is part of the bigger process, such flexibility is not necessary; in fact, it is not even recommended.\nTherefore, StubBuilders from the external package model responses using real objects.\nAll StubBuilders from the external packages are declared in the class <code class=\"language-plaintext highlighter-rouge\">ExternalServiceStubs</code>, to which a reference is located in the base class for\nall integration tests, <code class=\"language-plaintext highlighter-rouge\">BaseIntegrationTest</code>. This allows us to have very easy access to all external service stubs in our integration tests.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">stub</span><span class=\"p\">.</span><span class=\"nf\">orderManagementService</span><span class=\"p\">().</span><span class=\"nf\">willReturnOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">,</span> <span class=\"n\">response</span> <span class=\"p\">=</span> <span class=\"nf\">ordersPlacedBySomeCustomer</span><span class=\"p\">())</span>\n</code></pre></div></div>\n\n<p>Reading the code above, we immediately know <strong>which</strong> service is being interacted with (Order Management Service) and what will be returned from it (Orders).\nThe technical details of the stubbed endpoint have been hidden inside the StubBuilder object.\nTests should emphasize ‚Äúwhat‚Äù and encapsulate ‚Äúhow.‚Äù This way, they can serve as documentation.</p>\n\n<h4 id=\"test-data\">Test Data</h4>\n\n<p>The data returned by our stubs can be prepared in three ways:</p>\n<ol type=\"a\">\n  <li>Read the entire response from a file/string.</li>\n  <li>Prepare the response using real objects used in the service for deserializing responses from called services.</li>\n  <li>Create a set of separate objects modeling the returned response from the service for testing purposes and use them to prepare the returned data.</li>\n</ol>\n\n<p>Which option to choose?\nTo answer this question, we should analyze the advantages and disadvantages of each approach.</p>\n\n<p>Option A ‚Äî read response from a file/string. Response creation is very fast and simple.\nIt allows <strong>verifying the contract</strong> between the client and the supplier (at least at the time of writing the test).\nImagine that during refactoring, one of the fields in the response object accidentally changes.\nIn such a case, client tests using this approach will detect the defect before the code reaches production.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nd\">@Test</span>\n<span class=\"k\">fun</span> <span class=\"nf\">`should</span> <span class=\"k\">return</span> <span class=\"n\">orders</span> <span class=\"k\">for</span> <span class=\"n\">a</span> <span class=\"n\">given</span> <span class=\"nf\">clientId`</span><span class=\"p\">():</span> <span class=\"nc\">Unit</span> <span class=\"p\">=</span> <span class=\"nf\">runBlocking</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// given</span>\n        <span class=\"kd\">val</span> <span class=\"py\">clientId</span> <span class=\"p\">=</span> <span class=\"nf\">anyClientId</span><span class=\"p\">()</span>\n        <span class=\"n\">orderManagementServiceStub</span><span class=\"p\">.</span><span class=\"nf\">willReturnOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">,</span> <span class=\"n\">response</span> <span class=\"p\">=</span> <span class=\"nf\">ordersPlacedBySomeCustomer</span><span class=\"p\">())</span>\n\n        <span class=\"c1\">// when</span>\n        <span class=\"kd\">val</span> <span class=\"py\">response</span><span class=\"p\">:</span> <span class=\"nc\">OrdersDto</span> <span class=\"p\">=</span> <span class=\"n\">orderManagementServiceClient</span><span class=\"p\">.</span><span class=\"nf\">getOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">)</span>\n\n        <span class=\"c1\">// then</span>\n        <span class=\"n\">response</span> <span class=\"n\">shouldBe</span> <span class=\"nc\">OrdersDto</span><span class=\"p\">(</span><span class=\"nf\">listOf</span><span class=\"p\">(</span><span class=\"nc\">OrderDto</span><span class=\"p\">(</span><span class=\"s\">\"7952a9ab-503c-4483-beca-32d081cc2446\"</span><span class=\"p\">)))</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>On the other hand, keeping data in files/strings is difficult to maintain and reuse.\nProgrammers often copy entire files for new tests, introducing only minimal changes.\nThere is a problem with naming these files and refactoring them when the called service introduces an incompatible change.</p>\n\n<p>Option B ‚Äî Use real response objects.\nIt allows writing one-line, readable assertions and maximally reusing already created data, especially using <a href=\"https://www.natpryce.com/articles/000714.html\">test data builders</a>.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>    <span class=\"nd\">@Test</span>\n    <span class=\"k\">fun</span> <span class=\"nf\">`should</span> <span class=\"k\">return</span> <span class=\"n\">orders</span> <span class=\"k\">for</span> <span class=\"n\">a</span> <span class=\"n\">given</span> <span class=\"nf\">clientId`</span><span class=\"p\">():</span> <span class=\"nc\">Unit</span> <span class=\"p\">=</span> <span class=\"nf\">runBlocking</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// given</span>\n        <span class=\"kd\">val</span> <span class=\"py\">clientId</span> <span class=\"p\">=</span> <span class=\"nf\">anyClientId</span><span class=\"p\">()</span>\n        <span class=\"kd\">val</span> <span class=\"py\">clientOrders</span> <span class=\"p\">=</span> <span class=\"nc\">OrderManagementServiceFixture</span><span class=\"p\">.</span><span class=\"nf\">ordersPlacedBySomeCustomer</span><span class=\"p\">()</span>\n        <span class=\"n\">orderManagementServiceStub</span><span class=\"p\">.</span><span class=\"nf\">willReturnOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">,</span> <span class=\"n\">response</span> <span class=\"p\">=</span> <span class=\"n\">clientOrders</span><span class=\"p\">)</span>\n\n        <span class=\"c1\">// when</span>\n        <span class=\"kd\">val</span> <span class=\"py\">response</span><span class=\"p\">:</span> <span class=\"nc\">OrdersDto</span> <span class=\"p\">=</span> <span class=\"n\">orderManagementServiceClient</span><span class=\"p\">.</span><span class=\"nf\">getOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">)</span>\n\n        <span class=\"c1\">// then</span>\n        <span class=\"n\">response</span> <span class=\"n\">shouldBe</span> <span class=\"n\">clientOrders</span>\n    <span class=\"p\">}</span>\n</code></pre></div></div>\n<p>However, accidental change of field name which results in the  <strong>contract violation</strong> between the client and supplier won‚Äôt be caught.\nAs a result, we might have perfectly tested communication in integration tests that will not work in production.</p>\n\n<p>Option C ‚Äî create a set of separate response objects. It has all the advantages of options A and B, including maintainability, reusability, and\nverification of the contract between the client and the supplier. Unfortunately, maintaining a separate model for testing purposes comes with some overhead\nand requires discipline on the developers‚Äô side, which can be challenging to maintain.</p>\n\n<p>Which option to choose? Personally, I prefer a hybrid of options A and B.\nFor the purpose of testing the ‚Äúhappy path‚Äú in client tests, I return a response that is entirely stored as a string (alternatively, it can be read from a file).\nSuch a test allows not only to verify the contract but also the correctness of deserializing the received response into a response object.\nIn other tests (cache, adapter, end-to-end), I create responses returned by the stubbed endpoint using production response objects.</p>\n\n<p>It‚Äôs worthwhile to keep sample test data in dedicated classes, such as a Fixture class, for each integration (for example <code class=\"language-plaintext highlighter-rouge\">OrderManagementServiceFixture</code>).\nThis allows the reuse of test data and enhances the readability of the tests themselves.</p>\n\n<h3 id=\"test-scenarios\">Test Scenarios</h3>\n<h4 id=\"happy-path\">Happy Path</h4>\n<p><strong>Fetching a resource</strong> ‚Äî verification whether the client can retrieve data from the previously stubbed endpoint and deserialize it into a response object.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nd\">@Test</span>\n<span class=\"k\">fun</span> <span class=\"nf\">`should</span> <span class=\"k\">return</span> <span class=\"n\">orders</span> <span class=\"k\">for</span> <span class=\"n\">a</span> <span class=\"n\">given</span> <span class=\"nf\">clientId`</span><span class=\"p\">():</span> <span class=\"nc\">Unit</span> <span class=\"p\">=</span> <span class=\"nf\">runBlocking</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// given</span>\n        <span class=\"kd\">val</span> <span class=\"py\">clientId</span> <span class=\"p\">=</span> <span class=\"nf\">anyClientId</span><span class=\"p\">()</span>\n        <span class=\"n\">orderManagementServiceStub</span><span class=\"p\">.</span><span class=\"nf\">willReturnOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">,</span> <span class=\"n\">response</span> <span class=\"p\">=</span> <span class=\"nf\">ordersPlacedBySomeCustomer</span><span class=\"p\">())</span>\n\n        <span class=\"c1\">// when</span>\n        <span class=\"kd\">val</span> <span class=\"py\">response</span><span class=\"p\">:</span> <span class=\"nc\">OrdersDto</span> <span class=\"p\">=</span> <span class=\"n\">orderManagementServiceClient</span><span class=\"p\">.</span><span class=\"nf\">getOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">)</span>\n\n        <span class=\"c1\">// then</span>\n        <span class=\"n\">response</span> <span class=\"n\">shouldBe</span> <span class=\"nc\">OrdersDto</span><span class=\"p\">(</span><span class=\"nf\">listOf</span><span class=\"p\">(</span><span class=\"nc\">OrderDto</span><span class=\"p\">(</span><span class=\"s\">\"7952a9ab-503c-4483-beca-32d081cc2446\"</span><span class=\"p\">)))</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n<p>An essential part of the test for the ‚Äúhappy path‚Äú is verification of the contract between the client and the supplier.\nThe <code class=\"language-plaintext highlighter-rouge\">ordersPlacedBySomeCustomer</code> method returns a sample response guaranteed by the supplier (Order Management Service).\nOn the client side, in the assertion section, we check if this message has been correctly deserialized into a response object.\nInstead of comparing individual fields with the expected value, I highly recommend comparing entire objects (returned and expected).\nIt gives us confidence that all fields have been compared. In the case of regression, modern IDEs such as IntelliJ indicate exactly where the problem is.</p>\n\n<p><img alt=\"Test regression\" src=\"/img/articles/2024-06-04-rest-service-client-design-testing-monitoring/regression.png\" /></p>\n\n<p><strong>Sending a resource</strong> ‚Äî verification whether the client sends data to the specified URL in a format acceptable by the previously stubbed endpoint.\nIn the following example, I test publishing an event to <a href=\"https://hermes.allegro.tech/\">Hermes</a>, a message broker built on top of Kafka widely used at Allegro.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nd\">@Test</span>\n<span class=\"k\">fun</span> <span class=\"nf\">`should</span> <span class=\"n\">successfully</span> <span class=\"n\">publish</span> <span class=\"nc\">InvoiceCreatedEvent`</span><span class=\"p\">():</span> <span class=\"nc\">Unit</span> <span class=\"p\">=</span> <span class=\"nf\">runBlocking</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// given</span>\n        <span class=\"kd\">val</span> <span class=\"py\">invoiceCreatedEvent</span> <span class=\"p\">=</span> <span class=\"nc\">HermesFixture</span><span class=\"p\">.</span><span class=\"nf\">invoiceCreatedEvent</span><span class=\"p\">()</span>\n        <span class=\"n\">stub</span><span class=\"p\">.</span><span class=\"nf\">hermes</span><span class=\"p\">().</span><span class=\"nf\">willAcceptInvoiceCreatedEvent</span><span class=\"p\">()</span>\n\n        <span class=\"c1\">// when</span>\n        <span class=\"n\">hermesClient</span><span class=\"p\">.</span><span class=\"nf\">publish</span><span class=\"p\">(</span><span class=\"n\">invoiceCreatedEvent</span><span class=\"p\">)</span>\n\n        <span class=\"c1\">// then</span>\n        <span class=\"n\">stub</span><span class=\"p\">.</span><span class=\"nf\">hermes</span><span class=\"p\">().</span><span class=\"nf\">verifyInvoiceCreatedEventPublished</span><span class=\"p\">(</span><span class=\"n\">event</span> <span class=\"p\">=</span> <span class=\"n\">invoiceCreatedEvent</span><span class=\"p\">)</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>Stubbed endpoints for methods accepting request bodies (e.g., POST, PUT) should not verify the values of the received request body but only its <ins>structure</ins>.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"k\">fun</span> <span class=\"nf\">willAcceptInvoiceCreatedEvent</span><span class=\"p\">()</span> <span class=\"p\">{</span>\n    <span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">stubFor</span><span class=\"p\">(</span>\n        <span class=\"nf\">invoiceCreatedEventTopic</span><span class=\"p\">()</span>\n            <span class=\"p\">.</span><span class=\"nf\">withRequestBody</span><span class=\"p\">(</span><span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">matchingJsonPath</span><span class=\"p\">(</span><span class=\"s\">\"$.invoiceId\"</span><span class=\"p\">))</span>\n            <span class=\"p\">.</span><span class=\"nf\">withRequestBody</span><span class=\"p\">(</span><span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">matchingJsonPath</span><span class=\"p\">(</span><span class=\"s\">\"$.orderId\"</span><span class=\"p\">))</span>\n            <span class=\"p\">.</span><span class=\"nf\">withRequestBody</span><span class=\"p\">(</span><span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">matchingJsonPath</span><span class=\"p\">(</span><span class=\"s\">\"$.timestamp\"</span><span class=\"p\">))</span>\n            <span class=\"p\">.</span><span class=\"nf\">willReturn</span><span class=\"p\">(</span>\n                <span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">aResponse</span><span class=\"p\">()</span>\n                    <span class=\"p\">.</span><span class=\"nf\">withFixedDelay</span><span class=\"p\">(</span><span class=\"n\">responseTime</span><span class=\"p\">)</span>\n                    <span class=\"p\">.</span><span class=\"nf\">withStatus</span><span class=\"p\">(</span><span class=\"nc\">HttpStatus</span><span class=\"p\">.</span><span class=\"nc\">OK</span><span class=\"p\">.</span><span class=\"nf\">value</span><span class=\"p\">())</span>\n            <span class=\"p\">)</span>\n    <span class=\"p\">)</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>We verify the content of the request body in the assertion section.\nHere, we also want to hide the technical aspects of assertions behind a method.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"n\">stubs</span><span class=\"p\">.</span><span class=\"nf\">hermes</span><span class=\"p\">().</span><span class=\"nf\">verifyInvoiceCreatedEventPublished</span><span class=\"p\">(</span><span class=\"n\">event</span> <span class=\"p\">=</span> <span class=\"n\">invoiceCreatedEvent</span><span class=\"p\">)</span>\n\n\n<span class=\"k\">fun</span> <span class=\"nf\">verifyInvoiceCreatedEventPublished</span><span class=\"p\">(</span><span class=\"n\">event</span><span class=\"p\">:</span> <span class=\"nc\">InvoiceCreatedEventDto</span><span class=\"p\">)</span> <span class=\"p\">{</span>\n    <span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">verify</span><span class=\"p\">(</span>\n        <span class=\"mi\">1</span><span class=\"p\">,</span>\n        <span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">postRequestedFor</span><span class=\"p\">(</span><span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">urlPathEqualTo</span><span class=\"p\">(</span><span class=\"nc\">INVOICE_CREATED_URL</span><span class=\"p\">))</span>\n            <span class=\"p\">.</span><span class=\"nf\">withRequestBody</span><span class=\"p\">(</span><span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">matchingJsonPath</span><span class=\"p\">(</span><span class=\"s\">\"$.invoiceId\"</span><span class=\"p\">,</span> <span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">equalTo</span><span class=\"p\">(</span><span class=\"n\">event</span><span class=\"p\">.</span><span class=\"n\">invoiceId</span><span class=\"p\">)))</span>\n            <span class=\"p\">.</span><span class=\"nf\">withRequestBody</span><span class=\"p\">(</span><span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">matchingJsonPath</span><span class=\"p\">(</span><span class=\"s\">\"$.orderId\"</span><span class=\"p\">,</span> <span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">equalTo</span><span class=\"p\">(</span><span class=\"n\">event</span><span class=\"p\">.</span><span class=\"n\">orderId</span><span class=\"p\">)))</span>\n            <span class=\"p\">.</span><span class=\"nf\">withRequestBody</span><span class=\"p\">(</span><span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">matchingJsonPath</span><span class=\"p\">(</span><span class=\"s\">\"$.timestamp\"</span><span class=\"p\">,</span> <span class=\"nc\">WireMock</span><span class=\"p\">.</span><span class=\"nf\">equalTo</span><span class=\"p\">(</span><span class=\"n\">event</span><span class=\"p\">.</span><span class=\"n\">timestamp</span><span class=\"p\">)))</span>\n    <span class=\"p\">)</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>Combining stubbing and request verification in one method is not recommended.\nCreating stubs in this way makes their usage less convenient since not every test requires detailed verification of what is being sent in the request body.\nThe vast majority of tests will stub the endpoint based on the principle:\naccept a given request as long as its structure is preserved and will verify hypotheses other than the content of the request body (mainly end-to-end tests).</p>\n\n<h4 id=\"client-side-errors\">Client-side errors</h4>\n\n<p>For 4xx type errors, we want to verify the following cases:</p>\n<ul>\n  <li>The absence of the requested resource signaled by the response code 404 and a custom exception <code class=\"language-plaintext highlighter-rouge\">ExternalServiceResourceNotFoundException</code></li>\n  <li>Validation error signaled by the response code 422 and a custom exception <code class=\"language-plaintext highlighter-rouge\">ExternalServiceRequestValidationException</code></li>\n  <li>Any other 4xx type errors  should be cast to an <code class=\"language-plaintext highlighter-rouge\">ExternalServiceClientException</code></li>\n</ul>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nd\">@ParameterizedTest</span><span class=\"p\">(</span><span class=\"n\">name</span> <span class=\"p\">=</span> <span class=\"s\">\"{index}) http status code: {0}\"</span><span class=\"p\">)</span>\n<span class=\"nd\">@MethodSource</span><span class=\"p\">(</span><span class=\"s\">\"clientErrors\"</span><span class=\"p\">)</span>\n<span class=\"k\">fun</span> <span class=\"nf\">`when</span> <span class=\"n\">receive</span> <span class=\"n\">response</span> <span class=\"n\">with</span> <span class=\"mi\">4</span><span class=\"n\">xx</span> <span class=\"n\">status</span> <span class=\"n\">code</span> <span class=\"n\">then</span> <span class=\"k\">throw</span> <span class=\"nf\">exception`</span><span class=\"p\">(</span>\n    <span class=\"n\">exceptionClass</span><span class=\"p\">:</span> <span class=\"nc\">Class</span><span class=\"p\">&lt;</span><span class=\"nc\">Exception</span><span class=\"p\">&gt;,</span>\n    <span class=\"n\">statusCode</span><span class=\"p\">:</span> <span class=\"nc\">Int</span><span class=\"p\">,</span>\n    <span class=\"n\">responseBody</span><span class=\"p\">:</span> <span class=\"nc\">String</span><span class=\"p\">?</span>\n<span class=\"p\">):</span> <span class=\"nc\">Unit</span> <span class=\"p\">=</span> <span class=\"nf\">runBlocking</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// given</span>\n        <span class=\"kd\">val</span> <span class=\"py\">clientId</span> <span class=\"p\">=</span> <span class=\"nf\">anyClientId</span><span class=\"p\">()</span>\n        <span class=\"n\">orderManagementServiceStub</span><span class=\"p\">.</span><span class=\"nf\">willReturnOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">,</span> <span class=\"n\">status</span> <span class=\"p\">=</span> <span class=\"n\">statusCode</span><span class=\"p\">,</span> <span class=\"n\">response</span> <span class=\"p\">=</span> <span class=\"n\">responseBody</span><span class=\"p\">)</span>\n\n        <span class=\"c1\">// when</span>\n        <span class=\"kd\">val</span> <span class=\"py\">exception</span> <span class=\"p\">=</span> <span class=\"nf\">shouldThrowAny</span> <span class=\"p\">{</span>\n            <span class=\"n\">orderManagementServiceClient</span><span class=\"p\">.</span><span class=\"nf\">getOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">)</span>\n        <span class=\"p\">}</span>\n\n        <span class=\"c1\">// then</span>\n        <span class=\"n\">exception</span><span class=\"p\">.</span><span class=\"n\">javaClass</span> <span class=\"n\">shouldBeSameInstanceAs</span> <span class=\"n\">exceptionClass</span>\n        <span class=\"n\">exception</span><span class=\"p\">.</span><span class=\"n\">message</span> <span class=\"n\">shouldContain</span> <span class=\"n\">clientId</span><span class=\"p\">.</span><span class=\"n\">clientId</span><span class=\"p\">.</span><span class=\"nf\">toString</span><span class=\"p\">()</span>\n        <span class=\"n\">exception</span><span class=\"p\">.</span><span class=\"n\">message</span> <span class=\"n\">shouldContain</span> <span class=\"n\">properties</span><span class=\"p\">.</span><span class=\"n\">clientName</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>In distributed systems, a <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404\">404</a> response code is quite common and may result from temporary inconsistency across the entire system.\nIts occurrence is signaled by the <code class=\"language-plaintext highlighter-rouge\">ExternalServiceResourceNotFoundException</code> and a warning-level log.\nHere, we are more interested in the scale of occurrences, which is why we use metrics, than analyzing individual cases, hence we log such cases at the warning level.</p>\n\n<p>The situation looks a bit different in the case of responses with a code of <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/422\">422</a>.\nIf the request is rejected due to validation errors, either our service has a defect and produces incorrect data,\nor we receive incorrect data from external services (which is why it‚Äôs crucial to log what we receive from external services).\nAlternatively, the error may be on the recipient side in the logic validating the received request. It‚Äôs worth analyzing each such case, which is why\nerrors of this type are logged at the error level and signaled by the <code class=\"language-plaintext highlighter-rouge\">ExternalServiceRequestValidationException</code>.</p>\n\n<p>Other errors from the 4xx family occur less frequently.\nThey are all marked by the <code class=\"language-plaintext highlighter-rouge\">ExternalServiceClientException</code> exception and logged at the error level.</p>\n\n<h4 id=\"server-side-errors\">Server-side errors</h4>\n<p>Regardless of the reason for a 5xx error, all of them are logged at the warn level because we have no control over them.\nThey are signaled by the <code class=\"language-plaintext highlighter-rouge\">ExternalServiceServerException</code> exception. Similar to 404 errors, we are more interested in aggregate information\nabout the number of such errors rather than analyzing each case individually, hence the warn log level.</p>\n\n<p>In tests, we consider two cases because the response from the service may or may not have a body.\nIf the response has a body, we want to log it.</p>\n\n<h4 id=\"read-timeout\">Read Timeout</h4>\n<p>Our HTTP client should have a finite response timeout configured, so it‚Äôs worthwhile to write an integration test that verifies the client‚Äôs configuration.\nSimulating the delay of the stubbed endpoint can be achieved using the <code class=\"language-plaintext highlighter-rouge\">withFixedDelay</code> method from wiremock.</p>\n\n<div class=\"language-kotlin highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nd\">@Test</span>\n<span class=\"k\">fun</span> <span class=\"nf\">`when</span> <span class=\"n\">service</span> <span class=\"n\">returns</span> <span class=\"n\">above</span> <span class=\"n\">timeout</span> <span class=\"n\">threshold</span> <span class=\"n\">then</span> <span class=\"k\">throw</span> <span class=\"nf\">exception`</span><span class=\"p\">():</span> <span class=\"nc\">Unit</span> <span class=\"p\">=</span> <span class=\"nf\">runBlocking</span> <span class=\"p\">{</span>\n        <span class=\"c1\">// given</span>\n        <span class=\"kd\">val</span> <span class=\"py\">clientId</span> <span class=\"p\">=</span> <span class=\"nf\">anyClientId</span><span class=\"p\">()</span>\n\n        <span class=\"n\">orderManagementServiceStub</span>\n            <span class=\"p\">.</span><span class=\"nf\">withDelay</span><span class=\"p\">(</span><span class=\"n\">properties</span><span class=\"p\">.</span><span class=\"n\">readTimeout</span><span class=\"p\">.</span><span class=\"nf\">toInt</span><span class=\"p\">())</span>\n            <span class=\"p\">.</span><span class=\"nf\">willReturnOrdersFor</span><span class=\"p\">(</span>\n                <span class=\"n\">clientId</span><span class=\"p\">,</span>\n                <span class=\"n\">response</span> <span class=\"p\">=</span> <span class=\"nf\">ordersPlacedBySomeCustomer</span><span class=\"p\">()</span>\n            <span class=\"p\">)</span>\n\n        <span class=\"c1\">// when</span>\n        <span class=\"kd\">val</span> <span class=\"py\">exception</span> <span class=\"p\">=</span> <span class=\"n\">shouldThrow</span><span class=\"p\">&lt;</span><span class=\"nc\">ExternalServiceReadTimeoutException</span><span class=\"p\">&gt;</span> <span class=\"p\">{</span>\n            <span class=\"n\">orderManagementServiceClient</span><span class=\"p\">.</span><span class=\"nf\">getOrdersFor</span><span class=\"p\">(</span><span class=\"n\">clientId</span><span class=\"p\">)</span>\n        <span class=\"p\">}</span>\n        <span class=\"c1\">// then</span>\n        <span class=\"n\">exception</span><span class=\"p\">.</span><span class=\"n\">message</span> <span class=\"n\">shouldContain</span> <span class=\"n\">clientId</span><span class=\"p\">.</span><span class=\"n\">clientId</span><span class=\"p\">.</span><span class=\"nf\">toString</span><span class=\"p\">()</span>\n        <span class=\"n\">exception</span><span class=\"p\">.</span><span class=\"n\">message</span> <span class=\"n\">shouldContain</span> <span class=\"n\">properties</span><span class=\"p\">.</span><span class=\"n\">clientName</span>\n<span class=\"p\">}</span>\n</code></pre></div></div>\n\n<p>No, this is not testing properties in tests.\nThis test ensures that the configuration derived from properties has indeed been applied to the given client.\nEnsuring a response within a specified time frame might be part of non-functional requirements and requires verification.</p>\n\n<h4 id=\"invalid-response-body\">Invalid Response Body</h4>\n<p>Considered cases:</p>\n<ul>\n  <li>Response body does not contain required field.</li>\n  <li>Response body is empty.</li>\n  <li>Response has an incorrect format.</li>\n</ul>\n\n<p>Errors of this type are signaled through <code class=\"language-plaintext highlighter-rouge\">ExternalServiceIncorrectResponseBodyException</code> and logged at the error level.</p>\n\n<h3 id=\"metrics\">Metrics</h3>\n<p>When dealing with HTTP clients, it‚Äôs essential to monitor several aspects: response times, throughput, and error rates.\nTo differentiate metrics generated by different clients easily, it‚Äôs advisable to include a <code class=\"language-plaintext highlighter-rouge\">service.name</code> tag with the respective client‚Äôs name.</p>\n\n<p>In HTTP clients offered by the Spring framework (WebClient, RestClient),\nmetrics are enabled out-of-the-box if we create them using predefined builders (WebClient.Builder, RestClient.Builder).\nHowever, for other technologies, third-party solutions must be employed. In Allegro, we have a set of libraries that allows us to quickly create new\nHTTP clients in the most popular technologies that provide support for our infrastructure.\nAs a result, all clients generate consistent metrics by default tailored to our dashboards.</p>\n\n<h4 id=\"response-time\">Response Time</h4>\n<p>Measuring the response time of HTTP clients allows us to identify bottlenecks.\nAt which percentile should we set such a metric?\nGenerally, the more requests a client generates, the higher the percentile we should aim for.\nSometimes, issues become visible only at high percentiles (P99, P99.9) for a very high volume of requests.</p>\n\n<p><img alt=\"Response Time\" src=\"/img/articles/2024-06-04-rest-service-client-design-testing-monitoring/response_time.png\" /></p>\n\n<h4 id=\"throughput\">Throughput</h4>\n<p>Number of requests that our application sends to external services per second (RPS).\nAn auxiliary metric for the response time metric, where response time is always considered in the context of the generated traffic.</p>\n\n<p><img alt=\"Throughput\" src=\"/img/articles/2024-06-04-rest-service-client-design-testing-monitoring/rps.png\" /></p>\n\n<h4 id=\"error-rate\">Error Rate</h4>\n<p>Counting responses with codes 4xx/5xx.\nHere, we are interested in visualizing how many such errors occurred within a specific timeframe.\nThe number of errors we analyze depends on the overall traffic, therefore, both metrics should be expressed in the same units, usually requests per second.\nFor high traffic and a small number of errors, we can expect that the presented values will be on the order of thousandths.</p>\n\n<p><img alt=\"Error Rate\" src=\"/img/articles/2024-06-04-rest-service-client-design-testing-monitoring/errors.png\" /></p>\n\n<h2 id=\"summary\">Summary</h2>\n<p><a href=\"https://martinfowler.com/articles/microservices.html\">Microservices Architecture</a> relies heavily on network communication.\nThe most common method of communication is REST API calls between different services.\nWriting integration code involves more than just invoking a URL and parsing a response.\nLogs, error handling, and metrics are crucial for creating a stable and fault-tolerant microservices environment.\nDevelopers should have tools that take care of these aspects, enabling fast and reliable development of such integrations.\nHowever, tools alone are insufficient. We also need established rules and guidelines that allow us to write readable and maintainable code,\nboth in production and tests.</p>\n\n<h2 id=\"code-examples\">Code examples</h2>\n<p>To explore comprehensive examples, including the usage of WebClient and other HTTP clients, check out the GitHub <a href=\"https://github.com/Klimiec/webclients\">repository</a>.</p>\n","contentSnippet":"The purpose of this article is to present how to design, test, and monitor a REST service client.\nThe article includes a repository with clients written in Kotlin using various technologies such as WebClient,\nRestClient,\nKtor Client,\nRetrofit.\nIt demonstrates how to send and retrieve data from an external service, add a cache layer, and parse the received response into domain objects.\nMotivation\nWhy do we need objects in the project that encapsulate the HTTP clients we use?\nTo begin with, we want to separate the domain from technical details.\nThe way we retrieve/send data and handle errors, which can be quite complex in the case of HTTP clients, should not clutter business logic.\nNext, testability. Even if we do not use hexagonal architecture in our applications,\nit‚Äôs beneficial to separate the infrastructure from the service layer, as it improves testability.\nVerifying an HTTP service client is not a simple task and requires consideration of many cases ‚Äî mainly at the integration level.\nHaving a separate ‚Äúbuilding block‚Äú that encapsulates communication with the outside world makes testing much easier.\nFinally, reusability. A service client that has been written once can be successfully used in other projects.\nClient Design\nAs a case study, I will use an example implementation that utilizes WebClient for retrieving data from the Order Management Service,\nan example service that might appear in an e-commerce site such as Allegro.\nThe heart of our client is the executeHttpRequest method, which is responsible for executing the provided HTTP request, logging, and error handling.\nIt is not part of the WebClient library.\n\nclass OrderManagementServiceClient(\n    private val orderManagementServiceApi: OrderManagementServiceApi,\n    private val clientName: String\n) {\n    suspend fun getOrdersFor(clientId: ClientId): OrdersDto {\n        return executeHttpRequest(\n            initialLog = \"[$clientName] Get orders for a clientId= $clientId\",\n            request = { orderManagementServiceApi.getOrdersFor(clientId) },\n            successLog = \"[$clientName] Returned orders for a clientId= $clientId\",\n            failureMessage = \"[$clientName] Failed to get orders for clientId= $clientId\"\n        )\n    }\n}\n\n\n\nFull working example can be found here.\nClient name\nI like to name clients using the convention: name of the service we integrate with, plus the suffix Client.\nIn the case of integration with the Order Management Service, such a class will be named OrderManagementServiceClient.\nIf the technology we use employs an interface to describe the called REST API (RestClient, WebClient, Retrofit),\nwe can name such an interface OrderManagementServiceApi ‚Äî following the general pattern of the service name with the suffix Api.\nThese names may seem intuitive and obvious, but without an established naming convention, we might end up with a project where\ndifferent integrations have the following suffixes: HttpClient, Facade, WebClient, Adapter, and Service.\nIt‚Äôs important to have a consistent convention and adhere to it throughout the project.\nAPI\nMethods of our clients should have names that reflect the communicative intention behind them.\nTo capture this intention, it is necessary to use a verb in the method‚Äôs name.\nTypically, the correct name will have a structure of verb + resource name, for example, getOrders  ‚Äî  for methods that retrieve resources.\nIf we want to narrow down the number of returned resources using filters or return a particular resource, I recommend adding the suffix ‚ÄúFor‚Äù before the list of parameters.\nTechnically, these parameters will be part of the query or path parameters.\n\nfun getOrdersFor(clientId: ClientId): OrdersDto\n\n\nFor methods responsible for creating resources, simply using the verb in the method name is enough,\nas the resource being passed as a parameter effectively conveys the intention of the method.\n\nfun publish(event: InvoiceCreatedEventDto)\n\n\nLogging\nWhen communicating with external service we‚Äôd like to log the beginning of the interaction, indicating our intention to fetch or send a resource,\nas well as its outcome. The outcome can be either a success, meaning receiving a response with a 2xx status code, or a failure.\nFailure can be signaled by status codes (3xx, 4xx, 5xx), resulting from the inability to deserialize the received response into an object,\nexceeding the response time, etc. Generally, many things can go wrong.\nDepending on the cause of failure, we may want to log the interaction result at different levels (warn/error).\nThere are critical errors that are worth distinguishing (error), and those that will occasionally occur (warn) and don‚Äôt require urgent intervention.\nTo filter logs related to a specific service while browsing through them, I like to include the client‚Äôs name within curly braces at the beginning of the logs.\nFor logging technical aspects of the communication, such as the URL called, HTTP method used, and response code,\nwe use filters (logRequestInfo, logResponseInfo) that are plugged in at the client configuration level in the createExternalServiceApi method.\n\ninline fun <reified T> createExternalServiceApi(\n    webClientBuilder: WebClient.Builder,\n    properties: ConnectionProperties\n): T =\n    webClientBuilder\n        .clientConnector(httpClient(properties))\n        .baseUrl(properties.baseUrl)\n        .defaultRequest { it.attribute(SERVICE_NAME, properties.clientName) }\n        .filter(logRequestInfo(properties.clientName))\n        .filter(logResponseInfo(properties.clientName))\n        .build()\n        .let { WebClientAdapter.create(it) }\n        .let { HttpServiceProxyFactory.builderFor(it).build() }\n        .createClient(T::class.java)\n\nfun logRequestInfo(clientName: String) = ExchangeFilterFunction.ofRequestProcessor { request ->\n    logger.info {\n        \"[$clientName] method=[${request.method().name()}] url=${request.url()}}\"\n    }\n    Mono.just(request)\n}\n\nfun logResponseInfo(clientName: String) = ExchangeFilterFunction.ofResponseProcessor { response ->\n    logger.info { \"[$clientName] service responded with a status code= ${response.statusCode()}\" }\n    Mono.just(response)\n}\n\n\nHere‚Äôs an example of logged interaction for successfully fetching a resource.\n\nTo prevent redundancy in logging code across multiple clients, it is centralized inside executeHttpRequest method.\nThe only thing the developer needs to do is to provide a business-oriented description for the beginning of the interaction and its outcome (parameters: initialLog, successLog, failureMessage).\nWhy do I emphasize logging so much?\nIsn‚Äôt it enough to log only errors?\nAfter all, we have metrics that inform us about the performance of our clients.\nMetrics won‚Äôt provide us with the details of the communication, but logs will.\nThese details can turn out to be crucial in the analysis of incidents, which may reveal, for example, incorrect data produced by our service.\nLogs are like backups. We find out if we have them and how valuable they are only when they are needed,\neither because the business team requests an analysis of a particular case or when resolving an incident.\nError handling\nWhen writing client code, we aim to highlight maximally how we send/retrieve data and hide the ‚Äúnoise‚Äú that comes from error handling.\nIn the case of HTTP clients, error handling is quite extensive but generic enough that the resulting code can be written once and reused across all clients.\nIn our example, error handling mechanism is hidden inside executeHttpRequest method.\nIt consists of two things: logging and throwing custom exceptions that encapsulate technical exceptions thrown by the underlying HTTP client.\nWhat are the benefits of using custom exceptions? The very name of such a custom exception tells us exactly what went wrong.\nFor comparison, ExternalServiceIncorrectResponseBodyException seems to be more descriptive than DecodingException.\nThey also help group various technical exceptions that lead to the same cause, for example, an incorrect response object structure.\nAdditionally, based on these exceptions, visualizations can be created to show the state of our integration.\nFor example, we can create a table that will show how many exceptions of any given type were thrown by our clients within a specified period.\nHaving custom exceptions, we are 100% certain that these exceptions were thrown only by our clients.\nTesting\nStubs\nTo verify different scenarios of our HTTP client, it is necessary to appropriately stub the called endpoints in tests.\nFor this purpose, we will use the WireMock library.\nIt is quite important that the technical details of created stubs do not leak into the tests.\nThe test should describe the behavior being tested and encapsulate technical details.\nFor example, changing the accept/content-type header or making minor modifications to the called URL should not affect the test itself.\nTo achieve this, for each service for which we write a service client, we create an object of type StubBuilder.\nThe StubBuilder allows hiding the details of stubbing and verification behind a readable API.\nIt takes on the impact of changes to the called API, protecting our test from modification.\nIt fulfills a similar role to the Page Object Pattern in end-to-end tests for web apps.\n\norderManagementServiceStub.willReturnOrdersFor(clientId, response = ordersPlacedBySomeCustomer())\n\n\nStubBuilders for services that return data come in two flavors - internal and external.\n\nWhen testing a service client, we want to have great flexibility in simulating responses.\nTherefore, StubBuilders from the internal package will model response objects as a string. This allows us to simulate any scenario.\nIn end-to-end tests, where a given service is part of the bigger process, such flexibility is not necessary; in fact, it is not even recommended.\nTherefore, StubBuilders from the external package model responses using real objects.\nAll StubBuilders from the external packages are declared in the class ExternalServiceStubs, to which a reference is located in the base class for\nall integration tests, BaseIntegrationTest. This allows us to have very easy access to all external service stubs in our integration tests.\n\nstub.orderManagementService().willReturnOrdersFor(clientId, response = ordersPlacedBySomeCustomer())\n\n\nReading the code above, we immediately know which service is being interacted with (Order Management Service) and what will be returned from it (Orders).\nThe technical details of the stubbed endpoint have been hidden inside the StubBuilder object.\nTests should emphasize ‚Äúwhat‚Äù and encapsulate ‚Äúhow.‚Äù This way, they can serve as documentation.\nTest Data\nThe data returned by our stubs can be prepared in three ways:\nRead the entire response from a file/string.\nPrepare the response using real objects used in the service for deserializing responses from called services.\nCreate a set of separate objects modeling the returned response from the service for testing purposes and use them to prepare the returned data.\nWhich option to choose?\nTo answer this question, we should analyze the advantages and disadvantages of each approach.\nOption A ‚Äî read response from a file/string. Response creation is very fast and simple.\nIt allows verifying the contract between the client and the supplier (at least at the time of writing the test).\nImagine that during refactoring, one of the fields in the response object accidentally changes.\nIn such a case, client tests using this approach will detect the defect before the code reaches production.\n\n@Test\nfun `should return orders for a given clientId`(): Unit = runBlocking {\n        // given\n        val clientId = anyClientId()\n        orderManagementServiceStub.willReturnOrdersFor(clientId, response = ordersPlacedBySomeCustomer())\n\n        // when\n        val response: OrdersDto = orderManagementServiceClient.getOrdersFor(clientId)\n\n        // then\n        response shouldBe OrdersDto(listOf(OrderDto(\"7952a9ab-503c-4483-beca-32d081cc2446\")))\n}\n\n\nOn the other hand, keeping data in files/strings is difficult to maintain and reuse.\nProgrammers often copy entire files for new tests, introducing only minimal changes.\nThere is a problem with naming these files and refactoring them when the called service introduces an incompatible change.\nOption B ‚Äî Use real response objects.\nIt allows writing one-line, readable assertions and maximally reusing already created data, especially using test data builders.\n\n    @Test\n    fun `should return orders for a given clientId`(): Unit = runBlocking {\n        // given\n        val clientId = anyClientId()\n        val clientOrders = OrderManagementServiceFixture.ordersPlacedBySomeCustomer()\n        orderManagementServiceStub.willReturnOrdersFor(clientId, response = clientOrders)\n\n        // when\n        val response: OrdersDto = orderManagementServiceClient.getOrdersFor(clientId)\n\n        // then\n        response shouldBe clientOrders\n    }\n\n\nHowever, accidental change of field name which results in the  contract violation between the client and supplier won‚Äôt be caught.\nAs a result, we might have perfectly tested communication in integration tests that will not work in production.\nOption C ‚Äî create a set of separate response objects. It has all the advantages of options A and B, including maintainability, reusability, and\nverification of the contract between the client and the supplier. Unfortunately, maintaining a separate model for testing purposes comes with some overhead\nand requires discipline on the developers‚Äô side, which can be challenging to maintain.\nWhich option to choose? Personally, I prefer a hybrid of options A and B.\nFor the purpose of testing the ‚Äúhappy path‚Äú in client tests, I return a response that is entirely stored as a string (alternatively, it can be read from a file).\nSuch a test allows not only to verify the contract but also the correctness of deserializing the received response into a response object.\nIn other tests (cache, adapter, end-to-end), I create responses returned by the stubbed endpoint using production response objects.\nIt‚Äôs worthwhile to keep sample test data in dedicated classes, such as a Fixture class, for each integration (for example OrderManagementServiceFixture).\nThis allows the reuse of test data and enhances the readability of the tests themselves.\nTest Scenarios\nHappy Path\nFetching a resource ‚Äî verification whether the client can retrieve data from the previously stubbed endpoint and deserialize it into a response object.\n\n@Test\nfun `should return orders for a given clientId`(): Unit = runBlocking {\n        // given\n        val clientId = anyClientId()\n        orderManagementServiceStub.willReturnOrdersFor(clientId, response = ordersPlacedBySomeCustomer())\n\n        // when\n        val response: OrdersDto = orderManagementServiceClient.getOrdersFor(clientId)\n\n        // then\n        response shouldBe OrdersDto(listOf(OrderDto(\"7952a9ab-503c-4483-beca-32d081cc2446\")))\n}\n\n\nAn essential part of the test for the ‚Äúhappy path‚Äú is verification of the contract between the client and the supplier.\nThe ordersPlacedBySomeCustomer method returns a sample response guaranteed by the supplier (Order Management Service).\nOn the client side, in the assertion section, we check if this message has been correctly deserialized into a response object.\nInstead of comparing individual fields with the expected value, I highly recommend comparing entire objects (returned and expected).\nIt gives us confidence that all fields have been compared. In the case of regression, modern IDEs such as IntelliJ indicate exactly where the problem is.\n\nSending a resource ‚Äî verification whether the client sends data to the specified URL in a format acceptable by the previously stubbed endpoint.\nIn the following example, I test publishing an event to Hermes, a message broker built on top of Kafka widely used at Allegro.\n\n@Test\nfun `should successfully publish InvoiceCreatedEvent`(): Unit = runBlocking {\n        // given\n        val invoiceCreatedEvent = HermesFixture.invoiceCreatedEvent()\n        stub.hermes().willAcceptInvoiceCreatedEvent()\n\n        // when\n        hermesClient.publish(invoiceCreatedEvent)\n\n        // then\n        stub.hermes().verifyInvoiceCreatedEventPublished(event = invoiceCreatedEvent)\n}\n\n\nStubbed endpoints for methods accepting request bodies (e.g., POST, PUT) should not verify the values of the received request body but only its structure.\n\nfun willAcceptInvoiceCreatedEvent() {\n    WireMock.stubFor(\n        invoiceCreatedEventTopic()\n            .withRequestBody(WireMock.matchingJsonPath(\"$.invoiceId\"))\n            .withRequestBody(WireMock.matchingJsonPath(\"$.orderId\"))\n            .withRequestBody(WireMock.matchingJsonPath(\"$.timestamp\"))\n            .willReturn(\n                WireMock.aResponse()\n                    .withFixedDelay(responseTime)\n                    .withStatus(HttpStatus.OK.value())\n            )\n    )\n}\n\n\nWe verify the content of the request body in the assertion section.\nHere, we also want to hide the technical aspects of assertions behind a method.\n\nstubs.hermes().verifyInvoiceCreatedEventPublished(event = invoiceCreatedEvent)\n\n\nfun verifyInvoiceCreatedEventPublished(event: InvoiceCreatedEventDto) {\n    WireMock.verify(\n        1,\n        WireMock.postRequestedFor(WireMock.urlPathEqualTo(INVOICE_CREATED_URL))\n            .withRequestBody(WireMock.matchingJsonPath(\"$.invoiceId\", WireMock.equalTo(event.invoiceId)))\n            .withRequestBody(WireMock.matchingJsonPath(\"$.orderId\", WireMock.equalTo(event.orderId)))\n            .withRequestBody(WireMock.matchingJsonPath(\"$.timestamp\", WireMock.equalTo(event.timestamp)))\n    )\n}\n\n\nCombining stubbing and request verification in one method is not recommended.\nCreating stubs in this way makes their usage less convenient since not every test requires detailed verification of what is being sent in the request body.\nThe vast majority of tests will stub the endpoint based on the principle:\naccept a given request as long as its structure is preserved and will verify hypotheses other than the content of the request body (mainly end-to-end tests).\nClient-side errors\nFor 4xx type errors, we want to verify the following cases:\nThe absence of the requested resource signaled by the response code 404 and a custom exception ExternalServiceResourceNotFoundException\nValidation error signaled by the response code 422 and a custom exception ExternalServiceRequestValidationException\nAny other 4xx type errors  should be cast to an ExternalServiceClientException\n\n@ParameterizedTest(name = \"{index}) http status code: {0}\")\n@MethodSource(\"clientErrors\")\nfun `when receive response with 4xx status code then throw exception`(\n    exceptionClass: Class<Exception>,\n    statusCode: Int,\n    responseBody: String?\n): Unit = runBlocking {\n        // given\n        val clientId = anyClientId()\n        orderManagementServiceStub.willReturnOrdersFor(clientId, status = statusCode, response = responseBody)\n\n        // when\n        val exception = shouldThrowAny {\n            orderManagementServiceClient.getOrdersFor(clientId)\n        }\n\n        // then\n        exception.javaClass shouldBeSameInstanceAs exceptionClass\n        exception.message shouldContain clientId.clientId.toString()\n        exception.message shouldContain properties.clientName\n}\n\n\nIn distributed systems, a 404 response code is quite common and may result from temporary inconsistency across the entire system.\nIts occurrence is signaled by the ExternalServiceResourceNotFoundException and a warning-level log.\nHere, we are more interested in the scale of occurrences, which is why we use metrics, than analyzing individual cases, hence we log such cases at the warning level.\nThe situation looks a bit different in the case of responses with a code of 422.\nIf the request is rejected due to validation errors, either our service has a defect and produces incorrect data,\nor we receive incorrect data from external services (which is why it‚Äôs crucial to log what we receive from external services).\nAlternatively, the error may be on the recipient side in the logic validating the received request. It‚Äôs worth analyzing each such case, which is why\nerrors of this type are logged at the error level and signaled by the ExternalServiceRequestValidationException.\nOther errors from the 4xx family occur less frequently.\nThey are all marked by the ExternalServiceClientException exception and logged at the error level.\nServer-side errors\nRegardless of the reason for a 5xx error, all of them are logged at the warn level because we have no control over them.\nThey are signaled by the ExternalServiceServerException exception. Similar to 404 errors, we are more interested in aggregate information\nabout the number of such errors rather than analyzing each case individually, hence the warn log level.\nIn tests, we consider two cases because the response from the service may or may not have a body.\nIf the response has a body, we want to log it.\nRead Timeout\nOur HTTP client should have a finite response timeout configured, so it‚Äôs worthwhile to write an integration test that verifies the client‚Äôs configuration.\nSimulating the delay of the stubbed endpoint can be achieved using the withFixedDelay method from wiremock.\n\n@Test\nfun `when service returns above timeout threshold then throw exception`(): Unit = runBlocking {\n        // given\n        val clientId = anyClientId()\n\n        orderManagementServiceStub\n            .withDelay(properties.readTimeout.toInt())\n            .willReturnOrdersFor(\n                clientId,\n                response = ordersPlacedBySomeCustomer()\n            )\n\n        // when\n        val exception = shouldThrow<ExternalServiceReadTimeoutException> {\n            orderManagementServiceClient.getOrdersFor(clientId)\n        }\n        // then\n        exception.message shouldContain clientId.clientId.toString()\n        exception.message shouldContain properties.clientName\n}\n\n\nNo, this is not testing properties in tests.\nThis test ensures that the configuration derived from properties has indeed been applied to the given client.\nEnsuring a response within a specified time frame might be part of non-functional requirements and requires verification.\nInvalid Response Body\nConsidered cases:\nResponse body does not contain required field.\nResponse body is empty.\nResponse has an incorrect format.\nErrors of this type are signaled through ExternalServiceIncorrectResponseBodyException and logged at the error level.\nMetrics\nWhen dealing with HTTP clients, it‚Äôs essential to monitor several aspects: response times, throughput, and error rates.\nTo differentiate metrics generated by different clients easily, it‚Äôs advisable to include a service.name tag with the respective client‚Äôs name.\nIn HTTP clients offered by the Spring framework (WebClient, RestClient),\nmetrics are enabled out-of-the-box if we create them using predefined builders (WebClient.Builder, RestClient.Builder).\nHowever, for other technologies, third-party solutions must be employed. In Allegro, we have a set of libraries that allows us to quickly create new\nHTTP clients in the most popular technologies that provide support for our infrastructure.\nAs a result, all clients generate consistent metrics by default tailored to our dashboards.\nResponse Time\nMeasuring the response time of HTTP clients allows us to identify bottlenecks.\nAt which percentile should we set such a metric?\nGenerally, the more requests a client generates, the higher the percentile we should aim for.\nSometimes, issues become visible only at high percentiles (P99, P99.9) for a very high volume of requests.\n\nThroughput\nNumber of requests that our application sends to external services per second (RPS).\nAn auxiliary metric for the response time metric, where response time is always considered in the context of the generated traffic.\n\nError Rate\nCounting responses with codes 4xx/5xx.\nHere, we are interested in visualizing how many such errors occurred within a specific timeframe.\nThe number of errors we analyze depends on the overall traffic, therefore, both metrics should be expressed in the same units, usually requests per second.\nFor high traffic and a small number of errors, we can expect that the presented values will be on the order of thousandths.\n\nSummary\nMicroservices Architecture relies heavily on network communication.\nThe most common method of communication is REST API calls between different services.\nWriting integration code involves more than just invoking a URL and parsing a response.\nLogs, error handling, and metrics are crucial for creating a stable and fault-tolerant microservices environment.\nDevelopers should have tools that take care of these aspects, enabling fast and reliable development of such integrations.\nHowever, tools alone are insufficient. We also need established rules and guidelines that allow us to write readable and maintainable code,\nboth in production and tests.\nCode examples\nTo explore comprehensive examples, including the usage of WebClient and other HTTP clients, check out the GitHub repository.","guid":"https://blog.allegro.tech/2024/06/rest-service-client-design-testing-monitoring.html","categories":["kotlin","testing","integration tests","rest","wiremock"],"isoDate":"2024-06-03T22:00:00.000Z"},{"title":"Unveiling bottlenecks of couchbase sub-documents operations","link":"https://blog.allegro.tech/2024/05/couchbase-subdocuments-bottleneck.html","pubDate":"Thu, 16 May 2024 00:00:00 +0200","authors":{"author":[{"name":["Tomasz Zi√≥≈Çkowski"],"photo":["https://blog.allegro.tech/img/authors/tomasz.ziolkowski.jpg"],"url":["https://blog.allegro.tech/authors/tomasz.ziolkowski"]}]},"content":"<p>This story shows our journey in addressing a platform stability issue related to autoscaling, which, paradoxically, added some additional overhead instead\nof reducing the load. A pivotal part of this narrative is how we used <a href=\"https://www.couchbase.com/\">Couchbase</a> ‚Äî a distributed NoSQL database. If you find\nyourself intrigued by another enigmatic story involving Couchbase, don‚Äôt miss my\n<a href=\"/2024/02/couchbase-expired-docs-tuning.html\">blog post on tuning expired doc settings</a>.</p>\n\n<p>This post unfolds our quest to discover the root cause of the bottleneck. Initially, I will outline the symptoms of the issue. Subsequently, you will be\nintroduced to how Couchbase is utilized by the aforementioned service. Equipped with this knowledge, I will recount our attempts to diagnose the problem and\nindicate which observations raised our suspicions. The following section is dedicated to conducting benchmarks to verify our predictions using\na custom benchmarking tool. Ultimately, we will explore the source code of Couchbase to uncover how the problematic operations are executed. This section\naims to provide a deep understanding of Couchbase‚Äôs inner workings. I firmly believe that the knowledge shared in that part is its most valuable asset and may\nenable you to swiftly identify and address some of the potential performance issues when using Couchbase.</p>\n\n<h2 id=\"set-the-scene\">Set the scene</h2>\n\n<p>The service at the heart of the stability issues handles external HTTP traffic; for the purpose of this discussion, we‚Äôll refer to it as\n‚Äúthe gateway service‚Äù. The traffic routed to the gateway service reflects a pattern similar to organic traffic on <a href=\"https://allegro.tech\">Allegro</a>,\ncharacterized by significant fluctuations in throughput between day and night hours. To efficiently utilize resources, the gateway service employs an autoscaler\nto dynamically adjust the number of instances based on current demands. It‚Äôs also important to note that spawning a new instance involves a warm-up phase,\nduring which the instance retrieves some data from Couchbase to populate its in-memory cache. The gateway service relies on a Couchbase cluster\ncomprised of <strong>three</strong> nodes.</p>\n\n<h2 id=\"observations\">Observations</h2>\n\n<p>The team managing the service encountered a series of errors in communication with Couchbase. These errors indicated that 3-second timeouts occurred while\nfetching data from Couchbase:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>com. couchbase.client.core.error.UnambiguousTimeoutException: SubdocGetRequest, Reason: TIMEOUT {\n    \"cancelled\":true,\n    \"completed\":true,\n    ... IRRELEVANT METADATA ...\n    \"timeoutMs\":3000,\n    \"timings\":{\"totalMicros\":3004052}\n}\n</code></pre></div></div>\n<p>Interestingly, during these incidents, the Couchbase cluster did not exhibit high CPU or RAM usage. Furthermore, the traffic to Couchbase, measured in\noperations per second, was not exceptionally high. I mean that other Couchbase clients (different microservices) were generating an order of magnitude more\noperations per second without encountering stability issues.</p>\n\n<p>Additional key observations related to the issue include:</p>\n<ul>\n  <li>The instability primarily occurred during the service scaling-up process, initially triggered by the autoscaler.</li>\n  <li>Newly spawned instances were predominantly affected.</li>\n  <li>The issues were reported solely for operations directed to a specific node within the cluster.</li>\n  <li>A temporary mitigation of the problems involved repeatedly restarting the failing application instances.</li>\n  <li>There was a noticeable pattern on the driver side that preceded the widespread errors, including timeouts and the inability to send requests due to\na non-writable channel.</li>\n</ul>\n\n<h3 id=\"temporary-solution\">Temporary solution</h3>\n\n<p>As a temporary measure, the team overseeing the gateway service implemented the following workarounds:</p>\n\n<ul>\n  <li>Disabled certain types of requests to reduce the overall traffic volume directed to Couchbase.</li>\n  <li>Deactivated the autoscaler, and manually scaled up the application to manage peak traffic loads.</li>\n</ul>\n\n<p>These actions successfully halted the problems, but they also had repercussions, including business impacts and decreased efficiency in resource utilization.</p>\n\n<h2 id=\"raising-suspicions\">Raising suspicions</h2>\n\n<p>A pivotal aspect of this issue was the use of the <a href=\"https://docs.couchbase.com/go-sdk/2.4/concept-docs/subdocument-operations.html\">Couchbase sub-document API</a>\nwithin the gateway service, an approach not widely adopted across our internal microservice landscape, yet notable for its efficiency. According to\nthe documentation, this API significantly reduces traffic by allowing the fetching or mutating only specific parts of a Couchbase document.\nEssentially, it acts as a substitute for the concept of <a href=\"https://en.wikipedia.org/wiki/Projection_(relational_algebra)\">projection</a>, familiar to SQL users.</p>\n\n<p>In our investigation we closely examined the data collected on the Couchbase node, the operational dynamics of the gateway service‚Äôs cache, and insights\nfrom scrutinizing both the Couchbase driver and server code. We hypothesized that the crux of the problem might be linked to the cache warm-up process for\nnewly launched instances.</p>\n\n<p>Our investigation uncovered several indicators pointing toward the core of the issue:</p>\n\n<ul>\n  <li>A disproportionately large number of requests targeted a single document, inevitably directing traffic to a specific node.</li>\n  <li>The node hosting this heavily queried document corresponded with the one mentioned in timeout-related logs.</li>\n  <li>Instances that had been running for an extended period reported virtually no errors.</li>\n  <li>The volume of requests to Couchbase from the affected instances was extraordinarily high, not aligning with the number of requests registered on\nthe Couchbase side. This discrepancy suggested that if the cache warming process was at fault, the sheer magnitude of attempted requests was overwhelming\neven the local network buffers.</li>\n</ul>\n\n<p>However, these observations were merely pieces of a larger puzzle. We noticed a ‚Äúsnowball effect‚Äù where the system‚Äôs inability to process an initial set\nof requests for newly initiated instances triggered a cascade of failures. But the question remained: Why? What made these instances different,\nand why didn‚Äôt other clients on the same cluster experience similar issues? This was the crucial moment to take a closer examination of the sub-document\noperations to determine their efficiency and optimization.</p>\n\n<h2 id=\"lets-benchmark-it\">Let‚Äôs benchmark it</h2>\n\n<p>Despite an extensive search, we were unable to locate any tools capable of reliably testing our hypothesis‚Äîthat sub-document operations executed during\nthe warm-up phase could significantly challenge Couchbase‚Äôs handling capabilities. As a result, we developed a simple tool and made it\n<a href=\"https://github.com/ziollek/cb-perf-tester\">available in on <em>GitHub</em></a>.\nThis tool is designed to create a sample document and then execute parallel sub-document fetch operations concurrently.\nThe sample document is structured as follows:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>{\n    \"key\": \"test-subdoc\",\n    \"data\": {\n        \"subkey-000000\": \"value-000000\",\n        \"subkey-000001\": \"value-000001\",\n        . . .\n        \"subkey-0‚Ä¶.N\": \"value-0‚Ä¶..N\",\n    }\n}\n</code></pre></div></div>\n\n<p>The tool allows manipulating several knobs, which includes:</p>\n\n<ul>\n  <li><strong>Parallelism</strong>: Determines the number of parallel <a href=\"https://gobyexample.com/goroutines\">goroutines</a> that will attempt to fetch the same sub-documents concurrently.</li>\n  <li><strong>Document Size</strong>: Defined by the number of sub-keys, this directly affects the document‚Äôs binary size.</li>\n  <li><strong>Level of Search Difficulty</strong>: This essentially refers to how deep or how far into the main document the target sub-document is located.\nThe concept is illustrated in the diagram below:</li>\n</ul>\n\n<p><img src=\"/img/articles/2024-05-16-couchbase-subdocuments-bottleneck/cb-sub-difficulty.png\" alt=\"Difficulty of sub-document search\" /></p>\n\n<h3 id=\"caveats\">Caveats</h3>\n\n<p>The primary objective of this exercise was to identify potential bottlenecks, not to conduct a highly accurate performance assessment of Couchbase clusters.\nTherefore, we opted to run our experiments using a local Docker container (<code class=\"language-plaintext highlighter-rouge\">couchbase:community-6.6.0</code>), rather than on a dedicated, well-isolated cluster.\nWe acknowledge that hosting both the server and the benchmarking tool on the same machine may compromise the reliability and accuracy of the results.\nConsequently, we advise against using the findings from these tests for comprehensive assessments or comparisons with other technologies.</p>\n\n<h3 id=\"benchmark-steps\">Benchmark steps</h3>\n\n<p>The procedure for each experiment follows a similar framework, outlined in the steps below:</p>\n\n<ul>\n  <li><strong>Document Preparation</strong>: Initiate the document with the desired number of sub-documents, as dictated by one of the experimental variables.</li>\n  <li><strong>Document Storage</strong>: Save this document under a predetermined key.</li>\n  <li><strong>Goroutine Initialization</strong>: Launch a specified number of goroutines, the quantity of which is determined by another experimental variable.</li>\n  <li><strong>Fetch Operations</strong>: Each goroutine executes a series of fetch operations, which can be either regular (retrieving the entire sample document) or\nsub-document (accessing a set of sub-documents). It‚Äôs important to note that these requests are executed in a blocking manner; a new fetch operation is\nperformed only after the completion of the preceding one. In sub-document mode, the difficulty of the fetch operation is controlled through\nan experiment variable.</li>\n  <li><strong>Completion Wait</strong>: Await the termination of all goroutines.</li>\n  <li><strong>Results Reporting</strong>: Calculate and display the estimated RPS (requests per second).</li>\n</ul>\n\n<h3 id=\"estimate-baseline\">Estimate baseline</h3>\n\n<p>Prior to delving into sub-document operations, we sought to establish the maximum number of regular get operations that our local Couchbase Server instance\ncould handle. Through testing at various levels of concurrency, we determined the maximum throughput for our specific setup.\nIt was approximately 6,000 to 7,000 RPS, regardless of whether the requests were for small documents (less than 200 bytes)\nor for non-existent documents. These findings were further validated by the statistics available through the Couchbase UI.</p>\n\n<p>Benchmark Command: Attempting to fetch a non-existent document yielded a rate of <em>6388 RPS</em>.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>./cb-perf-tester regular  --parallel 200 --repeat 1000 --keys 5 --search-non-existent\nUsing config file: /Users/tomasz.ziolkowski/.cb-perf-tester.yaml\nbenchmark params: keys=5, not-existent=true, repeats=1000, parallel=200\nGenerated doc with subkeys: 5, byte size is: 195\n\nsearch for key: not-exists\n\nregular report: successes: 0, errors: 200000, duration: 31.306684977s, rps: 6388.411937, success rps: 0.000000\n</code></pre></div></div>\n<p><img src=\"/img/articles/2024-05-16-couchbase-subdocuments-bottleneck/cb-baseline-non-exitstent.png\" alt=\"Baseline - fetch a not-existent document\" /></p>\n\n<p>Benchmark Command: Fetching an existing small (195 bytes) document yielded a rate of <em>6341 rps</em>.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>./cb-perf-tester regular  --parallel 200 --repeat 1000 --keys 5\nUsing config file: /Users/tomasz.ziolkowski/.cb-perf-tester.yaml\nbenchmark params: keys=5, not-existent=false, repeats=1000, parallel=200\nGenerated doc with subkeys: 5, byte size is: 195\n\nsearch for key: test-regular\n\nregular report: successes: 200000, errors: 0, duration: 31.536538682s, rps: 6341.850068, success rps: 6341.850068\n</code></pre></div></div>\n<p><img src=\"/img/articles/2024-05-16-couchbase-subdocuments-bottleneck/cb-baseline-hits.png\" alt=\"Baseline - fetch an existing document\" /></p>\n\n<h3 id=\"testing-scenarios\">Testing scenarios</h3>\n\n<p>Now that we have a baseline for comparison, we‚Äôre set to evaluate it against the outcomes of various scenarios. To ensure the tests are comparable,\nwe‚Äôll maintain constant parallelism across all tests, specifically using 200 goroutines. The variables that will differ across scenarios include:</p>\n\n<ul>\n  <li><strong>Total Number of Sub-Documents</strong>: This determines the overall size of the sample document, as the document‚Äôs size is directly related to the number\nof sub-documents it contains.</li>\n  <li><strong>Number of Searched Sub-Documents</strong>: This refers to how many sub-paths within the sample document will be targeted in a single fetch operation.</li>\n  <li><strong>Search Difficulty</strong>: This aspect dictates the difficulty of locating the searched sub-paths within the document.</li>\n</ul>\n\n<p>It‚Äôs important to highlight that in each scenario, we will manipulate only one variable at a time while keeping the other parameters constant.</p>\n\n<h4 id=\"scenario-a-the-impact-of-document-size-on-performance\">Scenario A: The impact of document size on performance</h4>\n\n<p><img src=\"/img/articles/2024-05-16-couchbase-subdocuments-bottleneck/cb-doc-size-vs-performance-all.png\" alt=\"Document size vs performance - aggregated\" /></p>\n\n<p>To better visualize the impact, let‚Äôs look at the diagram for HARD scenario:</p>\n\n<p><img src=\"/img/articles/2024-05-16-couchbase-subdocuments-bottleneck/cb-doc-size-vs-performance-hard.png\" alt=\"Document size vs performance - hard\" /></p>\n\n<p>It is clearly visible that there is a strict correlation between document size and performance.</p>\n\n<h4 id=\"scenario-b-the-impact-of-the-number-of-searched-sub-documents-on-performance\">Scenario B: The impact of the number of searched sub-documents on performance</h4>\n\n<p><img src=\"/img/articles/2024-05-16-couchbase-subdocuments-bottleneck/cb-subdocs-num-vs-performance-all.png\" alt=\"Number of searched sub-documents vs performance - aggregated\" /></p>\n\n<p>To better visualize the impact, let‚Äôs look at the diagram for HARD scenario:</p>\n\n<p><img src=\"/img/articles/2024-05-16-couchbase-subdocuments-bottleneck/cb-subdocs-num-vs-performance-hard.png\" alt=\"Number of searched sub-documents vs performance - hard\" /></p>\n\n<p>As observed in the previous scenario, there is a clear correlation between the number of sub-documents accessed and the system‚Äôs performance.</p>\n\n<h2 id=\"further-analysis\">Further analysis</h2>\n\n<p>Given the evident correlation between the document size/number of queried sub-paths and performance degradation, we delve into the mechanics to understand\nthe root cause of these test results. A notable observation during the tests relates to CPU utilization within the Docker environment, where, despite having\nsix cores available, only a single core was actively utilized. Intriguingly, this usage was monopolized by a single thread (<code class=\"language-plaintext highlighter-rouge\">mc:worker_X</code>).\nThis phenomenon directly stems from Couchbase‚Äôs handling of Key-Value (KV) connections. By default, the Couchbase driver initiates only a single connection to\neach cluster node for KV operations. However, this configuration can be adjusted in certain Software Development Kits (SDKs)‚Äîthe Java SDK,\nfor instance, allows modification through <a href=\"https://docs.couchbase.com/java-sdk/current/ref/client-settings.html#io-options\">IoConfig.numKvConnections</a>.</p>\n\n<p>When a connection is established, Couchbase assigns it to\na <a href=\"https://github.com/couchbase/kv_engine/blob/master/docs/in-depth/C10k.md#current-approach-why-not-both\">specific worker thread</a>) using\na <a href=\"https://github.com/couchbase/kv_engine/blob/master/daemon/front_end_thread.h#L84\">Round-Robin (RR)</a>) algorithm. As a result, the Couchbase Server does not\nfully utilize available CPU power for a single connection, even when a lot of resources are free. This behavior can be seen as beneficial, serving to mitigate\nthe <a href=\"https://en.wikipedia.org/wiki/Cloud_computing_issues#Performance_interference_and_noisy_neighbors\">‚Äúnoisy neighbor‚Äù effect</a>, provided there are sufficient\nspare cores available to manage new connections. This mechanism ensures balanced resource use across connections, as illustrated in the diagram below:</p>\n\n<p><img src=\"/img/articles/2024-05-16-couchbase-subdocuments-bottleneck/cb-dispatch-ok.png\" alt=\"Handling connections - free cores scenario\" /></p>\n\n<p>Conversely, one may encounter fluctuating performance due to instances of misfortune, where if other clients significantly burden certain worker threads,\nand your connection is allocated to one of these overloaded threads, performance inconsistencies arise. This scenario, where a client experiences higher than\nusual response times due to an imbalanced distribution of workload across worker threads, is depicted in the diagram below:</p>\n\n<p><img src=\"/img/articles/2024-05-16-couchbase-subdocuments-bottleneck/cb-dispatch-bad.png\" alt=\"Handling connections - overloaded core scenario\" /></p>\n\n<p>This behavior explains the apparent paradox observed during the stability issues: the Couchbase node showed no clear signs of being overloaded, yet certain\nanomalous symptoms were present, such as a metric indicating the minimum <a href=\"https://en.wikipedia.org/wiki/Idle_(CPU)\">idle</a> percentage across all cores plummeting\nto 0% during the disturbances. This leaves no doubt that operations on sub-documents have the potential to overburden worker threads within\nthe Couchbase Server. With this understanding we are now ready to delve deeper into the root cause of such behavior.</p>\n\n<h3 id=\"what-documentation-says\">What documentation says</h3>\n\n<p>The documentation for Couchbase, housed alongside the server‚Äôs source code, is notably comprehensive, including a dedicated section on\n<a href=\"https://github.com/couchbase/kv_engine/blob/master/docs/SubDocument.md\">sub-documents</a>. However, it falls short of providing detailed insights into\nthe internal workings of these operations. Additionally, there is a lack of discussion on the performance implications of sub-document operations,\nwith only a few remarks on data typing and float numbers that do not apply to the cases we tested. Attempts to find answers on the Couchbase forum were also\nunfruitful, yielding no substantial information on the performance issues we encountered. Despite this, there is confirmation from others in the community who\nhave observed\n<a href=\"https://www.couchbase.com/forums/t/frequent-timeouts-and-requests-over-threshold-for-subdocgetrequests-via-reactive-java-sdk/30211\">similar problems</a>.</p>\n\n<h3 id=\"what-source-code-says\">What source code says</h3>\n\n<p>A thorough analysis of the codebase reveals a definitive cause for the performance degradation observed. It‚Äôs important to note that Couchbase requires\n<a href=\"https://docs.couchbase.com/server/current/learn/buckets-memory-and-storage/compression.html\">decompression</a> of a document for any lookup or manipulation\noperation, whether the document is retrieved from RAM or disk. Let‚Äôs start from a point where Couchbase starts doing\n<a href=\"https://github.com/couchbase/kv_engine/blob/cf020888d2e09b132a02c90b99e160044ddabb11/daemon/subdocument.cc#L568\">lookups</a> on a decompressed object:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>// 2. Perform each of the operations on document.\nfor (auto&amp; op : operations) {\n    switch (op.traits.scope) {\n    case CommandScope::SubJSON:\n        if (cb::mcbp::datatype::is_json(doc_datatype)) {\n            // Got JSON, perform the operation.\n            op.status = subdoc_operate_one_path(context, op, current.view);\n        }\n</code></pre></div></div>\n<p>A critical observation from our analysis is that each operation (lookup) is executed sequentially through the invocation of <code class=\"language-plaintext highlighter-rouge\">subdoc_operate_one_path</code>.\nTo understand the performance implications, let‚Äôs examine\n<a href=\"https://github.com/couchbase/kv_engine/blob/cf020888d2e09b132a02c90b99e160044ddabb11/daemon/subdocument.cc#L413C5-L414C76\">the implementation</a> of this lookup\nprocess:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>// ... and execute it.\nconst auto subdoc_res = op.op_exec(spec.path.data(), spec.path.size());\n</code></pre></div></div>\n\n<p>The Investigation reveals that the lookup functionality is powered by a specialized library,\n<a href=\"https://github.com/couchbase/subjson/blob/4b93d966f791209209a0825e46f7049df0673e8f/subdoc/operations.cc#L757\">library <code class=\"language-plaintext highlighter-rouge\">subjson</code></a>, which in turn\n<a href=\"https://github.com/couchbase/subjson/blob/4b93d966f791209209a0825e46f7049df0673e8f/subdoc/match.cc#L371\">uses</a>\nthe <a href=\"https://github.com/mnunberg/jsonsl\"><code class=\"language-plaintext highlighter-rouge\">jsonsl</code> library</a> for parsing JSON in a streaming manner. An enlightening piece of information about performance can be found in\nthe README of the <code class=\"language-plaintext highlighter-rouge\">subjson</code> library, which is integral to Couchbase‚Äôs solution. The direct quote from the README is as follows:</p>\n\n<blockquote>\n  <p>Because the library does not actually build a JSON tree, the memory usage and CPU consumption is constant, regardless of the size of the actual JSON object\nbeing operated upon, and thus the only variable performance factor is the amount of actual time the library can seek to the location in the document to\nbe modified.</p>\n\n  <p>On a single Xeon E5520 core, this library can process about 150MB/s-300MB/s of JSON. This processing includes the search logic as well as any\nreplacement logic.</p>\n</blockquote>\n\n<p>This analysis clearly demonstrates that lookups targeting paths situated towards the end of a document are markedly slower compared to those aimed\nat the beginning. Moreover, each sequential lookup <strong>needs to repeat document parsing</strong>. The impact of this implementation on performance is significant.\nFor a more intuitive understanding of these effects, please refer to the diagram below:</p>\n\n<p><img src=\"/img/articles/2024-05-16-couchbase-subdocuments-bottleneck/cb-processing-sub-documents.png\" alt=\"Processing sub-documents in details\" /></p>\n\n<p>The performance characteristics we‚Äôve outlined align with the outcomes observed in our experiments. To illustrate, consider a detailed examination of\na single <code class=\"language-plaintext highlighter-rouge\">HARD</code> test scenario‚Äîspecifically, a case where the sub-documents targeted for search were positioned towards the end of the JSON document:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>./cb-perf-tester subdoc  --parallel 200 --repeat 50 --search-keys 10 --difficulty hard\nUsing config file: /Users/tomasz.ziolkowski/.cb-perf-tester.yaml\nbenchmark params: keys=10000, level=Hard, search-keys=10, repeats=50, parallel=200\nGenerated doc with subkeys: 10000, byte size is: 310043\n\nsearch for subkeys [level=Hard]: [data.subkey-009999 data.subkey-009998 data.subkey-009997 data.subkey-009996 data.subkey-009995 data.subkey-009994 data.subkey-009993 data.subkey-009992 data.subkey-009991 data.subkey-009990]\n\nsubdoc report: successes: 10000, errors: 0, duration: 1m19.784865193s, rps: 125.337055, success rps: 125.337055\n</code></pre></div></div>\n\n<p>By multiplying the size of the document by the number of sub-documents queried, we can determine the total stream size that the library must process, which,\nin this case, approximates to <code class=\"language-plaintext highlighter-rouge\">~3MB</code>. Further multiplying this figure by the RPS gives us an insight into the overall throughput of\nthe stream processing:</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">3MB x 125 RPS ~= 375 MBps</code></p>\n\n<p>The calculated throughput slightly exceeds the benchmarks outlined in the README. Moreover, the estimated throughput remains nearly constant across\nvarious tests. For a comprehensive view of these findings, please refer to the diagram below, which displays the estimated throughput for tests conducted under\nthe HARD level with a document size of approximately <code class=\"language-plaintext highlighter-rouge\">300KB</code>:</p>\n\n<p><img src=\"/img/articles/2024-05-16-couchbase-subdocuments-bottleneck/cb-estimated-subdocs-throughput.png\" alt=\"Estimated throughput\" /></p>\n\n<h2 id=\"conclusions\">Conclusions</h2>\n\n<p>The Couchbase sub-document API, while designed to optimize network throughput, introduces significant performance trade-offs. Notably, even\n<em>under optimal conditions</em>, operations on sub-documents are noticeably slower compared to regular get operations fetching\nsmall documents‚Äîevidenced by a comparison of the baseline performance; approximately 4-5k RPS for sub-document operations vs. 6-7k RPS for\nregular get operations.</p>\n\n<p>The method Couchbase employs for executing lookups directly influences performance, manifesting declines as either the document size increases or the number of\nlookups per request raises. This slowdown affects all requests over the same connection due to the high CPU demand of sub-document lookup operations.\nParticularly in environments utilizing reactive/asynchronous clients, this can overload the Couchbase worker thread, leading to a halt in request servicing.\nImportantly, an overloaded worker may manage connections from multiple clients, potentially exacerbating the ‚Äúnoisy neighbor‚Äù effect.</p>\n\n<p>While there are strategies to mitigate these issues from the perspective of a client, such as the gateway service, these considerations warrant\na separate discussion, which I plan to address in a future blog post.</p>\n","contentSnippet":"This story shows our journey in addressing a platform stability issue related to autoscaling, which, paradoxically, added some additional overhead instead\nof reducing the load. A pivotal part of this narrative is how we used Couchbase ‚Äî a distributed NoSQL database. If you find\nyourself intrigued by another enigmatic story involving Couchbase, don‚Äôt miss my\nblog post on tuning expired doc settings.\nThis post unfolds our quest to discover the root cause of the bottleneck. Initially, I will outline the symptoms of the issue. Subsequently, you will be\nintroduced to how Couchbase is utilized by the aforementioned service. Equipped with this knowledge, I will recount our attempts to diagnose the problem and\nindicate which observations raised our suspicions. The following section is dedicated to conducting benchmarks to verify our predictions using\na custom benchmarking tool. Ultimately, we will explore the source code of Couchbase to uncover how the problematic operations are executed. This section\naims to provide a deep understanding of Couchbase‚Äôs inner workings. I firmly believe that the knowledge shared in that part is its most valuable asset and may\nenable you to swiftly identify and address some of the potential performance issues when using Couchbase.\nSet the scene\nThe service at the heart of the stability issues handles external HTTP traffic; for the purpose of this discussion, we‚Äôll refer to it as\n‚Äúthe gateway service‚Äù. The traffic routed to the gateway service reflects a pattern similar to organic traffic on Allegro,\ncharacterized by significant fluctuations in throughput between day and night hours. To efficiently utilize resources, the gateway service employs an autoscaler\nto dynamically adjust the number of instances based on current demands. It‚Äôs also important to note that spawning a new instance involves a warm-up phase,\nduring which the instance retrieves some data from Couchbase to populate its in-memory cache. The gateway service relies on a Couchbase cluster\ncomprised of three nodes.\nObservations\nThe team managing the service encountered a series of errors in communication with Couchbase. These errors indicated that 3-second timeouts occurred while\nfetching data from Couchbase:\n\ncom. couchbase.client.core.error.UnambiguousTimeoutException: SubdocGetRequest, Reason: TIMEOUT {\n    \"cancelled\":true,\n    \"completed\":true,\n    ... IRRELEVANT METADATA ...\n    \"timeoutMs\":3000,\n    \"timings\":{\"totalMicros\":3004052}\n}\n\n\nInterestingly, during these incidents, the Couchbase cluster did not exhibit high CPU or RAM usage. Furthermore, the traffic to Couchbase, measured in\noperations per second, was not exceptionally high. I mean that other Couchbase clients (different microservices) were generating an order of magnitude more\noperations per second without encountering stability issues.\nAdditional key observations related to the issue include:\nThe instability primarily occurred during the service scaling-up process, initially triggered by the autoscaler.\nNewly spawned instances were predominantly affected.\nThe issues were reported solely for operations directed to a specific node within the cluster.\nA temporary mitigation of the problems involved repeatedly restarting the failing application instances.\nThere was a noticeable pattern on the driver side that preceded the widespread errors, including timeouts and the inability to send requests due to\na non-writable channel.\nTemporary solution\nAs a temporary measure, the team overseeing the gateway service implemented the following workarounds:\nDisabled certain types of requests to reduce the overall traffic volume directed to Couchbase.\nDeactivated the autoscaler, and manually scaled up the application to manage peak traffic loads.\nThese actions successfully halted the problems, but they also had repercussions, including business impacts and decreased efficiency in resource utilization.\nRaising suspicions\nA pivotal aspect of this issue was the use of the Couchbase sub-document API\nwithin the gateway service, an approach not widely adopted across our internal microservice landscape, yet notable for its efficiency. According to\nthe documentation, this API significantly reduces traffic by allowing the fetching or mutating only specific parts of a Couchbase document.\nEssentially, it acts as a substitute for the concept of projection, familiar to SQL users.\nIn our investigation we closely examined the data collected on the Couchbase node, the operational dynamics of the gateway service‚Äôs cache, and insights\nfrom scrutinizing both the Couchbase driver and server code. We hypothesized that the crux of the problem might be linked to the cache warm-up process for\nnewly launched instances.\nOur investigation uncovered several indicators pointing toward the core of the issue:\nA disproportionately large number of requests targeted a single document, inevitably directing traffic to a specific node.\nThe node hosting this heavily queried document corresponded with the one mentioned in timeout-related logs.\nInstances that had been running for an extended period reported virtually no errors.\nThe volume of requests to Couchbase from the affected instances was extraordinarily high, not aligning with the number of requests registered on\nthe Couchbase side. This discrepancy suggested that if the cache warming process was at fault, the sheer magnitude of attempted requests was overwhelming\neven the local network buffers.\nHowever, these observations were merely pieces of a larger puzzle. We noticed a ‚Äúsnowball effect‚Äù where the system‚Äôs inability to process an initial set\nof requests for newly initiated instances triggered a cascade of failures. But the question remained: Why? What made these instances different,\nand why didn‚Äôt other clients on the same cluster experience similar issues? This was the crucial moment to take a closer examination of the sub-document\noperations to determine their efficiency and optimization.\nLet‚Äôs benchmark it\nDespite an extensive search, we were unable to locate any tools capable of reliably testing our hypothesis‚Äîthat sub-document operations executed during\nthe warm-up phase could significantly challenge Couchbase‚Äôs handling capabilities. As a result, we developed a simple tool and made it\navailable in on GitHub.\nThis tool is designed to create a sample document and then execute parallel sub-document fetch operations concurrently.\nThe sample document is structured as follows:\n\n{\n    \"key\": \"test-subdoc\",\n    \"data\": {\n        \"subkey-000000\": \"value-000000\",\n        \"subkey-000001\": \"value-000001\",\n        . . .\n        \"subkey-0‚Ä¶.N\": \"value-0‚Ä¶..N\",\n    }\n}\n\n\nThe tool allows manipulating several knobs, which includes:\nParallelism: Determines the number of parallel goroutines that will attempt to fetch the same sub-documents concurrently.\nDocument Size: Defined by the number of sub-keys, this directly affects the document‚Äôs binary size.\nLevel of Search Difficulty: This essentially refers to how deep or how far into the main document the target sub-document is located.\nThe concept is illustrated in the diagram below:\n\nCaveats\nThe primary objective of this exercise was to identify potential bottlenecks, not to conduct a highly accurate performance assessment of Couchbase clusters.\nTherefore, we opted to run our experiments using a local Docker container (couchbase:community-6.6.0), rather than on a dedicated, well-isolated cluster.\nWe acknowledge that hosting both the server and the benchmarking tool on the same machine may compromise the reliability and accuracy of the results.\nConsequently, we advise against using the findings from these tests for comprehensive assessments or comparisons with other technologies.\nBenchmark steps\nThe procedure for each experiment follows a similar framework, outlined in the steps below:\nDocument Preparation: Initiate the document with the desired number of sub-documents, as dictated by one of the experimental variables.\nDocument Storage: Save this document under a predetermined key.\nGoroutine Initialization: Launch a specified number of goroutines, the quantity of which is determined by another experimental variable.\nFetch Operations: Each goroutine executes a series of fetch operations, which can be either regular (retrieving the entire sample document) or\nsub-document (accessing a set of sub-documents). It‚Äôs important to note that these requests are executed in a blocking manner; a new fetch operation is\nperformed only after the completion of the preceding one. In sub-document mode, the difficulty of the fetch operation is controlled through\nan experiment variable.\nCompletion Wait: Await the termination of all goroutines.\nResults Reporting: Calculate and display the estimated RPS (requests per second).\nEstimate baseline\nPrior to delving into sub-document operations, we sought to establish the maximum number of regular get operations that our local Couchbase Server instance\ncould handle. Through testing at various levels of concurrency, we determined the maximum throughput for our specific setup.\nIt was approximately 6,000 to 7,000 RPS, regardless of whether the requests were for small documents (less than 200 bytes)\nor for non-existent documents. These findings were further validated by the statistics available through the Couchbase UI.\nBenchmark Command: Attempting to fetch a non-existent document yielded a rate of 6388 RPS.\n\n./cb-perf-tester regular  --parallel 200 --repeat 1000 --keys 5 --search-non-existent\nUsing config file: /Users/tomasz.ziolkowski/.cb-perf-tester.yaml\nbenchmark params: keys=5, not-existent=true, repeats=1000, parallel=200\nGenerated doc with subkeys: 5, byte size is: 195\n\nsearch for key: not-exists\n\nregular report: successes: 0, errors: 200000, duration: 31.306684977s, rps: 6388.411937, success rps: 0.000000\n\n\n\nBenchmark Command: Fetching an existing small (195 bytes) document yielded a rate of 6341 rps.\n\n./cb-perf-tester regular  --parallel 200 --repeat 1000 --keys 5\nUsing config file: /Users/tomasz.ziolkowski/.cb-perf-tester.yaml\nbenchmark params: keys=5, not-existent=false, repeats=1000, parallel=200\nGenerated doc with subkeys: 5, byte size is: 195\n\nsearch for key: test-regular\n\nregular report: successes: 200000, errors: 0, duration: 31.536538682s, rps: 6341.850068, success rps: 6341.850068\n\n\n\nTesting scenarios\nNow that we have a baseline for comparison, we‚Äôre set to evaluate it against the outcomes of various scenarios. To ensure the tests are comparable,\nwe‚Äôll maintain constant parallelism across all tests, specifically using 200 goroutines. The variables that will differ across scenarios include:\nTotal Number of Sub-Documents: This determines the overall size of the sample document, as the document‚Äôs size is directly related to the number\nof sub-documents it contains.\nNumber of Searched Sub-Documents: This refers to how many sub-paths within the sample document will be targeted in a single fetch operation.\nSearch Difficulty: This aspect dictates the difficulty of locating the searched sub-paths within the document.\nIt‚Äôs important to highlight that in each scenario, we will manipulate only one variable at a time while keeping the other parameters constant.\nScenario A: The impact of document size on performance\n\nTo better visualize the impact, let‚Äôs look at the diagram for HARD scenario:\n\nIt is clearly visible that there is a strict correlation between document size and performance.\nScenario B: The impact of the number of searched sub-documents on performance\n\nTo better visualize the impact, let‚Äôs look at the diagram for HARD scenario:\n\nAs observed in the previous scenario, there is a clear correlation between the number of sub-documents accessed and the system‚Äôs performance.\nFurther analysis\nGiven the evident correlation between the document size/number of queried sub-paths and performance degradation, we delve into the mechanics to understand\nthe root cause of these test results. A notable observation during the tests relates to CPU utilization within the Docker environment, where, despite having\nsix cores available, only a single core was actively utilized. Intriguingly, this usage was monopolized by a single thread (mc:worker_X).\nThis phenomenon directly stems from Couchbase‚Äôs handling of Key-Value (KV) connections. By default, the Couchbase driver initiates only a single connection to\neach cluster node for KV operations. However, this configuration can be adjusted in certain Software Development Kits (SDKs)‚Äîthe Java SDK,\nfor instance, allows modification through IoConfig.numKvConnections.\nWhen a connection is established, Couchbase assigns it to\na specific worker thread) using\na Round-Robin (RR)) algorithm. As a result, the Couchbase Server does not\nfully utilize available CPU power for a single connection, even when a lot of resources are free. This behavior can be seen as beneficial, serving to mitigate\nthe ‚Äúnoisy neighbor‚Äù effect, provided there are sufficient\nspare cores available to manage new connections. This mechanism ensures balanced resource use across connections, as illustrated in the diagram below:\n\nConversely, one may encounter fluctuating performance due to instances of misfortune, where if other clients significantly burden certain worker threads,\nand your connection is allocated to one of these overloaded threads, performance inconsistencies arise. This scenario, where a client experiences higher than\nusual response times due to an imbalanced distribution of workload across worker threads, is depicted in the diagram below:\n\nThis behavior explains the apparent paradox observed during the stability issues: the Couchbase node showed no clear signs of being overloaded, yet certain\nanomalous symptoms were present, such as a metric indicating the minimum idle percentage across all cores plummeting\nto 0% during the disturbances. This leaves no doubt that operations on sub-documents have the potential to overburden worker threads within\nthe Couchbase Server. With this understanding we are now ready to delve deeper into the root cause of such behavior.\nWhat documentation says\nThe documentation for Couchbase, housed alongside the server‚Äôs source code, is notably comprehensive, including a dedicated section on\nsub-documents. However, it falls short of providing detailed insights into\nthe internal workings of these operations. Additionally, there is a lack of discussion on the performance implications of sub-document operations,\nwith only a few remarks on data typing and float numbers that do not apply to the cases we tested. Attempts to find answers on the Couchbase forum were also\nunfruitful, yielding no substantial information on the performance issues we encountered. Despite this, there is confirmation from others in the community who\nhave observed\nsimilar problems.\nWhat source code says\nA thorough analysis of the codebase reveals a definitive cause for the performance degradation observed. It‚Äôs important to note that Couchbase requires\ndecompression of a document for any lookup or manipulation\noperation, whether the document is retrieved from RAM or disk. Let‚Äôs start from a point where Couchbase starts doing\nlookups on a decompressed object:\n\n// 2. Perform each of the operations on document.\nfor (auto& op : operations) {\n    switch (op.traits.scope) {\n    case CommandScope::SubJSON:\n        if (cb::mcbp::datatype::is_json(doc_datatype)) {\n            // Got JSON, perform the operation.\n            op.status = subdoc_operate_one_path(context, op, current.view);\n        }\n\n\nA critical observation from our analysis is that each operation (lookup) is executed sequentially through the invocation of subdoc_operate_one_path.\nTo understand the performance implications, let‚Äôs examine\nthe implementation of this lookup\nprocess:\n\n// ... and execute it.\nconst auto subdoc_res = op.op_exec(spec.path.data(), spec.path.size());\n\n\nThe Investigation reveals that the lookup functionality is powered by a specialized library,\nlibrary subjson, which in turn\nuses\nthe jsonsl library for parsing JSON in a streaming manner. An enlightening piece of information about performance can be found in\nthe README of the subjson library, which is integral to Couchbase‚Äôs solution. The direct quote from the README is as follows:\nBecause the library does not actually build a JSON tree, the memory usage and CPU consumption is constant, regardless of the size of the actual JSON object\nbeing operated upon, and thus the only variable performance factor is the amount of actual time the library can seek to the location in the document to\nbe modified.\nOn a single Xeon E5520 core, this library can process about 150MB/s-300MB/s of JSON. This processing includes the search logic as well as any\nreplacement logic.\nThis analysis clearly demonstrates that lookups targeting paths situated towards the end of a document are markedly slower compared to those aimed\nat the beginning. Moreover, each sequential lookup needs to repeat document parsing. The impact of this implementation on performance is significant.\nFor a more intuitive understanding of these effects, please refer to the diagram below:\n\nThe performance characteristics we‚Äôve outlined align with the outcomes observed in our experiments. To illustrate, consider a detailed examination of\na single HARD test scenario‚Äîspecifically, a case where the sub-documents targeted for search were positioned towards the end of the JSON document:\n\n./cb-perf-tester subdoc  --parallel 200 --repeat 50 --search-keys 10 --difficulty hard\nUsing config file: /Users/tomasz.ziolkowski/.cb-perf-tester.yaml\nbenchmark params: keys=10000, level=Hard, search-keys=10, repeats=50, parallel=200\nGenerated doc with subkeys: 10000, byte size is: 310043\n\nsearch for subkeys [level=Hard]: [data.subkey-009999 data.subkey-009998 data.subkey-009997 data.subkey-009996 data.subkey-009995 data.subkey-009994 data.subkey-009993 data.subkey-009992 data.subkey-009991 data.subkey-009990]\n\nsubdoc report: successes: 10000, errors: 0, duration: 1m19.784865193s, rps: 125.337055, success rps: 125.337055\n\n\nBy multiplying the size of the document by the number of sub-documents queried, we can determine the total stream size that the library must process, which,\nin this case, approximates to ~3MB. Further multiplying this figure by the RPS gives us an insight into the overall throughput of\nthe stream processing:\n3MB x 125 RPS ~= 375 MBps\nThe calculated throughput slightly exceeds the benchmarks outlined in the README. Moreover, the estimated throughput remains nearly constant across\nvarious tests. For a comprehensive view of these findings, please refer to the diagram below, which displays the estimated throughput for tests conducted under\nthe HARD level with a document size of approximately 300KB:\n\nConclusions\nThe Couchbase sub-document API, while designed to optimize network throughput, introduces significant performance trade-offs. Notably, even\nunder optimal conditions, operations on sub-documents are noticeably slower compared to regular get operations fetching\nsmall documents‚Äîevidenced by a comparison of the baseline performance; approximately 4-5k RPS for sub-document operations vs. 6-7k RPS for\nregular get operations.\nThe method Couchbase employs for executing lookups directly influences performance, manifesting declines as either the document size increases or the number of\nlookups per request raises. This slowdown affects all requests over the same connection due to the high CPU demand of sub-document lookup operations.\nParticularly in environments utilizing reactive/asynchronous clients, this can overload the Couchbase worker thread, leading to a halt in request servicing.\nImportantly, an overloaded worker may manage connections from multiple clients, potentially exacerbating the ‚Äúnoisy neighbor‚Äù effect.\nWhile there are strategies to mitigate these issues from the perspective of a client, such as the gateway service, these considerations warrant\na separate discussion, which I plan to address in a future blog post.","guid":"https://blog.allegro.tech/2024/05/couchbase-subdocuments-bottleneck.html","categories":["tech","couchbase","sub-documents","performance","bottlenecks"],"isoDate":"2024-05-15T22:00:00.000Z"},{"title":"Ten Years and Counting: My Affair with Microservices","link":"https://blog.allegro.tech/2024/04/ten-years-microservices.html","pubDate":"Fri, 12 Apr 2024 00:00:00 +0200","authors":{"author":[{"name":["Micha≈Ç Kosmulski"],"photo":["https://blog.allegro.tech/img/authors/michal.kosmulski.jpg"],"url":["https://blog.allegro.tech/authors/michal.kosmulski"]}]},"content":"<p>In early 2024, I hit ten years at <a href=\"https://allegro.tech/\">Allegro</a>, which also happens to be how long I‚Äôve been working with <a href=\"https://martinfowler.com/microservices/\">microservices</a>.\nThis timespan also roughly corresponds to how long the company as a whole has been using them, so I think it‚Äôs a good time to outline the story of project\nRubicon: a very ambitious gamble which completely changed how we work and what our software is like. The idea probably seemed rather extreme at the time, yet I\nam certain that without this change, Allegro would not be where it is today, or perhaps would not be there at all.</p>\n\n<h2 id=\"background\">Background</h2>\n\n<p>Allegro is <a href=\"https://about.allegro.eu/who-we-are/at-a-glance\">one of the largest e-commerce sites in Central Europe</a>, with 20 million users and over 300 million\noffers. It was founded in 1999, originally with just the Polish market in mind. The story I want to tell you starts in 2013, a year before I joined.</p>\n\n<p><img src=\"/img/articles/2024-04-12-ten-years-microservices/allegro-site.png\" alt=\"Allegro website showing some offers\" class=\"small-image\" style=\"box-shadow: 0 0 4px 0 #D7DBD6;\" /></p>\n\n<p>In 2013, the site was already large and relevant, but its commercial success and further growth led to development bottlenecks emerging. The codebase was a\nmonolithic PHP application, with some auxiliary processes written in C. Checked out, the git monorepo weighed about 2 GB, and the number of pull requests\nproduced daily by a few hundred developers was so large that if you started a new branch in the morning, you were almost sure to get some conflicts if you\nwanted to merge in the afternoon. The system was centered around a single, huge database, with all the performance and architectural challenges you can imagine.\nTests were brittle and took ages to finish. Deployment was a mostly manual and thus time-consuming processes that required lots of attention and ran the risk of\ncausing a serious problem in production if something went wrong. It was so demanding and stressful I still remember my team having to run the deployment once\n(in place of the usual deployers) as a big event.</p>\n\n<h2 id=\"rubicon-rises\">Rubicon Rises</h2>\n\n<p><img src=\"/img/articles/2024-04-12-ten-years-microservices/Tabula_Peutingeriana_Rubicon.png\" alt=\"Rubicon river on an old map\" class=\"small-image-right\" />\nIt was becoming clear that we would hit a wall if we continued working this way. So, around 2012/2013, the idea for a complete overhaul of the architecture\nstarted to emerge. We began experimenting with <a href=\"https://en.wikipedia.org/wiki/Service-oriented_architecture\">SOA (Service-Oriented Architecture)</a> by\ncreating a small side project, the so-called New Platform, in PHP, as a proof-of-concept. We also decided we would start doing\n<a href=\"https://en.wikipedia.org/wiki/Agile_software_development\">Agile</a>, <a href=\"https://en.wikipedia.org/wiki/Test-driven_development\">TDD</a>, and\n<a href=\"https://en.wikipedia.org/wiki/Cloud_computing\">Cloud</a>. After a short while, on top of this, we decided to switch to Java for backend development.\nIt was becoming clear that <a href=\"/2015/02/Evolution-of-our-platform-architecture.html\">it would be a revolution indeed</a>, requiring everyone to change\nthe way they worked, and to switch out the whole development ecosystem, starting with the core programming language. Once we got this going, there would be\nno turning back, so a matching name also appeared: Project <a href=\"https://en.wikipedia.org/wiki/Crossing_the_Rubicon\">Rubicon</a>.</p>\n\n<p>The project had such a broad scope that it even came with its own constitution, a set of high-level guidelines to be used in case of doubt. It focused mostly\non ways of working and highlighted the value of learning (on personal, team, and company level), testing, reuse, empirical approach to software development,\nand active participation in the open-source community both as users and as contributors. Specific technical assumptions included:</p>\n<ul>\n  <li>focus on quality</li>\n  <li>microservices</li>\n  <li>distributed, multi-regional, active-active architecture</li>\n  <li>Java</li>\n  <li>cloud deployment</li>\n  <li>using open-source technologies</li>\n</ul>\n\n<p>There was also a list of success criteria for the project:</p>\n<ul>\n  <li>the monolith is gone</li>\n  <li>we have Java gurus on board</li>\n  <li>we have services</li>\n  <li>development is faster</li>\n  <li>we have continuous delivery</li>\n  <li>we don‚Äôt have another monolith</li>\n  <li>we still make money</li>\n</ul>\n\n<p>Faster development was probably the most important goal, since slow delivery was the direct reason we embarked on this long journey.</p>\n\n<p>On top of these lists, more detailed plans were made as well, of course. For example, various parts of the system were prioritized for moving out of the\nmonolith as we were well aware we would not be able to work on everything at once. Being Agile does not mean planning is to be avoided, only that plans have\nto be flexible. So, armed with a plan, we got off to work.</p>\n\n<h2 id=\"execution\">Execution</h2>\n\n<p><img src=\"/img/articles/2024-04-12-ten-years-microservices/tim-gouw-1K9T5YiZ2WU-unsplash.jpg\" alt=\"Man sitting at a laptop, overwhelmed by what he sees on the screen\" class=\"small-image-right\" />\nToo much has happened during the 10+ years to report here. The initial period was really frantic since we had to set up everything, and, first of all, teams had\nto switch to a new mindset. This was also a period of intense hiring, and the time I joined the recently opened office in Warsaw. Microservices were at that\ntime only starting to gain traction, so while we used the experiences of others as much has possible, we had to learn many things ourselves, sometimes learning\nthem the hard way.</p>\n\n<p>To give you an idea of the pace, here are just some of the things that happened in 2013:</p>\n<ul>\n  <li>outline of the common architecture (service discovery, logging) created</li>\n  <li>a set of common libraries created (<a href=\"https://youtu.be/PeioFobaq94\">presentation from 2016</a>)</li>\n  <li>training in Java and JVM for PHP developers</li>\n  <li>recruitment of Java developers started</li>\n  <li>first Java code got written</li>\n  <li>fierce discussions about technology choices (Guice vs Spring, Maven vs Gradle, Jetty vs Undertow)</li>\n</ul>\n\n<p>What followed in 2014 (this is the part I could already experience in person):</p>\n<ul>\n  <li>various self-service tools allowing developers to handle common tasks such as creating databases themselves rather than by involving specialized support teams</li>\n  <li>automation tools</li>\n  <li>development of <a href=\"https://hermes.allegro.tech/\">Hermes</a>, our open-source message broker built on top of Kafka, started</li>\n  <li>strategic DDD training with Eric Evans</li>\n  <li><a href=\"/2014/12/How-to-migrate-to-Java-8.html\">migration to Java 8</a></li>\n  <li>global architecture improvements</li>\n  <li><a href=\"https://allegro.tech/\">allegro.tech</a>, the project to coordinate the visibility of our tech division online and offline, of which this blog is a part,\nstarted</li>\n  <li>SRE team created</li>\n  <li><a href=\"/2016/09/CQK-TOP-10.html\">CQK (Code Quality Keepers) guild</a> opened</li>\n  <li>first Java services deployed to production</li>\n  <li>intense recruitment and learning</li>\n</ul>\n\n<p>The number of both production services and of tools supporting developers‚Äô work that got created thereafter is staggering. It should be clear from just the\nlist above that this was a huge investment, and could only proceed due to full buy-in of both technology and business parts of the company. It was indeed a\ngamble, well-informed, but still a gamble that carried big risk should it fail, but an even greater risk if we were to stay with the old architecture.</p>\n\n<p>At this point you probably can see that actually building microservices seems like a minor part of the whole undertaking. There was a lot of work to\nwriting so many parts of this huge system anew, but indeed the amount of work that we had to invest into\n<a href=\"/2016/02/datacenter-migration-great-adventure.html\">infrastructure</a>,\n<a href=\"/2018/10/turnilo-lets-change-the-way-people-explore-big-data.html\">tooling</a>, and\n<a href=\"/2016/09/are-code-reviews-worth-your-time.html\">learning</a>, was immense. It was also absolutely critical for the project‚Äôs success. A lot has been\nsaid about microservices, and it is true that for them to be beneficial, you need the right scale and the right kind of system. We had both, and so the decision\nto move to microservices proved to be worthwhile, but despite knowing the theory, I think no one expected the amount of auxiliary work to be so huge. Indeed,\nwhile microservices themselves may be simple, the glue that holds them together is not.</p>\n\n<h2 id=\"flashbacks\">Flashbacks</h2>\n\n<p>Summarizing ten years of rapid development is tough, so instead of trying to tell you the full story, I decided to share a few flashbacks: moments which I\nremembered for one reason or another.</p>\n\n<h3 id=\"no-ing-sql\">No-ing SQL</h3>\n\n<p><img src=\"/img/articles/2024-04-12-ten-years-microservices/tobias-fischer-PkbZahEG2Ng-unsplash.jpg\" alt=\"Huge modern library filled with books\" class=\"small-image-right\" />\nWhen <a href=\"/2015/01/working-with-legacy-architecture.html\">refactoring our huge monolith into smaller microservices</a>, we needed to also choose the\ndatabase to use for each of them. Since horizontal scalability was our focus, we preferred <a href=\"https://en.wikipedia.org/wiki/NoSQL\">NoSQL databases</a> when possible.\nThis was a big change since the monolithic solution relied on a single, huge SQL database. On top of that, it was not modularized well, and in many places\nthere was little or no separation between domain and persistence layers. If the monolith was structured well, splitting it into separate services would have\nbeen much easier. Unfortunately, this was not the case, so we had to perform the transition to NoSQL together with other refactorings and cleanup. Usually,\nwe had to deeply remodel data and operations handling it, especially transactional, so that they could be executed in the new environment. This was often\na significant effort even if we could divide the code in such way that the transaction or set of related operations ended up within the same service. Things\nbecame even more complicated if an operation spanned multiple services (and databases) in the new architecture. This is one of the reasons why dividing a\nbig application into smaller chunks is much harder than it may seem at first.</p>\n\n<p><a href=\"https://cassandra.apache.org/\">Cassandra</a> was initially our preferred NoSQL database for most tasks. Only after a while did we learn that each database is good\nfor some use cases and bad for others, and that we needed <a href=\"https://en.wikipedia.org/wiki/Polyglot_persistence\">polyglot persistence</a> to achieve high performance\nand get the required flexibility in all cases. The team I worked on was among the first Cassandra adopters at the company, and as is often the case when\nyou run something in production for the first time, we uncovered a number of issues in our Cassandra deployment which was ‚Äúready‚Äù but not tested in production\nyet. The team responsible for the DB was learning completely new stuff just as we were.</p>\n\n<p>An argument sometimes put up against the need to separate your application‚Äôs persistence layer from the domain logic is ‚Äúyou‚Äôre never going to switch out the\nDB for another one anyway‚Äù. Most of the time that‚Äôs true, but in one service we did have to switch from Cassandra to <a href=\"https://www.mongodb.com/\">MongoDB</a>\nafter we found out our access patterns were not very well aligned with Cassandra‚Äôs data model. We managed to do it inside a single two-week sprint, and\napart from the service becoming faster, its clients would not notice any difference as the external API stayed the same. While the (usually theoretical)\nprospect of switching databases is not the only reason for decoupling domain and persistence layers, it did help a lot in this case, and it is about this\ntime I started to understand why we were creating so many classes even though you could just cram all that code into one.</p>\n\n<p>I also managed to kill our Cassandra instance once when I was learning about big data processing and created a job that was supposed to process some data from\nthe DB. The job was so massively parallel that the barrage of requests it generated overwhelmed even Cassandra. Fortunately, this situation also showed the\nadvantage of having separate databases for each service, as only that single service experienced an outage.</p>\n\n<h3 id=\"into-the-cloud\">Into the cloud</h3>\n\n<p><img src=\"/img/articles/2024-04-12-ten-years-microservices/thisisengineering-raeng-zBLtU0zbJcU-unsplash.jpg\" alt=\"Engineer plugging in network cables into servers\" class=\"small-image-right\" />\nBefore joining Allegro, I had only deployed to physical servers, so moving to the cloud was a big change. At first, we deployed our services to virtual\nmachines configured in <a href=\"https://www.openstack.org/\">OpenStack</a>. What a convenience it was to be able to just set up a complete virtual server with a few\nclicks rather than wait days for a physical machine. We used <a href=\"https://www.puppet.com/\">Puppet</a> to fully configure the virtual machines for each service, so\nwhile you had to write some configuration once, you could spin up a new server configured for your service almost instantly afterwards.</p>\n\n<p>This <a href=\"https://en.wikipedia.org/wiki/Infrastructure_as_a_service\">IaaS (Infrastructure as a Service)</a> approach was very convenient, and quite a change, but in\nmany ways it still resembled what I had known before: you had a machine, even if virtual, and you could <code class=\"language-plaintext highlighter-rouge\">ssh</code> and run any commands there if you wanted, even\nif it was rarely needed since Puppet set up everything for you.</p>\n\n<p>The real revolution came when we switched to <a href=\"https://en.wikipedia.org/wiki/Platform_as_a_service\">PaaS (Platform as a Service)</a> model, at that time based on\n<a href=\"https://mesos.apache.org/\">Mesos</a> and <a href=\"https://mesosphere.github.io/marathon/\">Marathon</a>. Suddenly, there were no more virtual machines, and you could not <code class=\"language-plaintext highlighter-rouge\">ssh</code>\nto the server where your software was running. For me, this was a real culture shock, and even though up to this point I was very enthusiastic about all the\ncool technology we were introducing, the thought of <em>no more <code class=\"language-plaintext highlighter-rouge\">ssh</code></em> freaked me out. How would I know what was going on in the system if I couldn‚Äôt even access\nit? Despite my reservations, I gradually found out you could indeed deploy and monitor software despite not being able to access the machine via <code class=\"language-plaintext highlighter-rouge\">ssh</code>. It\nsounds weird in retrospect, but this was one of the most difficult technological transitions in my career.</p>\n\n<p>After a while, we built some abstraction layers on top of Mesos, including a custom <em>app console</em> that allows you to deploy a service and perform all\nmaintenance tasks. It isolates you from most details of the underlying system, and is so effective that when we migrated from Mesos to <a href=\"https://kubernetes.io/\">Kubernetes</a>\nlater on, the impact on most teams was much smaller that you could imagine for such a big change. Our App Console is an internal project, but if you are\nfamiliar with <a href=\"https://backstage.spotify.com/learn/backstage-for-all/backstage-for-all/1-introduction/\">Backstage</a>, it should give you an idea of what kind\nof tool we‚Äôre talking about here.</p>\n\n<h3 id=\"monitoring\">Monitoring</h3>\n\n<p><img src=\"/img/articles/2024-04-12-ten-years-microservices/carlos-muza-hpjSkU2UYSU-unsplash.jpg\" alt=\"Laptop displaying various charts\" class=\"small-image-right\" />\nBelieve it or not, initially all monitoring was centralized and handled by a single team. If you wanted to have any non-standard charts in\n<a href=\"https://www.zabbix.com/\">Zabbix</a> or any custom alerts (and obviously, you wanted to), you had to create a ticket in JIRA, describe exactly what you wanted,\nand after a while, the monitoring team would set it up for you. The whole process took about a week, and quite often, right after seeing the new chart you\nknew you wanted to improve it, so you would file another ticket and wait another week. Needless to say, this was incredibly frustrating, and I consider it\none of my early big successes when I kept pushing the monitoring team until they finally gave in and allowed development teams to configure all of their\nobservability settings themselves.</p>\n\n<h3 id=\"going-polyglot\">Going polyglot</h3>\n\n<p><img src=\"/img/articles/2024-04-12-ten-years-microservices/azamat-e-FP_N_InBPdg-unsplash.jpg\" alt=\"Man working on two laptops at the same time\" class=\"small-image-right\" />\nWhile Rubicon started out with the premise of rewriting our software in Java, we quickly started experimenting with other JVM languages. The team I worked\non considered Scala for a while, but after some experimentation decided against using it as our main language. Some other teams, however, did choose it, and\neven though they are a minority at Allegro, we have some microservices written in Scala to this day. On the other hand, Scala is the dominant language at\nAllegro when it comes to writing <a href=\"https://spark.apache.org/\">Spark</a> jobs.</p>\n\n<p>Some time around 2015, a teammate found out there was a relatively new, but promising, language called <a href=\"https://kotlinlang.org/\">Kotlin</a>. It so happened that we\nwere just starting work on a new microservice which was still very simple and not quite critical. He decided to use it as a testbed, and within I think two days\nrewrote the whole thing in Kotlin. Thanks to the services being independent and this one not being very important yet, we could safely experiment in production\nand assess the stability of the rewritten service. Learning the language by writing actual production-ready code rather than just playing with throw-away code\nallowed us to check what advantages and disadvantages the language offered under realistic usage scenarios. Kotlin caught on, and gradually we started to use\nit for more and more new services and to use it for new features in existing Java services as mixing the two was easy. Many services already used\n<a href=\"https://groovy-lang.org/\">Groovy</a> and <a href=\"https://spockframework.org/\">Spock</a> for tests anyway. At this point, Kotlin is more popular than Java at Allegro, and\non our blog we published <a href=\"/2016/06/kotlin-null-safety-part1.html\">some</a> articles <a href=\"/2021/04/kotlin-scripting.html\">about Kotlin</a>,\nincluding <a href=\"/2018/05/From-Java-to-Kotlin-and-Back-Again.html\">one</a> which unfortunately stirred a lot of controversy, and caused a (deserved IMO)\nshitstorm both inside and outside the company.</p>\n\n<p>Besides JVM languages, we by now have also microservices written in <a href=\"/2020/03/dotnet-new-templates.html\">C#</a>,\n<a href=\"/2016/03/writing-fast-cache-service-in-go.html\">Go</a>, <a href=\"/2022/01/how-do-coroutines-work-internally-in-python.html\">Python</a>,\n<a href=\"https://elixir-lang.org/\">Elixir</a>, and probably a few more languages I forgot to mention. This is just the backend, but our\n<a href=\"/2016/03/Managing-Frontend-in-the-microservices-architecture.html\">frontend architecture</a> also allows for components written in various\nlanguages. And besides customer-facing business code, there are also internal tools and utilities, sometimes written using yet other general-purpose languages\nand <a href=\"https://en.wikipedia.org/wiki/Domain-specific_language\">DSL</a>s. Finally, there‚Äôs the whole world of AI, including prompting for generative AI that you\ncan also consider a programming language of sorts.</p>\n\n<p>The main point I want to make here is that using microservices has allowed us to safely experiment with various programming languages, to consciously limit\nthe blast radius of those experiments should anything go wrong, and to perform all transitions gradually. Of course, this all has a purpose: finding the\nbest tool for the job, and using all the different languages‚Äô strengths where they can help us most. It is not about introducing new tools just for the sake\nof it, which would cause but chaos and introduce risks related to future maintenance. I think the autonomy teams get in making technical decisions, yet\ncombined with responsibility for the outcomes, is what allows us to learn and find new ways of doing things while at the same time it limits the risks\nassociated with experimenting. As in many other cases, things work well when the organization‚Äôs ways of working (team autonomy) are aligned with technical\nsolutions (microservices).</p>\n\n<h3 id=\"using-antipatterns-wisely\">Using antipatterns wisely</h3>\n\n<p><img src=\"/img/articles/2024-04-12-ten-years-microservices/alexander-schimmeck-kpihcevjT5w-unsplash.jpg\" alt=\"Two men performing a dangerous stunt on a bicycle\" class=\"small-image-right\" />\n<a href=\"/2016/01/microservices-and-macro-mistakes.html\">Good practices</a> are heuristics: most of the time, following them is a good idea. For example,\ntwo microservices should not share database tables since this introduces tight coupling: you can‚Äôt introduce a change to the schema and deploy just one service\nbut not the other. Your two services are not independent, but form a distributed monolith instead. Avoiding such situations is just common sense.</p>\n\n<p>Still, you should always keep in mind the reasons why a good practice exists, what it protects you from and what costs it introduces. At one point we had a\ndiscussion within our team about how to best handle a peculiar performance issue. Our service connected to an Elasticsearch instance and performed two kinds\nof operations: reads and writes. Reads were much more numerous, but writes introduced heavy load (on the service itself ‚Äî Elastic could handle it). Writes\ncame in bursts, so most of the time things worked well, but when a burst of writes arrived, performance of the whole service suffered and read times were\naffected. We tried various mechanisms for isolating the two kinds of operation, but couldn‚Äôt do it effectively.</p>\n\n<p>A colleague suggested we split the service in two, one responsible for handling reads and the other for writes. We had a long discussion, in which I\npresented arguments for having a single service as the owner of the data, responsible for both reads and writes, and highlighted what issues could arise due to\nthe split. While keeping the service intact seemed to be the elegant thing to do, I didn‚Äôt have a good solution for the performance issue. My colleague‚Äôs\nidea to split the service, on the other hand, while somewhat messy, did offer a chance to solve it.</p>\n\n<p>So, we decided to just try it and see whether this approach would solve the performance issue and how bad the side effects would be. We did just that, and the\nantipattern-based solution worked great: performance hiccups went away, and despite sharing the common Elasticsearch cluster, the two services remained\nmaintainable. We were not able to fully assess this aspect right away, but time proved my colleague right as well: during the 3+ years we worked with that\ncodebase later on, we only ran into issues related to sharing Elasticsearch once, and we managed to fix that case quickly. It certainly did help, though, that\nboth services kept being developed by the same team, and that by the time we introduced the split, the schema was already quite stable and did not change often.\nNonetheless, had I insisted on keeping things clean, we would have probably spent much more time fighting performance issues than we lost during the single\nissue that resulted from sharing Elasticsearch between services. Know when to use patterns, know when to use antipatterns, and use both wisely.</p>\n\n<h3 id=\"one-size-does-not-fit-all\">One size does not fit all</h3>\n\n<p><img src=\"/img/articles/2024-04-12-ten-years-microservices/brianna-r-_-54wJzpH6Q-unsplash.jpg\" alt=\"Adult lion with cub\" class=\"small-image-right\" />\nI think we‚Äôve always been quite pragmatic about sizing our microservices. It‚Äôs hard to define a set of specific rules for finding the right size, but going\ntoo far in one direction or the other causes considerable pain. Make a service huge, and it becomes too hard for a single team to maintain and develop, or\nscaling issues arise similar to those you could experience with a monolith. Make it very small, and you might get overwhelmed by the overhead of having your\nlogic split between too many places, issues with debugging, and the performance penalty of the system being distributed to the extreme.</p>\n\n<p>Most services I got to work on at Allegro were not too tiny, and contained some non-trivial amount of logic. There were sometimes agitated discussions about\nwhere to implement a certain feature, in particular whether it should be in an existing service or in a new one. In hindsight, I think most decisions made\nsense, but there were certainly cases where a feature that we believed would grow ended up in a new service which then never took off and remained too small,\nand cases where something was bolted onto an existing service because it was easier to implement this way, but which caused some pain later on.</p>\n\n<p>I think I only once saw a team fall into the nanoservice trap where services were designed so small the split caused more trouble than it was worth. On the\nother hand, there were certainly services which you could no longer call <em>micro</em> by any stretch. This was not necessarily a bad thing. As long as a service\nfulfilled a well-defined role, a single team was enough to take care of it, and it was OK that you had to deploy and scale the whole thing together, things\nwere fine. In some cases of services which grew really much too big (indicators being that they contained pieces of logic only very loosely related to each\nother, and that at some point multiple teams were regularly interested in contributing), we did get back to them and split them up. It was not very easy,\nbut doable, and the second-hardest part was usually finding the right lines along which to divide. The only thing harder was finding the time to perform\nsuch operations, but with a bit of negotiation and persistence, after a while we usually succeeded.</p>\n\n<p>There is an ongoing discussion of whether we have too many microservices. It‚Äôs not an urgent thing, but there are reasons to not go too high, such as\ncertain technical limitations in the infrastructure and the cost of overprovisioning (each service allocates resources such as memory or CPUs with a margin,\nand those margins add up). Still, the fact that we are well above a thousand services and yet their number is only a minor nuisance, speaks well of our\ntooling and organization. Indeed, thanks to some custom tools, creating a new service is very easy (maybe too easy?), and managing those already there is\nalso quite pleasant. This is possible due to huge investments we made early on (and continue): we knew right from the start that while each microservice may\nbe relatively simple, a lot of complexity goes into the glue that holds the whole system together. Without it, things would not quite work so well. Another\nfactor is, obviously, that our system has an actual use case for microservices: we have hundreds of teams, a system that keeps growing in capacity and\ncomplexity, and scale that makes a truly distributed system necessary. I think much of the anti-microservice sentiment you see around the internet today\nstems from treating microservices as a silver bullet that you can apply to any problem regardless of whether they actually make sense in given situation, or\nfrom not being aware that they can bring huge payoffs but also require great investments. There is a good summary of the advantages and disadvantages of\nmicroservices <a href=\"https://about.gitlab.com/blog/2022/09/29/what-are-the-benefits-of-a-microservices-architecture/\">in this Gitlab blog post</a>.</p>\n\n<h3 id=\"service-mesh-and-common-libraries\">Service Mesh and common libraries</h3>\n\n<p><img src=\"/img/articles/2024-04-12-ten-years-microservices/nasa-Q1p7bh3SHj8-unsplash.jpg\" alt=\"City lights visible from space\" class=\"small-image-right\" />\nProbably the most recent really significant change related to our microservice ecosystem was the <a href=\"/2020/05/migrating-to-service-mesh.html\">migration to service mesh</a>.\nFrom developers‚Äô perspective it did not seem all that radical, but it required a lot of work from infrastructure teams. The most important gain is the\npossibility to control some aspects of services‚Äô behavior in a single place. For example, originally if you wanted to have secure connections between\nservices, you had to support <a href=\"https://en.wikipedia.org/wiki/Transport_Layer_Security\">TLS</a> in code, using common libraries. With service mesh, you can just\nenable it globally without the developers even having to know. This makes maintaining the huge ecosystem that consists of more than a thousand services much\nmore bearable.</p>\n\n<p>Each microservice needs certain behaviors in order to work well within our environment. For example, it needs a healthcheck endpoint which allows Kubernetes\nto tell if the service instance is working or not. We have a written Microservice Contract which defines those requirements. There are also features that are\nnot strictly necessary, but which many services will find useful, for example various metrics. Our initial approach was to have a set of common libraries\nthat provided both the required and many of the nice-to-have features. Of course, if you can‚Äôt or don‚Äôt want to use those libraries, you are free to do so, as\nlong as your service implements the Microservice Contract some other way.</p>\n\n<p>Over time, the role of those libraries has changed, with the general direction being that of reducing their scope. There are several reasons.</p>\n\n<p>Reason number one is more and more features can be moved to infrastructure layer, of which Service Mesh is an important part. For example, originally\ncommunicating with another service required a service discovery client, implemented in a shared library.  Now, all this logic has been delegated to the\nService Mesh and requires no special support in shared libraries or service code.</p>\n\n<p>Another reason is that open source libraries have caught on and some features we used to need to implement ourselves, such as certain metrics, are now\navailable out of the box in Spring Boot or other frameworks. There is no point in reinventing the wheel and having more code to maintain.</p>\n\n<p>Finally, the problem with libraries is that updating a library in 1000+ services is a slow and costly process. Meanwhile, a feature that the Service Mesh\nprovides can be switched on or reconfigured for all services almost instantly.</p>\n\n<p>Despite common libraries falling out of favor with us, there are some features that are hard to implement in infrastructure alone. Even with a simple\nfeature such as logging, sometimes we need data that only code running within the services has access to. When we want to fill in certain standard fields in\norder to make searching logs easier, some fields, such as <code class=\"language-plaintext highlighter-rouge\">host</code> or <code class=\"language-plaintext highlighter-rouge\">dc</code>, can easily be filled in by the infrastructure, but some, such as <code class=\"language-plaintext highlighter-rouge\">thread_name</code> are\nonly known inside the service and can‚Äôt be handled externally. Thus, the role of libraries is diminished but not completely eliminated. In order to make\nworking with shared libraries less cumbersome, we are working on ways to automate upgrades as much as possible so that we can keep all versions up to date\nwithout it costing too much developers‚Äô time.</p>\n\n<h3 id=\"learning\">Learning</h3>\n\n<p><img src=\"/img/articles/2024-04-12-ten-years-microservices/thought-catalog-mmWqrsjZ4Lw-unsplash.jpg\" alt=\"Person reading\" class=\"small-image-right\" />\nDuring the transition, Allegro invested in learning and development heavily. Daily work was full of learning opportunities since everything we were doing\nwas quite new, and many approaches and technologies were not mature yet. We were really on the cutting edge of technology, so for many problems there were\nsimply no run-of-the-mill solutions yet. We were already several years into the microservice transition when microservices became a global hype.</p>\n\n<p>Since everybody was well aware of what an ambitious plan we were pursuing, it was also well understood that some things took experimenting, and while of\ncourse we were expected to ship value, there was a company-wide understanding that time for learning, <a href=\"/2019/09/team-tourism-at-allegro.html\">team tourism</a>,\ntrying out new things, and sometimes failing, were necessary for success. One of the things I really enjoyed was the focus on quality and doing things right.\nBusiness understood this as well, and actually at one point when Rubicon was quite advanced, developers were granted a 6-month grace period during which we\ncould focus on just technical changes without having to deliver any business value. As a matter of fact, many business logic changes were delivered anyway. For\nexample, the team I was on created a microservice-based approach to handling payments which was much more flexible than the old solution, so it was not just a\nrefactoring, but rather a rewrite that took new business requirements into account.</p>\n\n<p>Apart from learning by doing, we also invested in organized training and conferences. We bought a number of dedicated training sessions with\n<a href=\"/2015/07/it-stars.html\">established experts</a> from Silicon Valley on topics such as software architecture and JVM performance. Pretty much\neveryone could attend at least one good conference each year, and we also sponsored a number of developer-centric events in order to gain visibility and attract\ngood hires. About a year into my job, I got to attend JavaOne in San Francisco, whose scale and depth trumped even the biggest conferences I knew from Europe.\nAfter attending a few conferences, I decided to give speaking myself a try, and was able to take advantage of a number of useful trainings to help me with that.\nWe also started the <a href=\"https://allegro.tech/\">allegro.tech</a> initiative in order to organize all the activity used to promote our brand, and this blog is one\nof the projects that we run under the allegro.tech umbrella to this day.</p>\n\n<h3 id=\"the-cycle-of-life\">The cycle of life</h3>\n\n<p>In 2022, a service I had worked on when I first started at Allegro was shut down due to being replaced with a newer solution. This way, I witnessed the\nfull lifecycle of a service: building it from scratch, adding more features to the mature solution, maintenance, and finally seeing it discontinued. It was\nreally a great experience to see that something I had built had run its course and I could be there to see the whole cycle.</p>\n\n<h2 id=\"takeaways\">Takeaways</h2>\n\n<p><img src=\"/img/articles/2024-04-12-ten-years-microservices/pyramids.jpg\" alt=\"Pyramids of Egypt\" class=\"small-image-right\" />\nWhen we started out working with microservices, we were well aware of their benefits but also of their cost. The famous\n<a href=\"https://martinfowler.com/bliki/MicroservicePrerequisites.html\">You must be this tall to use microservices</a> image adorned many of our presentations at that\ntime. By taking a realistic stance, we avoided many pitfalls. Our transition to the microservice world took several years, but was successful, and I am\ncertain we would be in a much worse place had the company not made that bold decision. Apart from being a huge technical challenge, it was also a great\ntransformation in our way of thinking and in the way we work together. <a href=\"https://en.wikipedia.org/wiki/Conway%27s_law\">Conway‚Äôs Law</a> applies and the change\nin system architecture was possible only together with a change in company architecture. It was also possible thanks to many smart people with whom I had\nthe pleasure to work over these years.</p>\n\n<p>When I look back, I see how far we have come. Creating a new service used to take a week or two at first, and now it takes minutes. Scaling a service required\na human operator, creating virtual machines, and manually adding them to the monitoring system. Today, an autoscaler handles most services and developers\ndo not even need to know that instances were added or removed. Our tooling is really convenient, even though there are things we could improve, and some\ncomponents are already showing signs of aging. Nonetheless, many things that used to be a challenge, are trivial today. New joiners at the company can\nbenefit from all these conveniences right from the start, and sometimes I think they might not fully appreciate them since they never had to perform all\nthat work manually.</p>\n\n<p>The world does not stand still, though. Technologies change, and some assumptions we made when planning our architecture ten years ago, have already had to\nbe updated. Our system has grown, and so has the company, so many issues we are dealing with now are different from those that troubled us in the beginning\nof Project Rubicon. Initially, everything was a greenfield project, but by now, some places have accumulated bit rot and need cleanup. The system is much\nbigger (which microservices enabled) so introducing changes gets harder (still, much easier than it would be within a monolith). And since ten\nyears is a lot of time, many people have moved through the company, so <a href=\"/2023/10/battle-against-knowledge-loss.html\">knowledge transfer and continued learning</a>\nare still essential. Only change is certain, and this has not changed a bit. I‚Äôm happy I could experience the heroic age of microservices myself, and I‚Äôm\nlooking forward to whatever comes next.</p>\n","contentSnippet":"In early 2024, I hit ten years at Allegro, which also happens to be how long I‚Äôve been working with microservices.\nThis timespan also roughly corresponds to how long the company as a whole has been using them, so I think it‚Äôs a good time to outline the story of project\nRubicon: a very ambitious gamble which completely changed how we work and what our software is like. The idea probably seemed rather extreme at the time, yet I\nam certain that without this change, Allegro would not be where it is today, or perhaps would not be there at all.\nBackground\nAllegro is one of the largest e-commerce sites in Central Europe, with 20 million users and over 300 million\noffers. It was founded in 1999, originally with just the Polish market in mind. The story I want to tell you starts in 2013, a year before I joined.\n\nIn 2013, the site was already large and relevant, but its commercial success and further growth led to development bottlenecks emerging. The codebase was a\nmonolithic PHP application, with some auxiliary processes written in C. Checked out, the git monorepo weighed about 2 GB, and the number of pull requests\nproduced daily by a few hundred developers was so large that if you started a new branch in the morning, you were almost sure to get some conflicts if you\nwanted to merge in the afternoon. The system was centered around a single, huge database, with all the performance and architectural challenges you can imagine.\nTests were brittle and took ages to finish. Deployment was a mostly manual and thus time-consuming processes that required lots of attention and ran the risk of\ncausing a serious problem in production if something went wrong. It was so demanding and stressful I still remember my team having to run the deployment once\n(in place of the usual deployers) as a big event.\nRubicon Rises\n\nIt was becoming clear that we would hit a wall if we continued working this way. So, around 2012/2013, the idea for a complete overhaul of the architecture\nstarted to emerge. We began experimenting with SOA (Service-Oriented Architecture) by\ncreating a small side project, the so-called New Platform, in PHP, as a proof-of-concept. We also decided we would start doing\nAgile, TDD, and\nCloud. After a short while, on top of this, we decided to switch to Java for backend development.\nIt was becoming clear that it would be a revolution indeed, requiring everyone to change\nthe way they worked, and to switch out the whole development ecosystem, starting with the core programming language. Once we got this going, there would be\nno turning back, so a matching name also appeared: Project Rubicon.\nThe project had such a broad scope that it even came with its own constitution, a set of high-level guidelines to be used in case of doubt. It focused mostly\non ways of working and highlighted the value of learning (on personal, team, and company level), testing, reuse, empirical approach to software development,\nand active participation in the open-source community both as users and as contributors. Specific technical assumptions included:\nfocus on quality\nmicroservices\ndistributed, multi-regional, active-active architecture\nJava\ncloud deployment\nusing open-source technologies\nThere was also a list of success criteria for the project:\nthe monolith is gone\nwe have Java gurus on board\nwe have services\ndevelopment is faster\nwe have continuous delivery\nwe don‚Äôt have another monolith\nwe still make money\nFaster development was probably the most important goal, since slow delivery was the direct reason we embarked on this long journey.\nOn top of these lists, more detailed plans were made as well, of course. For example, various parts of the system were prioritized for moving out of the\nmonolith as we were well aware we would not be able to work on everything at once. Being Agile does not mean planning is to be avoided, only that plans have\nto be flexible. So, armed with a plan, we got off to work.\nExecution\n\nToo much has happened during the 10+ years to report here. The initial period was really frantic since we had to set up everything, and, first of all, teams had\nto switch to a new mindset. This was also a period of intense hiring, and the time I joined the recently opened office in Warsaw. Microservices were at that\ntime only starting to gain traction, so while we used the experiences of others as much has possible, we had to learn many things ourselves, sometimes learning\nthem the hard way.\nTo give you an idea of the pace, here are just some of the things that happened in 2013:\noutline of the common architecture (service discovery, logging) created\na set of common libraries created (presentation from 2016)\ntraining in Java and JVM for PHP developers\nrecruitment of Java developers started\nfirst Java code got written\nfierce discussions about technology choices (Guice vs Spring, Maven vs Gradle, Jetty vs Undertow)\nWhat followed in 2014 (this is the part I could already experience in person):\nvarious self-service tools allowing developers to handle common tasks such as creating databases themselves rather than by involving specialized support teams\nautomation tools\ndevelopment of Hermes, our open-source message broker built on top of Kafka, started\nstrategic DDD training with Eric Evans\nmigration to Java 8\nglobal architecture improvements\nallegro.tech, the project to coordinate the visibility of our tech division online and offline, of which this blog is a part,\nstarted\nSRE team created\nCQK (Code Quality Keepers) guild opened\nfirst Java services deployed to production\nintense recruitment and learning\nThe number of both production services and of tools supporting developers‚Äô work that got created thereafter is staggering. It should be clear from just the\nlist above that this was a huge investment, and could only proceed due to full buy-in of both technology and business parts of the company. It was indeed a\ngamble, well-informed, but still a gamble that carried big risk should it fail, but an even greater risk if we were to stay with the old architecture.\nAt this point you probably can see that actually building microservices seems like a minor part of the whole undertaking. There was a lot of work to\nwriting so many parts of this huge system anew, but indeed the amount of work that we had to invest into\ninfrastructure,\ntooling, and\nlearning, was immense. It was also absolutely critical for the project‚Äôs success. A lot has been\nsaid about microservices, and it is true that for them to be beneficial, you need the right scale and the right kind of system. We had both, and so the decision\nto move to microservices proved to be worthwhile, but despite knowing the theory, I think no one expected the amount of auxiliary work to be so huge. Indeed,\nwhile microservices themselves may be simple, the glue that holds them together is not.\nFlashbacks\nSummarizing ten years of rapid development is tough, so instead of trying to tell you the full story, I decided to share a few flashbacks: moments which I\nremembered for one reason or another.\nNo-ing SQL\n\nWhen refactoring our huge monolith into smaller microservices, we needed to also choose the\ndatabase to use for each of them. Since horizontal scalability was our focus, we preferred NoSQL databases when possible.\nThis was a big change since the monolithic solution relied on a single, huge SQL database. On top of that, it was not modularized well, and in many places\nthere was little or no separation between domain and persistence layers. If the monolith was structured well, splitting it into separate services would have\nbeen much easier. Unfortunately, this was not the case, so we had to perform the transition to NoSQL together with other refactorings and cleanup. Usually,\nwe had to deeply remodel data and operations handling it, especially transactional, so that they could be executed in the new environment. This was often\na significant effort even if we could divide the code in such way that the transaction or set of related operations ended up within the same service. Things\nbecame even more complicated if an operation spanned multiple services (and databases) in the new architecture. This is one of the reasons why dividing a\nbig application into smaller chunks is much harder than it may seem at first.\nCassandra was initially our preferred NoSQL database for most tasks. Only after a while did we learn that each database is good\nfor some use cases and bad for others, and that we needed polyglot persistence to achieve high performance\nand get the required flexibility in all cases. The team I worked on was among the first Cassandra adopters at the company, and as is often the case when\nyou run something in production for the first time, we uncovered a number of issues in our Cassandra deployment which was ‚Äúready‚Äù but not tested in production\nyet. The team responsible for the DB was learning completely new stuff just as we were.\nAn argument sometimes put up against the need to separate your application‚Äôs persistence layer from the domain logic is ‚Äúyou‚Äôre never going to switch out the\nDB for another one anyway‚Äù. Most of the time that‚Äôs true, but in one service we did have to switch from Cassandra to MongoDB\nafter we found out our access patterns were not very well aligned with Cassandra‚Äôs data model. We managed to do it inside a single two-week sprint, and\napart from the service becoming faster, its clients would not notice any difference as the external API stayed the same. While the (usually theoretical)\nprospect of switching databases is not the only reason for decoupling domain and persistence layers, it did help a lot in this case, and it is about this\ntime I started to understand why we were creating so many classes even though you could just cram all that code into one.\nI also managed to kill our Cassandra instance once when I was learning about big data processing and created a job that was supposed to process some data from\nthe DB. The job was so massively parallel that the barrage of requests it generated overwhelmed even Cassandra. Fortunately, this situation also showed the\nadvantage of having separate databases for each service, as only that single service experienced an outage.\nInto the cloud\n\nBefore joining Allegro, I had only deployed to physical servers, so moving to the cloud was a big change. At first, we deployed our services to virtual\nmachines configured in OpenStack. What a convenience it was to be able to just set up a complete virtual server with a few\nclicks rather than wait days for a physical machine. We used Puppet to fully configure the virtual machines for each service, so\nwhile you had to write some configuration once, you could spin up a new server configured for your service almost instantly afterwards.\nThis IaaS (Infrastructure as a Service) approach was very convenient, and quite a change, but in\nmany ways it still resembled what I had known before: you had a machine, even if virtual, and you could ssh and run any commands there if you wanted, even\nif it was rarely needed since Puppet set up everything for you.\nThe real revolution came when we switched to PaaS (Platform as a Service) model, at that time based on\nMesos and Marathon. Suddenly, there were no more virtual machines, and you could not ssh\nto the server where your software was running. For me, this was a real culture shock, and even though up to this point I was very enthusiastic about all the\ncool technology we were introducing, the thought of no more ssh freaked me out. How would I know what was going on in the system if I couldn‚Äôt even access\nit? Despite my reservations, I gradually found out you could indeed deploy and monitor software despite not being able to access the machine via ssh. It\nsounds weird in retrospect, but this was one of the most difficult technological transitions in my career.\nAfter a while, we built some abstraction layers on top of Mesos, including a custom app console that allows you to deploy a service and perform all\nmaintenance tasks. It isolates you from most details of the underlying system, and is so effective that when we migrated from Mesos to Kubernetes\nlater on, the impact on most teams was much smaller that you could imagine for such a big change. Our App Console is an internal project, but if you are\nfamiliar with Backstage, it should give you an idea of what kind\nof tool we‚Äôre talking about here.\nMonitoring\n\nBelieve it or not, initially all monitoring was centralized and handled by a single team. If you wanted to have any non-standard charts in\nZabbix or any custom alerts (and obviously, you wanted to), you had to create a ticket in JIRA, describe exactly what you wanted,\nand after a while, the monitoring team would set it up for you. The whole process took about a week, and quite often, right after seeing the new chart you\nknew you wanted to improve it, so you would file another ticket and wait another week. Needless to say, this was incredibly frustrating, and I consider it\none of my early big successes when I kept pushing the monitoring team until they finally gave in and allowed development teams to configure all of their\nobservability settings themselves.\nGoing polyglot\n\nWhile Rubicon started out with the premise of rewriting our software in Java, we quickly started experimenting with other JVM languages. The team I worked\non considered Scala for a while, but after some experimentation decided against using it as our main language. Some other teams, however, did choose it, and\neven though they are a minority at Allegro, we have some microservices written in Scala to this day. On the other hand, Scala is the dominant language at\nAllegro when it comes to writing Spark jobs.\nSome time around 2015, a teammate found out there was a relatively new, but promising, language called Kotlin. It so happened that we\nwere just starting work on a new microservice which was still very simple and not quite critical. He decided to use it as a testbed, and within I think two days\nrewrote the whole thing in Kotlin. Thanks to the services being independent and this one not being very important yet, we could safely experiment in production\nand assess the stability of the rewritten service. Learning the language by writing actual production-ready code rather than just playing with throw-away code\nallowed us to check what advantages and disadvantages the language offered under realistic usage scenarios. Kotlin caught on, and gradually we started to use\nit for more and more new services and to use it for new features in existing Java services as mixing the two was easy. Many services already used\nGroovy and Spock for tests anyway. At this point, Kotlin is more popular than Java at Allegro, and\non our blog we published some articles about Kotlin,\nincluding one which unfortunately stirred a lot of controversy, and caused a (deserved IMO)\nshitstorm both inside and outside the company.\nBesides JVM languages, we by now have also microservices written in C#,\nGo, Python,\nElixir, and probably a few more languages I forgot to mention. This is just the backend, but our\nfrontend architecture also allows for components written in various\nlanguages. And besides customer-facing business code, there are also internal tools and utilities, sometimes written using yet other general-purpose languages\nand DSLs. Finally, there‚Äôs the whole world of AI, including prompting for generative AI that you\ncan also consider a programming language of sorts.\nThe main point I want to make here is that using microservices has allowed us to safely experiment with various programming languages, to consciously limit\nthe blast radius of those experiments should anything go wrong, and to perform all transitions gradually. Of course, this all has a purpose: finding the\nbest tool for the job, and using all the different languages‚Äô strengths where they can help us most. It is not about introducing new tools just for the sake\nof it, which would cause but chaos and introduce risks related to future maintenance. I think the autonomy teams get in making technical decisions, yet\ncombined with responsibility for the outcomes, is what allows us to learn and find new ways of doing things while at the same time it limits the risks\nassociated with experimenting. As in many other cases, things work well when the organization‚Äôs ways of working (team autonomy) are aligned with technical\nsolutions (microservices).\nUsing antipatterns wisely\n\nGood practices are heuristics: most of the time, following them is a good idea. For example,\ntwo microservices should not share database tables since this introduces tight coupling: you can‚Äôt introduce a change to the schema and deploy just one service\nbut not the other. Your two services are not independent, but form a distributed monolith instead. Avoiding such situations is just common sense.\nStill, you should always keep in mind the reasons why a good practice exists, what it protects you from and what costs it introduces. At one point we had a\ndiscussion within our team about how to best handle a peculiar performance issue. Our service connected to an Elasticsearch instance and performed two kinds\nof operations: reads and writes. Reads were much more numerous, but writes introduced heavy load (on the service itself ‚Äî Elastic could handle it). Writes\ncame in bursts, so most of the time things worked well, but when a burst of writes arrived, performance of the whole service suffered and read times were\naffected. We tried various mechanisms for isolating the two kinds of operation, but couldn‚Äôt do it effectively.\nA colleague suggested we split the service in two, one responsible for handling reads and the other for writes. We had a long discussion, in which I\npresented arguments for having a single service as the owner of the data, responsible for both reads and writes, and highlighted what issues could arise due to\nthe split. While keeping the service intact seemed to be the elegant thing to do, I didn‚Äôt have a good solution for the performance issue. My colleague‚Äôs\nidea to split the service, on the other hand, while somewhat messy, did offer a chance to solve it.\nSo, we decided to just try it and see whether this approach would solve the performance issue and how bad the side effects would be. We did just that, and the\nantipattern-based solution worked great: performance hiccups went away, and despite sharing the common Elasticsearch cluster, the two services remained\nmaintainable. We were not able to fully assess this aspect right away, but time proved my colleague right as well: during the 3+ years we worked with that\ncodebase later on, we only ran into issues related to sharing Elasticsearch once, and we managed to fix that case quickly. It certainly did help, though, that\nboth services kept being developed by the same team, and that by the time we introduced the split, the schema was already quite stable and did not change often.\nNonetheless, had I insisted on keeping things clean, we would have probably spent much more time fighting performance issues than we lost during the single\nissue that resulted from sharing Elasticsearch between services. Know when to use patterns, know when to use antipatterns, and use both wisely.\nOne size does not fit all\n\nI think we‚Äôve always been quite pragmatic about sizing our microservices. It‚Äôs hard to define a set of specific rules for finding the right size, but going\ntoo far in one direction or the other causes considerable pain. Make a service huge, and it becomes too hard for a single team to maintain and develop, or\nscaling issues arise similar to those you could experience with a monolith. Make it very small, and you might get overwhelmed by the overhead of having your\nlogic split between too many places, issues with debugging, and the performance penalty of the system being distributed to the extreme.\nMost services I got to work on at Allegro were not too tiny, and contained some non-trivial amount of logic. There were sometimes agitated discussions about\nwhere to implement a certain feature, in particular whether it should be in an existing service or in a new one. In hindsight, I think most decisions made\nsense, but there were certainly cases where a feature that we believed would grow ended up in a new service which then never took off and remained too small,\nand cases where something was bolted onto an existing service because it was easier to implement this way, but which caused some pain later on.\nI think I only once saw a team fall into the nanoservice trap where services were designed so small the split caused more trouble than it was worth. On the\nother hand, there were certainly services which you could no longer call micro by any stretch. This was not necessarily a bad thing. As long as a service\nfulfilled a well-defined role, a single team was enough to take care of it, and it was OK that you had to deploy and scale the whole thing together, things\nwere fine. In some cases of services which grew really much too big (indicators being that they contained pieces of logic only very loosely related to each\nother, and that at some point multiple teams were regularly interested in contributing), we did get back to them and split them up. It was not very easy,\nbut doable, and the second-hardest part was usually finding the right lines along which to divide. The only thing harder was finding the time to perform\nsuch operations, but with a bit of negotiation and persistence, after a while we usually succeeded.\nThere is an ongoing discussion of whether we have too many microservices. It‚Äôs not an urgent thing, but there are reasons to not go too high, such as\ncertain technical limitations in the infrastructure and the cost of overprovisioning (each service allocates resources such as memory or CPUs with a margin,\nand those margins add up). Still, the fact that we are well above a thousand services and yet their number is only a minor nuisance, speaks well of our\ntooling and organization. Indeed, thanks to some custom tools, creating a new service is very easy (maybe too easy?), and managing those already there is\nalso quite pleasant. This is possible due to huge investments we made early on (and continue): we knew right from the start that while each microservice may\nbe relatively simple, a lot of complexity goes into the glue that holds the whole system together. Without it, things would not quite work so well. Another\nfactor is, obviously, that our system has an actual use case for microservices: we have hundreds of teams, a system that keeps growing in capacity and\ncomplexity, and scale that makes a truly distributed system necessary. I think much of the anti-microservice sentiment you see around the internet today\nstems from treating microservices as a silver bullet that you can apply to any problem regardless of whether they actually make sense in given situation, or\nfrom not being aware that they can bring huge payoffs but also require great investments. There is a good summary of the advantages and disadvantages of\nmicroservices in this Gitlab blog post.\nService Mesh and common libraries\n\nProbably the most recent really significant change related to our microservice ecosystem was the migration to service mesh.\nFrom developers‚Äô perspective it did not seem all that radical, but it required a lot of work from infrastructure teams. The most important gain is the\npossibility to control some aspects of services‚Äô behavior in a single place. For example, originally if you wanted to have secure connections between\nservices, you had to support TLS in code, using common libraries. With service mesh, you can just\nenable it globally without the developers even having to know. This makes maintaining the huge ecosystem that consists of more than a thousand services much\nmore bearable.\nEach microservice needs certain behaviors in order to work well within our environment. For example, it needs a healthcheck endpoint which allows Kubernetes\nto tell if the service instance is working or not. We have a written Microservice Contract which defines those requirements. There are also features that are\nnot strictly necessary, but which many services will find useful, for example various metrics. Our initial approach was to have a set of common libraries\nthat provided both the required and many of the nice-to-have features. Of course, if you can‚Äôt or don‚Äôt want to use those libraries, you are free to do so, as\nlong as your service implements the Microservice Contract some other way.\nOver time, the role of those libraries has changed, with the general direction being that of reducing their scope. There are several reasons.\nReason number one is more and more features can be moved to infrastructure layer, of which Service Mesh is an important part. For example, originally\ncommunicating with another service required a service discovery client, implemented in a shared library.  Now, all this logic has been delegated to the\nService Mesh and requires no special support in shared libraries or service code.\nAnother reason is that open source libraries have caught on and some features we used to need to implement ourselves, such as certain metrics, are now\navailable out of the box in Spring Boot or other frameworks. There is no point in reinventing the wheel and having more code to maintain.\nFinally, the problem with libraries is that updating a library in 1000+ services is a slow and costly process. Meanwhile, a feature that the Service Mesh\nprovides can be switched on or reconfigured for all services almost instantly.\nDespite common libraries falling out of favor with us, there are some features that are hard to implement in infrastructure alone. Even with a simple\nfeature such as logging, sometimes we need data that only code running within the services has access to. When we want to fill in certain standard fields in\norder to make searching logs easier, some fields, such as host or dc, can easily be filled in by the infrastructure, but some, such as thread_name are\nonly known inside the service and can‚Äôt be handled externally. Thus, the role of libraries is diminished but not completely eliminated. In order to make\nworking with shared libraries less cumbersome, we are working on ways to automate upgrades as much as possible so that we can keep all versions up to date\nwithout it costing too much developers‚Äô time.\nLearning\n\nDuring the transition, Allegro invested in learning and development heavily. Daily work was full of learning opportunities since everything we were doing\nwas quite new, and many approaches and technologies were not mature yet. We were really on the cutting edge of technology, so for many problems there were\nsimply no run-of-the-mill solutions yet. We were already several years into the microservice transition when microservices became a global hype.\nSince everybody was well aware of what an ambitious plan we were pursuing, it was also well understood that some things took experimenting, and while of\ncourse we were expected to ship value, there was a company-wide understanding that time for learning, team tourism,\ntrying out new things, and sometimes failing, were necessary for success. One of the things I really enjoyed was the focus on quality and doing things right.\nBusiness understood this as well, and actually at one point when Rubicon was quite advanced, developers were granted a 6-month grace period during which we\ncould focus on just technical changes without having to deliver any business value. As a matter of fact, many business logic changes were delivered anyway. For\nexample, the team I was on created a microservice-based approach to handling payments which was much more flexible than the old solution, so it was not just a\nrefactoring, but rather a rewrite that took new business requirements into account.\nApart from learning by doing, we also invested in organized training and conferences. We bought a number of dedicated training sessions with\nestablished experts from Silicon Valley on topics such as software architecture and JVM performance. Pretty much\neveryone could attend at least one good conference each year, and we also sponsored a number of developer-centric events in order to gain visibility and attract\ngood hires. About a year into my job, I got to attend JavaOne in San Francisco, whose scale and depth trumped even the biggest conferences I knew from Europe.\nAfter attending a few conferences, I decided to give speaking myself a try, and was able to take advantage of a number of useful trainings to help me with that.\nWe also started the allegro.tech initiative in order to organize all the activity used to promote our brand, and this blog is one\nof the projects that we run under the allegro.tech umbrella to this day.\nThe cycle of life\nIn 2022, a service I had worked on when I first started at Allegro was shut down due to being replaced with a newer solution. This way, I witnessed the\nfull lifecycle of a service: building it from scratch, adding more features to the mature solution, maintenance, and finally seeing it discontinued. It was\nreally a great experience to see that something I had built had run its course and I could be there to see the whole cycle.\nTakeaways\n\nWhen we started out working with microservices, we were well aware of their benefits but also of their cost. The famous\nYou must be this tall to use microservices image adorned many of our presentations at that\ntime. By taking a realistic stance, we avoided many pitfalls. Our transition to the microservice world took several years, but was successful, and I am\ncertain we would be in a much worse place had the company not made that bold decision. Apart from being a huge technical challenge, it was also a great\ntransformation in our way of thinking and in the way we work together. Conway‚Äôs Law applies and the change\nin system architecture was possible only together with a change in company architecture. It was also possible thanks to many smart people with whom I had\nthe pleasure to work over these years.\nWhen I look back, I see how far we have come. Creating a new service used to take a week or two at first, and now it takes minutes. Scaling a service required\na human operator, creating virtual machines, and manually adding them to the monitoring system. Today, an autoscaler handles most services and developers\ndo not even need to know that instances were added or removed. Our tooling is really convenient, even though there are things we could improve, and some\ncomponents are already showing signs of aging. Nonetheless, many things that used to be a challenge, are trivial today. New joiners at the company can\nbenefit from all these conveniences right from the start, and sometimes I think they might not fully appreciate them since they never had to perform all\nthat work manually.\nThe world does not stand still, though. Technologies change, and some assumptions we made when planning our architecture ten years ago, have already had to\nbe updated. Our system has grown, and so has the company, so many issues we are dealing with now are different from those that troubled us in the beginning\nof Project Rubicon. Initially, everything was a greenfield project, but by now, some places have accumulated bit rot and need cleanup. The system is much\nbigger (which microservices enabled) so introducing changes gets harder (still, much easier than it would be within a monolith). And since ten\nyears is a lot of time, many people have moved through the company, so knowledge transfer and continued learning\nare still essential. Only change is certain, and this has not changed a bit. I‚Äôm happy I could experience the heroic age of microservices myself, and I‚Äôm\nlooking forward to whatever comes next.","guid":"https://blog.allegro.tech/2024/04/ten-years-microservices.html","categories":["tech","microservices","architecture"],"isoDate":"2024-04-11T22:00:00.000Z"}],"jobs":[{"id":"743999992897540","name":"Senior Salesforce Software Engineer","uuid":"67fc7792-34c0-436c-84b1-c9591bebd80d","jobAdId":"274a39ab-ebda-4c9c-a9bd-5cd21a08a275","defaultJobAd":false,"refNumber":"REF4747J","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2024-06-07T12:50:10.755Z","location":{"city":"Warsaw","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572770","label":"IT - Software Development"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"id":"permanent","label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"61583054f15cea434e0be36f","fieldLabel":"Career Level","valueId":"26b58095-3c5f-4596-937f-27547fb80b07","valueLabel":"5"},{"fieldId":"61582f70e72a6b6d239c9857","fieldLabel":"Area","valueId":"76599a72-f283-4550-9303-52e2e0eb6e32","valueLabel":"Technology"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Recruitment Process","valueId":"ed4682c7-33c9-41c2-8d13-428ed39046f5","valueLabel":"Tech. Engineer - IC"},{"fieldId":"6406f92e638cbb2f415a94a9","fieldLabel":"Job Area","valueId":"e8731ea4-48a9-476d-ab1d-9a40eb3426f1","valueLabel":"Technology"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572770","valueLabel":"IT - Software Development"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro sp. z o.o."}],"visibility":"PUBLIC","ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999992897540","creator":{"name":"Agnieszka Adamus"},"language":{"code":"pl","label":"Polish","labelNative":"polski"}},{"id":"743999992876847","name":"Contractor Software Engineer (.NET)","uuid":"3ff8aa35-5b50-401c-8227-be2571d931e9","jobAdId":"9e43a9f2-2e7e-4fe5-9fe7-4fa136bc8257","defaultJobAd":true,"refNumber":"REF5027W","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2024-06-07T11:26:33.683Z","location":{"city":"Warsaw, Cracow","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572770","label":"IT - Software Development"},"function":{"id":"engineering","label":"Engineering"},"typeOfEmployment":{"id":"contract","label":"Contract"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"61583054f15cea434e0be36f","fieldLabel":"Career Level","valueId":"3c97f53f-19c2-4a25-9eb1-513f9fb38b80","valueLabel":"3-5"},{"fieldId":"61582f70e72a6b6d239c9857","fieldLabel":"Area","valueId":"76599a72-f283-4550-9303-52e2e0eb6e32","valueLabel":"Technology"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Recruitment Process","valueId":"e543c79f-6df9-499f-8ba8-237c3c331cc1","valueLabel":"NEW B2B Technology CL 1-6"},{"fieldId":"6406f92e638cbb2f415a94a9","fieldLabel":"Job Area","valueId":"e8731ea4-48a9-476d-ab1d-9a40eb3426f1","valueLabel":"Technology"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572770","valueLabel":"IT - Software Development"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"f7af19b5-5d6a-43a0-9a2b-1e99277515c7","valueLabel":"Opennet.pl Sp. z o.o."}],"visibility":"PUBLIC","ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999992876847","creator":{"name":"Martyna Stafa"},"language":{"code":"en-GB","label":"English (UK)","labelNative":"English (UK)"}},{"id":"743999992540561","name":"Junior Front-End Software Engineer - Ads","uuid":"31462660-1808-4114-b6f4-d1cda059e325","jobAdId":"fb5b74ad-85c4-4ae6-b670-a68bf6e5b18a","defaultJobAd":true,"refNumber":"REF4981A","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2024-06-06T07:30:17.155Z","location":{"city":"Warsaw","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572770","label":"IT - Software Development"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"id":"permanent","label":"Full-time"},"experienceLevel":{"id":"associate","label":"Associate"},"customField":[{"fieldId":"61583054f15cea434e0be36f","fieldLabel":"Career Level","valueId":"3976147c-fe25-42a8-8c97-78273250960b","valueLabel":"4"},{"fieldId":"61582f70e72a6b6d239c9857","fieldLabel":"Area","valueId":"76599a72-f283-4550-9303-52e2e0eb6e32","valueLabel":"Technology"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Recruitment Process","valueId":"b3da614a-1ddb-441b-a557-5acfdb6fcb90","valueLabel":"NEW Technology CL 1-6"},{"fieldId":"6406f92e638cbb2f415a94a9","fieldLabel":"Job Area","valueId":"e8731ea4-48a9-476d-ab1d-9a40eb3426f1","valueLabel":"Technology"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572770","valueLabel":"IT - Software Development"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro sp. z o.o."}],"visibility":"PUBLIC","ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999992540561","language":{"code":"en","label":"English","labelNative":"English (US)"}},{"id":"743999991717292","name":"Front-End Software Engineer","uuid":"4b416460-a0b5-45f8-a567-8ca955935c6f","jobAdId":"9aeb1a38-8423-4154-9c5b-0390c5a839f5","defaultJobAd":true,"refNumber":"REF4861R","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2024-06-03T15:47:59.565Z","location":{"city":"Prague","region":"Prague","country":"cz","remote":false,"latitude":"50.0755381","longitude":"14.4378005"},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572770","label":"IT - Software Development"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"id":"permanent","label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Recruitment Process","valueId":"f2bb5bc2-3fb0-4d5a-96d2-59e7d59ab3d7","valueLabel":"Tech Engineer/Non-Engineer - IC (MG)"},{"fieldId":"6406f92e638cbb2f415a94a9","fieldLabel":"Job Area","valueId":"e8731ea4-48a9-476d-ab1d-9a40eb3426f1","valueLabel":"Technology"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"cz","valueLabel":"Czechia"},{"fieldId":"61583054f15cea434e0be36f","fieldLabel":"Career Level","valueId":"3976147c-fe25-42a8-8c97-78273250960b","valueLabel":"4"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572770","valueLabel":"IT - Software Development"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"d319b522-5d2d-45d8-958a-4b99471a6446","valueLabel":"Allegro Retail a.s."},{"fieldId":"61582f70e72a6b6d239c9857","fieldLabel":"Area","valueId":"76599a72-f283-4550-9303-52e2e0eb6e32","valueLabel":"Technology"}],"visibility":"PUBLIC","ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999991717292","creator":{"name":"Agnieszka Adamus"},"language":{"code":"en","label":"English","labelNative":"English (US)"}},{"id":"743999991671250","name":"Senior Salesforce Software Engineer","uuid":"5069117f-7b5a-464d-a4ad-9f4c133cde35","jobAdId":"d0b08f39-f02c-4e32-ad36-475f900ddfc1","defaultJobAd":true,"refNumber":"REF4747J","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2024-06-03T12:56:05.571Z","location":{"city":"Warsaw","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572770","label":"IT - Software Development"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"id":"permanent","label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"61583054f15cea434e0be36f","fieldLabel":"Career Level","valueId":"26b58095-3c5f-4596-937f-27547fb80b07","valueLabel":"5"},{"fieldId":"61582f70e72a6b6d239c9857","fieldLabel":"Area","valueId":"76599a72-f283-4550-9303-52e2e0eb6e32","valueLabel":"Technology"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Recruitment Process","valueId":"ed4682c7-33c9-41c2-8d13-428ed39046f5","valueLabel":"Tech. Engineer - IC"},{"fieldId":"6406f92e638cbb2f415a94a9","fieldLabel":"Job Area","valueId":"e8731ea4-48a9-476d-ab1d-9a40eb3426f1","valueLabel":"Technology"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572770","valueLabel":"IT - Software Development"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro sp. z o.o."}],"visibility":"PUBLIC","ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999991671250","creator":{"name":"Agnieszka Adamus"},"language":{"code":"en","label":"English","labelNative":"English (US)"}}],"events":[{"created":1715716710000,"duration":7200000,"id":"301022703","name":"Allegro Tech Talks #43 - Wszystko o programie e-Xperience","date_in_series_pattern":false,"status":"past","time":1716393600000,"local_date":"2024-05-22","local_time":"18:00","updated":1716406648000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":14,"venue":{"id":27570147,"name":"Allegro Office - Pozna≈Ñ (Nowy Rynek)","lat":52.40021514892578,"lon":16.92083168029785,"repinned":false,"address_1":"Wierzbiƒôcice 1B - budynek D","city":"Pozna≈Ñ","country":"pl","localized_country_name":"Poland"},"is_online_event":false,"eventType":"PHYSICAL","group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/301022703/","description":"**‚û° Rejestracja:** [https://app.evenea.pl/event/allegro-tech-talk-43/](https://app.evenea.pl/event/allegro-tech-talk-43/) Zapraszamy Was na #43¬†wydarzenie z serii Allegro Tech Talk, podczas kt√≥rych dzielimy siƒô wiedzƒÖ, wzajemnie inspirujemy oraz integrujemy przy dobrej kawie‚òï, napojachü•§‚Ä¶","how_to_find_us":"Biuro Allegro znajduje siƒô w kompleksie Nowy Rynek. Szukaj budynku D i kieruj siƒô do wej≈õcia od ul. Wierzbiƒôcice. Komunikacja miejska: najbli≈ºszy przystanek to Wierzbiƒôcice i kursujƒÖ tu linie tramwajowe numer 2, 5, 6, 10, 12, 18 Spacerem - z dworca Pozna≈Ñ G≈Ç√≥wny przej≈õcie zajmie Ci oko≈Ço 5 minut.","visibility":"public","member_pay_fee":false},{"created":1702979844000,"duration":187200000,"id":"298027809","name":"UX Research Confetti - IV edycja","date_in_series_pattern":false,"status":"past","time":1716202800000,"local_date":"2024-05-20","local_time":"13:00","updated":1716392955000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":82,"venue":{"id":27549223,"name":"Allegro Warsaw Office","lat":52.23224639892578,"lon":20.992111206054688,"repinned":true,"address_1":"ul. ≈ªelazna 51/53","city":"Warszawa","country":"pl","localized_country_name":"Poland"},"is_online_event":false,"eventType":"PHYSICAL","group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/298027809/","description":"**üéâ Przedstawiamy 4. edycjƒô UX Research Confetti - bezp≈ÇatnƒÖ, polskƒÖ konferencjƒô po≈õwiƒôconƒÖ badaniom UX, organizowanƒÖ przez zesp√≥≈Ç badaczy z Allegro.** ‚ú® Konferencja odbƒôdzie siƒô w‚Ä¶","visibility":"public","member_pay_fee":false},{"created":1712583756000,"duration":14400000,"id":"300288303","name":"DDD & EventStorming na luzie - unconference na 2 lata gildii w Allegro","date_in_series_pattern":false,"status":"past","time":1714129200000,"local_date":"2024-04-26","local_time":"13:00","updated":1714146607000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":103,"venue":{"id":27549223,"name":"Allegro Warsaw Office","lat":52.23224639892578,"lon":20.992111206054688,"repinned":true,"address_1":"ul. ≈ªelazna 51/53","city":"Warszawa","country":"pl","localized_country_name":"Poland"},"is_online_event":false,"eventType":"PHYSICAL","group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/300288303/","description":"**‚û° Rejestracja:** **[https://app.evenea.pl/event/allegro-tech-talk-ddd/](https://app.evenea.pl/event/allegro-tech-talk-ddd/)** Dobrze Was widzieƒá! Allegro Tech to miejsce, w kt√≥rym dzielimy siƒô wiedzƒÖ, dobrymi praktykami i case study z r√≥≈ºnych projekt√≥w prowadzonych w‚Ä¶","how_to_find_us":"Biuro Allegro znajduje siƒô w kompleksie Fabryki Norblina. Szukaj wej≈õcia Plater 3, od ul. ≈ªelaznej. \n\nKomunikacja miejska: najbli≈ºsze przystanki to Norblin 05 i 06 z liniami: 109, 178, 157. Dojedziecie do nas r√≥wnie≈º tramwajami numer 10 i 11 oraz metrem (Rondo ONZ lub Rondo Daszy≈Ñskiego).","visibility":"public","member_pay_fee":false},{"created":1712756447000,"duration":7200000,"id":"300327359","name":"Allegro Tech Talks #42 - Kariera Product Managera","date_in_series_pattern":false,"status":"past","time":1713888000000,"local_date":"2024-04-23","local_time":"18:00","updated":1713900030000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":37,"venue":{"id":27549223,"name":"Allegro Warsaw Office","lat":52.23224639892578,"lon":20.992111206054688,"repinned":true,"address_1":"ul. ≈ªelazna 51/53","city":"Warszawa","country":"pl","localized_country_name":"Poland"},"is_online_event":false,"eventType":"PHYSICAL","group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/300327359/","description":"**‚û° Rejestracja:** [https://app.evenea.pl/event/allegro-tech-talk-42/ ](https://app.evenea.pl/event/allegro-tech-talk-42/) Zapraszamy Was na #42 wydarzenie z serii Allegro Tech Talk, podczas kt√≥rych dzielimy siƒô wiedzƒÖ, wzajemnie inspirujemy oraz integrujemy przy dobrej‚Ä¶","how_to_find_us":"Biuro Allegro znajduje siƒô w kompleksie Fabryki Norblina. Szukaj wej≈õcia Plater 3, od ul. ≈ªelaznej. \n\nKomunikacja miejska: najbli≈ºsze przystanki to Norblin 05 i 06 z liniami: 109, 178, 157. Dojedziesz do nas r√≥wnie≈º tramwajami numer 10 i 11 oraz metrem (Rondo ONZ lub Rondo Daszy≈Ñskiego).","visibility":"public","member_pay_fee":false}],"podcasts":[{"title":"O pracy analityk√≥w w obszarze technologii i przetwarzaniu danych w du≈ºej skali","link":"https://podcast.allegro.tech/o-pracy-analitykow-w-obszarze-technologii-i-przetwarzaniu-danych-w-duzej-skali/","pubDate":"Thu, 29 Feb 2024 00:00:00 GMT","content":"Na czym polega praca analityk√≥w w obszarze technologii w Allegro? Jakich narzƒôdzi i technologii na co dzie≈Ñ u≈ºywajƒÖ osoby pracujƒÖce na tych stanowiskach? Jak efekty pracy analityk√≥w wp≈ÇywajƒÖ na naszƒÖ platformƒô, produkty i funkcjonalno≈õci? Czym zajmuje siƒô Data Product Manager w Allegro Pay? Dlaczego monety sƒÖ wa≈ºnym elementem ekosystemu Allegro? Pos≈Çuchajcie kolejnego odcinka Allegro Tech Podcast tym razem z udzia≈Çem Adrianny Napi√≥rkowskiej - Data Product Managerki w Allegro Pay oraz Kaya Akcelikli - Senior Managera w obszarze Data w Allegro.","contentSnippet":"Na czym polega praca analityk√≥w w obszarze technologii w Allegro? Jakich narzƒôdzi i technologii na co dzie≈Ñ u≈ºywajƒÖ osoby pracujƒÖce na tych stanowiskach? Jak efekty pracy analityk√≥w wp≈ÇywajƒÖ na naszƒÖ platformƒô, produkty i funkcjonalno≈õci? Czym zajmuje siƒô Data Product Manager w Allegro Pay? Dlaczego monety sƒÖ wa≈ºnym elementem ekosystemu Allegro? Pos≈Çuchajcie kolejnego odcinka Allegro Tech Podcast tym razem z udzia≈Çem Adrianny Napi√≥rkowskiej - Data Product Managerki w Allegro Pay oraz Kaya Akcelikli - Senior Managera w obszarze Data w Allegro.","guid":"https://podcast.allegro.tech/o-pracy-analitykow-w-obszarze-technologii-i-przetwarzaniu-danych-w-duzej-skali/","isoDate":"2024-02-29T00:00:00.000Z"},{"title":"Programowanie - co liczy siƒô w nim najbardziej?","link":"https://podcast.allegro.tech/programowanie-co-liczy-sie-w-nim-najbardziej/","pubDate":"Thu, 01 Feb 2024 00:00:00 GMT","content":"JakƒÖ ≈õcie≈ºkƒô trzeba przej≈õƒá, aby dobrze programowaƒá? Gdzie zdobywaƒá wiedzƒô, do≈õwiadczenie i szlifowaƒá swoje umiejƒôtno≈õci? Ile czasu potrzeba aby nabraƒá do≈õwiadczenia i jak zadbaƒá o sw√≥j dalszy rozw√≥j? Na czym w praktyce polegajƒÖ role (Senior) Software Engineer oraz Engineering Manager w Allegro i kto najlepiej sprawdza siƒô w naszych zespo≈Çach? Pos≈Çuchajcie nowego odcinka Allegro Tech Podcast z udzia≈Çem Rafa≈Ça Schmidta (Senior Software Engineer) i Waldemara Panasa (Manager, Engineering) z Allegro.","contentSnippet":"JakƒÖ ≈õcie≈ºkƒô trzeba przej≈õƒá, aby dobrze programowaƒá? Gdzie zdobywaƒá wiedzƒô, do≈õwiadczenie i szlifowaƒá swoje umiejƒôtno≈õci? Ile czasu potrzeba aby nabraƒá do≈õwiadczenia i jak zadbaƒá o sw√≥j dalszy rozw√≥j? Na czym w praktyce polegajƒÖ role (Senior) Software Engineer oraz Engineering Manager w Allegro i kto najlepiej sprawdza siƒô w naszych zespo≈Çach? Pos≈Çuchajcie nowego odcinka Allegro Tech Podcast z udzia≈Çem Rafa≈Ça Schmidta (Senior Software Engineer) i Waldemara Panasa (Manager, Engineering) z Allegro.","guid":"https://podcast.allegro.tech/programowanie-co-liczy-sie-w-nim-najbardziej/","isoDate":"2024-02-01T00:00:00.000Z"},{"title":"MBox: server-driven UI dla aplikacji mobilnych","link":"https://podcast.allegro.tech/mbox-server-driven-ui-dla-aplikacji-mobilnych/","pubDate":"Thu, 16 Nov 2023 00:00:00 GMT","content":"Czym jest i jak powsta≈Ç MBox: wewnƒôtrzna platforma server-driven UI dla aplikacji mobilnych w Allegro? SkƒÖd wziƒÖ≈Ç siƒô pomys≈Ç na to rozwiƒÖzanie i na jakie bolƒÖczki odpowiada? Dlaczego zdecydowali≈õmy siƒô na budowanie tego typu rozwiƒÖzania in-house i z jakimi wyzwaniami mierzyli≈õmy siƒô w procesie tworzenia? Co wyr√≥≈ºnia zespo≈Çy pracujƒÖce nad tym narzƒôdziem i jak pracuje im siƒô bez Product Ownera? Pos≈Çuchajcie si√≥dmego odcinka Allegro Tech Podcast z udzia≈Çem Pauliny Sadowskiej i Tomasza Gƒôbarowskiego - Manager√≥w w obszarze Technical Platform Services w Allegro.","contentSnippet":"Czym jest i jak powsta≈Ç MBox: wewnƒôtrzna platforma server-driven UI dla aplikacji mobilnych w Allegro? SkƒÖd wziƒÖ≈Ç siƒô pomys≈Ç na to rozwiƒÖzanie i na jakie bolƒÖczki odpowiada? Dlaczego zdecydowali≈õmy siƒô na budowanie tego typu rozwiƒÖzania in-house i z jakimi wyzwaniami mierzyli≈õmy siƒô w procesie tworzenia? Co wyr√≥≈ºnia zespo≈Çy pracujƒÖce nad tym narzƒôdziem i jak pracuje im siƒô bez Product Ownera? Pos≈Çuchajcie si√≥dmego odcinka Allegro Tech Podcast z udzia≈Çem Pauliny Sadowskiej i Tomasza Gƒôbarowskiego - Manager√≥w w obszarze Technical Platform Services w Allegro.","guid":"https://podcast.allegro.tech/mbox-server-driven-ui-dla-aplikacji-mobilnych/","isoDate":"2023-11-16T00:00:00.000Z"},{"title":"O chatbotach i ich wp≈Çywie na Allegro","link":"https://podcast.allegro.tech/o-chatbotach-i-ich-wplywie-na-allegro/","pubDate":"Wed, 11 Oct 2023 00:00:00 GMT","content":"Jakie procesy automatyzujemy w Allegro i co warto o nich wiedzieƒá w kontek≈õcie obszaru Customer Experience? W czym pomagajƒÖ nam chatboty, jak je rozwijamy i dbamy o ich jako≈õƒá? Kim sƒÖ Allina oraz Albert i co majƒÖ wsp√≥lnego z automatyzacjƒÖ? Za jakie rozwiƒÖzania otrzymali≈õmy nagrodƒô hiperautomatyzacji? O tym wszystkim pos≈Çuchacie w odcinku z udzia≈Çem Rafa≈Ça Gajewskiego - Managera w obszarze IT Services w Allegro.","contentSnippet":"Jakie procesy automatyzujemy w Allegro i co warto o nich wiedzieƒá w kontek≈õcie obszaru Customer Experience? W czym pomagajƒÖ nam chatboty, jak je rozwijamy i dbamy o ich jako≈õƒá? Kim sƒÖ Allina oraz Albert i co majƒÖ wsp√≥lnego z automatyzacjƒÖ? Za jakie rozwiƒÖzania otrzymali≈õmy nagrodƒô hiperautomatyzacji? O tym wszystkim pos≈Çuchacie w odcinku z udzia≈Çem Rafa≈Ça Gajewskiego - Managera w obszarze IT Services w Allegro.","guid":"https://podcast.allegro.tech/o-chatbotach-i-ich-wplywie-na-allegro/","isoDate":"2023-10-11T00:00:00.000Z"}]},"__N_SSG":true}