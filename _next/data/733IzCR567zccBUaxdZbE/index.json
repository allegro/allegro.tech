{"pageProps":{"posts":[{"title":"Dynamic Workload Balancing in Hermes","link":"https://blog.allegro.tech/2023/04/dynamic-workload-balancing-in-hermes.html","pubDate":"Wed, 05 Apr 2023 00:00:00 +0200","authors":{"author":[{"name":["Piotr Rżysko"],"photo":["https://blog.allegro.tech/img/authors/piotr.rzysko.jpg"],"url":["https://blog.allegro.tech/authors/piotr.rzysko"]}]},"content":"<p><a href=\"https://github.com/allegro/hermes\">Hermes</a> is a distributed <a href=\"https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern\">publish-subscribe</a>\nmessage broker that we use at <a href=\"https://allegro.tech\">Allegro</a> to facilitate asynchronous communication between our\nmicroservices. As our usage of Hermes has grown over time, we faced a challenge in effectively distributing the\nload it handles to optimize resource utilization. In this blog post, we will present the implementation of a dynamic\nworkload balancing algorithm that we developed to address this challenge. We will describe the approach we took, the\nlessons we learned along the way, and the results we achieved.</p>\n\n<h2 id=\"hermes-architecture\">Hermes Architecture</h2>\n\n<p>Before we delve deeper into the article’s topic, let’s first briefly introduce the architecture of Hermes, depicted in\nthe diagram below:</p>\n\n<p><img src=\"/img/articles/2023-04-05-dynamic-workload-balancing-in-hermes/hermes_architecture.png\" alt=\"Hermes Architecture\" /></p>\n\n<p>As we can see, Hermes is composed of two main modules:</p>\n\n<ul>\n  <li>\n    <p><strong>Hermes Frontend</strong> acts as a gateway, receiving messages from publishers via its REST interface, applying necessary\n  preprocessing, and eventually storing them in <a href=\"https://kafka.apache.org/\">Apache Kafka</a>.</p>\n  </li>\n  <li>\n    <p><strong>Hermes Consumers</strong> is a component that constitutes the delivery part of the system. Its role is to fetch messages\n  from Kafka and push them to predefined subscribers while providing reliability mechanisms such as retries, backpressure,\n  and rate limiting. For the sake of brevity, in the latter parts of the article, we’ll refer to a single instance of this\n  module as a <em>consumer</em>.</p>\n  </li>\n</ul>\n\n<p>Since the rest of this post discusses topics that mainly pertain to the delivery side of the system, let’s turn our\nattention to that now.</p>\n\n<p>Apache Kafka organizes messages, also known as events, into topics. To facilitate parallelism, a topic usually has\nmultiple partitions. Each event is stored in only one partition. When someone wants to receive messages from a given\ntopic via Hermes, they create a new subscription with the defined HTTP endpoint to which messages will be delivered. Under the\nhood, Hermes assigns a group of <em>consumers</em> to that subscription, with each <em>consumer</em> handling at least one of the\ntopic partitions. By default, a fixed number of <em>consumers</em> are assigned to a subscription, but the administrator can\nmanually override this number on a per-subscription basis. It’s also worth noting that a single <em>consumer</em> can handle\nmultiple subscriptions. The following diagram illustrates this:</p>\n\n<p><img src=\"/img/articles/2023-04-05-dynamic-workload-balancing-in-hermes/partitions.png\" alt=\"Hermes Consumers\" /></p>\n\n<h2 id=\"workload-balancer\">Workload Balancer</h2>\n\n<p>The Hermes Consumers module is designed to operate in highly dynamic environments, e.g. in the cloud, where new\ninstances can be added, restarted, or removed at almost any time. This means that the module can handle these situations\nseamlessly and without disrupting the flow of messages. Additionally, it is horizontally scalable, meaning that\nwhen there is an increase in the number of subscriptions or an increase in outgoing traffic, we can easily scale out\nthe cluster by adding new <em>consumers</em>. This adaptability to changing circumstances is achieved by a mechanism called the\n“workload balancer.” It acts as an arbiter, monitoring the state of the cluster, and if necessary, proposing\nappropriate adjustments in the distribution of subscriptions to the rest of the nodes.</p>\n\n<h2 id=\"motivations-for-improving-workload-balancer\">Motivations for Improving Workload Balancer</h2>\n\n<p>Our first implementation of the workload balancer aimed to always assign the same number of subscriptions to each\n<em>consumer</em>. This strategy is easy to understand and performs optimally when subscriptions are equal with respect to\ntheir load. However, this is not always the case. For example, imagine that we have two subscriptions. The first\nprocesses 1,000 messages per second, and the second only 10 messages per second. It is highly likely that they will\nnot consume the same number of CPU cores, network bandwidth, etc. Thus, if we want to spread the load evenly,\nwe should not assume that they are equal.</p>\n\n<p>Usually, when we deploy our application in the cloud, we have to predefine the number of instances and the amount of\nresources (e.g. CPU, memory, etc.) that should be allocated to it. Unless we use a mechanism that adjusts these\nvalues on a per-instance basis, each instance will receive an equal share of the available resources. Now, let’s take\na look at the CPU usage of each <em>consumer</em> from one of our Hermes production clusters using the workload balancer\nwhich does not account for the disproportions between subscriptions:</p>\n\n<p><a href=\"/img/articles/2023-04-05-dynamic-workload-balancing-in-hermes/cpu_before.png\"><img src=\"/img/articles/2023-04-05-dynamic-workload-balancing-in-hermes/cpu_before.png\" alt=\"Initial CPU usage\" /></a></p>\n\n<p>The figure below shows the difference in CPU usage between the least and most heavily loaded <em>consumers</em>:</p>\n\n<p><a href=\"/img/articles/2023-04-05-dynamic-workload-balancing-in-hermes/cpu_before_least_and_most.png\"><img src=\"/img/articles/2023-04-05-dynamic-workload-balancing-in-hermes/cpu_before_least_and_most.png\" alt=\"CPU usage of the least and most heavily loaded consumers\" /></a></p>\n\n<p>Taking into account all of the above factors, in order not to compromise system performance, we always had to determine\nthe right allocation based on the most loaded instance. Consequently, less busy instances were wasting resources as\ntheir demands were lower, not making the most of what was available. Knowing that our Hermes production clusters will\ncontinue to grow in terms of both traffic and the number of topics and subscriptions, we decided to develop a new and\nimproved workload balancer, which we will discuss in the next section. We knew that if we didn’t do this, we would have\nto over-allocate even more resources in the future.</p>\n\n<h2 id=\"solution\">Solution</h2>\n\n<h3 id=\"constraints-and-requirements\">Constraints and Requirements</h3>\n\n<p>Before we proceed to the description of the solution we devised, we would like to discuss the requirements and\nconstraints that guided our design process.</p>\n\n<p>First, we wanted to preserve the core responsibilities of the original workload balancer, such as:</p>\n\n<ul>\n  <li>Allocating work across newly added <em>consumers</em></li>\n  <li>Distributing work from removed <em>consumers</em></li>\n  <li>Assigning newly added subscriptions to available <em>consumers</em></li>\n  <li>Reclaiming resources previously assigned to removed subscriptions</li>\n</ul>\n\n<p>Secondly, we decided not to change the existing rule of assigning the same number of subscriptions to each <em>consumer</em>.\nThe reasoning behind this decision stemmed from the threading model implemented in Hermes Consumers, where every\nsubscription assigned to a <em>consumer</em> is handled by a separate thread. Having an unequal number of threads between\n<em>consumers</em> could potentially lead to some consumers being overwhelmed with more\n<a href=\"https://en.wikipedia.org/wiki/Context_switch\">context switches</a> and a higher memory footprint.</p>\n\n<p>Similarly, we wanted to preserve the strategy of determining the number of <em>consumers</em> a subscription should be\nassigned to (fixed and globally configured, but with the option of being overridden on a per-subscription basis by the\nadministrator). Although it may not be optimal, for the reasons mentioned earlier, we chose to narrow down the scope of the\nimprovements, keep it as is, and potentially revisit it in the future.</p>\n\n<p>The last and very important factor that we had to consider while designing the new algorithm was the cost tied to\nevery change in the assignment of subscriptions, particularly the cost of rebalancing Kafka’s consumer groups\n(i.e. temporarily suspending the delivery of messages from partitions affected by the rebalance until the process is\ncompleted).</p>\n\n<p>With all of the above preconditions met, we were able to augment the capabilities of the workload balancer by making it\naware of the heterogeneity of the subscriptions. We will discuss how we approached this in the following two subsections.</p>\n\n<h3 id=\"first-attempt\">First Attempt</h3>\n\n<p>As we mentioned earlier, the main reason for the imbalance was the fact that the original balancing algorithm was\nunaware of the differences between subscriptions. Therefore, in the first place, we wanted to make subscriptions\ncomparable by associating with each of them an attribute called “weight.” Internally, it’s a vector of metrics\ncharacterizing a subscription. Currently, this vector has only one element, named “operations per second.” A single\noperation is an action executed by a <em>consumer</em> in the context of a given subscription, such as fetching an event from\nKafka, committing offsets to Kafka, or sending an event to a subscriber. In the future, we may extend the\nweight vector by adding metrics that will allow us to eliminate uneven consumption of resources other than CPU.</p>\n\n<p>Based on weights reported by individual <em>consumers</em>, a leader (one of the nodes from the Hermes Consumers cluster)\nbuilds subscription profiles, which are records containing information about subscriptions necessary for making\nbalancing decisions. Among the details included in each profile are the weight and the timestamp of the last rebalance.\nIt’s important to remember that a single subscription can be spanned across multiple <em>consumers</em>, resulting in multiple\nweight vectors associated with a single subscription. To resolve this, the leader builds a final weight vector (\\(W\\)),\nwhich is used in further calculations:</p>\n\n<p>\\begin{equation}\nW =\n\\begin{bmatrix}\nmax(m_{11},m_{12},\\cdots,m_{1M}) &amp; max(m_{21},m_{22},\\cdots,m_{2M}) &amp; \\cdots &amp; max(m_{N1},m_{N2},\\cdots,m_{NM})\n\\end{bmatrix}\n\\end{equation}</p>\n\n<p>where:</p>\n\n<p>\\(m_{ij}\\) is the value of metric \\(i\\) reported by <em>consumer</em> \\(j\\)</p>\n\n<p>\\(N\\) is the number of metrics included in the weight vector</p>\n\n<p>\\(M\\) is the number of <em>consumers</em></p>\n\n<p>It’s also worth noting that in order to smooth out abrupt changes and short-term fluctuations in traffic, we apply an\n<a href=\"https://en.wikipedia.org/wiki/Exponential_smoothing\">exponentially weighted moving average (EWMA)</a> to the collected\nmetrics.</p>\n\n<p>To address the requirement regarding the cost of reassigning subscriptions, we introduced a global parameter called\n“stabilization window.” After a subscription is assigned, the stabilization window determines the minimum time before\nthe subscription can be reassigned. This “freezes” the subscription so that it doesn’t get reassigned too quickly,\nallowing the subscription to catch up with the events produced during the rebalancing process.</p>\n\n<p>Equipped with the necessary terminology, we can now proceed to describe the algorithm itself. The high-level idea is\nfairly simple and boils down to the leader periodically executing the following steps:</p>\n<ol>\n  <li>Fetch subscription weights from every <em>consumer</em>.</li>\n  <li>Using information from the previous step, rebuild subscription profiles.</li>\n  <li>Calculate the total weight of the whole Hermes Consumers cluster by summing all subscription weights.</li>\n  <li>Determine the target consumer weight as an average of the weights of all <em>consumers</em> in the cluster.</li>\n  <li>Build a set of <em>consumers</em> whose weights are above the average calculated in step 4.</li>\n  <li>Build a set of <em>consumers</em> whose weights are below the average calculated in step 4.</li>\n  <li>Swap subscriptions between the sets calculated in the previous two steps while maintaining the following restrictions:\n    <ul>\n      <li>The weight of an instance from the overloaded set (step 5) is smaller than it was before the swap but is not\nsmaller than the target value.</li>\n      <li>The weight of an instance from the underloaded set (step 6) is greater than it was before the swap but is not\ngreater than the target value.</li>\n      <li>If, for a given subscription, the period of time since the last rebalance is shorter than the stabilization\nwindow, don’t consider the subscription eligible for the swap.</li>\n    </ul>\n  </li>\n</ol>\n\n<p>The graph below shows the results we obtained after deploying the implementation of this algorithm to production:</p>\n\n<p><a href=\"/img/articles/2023-04-05-dynamic-workload-balancing-in-hermes/cpu_first_attempt.png\"><img src=\"/img/articles/2023-04-05-dynamic-workload-balancing-in-hermes/cpu_first_attempt.png\" alt=\"CPU usage after the first attempt\" /></a></p>\n\n<p>Although the graph shows that the new algorithm got us closer to having uniform utilization of CPU, we were not fully\nsatisfied with that outcome. The reason for that is depicted below, where we compare the most loaded instance with the\nleast loaded one. The degree of disparity in terms of CPU usage is still significant. Therefore, we decided to at least\ndetermine the reason for that state of affairs and, if possible, refine the algorithm.</p>\n\n<p><a href=\"/img/articles/2023-04-05-dynamic-workload-balancing-in-hermes/cpu_first_attempt_least_most.png\"><img src=\"/img/articles/2023-04-05-dynamic-workload-balancing-in-hermes/cpu_first_attempt_least_most.png\" alt=\"CPU usage of the least and most heavily loaded consumers after the first attempt\" /></a></p>\n\n<p>While investigating this issue, we noticed a correlation between the class of hardware that <em>consumers</em> run on and\ntheir CPU usage. This observation led us to the conclusion that, despite the fact that load is evenly distributed,\ninstances running on older generations of hardware utilize a higher percentage of available CPU power than those running\non newer hardware, which is understandable as older machines are typically less performant. In the following section, we\ndescribe how we tackled this issue.</p>\n\n<h3 id=\"second-attempt\">Second Attempt</h3>\n\n<p>After our investigation, it was clear to us that if we wanted to achieve uniform CPU usage across the entire Hermes cluster,\naiming for processing the same number of operations per second on each instance was not the way to go. This led us to the\nquestion of how to determine the ideal number of operations per second that each instance can handle without being either\noverloaded or underloaded. To answer this, we had to take into account the fact that in the cloud environment, it is not\nalways possible to precisely define the hardware that our application will be running on. Potentially, we could put the\nburden of making the right decision on the Hermes administrator. However, this is a very tedious task and also hard to\nmaintain in dynamic environments where applications are almost constantly moved around different physical machines.</p>\n\n<p>As we wanted to avoid any manual tuning, we decided to employ a concept well-known in\n<a href=\"https://en.wikipedia.org/wiki/Classical_control_theory\">Control Theory</a>, called a\n<a href=\"https://en.wikipedia.org/wiki/Proportional_control\">proportional controller</a>. To explain the idea behind this concept,\nlet’s use an example. In the following picture, we see an operator who must adjust a hand valve to achieve the desired\ntemperature in a furnace. The operator doesn’t know upfront what the appropriate degree to which the valve should be\nopen is, therefore it is necessary to use a trial-and-error method to attain the desired outcome.</p>\n\n<p><img src=\"/img/articles/2023-04-05-dynamic-workload-balancing-in-hermes/proportional_controler.png\" alt=\"Proportional Controller\" /></p>\n\n<p>Now let’s take a look at how this example relates to Control Theory. Using Control Theory terms, we can say that the\npicture presents a feedback control system, also known as a closed-loop control system. In such systems, the current\nstate and desired state of the system are referred to as the process variable and set point, respectively. In the example,\nthe current temperature in the furnace represents the process variable, while the temperature that the operator wants to\nachieve is the set point. To fully automate the control system and eliminate the need for manual adjustments, we typically\nreplace the operator with two components: an actuator and a controller. The controller calculates an error, which is the\ndifference between the set point and the process variable. Based on the error, the controller proportionally increases\nor decreases its output (in this example, the degree to which the valve is open). The actuator uses the controller’s\noutput to physically adjust the state of the system.</p>\n\n<p>If we think about it, we realize that the problem a proportional controller solves is very similar to the one we\nencounter when we run Hermes on heterogeneous hardware. Specifically, our goal is to achieve equal CPU usage across all\n<em>consumers</em>, with the average usage of all <em>consumers</em> being our target. Additionally, we know that the number of\noperations per second processed by each <em>consumer</em> directly affects CPU usage. By utilizing a proportional\ncontroller, we can determine the value of this variable by calculating the error (the difference between the\ntarget and current CPU usage) and then adjusting the target weight accordingly. If we run the controller\nin a continuous loop, where it increases the target weight when current usage is below the target and vice versa, we\nshould eventually reach the set point.</p>\n\n<p>After integrating a proportional controller into our algorithm and deploying it to production, we were able to achieve\nthe following results:</p>\n\n<p><a href=\"/img/articles/2023-04-05-dynamic-workload-balancing-in-hermes/cpu_second_attempt.png\"><img src=\"/img/articles/2023-04-05-dynamic-workload-balancing-in-hermes/cpu_second_attempt.png\" alt=\"CPU usage after the second attempt\" /></a></p>\n\n<p>As we can see, the current CPU usage of all instances is very similar. This is exactly what we aimed for. If we\nassume that we are targeting 40% CPU utilization (to be able to handle additional traffic in case of a datacenter failover),\nby introducing the new algorithm we reduced the amount of allocated resources by approximately 42%.</p>\n\n<h2 id=\"conclusion-and-potential-improvements\">Conclusion and Potential Improvements</h2>\n\n<p>In this post, we have described the challenges we faced with balancing load in our Hermes clusters, and the steps we\ntook to overcome them. By introducing our new workload balancing algorithm that dynamically adapts to varying\nsubscription loads and heterogeneous hardware, we were able to achieve a more uniform distribution of CPU usage across\nHermes Consumers instances.</p>\n\n<p>This approach has allowed us to significantly reduce the amount of allocated resources and avoid performance issues\ncaused by the imbalance that we observed earlier. However, there is still room for improvement. So far, we have been\nfocused on optimizing CPU utilization, but the way the algorithm is designed, enables us to extend the spectrum of\nbalanced resources in the future. For instance, we may consider factoring in memory and network bandwidth as well.</p>\n\n<p>Additionally, we plan to improve the ease of operating Hermes clusters. We aim to avoid having tuning knobs and putting\nthe burden of setting them correctly on the user. One such knob that we may want to remove in the future is the parameter\ndefining how many consumers are assigned to a subscription. Currently, the Hermes administrator is responsible for\nchoosing the value of this parameter for subscriptions where the default value is not a good fit. We suspect that this\ntask could be automated by delegating it to the workload balancer.</p>\n","contentSnippet":"Hermes is a distributed publish-subscribe\nmessage broker that we use at Allegro to facilitate asynchronous communication between our\nmicroservices. As our usage of Hermes has grown over time, we faced a challenge in effectively distributing the\nload it handles to optimize resource utilization. In this blog post, we will present the implementation of a dynamic\nworkload balancing algorithm that we developed to address this challenge. We will describe the approach we took, the\nlessons we learned along the way, and the results we achieved.\nHermes Architecture\nBefore we delve deeper into the article’s topic, let’s first briefly introduce the architecture of Hermes, depicted in\nthe diagram below:\n\nAs we can see, Hermes is composed of two main modules:\nHermes Frontend acts as a gateway, receiving messages from publishers via its REST interface, applying necessary\n  preprocessing, and eventually storing them in Apache Kafka.\nHermes Consumers is a component that constitutes the delivery part of the system. Its role is to fetch messages\n  from Kafka and push them to predefined subscribers while providing reliability mechanisms such as retries, backpressure,\n  and rate limiting. For the sake of brevity, in the latter parts of the article, we’ll refer to a single instance of this\n  module as a consumer.\nSince the rest of this post discusses topics that mainly pertain to the delivery side of the system, let’s turn our\nattention to that now.\nApache Kafka organizes messages, also known as events, into topics. To facilitate parallelism, a topic usually has\nmultiple partitions. Each event is stored in only one partition. When someone wants to receive messages from a given\ntopic via Hermes, they create a new subscription with the defined HTTP endpoint to which messages will be delivered. Under the\nhood, Hermes assigns a group of consumers to that subscription, with each consumer handling at least one of the\ntopic partitions. By default, a fixed number of consumers are assigned to a subscription, but the administrator can\nmanually override this number on a per-subscription basis. It’s also worth noting that a single consumer can handle\nmultiple subscriptions. The following diagram illustrates this:\n\nWorkload Balancer\nThe Hermes Consumers module is designed to operate in highly dynamic environments, e.g. in the cloud, where new\ninstances can be added, restarted, or removed at almost any time. This means that the module can handle these situations\nseamlessly and without disrupting the flow of messages. Additionally, it is horizontally scalable, meaning that\nwhen there is an increase in the number of subscriptions or an increase in outgoing traffic, we can easily scale out\nthe cluster by adding new consumers. This adaptability to changing circumstances is achieved by a mechanism called the\n“workload balancer.” It acts as an arbiter, monitoring the state of the cluster, and if necessary, proposing\nappropriate adjustments in the distribution of subscriptions to the rest of the nodes.\nMotivations for Improving Workload Balancer\nOur first implementation of the workload balancer aimed to always assign the same number of subscriptions to each\nconsumer. This strategy is easy to understand and performs optimally when subscriptions are equal with respect to\ntheir load. However, this is not always the case. For example, imagine that we have two subscriptions. The first\nprocesses 1,000 messages per second, and the second only 10 messages per second. It is highly likely that they will\nnot consume the same number of CPU cores, network bandwidth, etc. Thus, if we want to spread the load evenly,\nwe should not assume that they are equal.\nUsually, when we deploy our application in the cloud, we have to predefine the number of instances and the amount of\nresources (e.g. CPU, memory, etc.) that should be allocated to it. Unless we use a mechanism that adjusts these\nvalues on a per-instance basis, each instance will receive an equal share of the available resources. Now, let’s take\na look at the CPU usage of each consumer from one of our Hermes production clusters using the workload balancer\nwhich does not account for the disproportions between subscriptions:\n\nThe figure below shows the difference in CPU usage between the least and most heavily loaded consumers:\n\nTaking into account all of the above factors, in order not to compromise system performance, we always had to determine\nthe right allocation based on the most loaded instance. Consequently, less busy instances were wasting resources as\ntheir demands were lower, not making the most of what was available. Knowing that our Hermes production clusters will\ncontinue to grow in terms of both traffic and the number of topics and subscriptions, we decided to develop a new and\nimproved workload balancer, which we will discuss in the next section. We knew that if we didn’t do this, we would have\nto over-allocate even more resources in the future.\nSolution\nConstraints and Requirements\nBefore we proceed to the description of the solution we devised, we would like to discuss the requirements and\nconstraints that guided our design process.\nFirst, we wanted to preserve the core responsibilities of the original workload balancer, such as:\nAllocating work across newly added consumers\nDistributing work from removed consumers\nAssigning newly added subscriptions to available consumers\nReclaiming resources previously assigned to removed subscriptions\nSecondly, we decided not to change the existing rule of assigning the same number of subscriptions to each consumer.\nThe reasoning behind this decision stemmed from the threading model implemented in Hermes Consumers, where every\nsubscription assigned to a consumer is handled by a separate thread. Having an unequal number of threads between\nconsumers could potentially lead to some consumers being overwhelmed with more\ncontext switches and a higher memory footprint.\nSimilarly, we wanted to preserve the strategy of determining the number of consumers a subscription should be\nassigned to (fixed and globally configured, but with the option of being overridden on a per-subscription basis by the\nadministrator). Although it may not be optimal, for the reasons mentioned earlier, we chose to narrow down the scope of the\nimprovements, keep it as is, and potentially revisit it in the future.\nThe last and very important factor that we had to consider while designing the new algorithm was the cost tied to\nevery change in the assignment of subscriptions, particularly the cost of rebalancing Kafka’s consumer groups\n(i.e. temporarily suspending the delivery of messages from partitions affected by the rebalance until the process is\ncompleted).\nWith all of the above preconditions met, we were able to augment the capabilities of the workload balancer by making it\naware of the heterogeneity of the subscriptions. We will discuss how we approached this in the following two subsections.\nFirst Attempt\nAs we mentioned earlier, the main reason for the imbalance was the fact that the original balancing algorithm was\nunaware of the differences between subscriptions. Therefore, in the first place, we wanted to make subscriptions\ncomparable by associating with each of them an attribute called “weight.” Internally, it’s a vector of metrics\ncharacterizing a subscription. Currently, this vector has only one element, named “operations per second.” A single\noperation is an action executed by a consumer in the context of a given subscription, such as fetching an event from\nKafka, committing offsets to Kafka, or sending an event to a subscriber. In the future, we may extend the\nweight vector by adding metrics that will allow us to eliminate uneven consumption of resources other than CPU.\nBased on weights reported by individual consumers, a leader (one of the nodes from the Hermes Consumers cluster)\nbuilds subscription profiles, which are records containing information about subscriptions necessary for making\nbalancing decisions. Among the details included in each profile are the weight and the timestamp of the last rebalance.\nIt’s important to remember that a single subscription can be spanned across multiple consumers, resulting in multiple\nweight vectors associated with a single subscription. To resolve this, the leader builds a final weight vector (\\(W\\)),\nwhich is used in further calculations:\n\\begin{equation}\nW =\n\\begin{bmatrix}\nmax(m_{11},m_{12},\\cdots,m_{1M}) & max(m_{21},m_{22},\\cdots,m_{2M}) & \\cdots & max(m_{N1},m_{N2},\\cdots,m_{NM})\n\\end{bmatrix}\n\\end{equation}\nwhere:\n\\(m_{ij}\\) is the value of metric \\(i\\) reported by consumer \\(j\\)\n\\(N\\) is the number of metrics included in the weight vector\n\\(M\\) is the number of consumers\nIt’s also worth noting that in order to smooth out abrupt changes and short-term fluctuations in traffic, we apply an\nexponentially weighted moving average (EWMA) to the collected\nmetrics.\nTo address the requirement regarding the cost of reassigning subscriptions, we introduced a global parameter called\n“stabilization window.” After a subscription is assigned, the stabilization window determines the minimum time before\nthe subscription can be reassigned. This “freezes” the subscription so that it doesn’t get reassigned too quickly,\nallowing the subscription to catch up with the events produced during the rebalancing process.\nEquipped with the necessary terminology, we can now proceed to describe the algorithm itself. The high-level idea is\nfairly simple and boils down to the leader periodically executing the following steps:\nFetch subscription weights from every consumer.\nUsing information from the previous step, rebuild subscription profiles.\nCalculate the total weight of the whole Hermes Consumers cluster by summing all subscription weights.\nDetermine the target consumer weight as an average of the weights of all consumers in the cluster.\nBuild a set of consumers whose weights are above the average calculated in step 4.\nBuild a set of consumers whose weights are below the average calculated in step 4.\nSwap subscriptions between the sets calculated in the previous two steps while maintaining the following restrictions:\n    \nThe weight of an instance from the overloaded set (step 5) is smaller than it was before the swap but is not\nsmaller than the target value.\nThe weight of an instance from the underloaded set (step 6) is greater than it was before the swap but is not\ngreater than the target value.\nIf, for a given subscription, the period of time since the last rebalance is shorter than the stabilization\nwindow, don’t consider the subscription eligible for the swap.\nThe graph below shows the results we obtained after deploying the implementation of this algorithm to production:\n\nAlthough the graph shows that the new algorithm got us closer to having uniform utilization of CPU, we were not fully\nsatisfied with that outcome. The reason for that is depicted below, where we compare the most loaded instance with the\nleast loaded one. The degree of disparity in terms of CPU usage is still significant. Therefore, we decided to at least\ndetermine the reason for that state of affairs and, if possible, refine the algorithm.\n\nWhile investigating this issue, we noticed a correlation between the class of hardware that consumers run on and\ntheir CPU usage. This observation led us to the conclusion that, despite the fact that load is evenly distributed,\ninstances running on older generations of hardware utilize a higher percentage of available CPU power than those running\non newer hardware, which is understandable as older machines are typically less performant. In the following section, we\ndescribe how we tackled this issue.\nSecond Attempt\nAfter our investigation, it was clear to us that if we wanted to achieve uniform CPU usage across the entire Hermes cluster,\naiming for processing the same number of operations per second on each instance was not the way to go. This led us to the\nquestion of how to determine the ideal number of operations per second that each instance can handle without being either\noverloaded or underloaded. To answer this, we had to take into account the fact that in the cloud environment, it is not\nalways possible to precisely define the hardware that our application will be running on. Potentially, we could put the\nburden of making the right decision on the Hermes administrator. However, this is a very tedious task and also hard to\nmaintain in dynamic environments where applications are almost constantly moved around different physical machines.\nAs we wanted to avoid any manual tuning, we decided to employ a concept well-known in\nControl Theory, called a\nproportional controller. To explain the idea behind this concept,\nlet’s use an example. In the following picture, we see an operator who must adjust a hand valve to achieve the desired\ntemperature in a furnace. The operator doesn’t know upfront what the appropriate degree to which the valve should be\nopen is, therefore it is necessary to use a trial-and-error method to attain the desired outcome.\n\nNow let’s take a look at how this example relates to Control Theory. Using Control Theory terms, we can say that the\npicture presents a feedback control system, also known as a closed-loop control system. In such systems, the current\nstate and desired state of the system are referred to as the process variable and set point, respectively. In the example,\nthe current temperature in the furnace represents the process variable, while the temperature that the operator wants to\nachieve is the set point. To fully automate the control system and eliminate the need for manual adjustments, we typically\nreplace the operator with two components: an actuator and a controller. The controller calculates an error, which is the\ndifference between the set point and the process variable. Based on the error, the controller proportionally increases\nor decreases its output (in this example, the degree to which the valve is open). The actuator uses the controller’s\noutput to physically adjust the state of the system.\nIf we think about it, we realize that the problem a proportional controller solves is very similar to the one we\nencounter when we run Hermes on heterogeneous hardware. Specifically, our goal is to achieve equal CPU usage across all\nconsumers, with the average usage of all consumers being our target. Additionally, we know that the number of\noperations per second processed by each consumer directly affects CPU usage. By utilizing a proportional\ncontroller, we can determine the value of this variable by calculating the error (the difference between the\ntarget and current CPU usage) and then adjusting the target weight accordingly. If we run the controller\nin a continuous loop, where it increases the target weight when current usage is below the target and vice versa, we\nshould eventually reach the set point.\nAfter integrating a proportional controller into our algorithm and deploying it to production, we were able to achieve\nthe following results:\n\nAs we can see, the current CPU usage of all instances is very similar. This is exactly what we aimed for. If we\nassume that we are targeting 40% CPU utilization (to be able to handle additional traffic in case of a datacenter failover),\nby introducing the new algorithm we reduced the amount of allocated resources by approximately 42%.\nConclusion and Potential Improvements\nIn this post, we have described the challenges we faced with balancing load in our Hermes clusters, and the steps we\ntook to overcome them. By introducing our new workload balancing algorithm that dynamically adapts to varying\nsubscription loads and heterogeneous hardware, we were able to achieve a more uniform distribution of CPU usage across\nHermes Consumers instances.\nThis approach has allowed us to significantly reduce the amount of allocated resources and avoid performance issues\ncaused by the imbalance that we observed earlier. However, there is still room for improvement. So far, we have been\nfocused on optimizing CPU utilization, but the way the algorithm is designed, enables us to extend the spectrum of\nbalanced resources in the future. For instance, we may consider factoring in memory and network bandwidth as well.\nAdditionally, we plan to improve the ease of operating Hermes clusters. We aim to avoid having tuning knobs and putting\nthe burden of setting them correctly on the user. One such knob that we may want to remove in the future is the parameter\ndefining how many consumers are assigned to a subscription. Currently, the Hermes administrator is responsible for\nchoosing the value of this parameter for subscriptions where the default value is not a good fit. We suspect that this\ntask could be automated by delegating it to the workload balancer.","guid":"https://blog.allegro.tech/2023/04/dynamic-workload-balancing-in-hermes.html","categories":["tech","architecture","hermes","kafka","algorithms","pub/sub","publish-subscribe","load balancing","open source"],"isoDate":"2023-04-04T22:00:00.000Z","thumbnail":"images/post-headers/default.jpg"},{"title":"How neuroscience can help you as a software engineer - motivation","link":"https://blog.allegro.tech/2023/03/neuroscience-for-software-engineers-motivation.html","pubDate":"Tue, 21 Mar 2023 00:00:00 +0100","authors":{"author":[{"name":["Paulina Szwed"],"photo":["https://blog.allegro.tech/img/authors/paulina.szwed.jpg"],"url":["https://blog.allegro.tech/authors/paulina.szwed"]}]},"content":"<p>Many of us, software engineers, have experienced those days when nothing really sparks joy in coding, debugging,\npreparing spikes or refining tasks for the next sprints. Obviously, we would like to have as few of such days as possible\nand go on with our work effectively. A solution to this definitely is not tormenting our brains with guilt and forced\nlabour. There are other ways, and I would like to invite you to explore them with me and learn a little about our\nnervous systems in the process. We’ll find out where the motivation comes from on a biological and psychological level.\nWe’ll also take a look at the changes you can introduce into your day to take advantage of certain mechanisms working\non a neural level and boost your motivation and productivity.</p>\n\n<h2 id=\"the-neuroscience-of-motivation\">The neuroscience of motivation</h2>\n\n<p>The key to maintaining energy to work throughout the day is simple – getting and staying motivated. Even though it seems\nlike something not necessarily in our power, motivation can be, to an extent, consciously modulated once we know\nthe biological and psychological mechanisms behind it.</p>\n\n<h3 id=\"the-source\">The source</h3>\n\n<p>On a neural level, the fuel of motivation is <strong>dopamine</strong>. Dopamine is a hormone (meaning it’s a messenger of the\nbody travelling through the bloodstream) and a neurotransmitter (which indicates its ability to affect communication between\nneurons).</p>\n\n<p>In general, high levels of dopamine cause high drive, motivation and willingness to live, do and experience. Low levels\nof dopamine cause the opposite state — a lack of will to do any effort (doomscrolling or examining the contents of the\nfridge is still in our reach). How much dopamine is currently in our system, how much dopamine there was a moment ago\nand how much we remember enjoying a particular state is for our brains a way to set our level of motivation.</p>\n\n<h3 id=\"the-workspace\">The workspace</h3>\n\n<p>In the context of motivation our main area of focus across the nervous system should be the mesocorticolimbic system,\nwhich is responsible for the reward mechanism.</p>\n\n<p>Mesocorticolimbic system consists of dopaminergic and dopaminoceptive neurons — the former is a specialised kind of\nneurons that is capable of producing and emitting dopamine into our body; the latter is capable of detecting and\nreacting to the dopamine. The pathways of this system go through different areas of the brain — they extend from the\nventral tegmental area (VTA) to the part of the brain responsible for memory (hippocampus), reward, pleasure and movement\n(nucleus accumbens) and reasoning (prefrontal cortex).</p>\n\n<p><img src=\"/img/articles/2023-03-21-neuroscience-for-software-engineers-motivation/1280px-Dopamine_pathways.svg.png\" alt=\"Dopamine pathways in the brain\" title=\"Dopamine pathways in the brain (Public Domain from [Wikipedia](https://en.wikipedia.org/wiki/Dopamine#/media/File:Dopamine_pathways.svg))\" /></p>\n\n<p>The complexity of this structure might be a hint that there are a multiple implications of dopamine release, but\nalso many different ways to interact with this area.</p>\n\n<h3 id=\"the-process\">The process</h3>\n\n<p>When we talk about managing dopamine levels in healthy individuals, we actually should consider two different things:</p>\n\n<ul>\n  <li><strong>baseline level</strong>, which is how much dopamine circulates in the body and determines how much dopamine we are capable\nof having,</li>\n  <li><strong>peak level</strong>, which tells us how much dopamine we have at the moment or as a result of a rapid change.</li>\n</ul>\n\n<p>Baseline level and peak level are closely related to each other. Evolutionally we are prepared to go out and search for\ndifferent resources, such as food, water or shelter, even though nowadays we might use it to gain slightly different\nthings (like a morning coffee or a salary). The drive to do so is provided by dopamine – which is, as we already know, a\nhormonal fuel of motivation. This mechanism is pretty old and it can be observed widely across the animal kingdom.</p>\n\n<p>When the resources are found we experience a dopamine release — that is an effect of the reward mechanism in our\nmesocorticolimbic pathway. Now, in order to make us go and search for the resources again, the dopamine level must drop,\nso that we feel the lack of those resources as unpleasurable and seek for them again.</p>\n\n<p>The dopamine level drops <strong>lower</strong> than the baseline and the extent of the drop is proportional to the height of the\npeak. Why? The drop of the dopamine level is caused by releasing available dopamine from synaptic vesicles – small\nstructures in the dopaminergic neurons. In time the vesicles get depleted of dopamine – we can only release the hormone\nthat is already there, ready to be deployed. After the release there isn’t enough dopamine in the vesicles to keep the\nbaseline level. It will go back to the baseline eventually, as the neurons produce more of it, but for a period of time\nit’s going to remain low.</p>\n\n<p>Continuous peaks in dopamine level may eventually lead to drop of the baseline level. In that situation a person’s\nbrain, seeking for another reward to elevate it, will try repeating previous dopamine-increasing behaviours. A cascade\nof peaks and drops with repeated behaviours is a mechanism for addiction. This is something that may happen over\nexcessive usage of certain substances but also with social media. Incoming likes, comments and notifications or\nscrollable, neverending feed of videos — all of these generate peaks of dopamine. When we spend time on social media\nexperiencing peak after peak we may start feeling less and less satisfaction but still feel the urge to scroll further —\ndue to the mechanism I have just described. That would explain why social media addiction is such a great challenge\nfor our society.</p>\n\n<h2 id=\"how-to-get-and-stay-motivated\">How to get and stay motivated</h2>\n\n<p>After that long lecture on neurobiology, those who are still with me may be asking the question “are we there yet”? Yes,\nwe are! That knowledge is going to let us dive into different strategies of managing our dopamine levels, hence\nmodulating our motivation.</p>\n\n<p><img src=\"/img/articles/2023-03-21-neuroscience-for-software-engineers-motivation/54e8c52c-c40e-4197-a0ec-d17be266ed90_text.gif\" alt=\"Are we there yet...? Asked Donkey from Shrek\" title=\"(from [Giphy](https://y.yarn.co/54e8c52c-c40e-4197-a0ec-d17be266ed90_text.gif)\" /></p>\n\n<h3 id=\"short-term-increase\">Short-term increase</h3>\n\n<p>There are multiple possibilities to invoke a peak of dopamine and give our bodies that immediate impulse lasting a few\nminutes or even seconds. We should be aware of them, both when we need those peaks and when we want to avoid them — and\nsoon you’ll know why.</p>\n\n<p>There is a significant number of substances that may increase the dopamine level above the baseline:</p>\n\n<ul>\n  <li>Chocolate might increase it up to 1,5 times, although it only lasts a few seconds.</li>\n  <li>Smoked nicotine or cocaine may cause a 2,5 times increase, amphetamine causes up to 10-fold increase (knowing that\nand how peak and baseline levels of dopamine work, explains the addictive effect those substances have).</li>\n  <li>Alcohol in low doses is also known to cause dopamine release.</li>\n  <li>Ingestion of herbs like saffron, rosemary or oregano may lead to elevation of dopamine levels.</li>\n  <li>Caffeine causes a rather modest increase of dopamine, but also increases sensitivity of some dopamine receptors as\nwell as their number and density. This is worth noting, especially for coffee-fueled machines like programmers – a cup\nof coffee in the morning will make us more susceptible to dopamine changes throughout the day.</li>\n</ul>\n\n<p>There are also several actions which we might take to induce a peak of dopamine like physical activity or thinking and\ntalking about things we enjoy. The former is rather subjective and the height of the peak depends on whether the person\nenjoys the activity itself. For those who do, it may double the dopamine level.</p>\n\n<p>The latter results from involvement of the prefrontal cortex in the mesocorticolimbic system. Do you remember the last\ntime when you’ve been telling somebody about that new thing you’d recently learned? How passionate you’ve felt and how\nhappy and excited you’ve been afterwards? The prefrontal cortex is responsible for assigning rational explanations and\nsubjective experiences to things we engage with. Recalling those interactions might cause a dopamine release and make us\nhappier and more motivated.</p>\n\n<h3 id=\"long-term-strategies\">Long-term strategies</h3>\n\n<p>As previously said, the peaks of the dopamine, especially one after the other, will cause the dopamine level to drop\nbelow the baseline. In order to maintain high levels of dopamine (hence high motivation) on a daily basis we should act\nlong-term and affect the baseline level as much as possible. There are ways to do it.</p>\n\n<h4 id=\"exposure-to-cold\">Exposure to cold</h4>\n\n<p>Research shows that when a human subject enters cold water (14°C) and stays there for up to an hour it leads to rapid\nincrease in norepinephrine and epinephrine (i.e. adrenaline) and also an increase in dopamine. Dopamine was observed to\ncontinuously rise up to 250% of baseline level and it stayed there for a few hours. It also limited release of cortisol\n— the stress hormone.</p>\n\n<p>An hour-long cold bath is too much for an average person, but the same effect (although on a smaller scale) can be\nacquired by more accessible measures. How about a quick cold shower before work to charge up on that dopamine? Or maybe\njoining a winter swimming community?</p>\n\n<p><img src=\"/img/articles/2023-03-21-neuroscience-for-software-engineers-motivation/giphy-downsized-large.gif\" alt=\"A man jumping into snow\" title=\"(from [Giphy](https://media.giphy.com/media/MpJJ7gWng24bjxrMiK/giphy-downsized-large.gif))\" /></p>\n\n<h4 id=\"avoiding-layers-of-dopamine-increasing-factors\">Avoiding layers of dopamine-increasing factors</h4>\n\n<p>Do you start working only with a big hot cup of coffee in your hand? Do you listen to loud music while programming? Or\nmaybe do you treat yourself with a sweet drink after a workout? Are there a lot of such rituals? You might want to\nconsider not having them on a daily basis.</p>\n\n<p>Every one of these rituals is a dopamine-increasing factor. As you’ve already read, multiple peaks of dopamine one on\ntop of the other might not be a great idea. Layering multiple dopamine-increasing factors on a regular basis might\nseriously affect our ability to release dopamine in general. Spiking the dopamine by multiple activities in a short\nperiod of time leads to lowering the baseline by depleting stored, ready-to-deploy dopamine. That may lead to lowering\nthe baseline dopamine level, what will result in lack of motivation and feeling low in general.</p>\n\n<p>So what should we do? Are those things bad for us? Well, not really. Sometimes these spikes of dopamine from listening\nto music or sweet treats are exactly what we need to get through the day. The key is to differentiate all these “extras”\nwhile we work. Listen to music while working — just not every time. Have that sweet drink — just not every day. Meet\nwith friends for a workout session — but also have these individual sessions once in a while.</p>\n\n<p>Some of us spend our time on meetings while trying to do our individual work at the same time. Some listen to podcasts\nwhile coding. We should keep in mind, though, that multitasking is another way of layering dopamine and doing that on a\ndaily basis will have a negative effect on general motivation.</p>\n\n<p><img src=\"/img/articles/2023-03-21-neuroscience-for-software-engineers-motivation/giphy.webp\" alt=\"A man multitasking at work \" title=\"(from [Giphy](\nhttps://media3.giphy.com/media/PvvSfSDFoAL5e/giphy.gif?cid=ecf05e47mym26elkkk7obya4xr8zj83hva1jlu12l7cvmglq&amp;rid=giphy.gif&amp;ct=g)\n)\" /></p>\n\n<p>Another factor we should keep in mind are distractions. Every email, every slack message, every push notification on\nyour phone will cause a small peak of dopamine. That makes it yet another thing to eliminate if you want to avoid\ndopamine layering.</p>\n\n<h4 id=\"focusing-on-intrinsic-motivation\">Focusing on intrinsic motivation</h4>\n\n<p>When we look at the sources of motivation we can divide them in two groups — external sources, such as meeting\nexpectations of other people, fame or financial compensation and intrinsic sources, like enjoyment during an activity or\nfulfilling a personal mission.</p>\n\n<p>What do you like to do after work? Is it playing video games, playing music, baking, practising yoga or maybe watching\nlectures on mathematics on YouTube? (don’t judge me…) Whatever this would be, I bet no one needs to encourage you to do\nthis — you have an intrinsic drive to go and do your thing. You could spend hours on it, and then you’ll feel happy and\nfulfilled. This is how intrinsic motivation works — no external reward is required for you to feel motivated. Wouldn’t\nit be great if you had that in your job?</p>\n\n<p>Research shows that intrinsic motivation brings better results than extrinsic motivation. One could ask a question —\nwhat if we brought those two things together? Well, the results might surprise you. Researchers gave out to participants\na rather enjoyable task like assembling the jigsaw puzzle or drawing and measured their motivation to do so. Then they\nintroduced small rewards for finishing the puzzle. Curiously, the participants were no longer as motivated as at the\nbeginning.</p>\n\n<p>The conclusion is that when we add an extrinsic motivation to an existing intrinsic one, we observe an overall decrease\nin willingness to do the activity!\nThis is what we call an undermining effect.</p>\n\n<p>The effect comes from the reward being perceived as the ultimate goal of the activity. When the reward comes at the end\nof the activity, only then is dopamine release activated, whereas it could be active during the whole time if only we\nmindfully focused on the joyful part of the activity itself. Introducing the reward leads to perceiving the whole\nexperience as less and less pleasurable over time.</p>\n\n<p>How to avoid the undermining effect? It’s rather simple. Don’t layer other sources of dopamine, avoid dopamine peaks\nright before and right after the activity and be mindful about your intrinsic motivation. But what if getting it done\nbecomes really hard? It is difficult to have intrinsic motivation at such times. A good tactic to try is\ntelling ourselves that overcoming those difficulties is a kind of pleasure, so we can activate our prefrontal cortex as\na part of the dopaminergic pathway and eventually get ourselves motivated.</p>\n\n<h4 id=\"thinking-positively-practising-gratitude-meditation\">Thinking positively, practising gratitude, meditation</h4>\n\n<p>Remember that aspect of the mesocorticolimbic pathway where thinking about something enjoyable caused a dopamine\nrelease? There is more to it! By repeatedly having positive or negative interactions with something we can make a\nsignificant impact on its rewarding or non-rewarding properties. It effectively means that focusing on positive aspects\nof our surroundings and activities will eventually lead to an increase of dopamine releases from engaging with it.</p>\n\n<p>Having said that, I would strongly encourage you to use different forms of appreciation or gratitude practice. Maybe try\njournaling a little at the end of the day? I dare you to think about 3 good things that happened to you at work every\nday and write it down.</p>\n\n<p>Research also shows that engaging in meditational practices leads to activation of reward-related areas of the brain.\nHaving a long-term habit of meditation and mindfulness will contribute to having sustained feelings of deep joy and\npeace, which is associated with higher dopamine levels.</p>\n\n<h2 id=\"summary\">Summary</h2>\n\n<p>You now know how your dopamine mechanisms work and how to use your biological hardware\nto modulate your overall motivation. What you should remember is that the thing most important for your\nmotivation is maintaining a high baseline dopamine level. Avoid dopamine peaks, differentiate stimuli when you work,\nuse other tactics such as exposing yourself to cold water or meditation. Also, keep your focus\nmostly (preferably only) on your intrinsic motivation to avoid the undermining effect. Now, go conquer the world!</p>\n\n<h2 id=\"references\">References</h2>\n\n<ol>\n  <li>Lee W, Reeve J, Xue Y, Xiong J. Neural differences between intrinsic reasons for doing versus extrinsic reasons for\ndoing: an fMRI study. Neurosci Res. 2012 May;73(1):68-72. doi: 10.1016/j.neures.2012.02.010. PMID: 23565014; PMCID:\nPMC3614004.</li>\n  <li>Liu, C., Goel, P. &amp; Kaeser, P.S. Spatial and temporal scales of dopamine transmission. Nat Rev Neurosci 22, 345–358 (\n2021). https://doi.org/10.1038/s41583-021-00455-7</li>\n  <li>Šrámek, P., Šimečková, M., Janský, L. et al. Human physiological responses to immersion into water of different\ntemperatures. Eur J Appl Physiol 81, 436–442 (2000). https://doi.org/10.1007/s004210050065</li>\n  <li>Volkow, N., Wang, GJ., Logan, J. et al. Caffeine increases striatal dopamine D2/D3 receptor availability in the human\nbrain. Transl Psychiatry 5, e549 (2015). https://doi.org/10.1038/tp.2015.46</li>\n  <li>Neuroscience. 2nd edition. Purves D, Augustine GJ, Fitzpatrick D, et al., editors. Sunderland (MA): Sinauer\nAssociates;</li>\n  <li>Vani Pariyadath, Joshua L. Gowin, Elliot A. Stein, Chapter 8 - Resting state functional connectivity analysis for\naddiction medicine: From individual loci to complex networks, Editor(s): Hamed Ekhtiari, Martin P. Paulus, Progress\nin Brain Research, Elsevier, Volume 224, 2016</li>\n  <li>Deci, E. L., Koestner, R., &amp; Ryan, R. M. (1999). A meta-analytic review of experiments examining the effects of\nextrinsic rewards on intrinsic motivation. Psychological Bulletin, 125(6),\n627–668. https://doi.org/10.1037/0033-2909.125.6.627</li>\n  <li>Chen W. Neural circuits provide insights into reward and aversion. Front Neural Circuits. 2022 Oct 28;16:1002485.\ndoi:\n10.3389/fncir.2022.1002485. PMID: 36389177; PMCID: PMC9650032.</li>\n  <li>Looby A, Zimmerman L, Livingston NR. Expectation for stimulant type modifies caffeine’s effects on mood and cognition\namong college students. Exp Clin Psychopharmacol. 2022 Oct;30(5):525-535. doi: 10.1037/pha0000448. Epub 2021 Mar 18.\nPMID: 33734725.</li>\n  <li>Arias-Carrión, O., Stamelou, M., Murillo-Rodríguez, E. et al. Dopaminergic reward system: a short integrative\nreview. Int Arch Med 3, 24 (2010)\n. https://doi.org/10.1186/1755-7682-3-24</li>\n  <li>Esch, Tobias. “The neurobiology of meditation and mindfulness.” Meditation–neuroscientific approaches and\nphilosophical implications. Springer, Cham, 2014. 153-173.</li>\n  <li>Di Chiara G. Alcohol and dopamine. Alcohol Health Res World. 1997;21(2):\n108-14. PMID: 15704345; PMCID: PMC6826820.</li>\n  <li>Farahani MS, Bahramsoltani R, Farzaei MH, Abdollahi M, Rahimi R. Plant-derived natural medicines for the management\nof depression: an overview of mechanisms of action. Rev Neurosci. 2015;26(3):305-21. doi:\n10.1515/revneuro-2014-0058. PMID: 25719303.</li>\n  <li>Mechan AO, Fowler A, Seifert N, Rieger H, Wöhrle T, Etheve S, Wyss A, Schüler G, Colletto B, Kilpert C, Aston J,\nElliott JM, Goralczyk R, Mohajeri MH. Monoamine reuptake inhibition and mood-enhancing potential of a specified\noregano extract. Br J Nutr. 2011 Apr;105(8):1150-63. doi:\n10.1017/S0007114510004940. Epub 2010 Dec 21. PMID: 21205415.</li>\n  <li>Khazdair MR, Boskabady MH, Hosseini M, Rezaee R, M Tsatsakis A. The effects of Crocus sativus (saffron) and its\nconstituents on nervous system: A review. Avicenna J Phytomed. 2015 Sep-Oct;5(5):376-91. PMID: 26468457; PMCID:\nPMC4599112.</li>\n  <li>Marques A, Marconcin P, Werneck AO, Ferrari G, Gouveia ÉR, Kliegel M, Peralta M, Ihle A. Bidirectional Association\nbetween Physical Activity and Dopamine Across Adulthood-A Systematic Review. Brain Sci. 2021 Jun 23;11(7):829. doi:\n10.3390/brainsci11070829. PMID: 34201523; PMCID:\nPMC8301978.</li>\n  <li>R. Kotarski “Inaczej”, Altenberg, 2020</li>\n  <li>A. Huberman, Controlling Your Dopamine For Motivation, Focus &amp; Satisfaction | Huberman Lab Podcast #39,\nYoutube, https://www.youtube.com/watch?v=QmOF0crdyRU</li>\n</ol>\n\n","contentSnippet":"Many of us, software engineers, have experienced those days when nothing really sparks joy in coding, debugging,\npreparing spikes or refining tasks for the next sprints. Obviously, we would like to have as few of such days as possible\nand go on with our work effectively. A solution to this definitely is not tormenting our brains with guilt and forced\nlabour. There are other ways, and I would like to invite you to explore them with me and learn a little about our\nnervous systems in the process. We’ll find out where the motivation comes from on a biological and psychological level.\nWe’ll also take a look at the changes you can introduce into your day to take advantage of certain mechanisms working\non a neural level and boost your motivation and productivity.\nThe neuroscience of motivation\nThe key to maintaining energy to work throughout the day is simple – getting and staying motivated. Even though it seems\nlike something not necessarily in our power, motivation can be, to an extent, consciously modulated once we know\nthe biological and psychological mechanisms behind it.\nThe source\nOn a neural level, the fuel of motivation is dopamine. Dopamine is a hormone (meaning it’s a messenger of the\nbody travelling through the bloodstream) and a neurotransmitter (which indicates its ability to affect communication between\nneurons).\nIn general, high levels of dopamine cause high drive, motivation and willingness to live, do and experience. Low levels\nof dopamine cause the opposite state — a lack of will to do any effort (doomscrolling or examining the contents of the\nfridge is still in our reach). How much dopamine is currently in our system, how much dopamine there was a moment ago\nand how much we remember enjoying a particular state is for our brains a way to set our level of motivation.\nThe workspace\nIn the context of motivation our main area of focus across the nervous system should be the mesocorticolimbic system,\nwhich is responsible for the reward mechanism.\nMesocorticolimbic system consists of dopaminergic and dopaminoceptive neurons — the former is a specialised kind of\nneurons that is capable of producing and emitting dopamine into our body; the latter is capable of detecting and\nreacting to the dopamine. The pathways of this system go through different areas of the brain — they extend from the\nventral tegmental area (VTA) to the part of the brain responsible for memory (hippocampus), reward, pleasure and movement\n(nucleus accumbens) and reasoning (prefrontal cortex).\n\nThe complexity of this structure might be a hint that there are a multiple implications of dopamine release, but\nalso many different ways to interact with this area.\nThe process\nWhen we talk about managing dopamine levels in healthy individuals, we actually should consider two different things:\nbaseline level, which is how much dopamine circulates in the body and determines how much dopamine we are capable\nof having,\npeak level, which tells us how much dopamine we have at the moment or as a result of a rapid change.\nBaseline level and peak level are closely related to each other. Evolutionally we are prepared to go out and search for\ndifferent resources, such as food, water or shelter, even though nowadays we might use it to gain slightly different\nthings (like a morning coffee or a salary). The drive to do so is provided by dopamine – which is, as we already know, a\nhormonal fuel of motivation. This mechanism is pretty old and it can be observed widely across the animal kingdom.\nWhen the resources are found we experience a dopamine release — that is an effect of the reward mechanism in our\nmesocorticolimbic pathway. Now, in order to make us go and search for the resources again, the dopamine level must drop,\nso that we feel the lack of those resources as unpleasurable and seek for them again.\nThe dopamine level drops lower than the baseline and the extent of the drop is proportional to the height of the\npeak. Why? The drop of the dopamine level is caused by releasing available dopamine from synaptic vesicles – small\nstructures in the dopaminergic neurons. In time the vesicles get depleted of dopamine – we can only release the hormone\nthat is already there, ready to be deployed. After the release there isn’t enough dopamine in the vesicles to keep the\nbaseline level. It will go back to the baseline eventually, as the neurons produce more of it, but for a period of time\nit’s going to remain low.\nContinuous peaks in dopamine level may eventually lead to drop of the baseline level. In that situation a person’s\nbrain, seeking for another reward to elevate it, will try repeating previous dopamine-increasing behaviours. A cascade\nof peaks and drops with repeated behaviours is a mechanism for addiction. This is something that may happen over\nexcessive usage of certain substances but also with social media. Incoming likes, comments and notifications or\nscrollable, neverending feed of videos — all of these generate peaks of dopamine. When we spend time on social media\nexperiencing peak after peak we may start feeling less and less satisfaction but still feel the urge to scroll further —\ndue to the mechanism I have just described. That would explain why social media addiction is such a great challenge\nfor our society.\nHow to get and stay motivated\nAfter that long lecture on neurobiology, those who are still with me may be asking the question “are we there yet”? Yes,\nwe are! That knowledge is going to let us dive into different strategies of managing our dopamine levels, hence\nmodulating our motivation.\n\nShort-term increase\nThere are multiple possibilities to invoke a peak of dopamine and give our bodies that immediate impulse lasting a few\nminutes or even seconds. We should be aware of them, both when we need those peaks and when we want to avoid them — and\nsoon you’ll know why.\nThere is a significant number of substances that may increase the dopamine level above the baseline:\nChocolate might increase it up to 1,5 times, although it only lasts a few seconds.\nSmoked nicotine or cocaine may cause a 2,5 times increase, amphetamine causes up to 10-fold increase (knowing that\nand how peak and baseline levels of dopamine work, explains the addictive effect those substances have).\nAlcohol in low doses is also known to cause dopamine release.\nIngestion of herbs like saffron, rosemary or oregano may lead to elevation of dopamine levels.\nCaffeine causes a rather modest increase of dopamine, but also increases sensitivity of some dopamine receptors as\nwell as their number and density. This is worth noting, especially for coffee-fueled machines like programmers – a cup\nof coffee in the morning will make us more susceptible to dopamine changes throughout the day.\nThere are also several actions which we might take to induce a peak of dopamine like physical activity or thinking and\ntalking about things we enjoy. The former is rather subjective and the height of the peak depends on whether the person\nenjoys the activity itself. For those who do, it may double the dopamine level.\nThe latter results from involvement of the prefrontal cortex in the mesocorticolimbic system. Do you remember the last\ntime when you’ve been telling somebody about that new thing you’d recently learned? How passionate you’ve felt and how\nhappy and excited you’ve been afterwards? The prefrontal cortex is responsible for assigning rational explanations and\nsubjective experiences to things we engage with. Recalling those interactions might cause a dopamine release and make us\nhappier and more motivated.\nLong-term strategies\nAs previously said, the peaks of the dopamine, especially one after the other, will cause the dopamine level to drop\nbelow the baseline. In order to maintain high levels of dopamine (hence high motivation) on a daily basis we should act\nlong-term and affect the baseline level as much as possible. There are ways to do it.\nExposure to cold\nResearch shows that when a human subject enters cold water (14°C) and stays there for up to an hour it leads to rapid\nincrease in norepinephrine and epinephrine (i.e. adrenaline) and also an increase in dopamine. Dopamine was observed to\ncontinuously rise up to 250% of baseline level and it stayed there for a few hours. It also limited release of cortisol\n— the stress hormone.\nAn hour-long cold bath is too much for an average person, but the same effect (although on a smaller scale) can be\nacquired by more accessible measures. How about a quick cold shower before work to charge up on that dopamine? Or maybe\njoining a winter swimming community?\n\nAvoiding layers of dopamine-increasing factors\nDo you start working only with a big hot cup of coffee in your hand? Do you listen to loud music while programming? Or\nmaybe do you treat yourself with a sweet drink after a workout? Are there a lot of such rituals? You might want to\nconsider not having them on a daily basis.\nEvery one of these rituals is a dopamine-increasing factor. As you’ve already read, multiple peaks of dopamine one on\ntop of the other might not be a great idea. Layering multiple dopamine-increasing factors on a regular basis might\nseriously affect our ability to release dopamine in general. Spiking the dopamine by multiple activities in a short\nperiod of time leads to lowering the baseline by depleting stored, ready-to-deploy dopamine. That may lead to lowering\nthe baseline dopamine level, what will result in lack of motivation and feeling low in general.\nSo what should we do? Are those things bad for us? Well, not really. Sometimes these spikes of dopamine from listening\nto music or sweet treats are exactly what we need to get through the day. The key is to differentiate all these “extras”\nwhile we work. Listen to music while working — just not every time. Have that sweet drink — just not every day. Meet\nwith friends for a workout session — but also have these individual sessions once in a while.\nSome of us spend our time on meetings while trying to do our individual work at the same time. Some listen to podcasts\nwhile coding. We should keep in mind, though, that multitasking is another way of layering dopamine and doing that on a\ndaily basis will have a negative effect on general motivation.\n\nAnother factor we should keep in mind are distractions. Every email, every slack message, every push notification on\nyour phone will cause a small peak of dopamine. That makes it yet another thing to eliminate if you want to avoid\ndopamine layering.\nFocusing on intrinsic motivation\nWhen we look at the sources of motivation we can divide them in two groups — external sources, such as meeting\nexpectations of other people, fame or financial compensation and intrinsic sources, like enjoyment during an activity or\nfulfilling a personal mission.\nWhat do you like to do after work? Is it playing video games, playing music, baking, practising yoga or maybe watching\nlectures on mathematics on YouTube? (don’t judge me…) Whatever this would be, I bet no one needs to encourage you to do\nthis — you have an intrinsic drive to go and do your thing. You could spend hours on it, and then you’ll feel happy and\nfulfilled. This is how intrinsic motivation works — no external reward is required for you to feel motivated. Wouldn’t\nit be great if you had that in your job?\nResearch shows that intrinsic motivation brings better results than extrinsic motivation. One could ask a question —\nwhat if we brought those two things together? Well, the results might surprise you. Researchers gave out to participants\na rather enjoyable task like assembling the jigsaw puzzle or drawing and measured their motivation to do so. Then they\nintroduced small rewards for finishing the puzzle. Curiously, the participants were no longer as motivated as at the\nbeginning.\nThe conclusion is that when we add an extrinsic motivation to an existing intrinsic one, we observe an overall decrease\nin willingness to do the activity!\nThis is what we call an undermining effect.\nThe effect comes from the reward being perceived as the ultimate goal of the activity. When the reward comes at the end\nof the activity, only then is dopamine release activated, whereas it could be active during the whole time if only we\nmindfully focused on the joyful part of the activity itself. Introducing the reward leads to perceiving the whole\nexperience as less and less pleasurable over time.\nHow to avoid the undermining effect? It’s rather simple. Don’t layer other sources of dopamine, avoid dopamine peaks\nright before and right after the activity and be mindful about your intrinsic motivation. But what if getting it done\nbecomes really hard? It is difficult to have intrinsic motivation at such times. A good tactic to try is\ntelling ourselves that overcoming those difficulties is a kind of pleasure, so we can activate our prefrontal cortex as\na part of the dopaminergic pathway and eventually get ourselves motivated.\nThinking positively, practising gratitude, meditation\nRemember that aspect of the mesocorticolimbic pathway where thinking about something enjoyable caused a dopamine\nrelease? There is more to it! By repeatedly having positive or negative interactions with something we can make a\nsignificant impact on its rewarding or non-rewarding properties. It effectively means that focusing on positive aspects\nof our surroundings and activities will eventually lead to an increase of dopamine releases from engaging with it.\nHaving said that, I would strongly encourage you to use different forms of appreciation or gratitude practice. Maybe try\njournaling a little at the end of the day? I dare you to think about 3 good things that happened to you at work every\nday and write it down.\nResearch also shows that engaging in meditational practices leads to activation of reward-related areas of the brain.\nHaving a long-term habit of meditation and mindfulness will contribute to having sustained feelings of deep joy and\npeace, which is associated with higher dopamine levels.\nSummary\nYou now know how your dopamine mechanisms work and how to use your biological hardware\nto modulate your overall motivation. What you should remember is that the thing most important for your\nmotivation is maintaining a high baseline dopamine level. Avoid dopamine peaks, differentiate stimuli when you work,\nuse other tactics such as exposing yourself to cold water or meditation. Also, keep your focus\nmostly (preferably only) on your intrinsic motivation to avoid the undermining effect. Now, go conquer the world!\nReferences\nLee W, Reeve J, Xue Y, Xiong J. Neural differences between intrinsic reasons for doing versus extrinsic reasons for\ndoing: an fMRI study. Neurosci Res. 2012 May;73(1):68-72. doi: 10.1016/j.neures.2012.02.010. PMID: 23565014; PMCID:\nPMC3614004.\nLiu, C., Goel, P. & Kaeser, P.S. Spatial and temporal scales of dopamine transmission. Nat Rev Neurosci 22, 345–358 (\n2021). https://doi.org/10.1038/s41583-021-00455-7\nŠrámek, P., Šimečková, M., Janský, L. et al. Human physiological responses to immersion into water of different\ntemperatures. Eur J Appl Physiol 81, 436–442 (2000). https://doi.org/10.1007/s004210050065\nVolkow, N., Wang, GJ., Logan, J. et al. Caffeine increases striatal dopamine D2/D3 receptor availability in the human\nbrain. Transl Psychiatry 5, e549 (2015). https://doi.org/10.1038/tp.2015.46\nNeuroscience. 2nd edition. Purves D, Augustine GJ, Fitzpatrick D, et al., editors. Sunderland (MA): Sinauer\nAssociates;\nVani Pariyadath, Joshua L. Gowin, Elliot A. Stein, Chapter 8 - Resting state functional connectivity analysis for\naddiction medicine: From individual loci to complex networks, Editor(s): Hamed Ekhtiari, Martin P. Paulus, Progress\nin Brain Research, Elsevier, Volume 224, 2016\nDeci, E. L., Koestner, R., & Ryan, R. M. (1999). A meta-analytic review of experiments examining the effects of\nextrinsic rewards on intrinsic motivation. Psychological Bulletin, 125(6),\n627–668. https://doi.org/10.1037/0033-2909.125.6.627\nChen W. Neural circuits provide insights into reward and aversion. Front Neural Circuits. 2022 Oct 28;16:1002485.\ndoi:\n10.3389/fncir.2022.1002485. PMID: 36389177; PMCID: PMC9650032.\nLooby A, Zimmerman L, Livingston NR. Expectation for stimulant type modifies caffeine’s effects on mood and cognition\namong college students. Exp Clin Psychopharmacol. 2022 Oct;30(5):525-535. doi: 10.1037/pha0000448. Epub 2021 Mar 18.\nPMID: 33734725.\nArias-Carrión, O., Stamelou, M., Murillo-Rodríguez, E. et al. Dopaminergic reward system: a short integrative\nreview. Int Arch Med 3, 24 (2010)\n. https://doi.org/10.1186/1755-7682-3-24\nEsch, Tobias. “The neurobiology of meditation and mindfulness.” Meditation–neuroscientific approaches and\nphilosophical implications. Springer, Cham, 2014. 153-173.\nDi Chiara G. Alcohol and dopamine. Alcohol Health Res World. 1997;21(2):\n108-14. PMID: 15704345; PMCID: PMC6826820.\nFarahani MS, Bahramsoltani R, Farzaei MH, Abdollahi M, Rahimi R. Plant-derived natural medicines for the management\nof depression: an overview of mechanisms of action. Rev Neurosci. 2015;26(3):305-21. doi:\n10.1515/revneuro-2014-0058. PMID: 25719303.\nMechan AO, Fowler A, Seifert N, Rieger H, Wöhrle T, Etheve S, Wyss A, Schüler G, Colletto B, Kilpert C, Aston J,\nElliott JM, Goralczyk R, Mohajeri MH. Monoamine reuptake inhibition and mood-enhancing potential of a specified\noregano extract. Br J Nutr. 2011 Apr;105(8):1150-63. doi:\n10.1017/S0007114510004940. Epub 2010 Dec 21. PMID: 21205415.\nKhazdair MR, Boskabady MH, Hosseini M, Rezaee R, M Tsatsakis A. The effects of Crocus sativus (saffron) and its\nconstituents on nervous system: A review. Avicenna J Phytomed. 2015 Sep-Oct;5(5):376-91. PMID: 26468457; PMCID:\nPMC4599112.\nMarques A, Marconcin P, Werneck AO, Ferrari G, Gouveia ÉR, Kliegel M, Peralta M, Ihle A. Bidirectional Association\nbetween Physical Activity and Dopamine Across Adulthood-A Systematic Review. Brain Sci. 2021 Jun 23;11(7):829. doi:\n10.3390/brainsci11070829. PMID: 34201523; PMCID:\nPMC8301978.\nR. Kotarski “Inaczej”, Altenberg, 2020\nA. Huberman, Controlling Your Dopamine For Motivation, Focus & Satisfaction | Huberman Lab Podcast #39,\nYoutube, https://www.youtube.com/watch?v=QmOF0crdyRU","guid":"https://blog.allegro.tech/2023/03/neuroscience-for-software-engineers-motivation.html","categories":["tech","soft skills","neuroscience","productivity"],"isoDate":"2023-03-20T23:00:00.000Z","thumbnail":"images/post-headers/default.jpg"},{"title":"Automating the Cloud — hiding the complexity of hardware provisioning","link":"https://blog.allegro.tech/2023/03/provisioning-cloud-infrastructure.html","pubDate":"Fri, 10 Mar 2023 00:00:00 +0100","authors":{"author":[{"name":["Łukasz Rokita"],"photo":["https://blog.allegro.tech/img/authors/lukasz.rokita.jpg"],"url":["https://blog.allegro.tech/authors/lukasz.rokita"]}]},"content":"<p>Hardware is always hard. The amount of operations, maintenance and planning that goes into supporting a data center\nis a daunting challenge for any enterprise. Though often unseen, without hardware there is no software.</p>\n\n<p>Although software seems to be a well defined domain with stable tools, practices and languages, hardware has had no such luck.\nThat is why the complexities are often hidden.\nWe try to hide networks, disks and IO, memory and CPU behind abstractions pretending that those are all reliable components.</p>\n\n<p>That is also what Cloud computing promises. Resources available on demand, cheap, scalable and flexible The promise has its allure.\nIncreasingly, companies are beginning in the Cloud, migrating, or utilizing the Cloud as a buffer for unexpected surges in traffic.</p>\n\n<p>There is no doubt that Cloud and overall approach to hardware have matured in recent years,\nadopting practices that proved useful in software development.\nIn this post I would like to explain how Allegro tries to manage Cloud and hide its inherent intricacies.</p>\n\n<h2 id=\"infrastructure-as-code\">Infrastructure as Code</h2>\n\n<p>The cornerstone of hardware management is a methodology called Infrastructure as Code. Long gone are the days of brave men and women\nthat would roam data centers and manually install OS, plug cables into network interfaces and set up mainframes.\nRight now all those operations are still there but are abstracted away through a layer of standard components.</p>\n\n<p>Thus, every component can be set up as a piece of code. Each IaC tool has its own unique set of strengths and weaknesses,\nand it is crucial for teams to carefully weigh these factors before adoption.</p>\n\n<p>At Allegro we settled on <a href=\"https://www.terraform.io/\">Terraform</a>. Code deploying infrastructure has to be versioned, reviewed and then executed.\nWe also use a set of standard modules that enforce consistent setup. However, not everyone is a Cloud Engineer and not everyone has to be.\nThat is why we created yet another layer of abstraction that aims at simplifying IaC even further.</p>\n\n<h2 id=\"the-requirements\">The Requirements</h2>\n\n<p>We did that because our audience are Data Scientists and Data Analysts. People who, although they make heavy use of Cloud,\nshould be insulated from the complexities of its tools. Their day to day work focuses on finding new insights in the data\nand feeding them to the organization to help make the correct decisions.</p>\n\n<p>Knowing that, we had a simple requirement. Streamline creation of Cloud infrastructure that is needed to analyse and process large volumes of data.</p>\n\n<p>To assure eager adoption,\nwe needed to establish a set of standard tools, permissions, and practices that would be widely used among data analytics teams,\nand so we created an architecture that would support any current or future needs.</p>\n\n<h2 id=\"the-solution\">The Solution</h2>\n\n<p>The solution consists of four components:</p>\n<ul>\n  <li>DSL</li>\n  <li>Terraform modules</li>\n  <li>Artifact</li>\n  <li>Runtime</li>\n</ul>\n\n<h3 id=\"dsl\">DSL</h3>\n\n<p>We created a simple Domain Specific Language that aims at hiding any Cloud provider under common conventions.\nThis is what our production configuration looks like:</p>\n<div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"na\">infrastructure</span><span class=\"pi\">:</span>\n  <span class=\"na\">gcp</span><span class=\"pi\">:</span>\n    <span class=\"na\">schedulers</span><span class=\"pi\">:</span>\n      <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">my-team-composer</span>\n        <span class=\"na\">version</span><span class=\"pi\">:</span> <span class=\"s\">v2</span>\n        <span class=\"na\">parameters</span><span class=\"pi\">:</span>\n          <span class=\"na\">airflow_config_overrides</span><span class=\"pi\">:</span>\n            <span class=\"na\">email-email_backend</span><span class=\"pi\">:</span> <span class=\"s\">airflow.utils.email.send_email_smtp</span>\n            <span class=\"na\">smtp-smtp_host</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">smtp.gateway.my.domain\"</span>\n            <span class=\"na\">smtp-smtp_mail_from</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">my-team@allegro.pl\"</span>\n            <span class=\"na\">smtp-smtp_starttls</span><span class=\"pi\">:</span> <span class=\"s\">False</span>\n            <span class=\"na\">smtp-smtp_user</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">\"</span>\n          <span class=\"na\">pypi_packages</span><span class=\"pi\">:</span>\n            <span class=\"na\">jira</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">==2.0.0\"</span>\n            <span class=\"na\">google-api-core</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">==1.31.5\"</span>\n            <span class=\"na\">oauthlib</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">==3.1.0\"</span>\n            <span class=\"na\">allegro-composer-extras</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">==2.0.0rc8\"</span>\n    <span class=\"na\">processing_clusters</span><span class=\"pi\">:</span> <span class=\"s\">~</span>\n</code></pre></div></div>\n<p>Though the simplest possible configuration would look as follows:</p>\n\n<div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"na\">infrastructure</span><span class=\"pi\">:</span>\n  <span class=\"na\">gcp</span><span class=\"pi\">:</span>\n    <span class=\"na\">schedulers</span><span class=\"pi\">:</span>\n      <span class=\"pi\">-</span> <span class=\"na\">name</span><span class=\"pi\">:</span> <span class=\"s\">my-team-composer</span>\n</code></pre></div></div>\n<p>In the background this gets translated into Terraform code that uses our custom modules and defaults.\nAdvanced users are not constrained since we also allow for pure Terraform code instead of our DSL.\nOne has to choose freedom and maintenance cost over defaults and ease of getting started.</p>\n\n<h3 id=\"artifact\">Artifact</h3>\n\n<p>Once the IaC gets reviewed and accepted, whether DSL or Terraform, it gets packaged into an artifact.\nThe artifact is an immutable, versioned archive that contains infrastructure’s definition.\nWe prevent manual changes by revoking permissions in the the Cloud. This means that we have a controlled and auditable environment.\nAn added bonus is that we can easily roll back to the previous version should the change prove wrong.</p>\n\n<p>Internally, the artifact is a simple zip archive that can be extracted and inspected by hand to see whether it really contains what we expect.</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>unzip artifact.zip\nArchive:  artifact.zip\n   creating: infrastructure/\n   creating: infrastructure/prod/\n  inflating: infrastructure/prod/main.yaml\n  inflating: infrastructure/prod/data-engine-backend.tf\n  inflating: infrastructure/prod/main.tf\n  inflating: infrastructure/prod/output.tf\n   creating: infrastructure/test/\n  inflating: infrastructure/test/main.yaml\n  inflating: infrastructure/test/data-engine-backend.tf\n  inflating: infrastructure/test/main.tf\n  inflating: infrastructure/test/output.tf\n   creating: infrastructure/dev/\n  inflating: infrastructure/dev/main.yaml\n  inflating: infrastructure/dev/data-engine-backend.tf\n  inflating: infrastructure/dev/main.tf\n  inflating: infrastructure/dev/output.tf\n  inflating: tycho.yaml\n  inflating: metadata.yaml\n</code></pre></div></div>\n<h3 id=\"terraform-modules\">Terraform modules</h3>\n\n<p>We wrap and repackage external Terraform modules.\nWe do that to provide sane defaults and create conventions that will be consistent across the entire organisation.\nWe also provide libraries that integrate with these conventions so that users can use advanced functionalities\nwithout thinking about setup choices. <em>They just work</em>.</p>\n\n<h3 id=\"runtime\">Runtime</h3>\n\n<p>At runtime the user has to go to their infrastructure project, choose which infrastructure version they would like to deploy\nand observe the changes as they are executed live, in the Cloud. This is what it looks like:</p>\n\n<p><img src=\"/img/articles/2023-03-10-provisioning-cloud-infrastructure/appconsole.png\" alt=\"console logs\" /></p>\n\n<p>Under the hood a K8s job is created which uses a dedicated Docker runtime that helps us control environment versions\nand the overall process. This image is also quite useful for debugging and development.\nSince we have access to the artifact and runtime environment the work is easy and done comfortably on our own machine.</p>\n\n<p>K8s jobs have another useful feature - they are independent.\nWe have a guaranteed stable environment that gets provisioned and cleaned up on demand and is separated from other jobs.\nThe orchestration is automated and supervised so that users need not think about installing Docker, Terraform or any other tool that\nwould otherwise be required and we have the freedom to change the process (provided that we stay compatible).</p>\n\n<h2 id=\"the-good\">The Good</h2>\n\n<p>From my point of view the good parts are what every engineer likes about a solution.</p>\n<ul>\n  <li>Ease of use</li>\n  <li>Extendability</li>\n  <li>Clean and repeatable deployments</li>\n  <li>Observability and debuggability</li>\n</ul>\n\n<p>We achieved that by packaging the deployment into a couple of simple, decoupled steps.\nWe based the solution on an existing process for microservices, which should already look familiar to everyone at Allegro.\nWe provide extensive documentation, support for all people that use our deployment process, and try to exhaustively test every change\nso that users can focus on what’s important in their day to day tasks and think of Cloud as just another data center.</p>\n\n<h2 id=\"the-bad\">The Bad</h2>\n\n<p>There is no free lunch and that is also the case with provisioning infrastructure.\nAlthough we did our best to create a coherent and enjoyable environment there are shortcomings that could not be eliminated.</p>\n\n<p>We need to acknowledge that Cloud is as fickle as the wind.\nThough everyone does their best to navigate its torrents, there is no question that we can’t completely hide the hardware.\nThus we sometimes land on an island of incoherent state. Occasionally, the automatic processes fail to apply changes.\nThe runtime thinks that the infrastructure should look different than it is actually provisioned, reports that\nit can’t reconcile the state automatically and fails. This requires manual intervention which always worsens the user experience.</p>\n\n<p>At the end of the day Cloud uses different primitives than software does and Infrastructure as Code can’t address that.\nYou don’t have atomic operations so provisioning a service can fail or land in an unknown state.\nYou also can’t run unit tests for infrastructure without actually running a deployment.\nIn essence you have a Schrödingers Cloud - you won’t be sure what will happen until you execute your change.\nThis contrasts with all that we know and came to love about software which we try to test in all possible scenarios.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>Our migration to Cloud is an ongoing process. This may be a never ending challenge as both Cloud and our organization evolve.\nWe needed to create a whole new environment that would be both flexible and invisible to the users.\nBy using some simple patterns and tools we encapsulated infrastructure provisioning in components used for microservices.\nAdditionally these components are testable and extendable which helps adapt to changes and users’ feedback.</p>\n\n<p>At the moment of writing this the solution has been running in production for six months.\nMore than one thousand deployments have been made to production and countless more to dev and test.</p>\n\n<p>I hope this post will spark your creativity and inspire new ways of thinking about Cloud provisioning.</p>\n","contentSnippet":"Hardware is always hard. The amount of operations, maintenance and planning that goes into supporting a data center\nis a daunting challenge for any enterprise. Though often unseen, without hardware there is no software.\nAlthough software seems to be a well defined domain with stable tools, practices and languages, hardware has had no such luck.\nThat is why the complexities are often hidden.\nWe try to hide networks, disks and IO, memory and CPU behind abstractions pretending that those are all reliable components.\nThat is also what Cloud computing promises. Resources available on demand, cheap, scalable and flexible The promise has its allure.\nIncreasingly, companies are beginning in the Cloud, migrating, or utilizing the Cloud as a buffer for unexpected surges in traffic.\nThere is no doubt that Cloud and overall approach to hardware have matured in recent years,\nadopting practices that proved useful in software development.\nIn this post I would like to explain how Allegro tries to manage Cloud and hide its inherent intricacies.\nInfrastructure as Code\nThe cornerstone of hardware management is a methodology called Infrastructure as Code. Long gone are the days of brave men and women\nthat would roam data centers and manually install OS, plug cables into network interfaces and set up mainframes.\nRight now all those operations are still there but are abstracted away through a layer of standard components.\nThus, every component can be set up as a piece of code. Each IaC tool has its own unique set of strengths and weaknesses,\nand it is crucial for teams to carefully weigh these factors before adoption.\nAt Allegro we settled on Terraform. Code deploying infrastructure has to be versioned, reviewed and then executed.\nWe also use a set of standard modules that enforce consistent setup. However, not everyone is a Cloud Engineer and not everyone has to be.\nThat is why we created yet another layer of abstraction that aims at simplifying IaC even further.\nThe Requirements\nWe did that because our audience are Data Scientists and Data Analysts. People who, although they make heavy use of Cloud,\nshould be insulated from the complexities of its tools. Their day to day work focuses on finding new insights in the data\nand feeding them to the organization to help make the correct decisions.\nKnowing that, we had a simple requirement. Streamline creation of Cloud infrastructure that is needed to analyse and process large volumes of data.\nTo assure eager adoption,\nwe needed to establish a set of standard tools, permissions, and practices that would be widely used among data analytics teams,\nand so we created an architecture that would support any current or future needs.\nThe Solution\nThe solution consists of four components:\nDSL\nTerraform modules\nArtifact\nRuntime\nDSL\nWe created a simple Domain Specific Language that aims at hiding any Cloud provider under common conventions.\nThis is what our production configuration looks like:\n\ninfrastructure:\n  gcp:\n    schedulers:\n      - name: my-team-composer\n        version: v2\n        parameters:\n          airflow_config_overrides:\n            email-email_backend: airflow.utils.email.send_email_smtp\n            smtp-smtp_host: \"smtp.gateway.my.domain\"\n            smtp-smtp_mail_from: \"my-team@allegro.pl\"\n            smtp-smtp_starttls: False\n            smtp-smtp_user: \"\"\n          pypi_packages:\n            jira: \"==2.0.0\"\n            google-api-core: \"==1.31.5\"\n            oauthlib: \"==3.1.0\"\n            allegro-composer-extras: \"==2.0.0rc8\"\n    processing_clusters: ~\n\n\nThough the simplest possible configuration would look as follows:\n\ninfrastructure:\n  gcp:\n    schedulers:\n      - name: my-team-composer\n\n\nIn the background this gets translated into Terraform code that uses our custom modules and defaults.\nAdvanced users are not constrained since we also allow for pure Terraform code instead of our DSL.\nOne has to choose freedom and maintenance cost over defaults and ease of getting started.\nArtifact\nOnce the IaC gets reviewed and accepted, whether DSL or Terraform, it gets packaged into an artifact.\nThe artifact is an immutable, versioned archive that contains infrastructure’s definition.\nWe prevent manual changes by revoking permissions in the the Cloud. This means that we have a controlled and auditable environment.\nAn added bonus is that we can easily roll back to the previous version should the change prove wrong.\nInternally, the artifact is a simple zip archive that can be extracted and inspected by hand to see whether it really contains what we expect.\n\nunzip artifact.zip\nArchive:  artifact.zip\n   creating: infrastructure/\n   creating: infrastructure/prod/\n  inflating: infrastructure/prod/main.yaml\n  inflating: infrastructure/prod/data-engine-backend.tf\n  inflating: infrastructure/prod/main.tf\n  inflating: infrastructure/prod/output.tf\n   creating: infrastructure/test/\n  inflating: infrastructure/test/main.yaml\n  inflating: infrastructure/test/data-engine-backend.tf\n  inflating: infrastructure/test/main.tf\n  inflating: infrastructure/test/output.tf\n   creating: infrastructure/dev/\n  inflating: infrastructure/dev/main.yaml\n  inflating: infrastructure/dev/data-engine-backend.tf\n  inflating: infrastructure/dev/main.tf\n  inflating: infrastructure/dev/output.tf\n  inflating: tycho.yaml\n  inflating: metadata.yaml\n\n\nTerraform modules\nWe wrap and repackage external Terraform modules.\nWe do that to provide sane defaults and create conventions that will be consistent across the entire organisation.\nWe also provide libraries that integrate with these conventions so that users can use advanced functionalities\nwithout thinking about setup choices. They just work.\nRuntime\nAt runtime the user has to go to their infrastructure project, choose which infrastructure version they would like to deploy\nand observe the changes as they are executed live, in the Cloud. This is what it looks like:\n\nUnder the hood a K8s job is created which uses a dedicated Docker runtime that helps us control environment versions\nand the overall process. This image is also quite useful for debugging and development.\nSince we have access to the artifact and runtime environment the work is easy and done comfortably on our own machine.\nK8s jobs have another useful feature - they are independent.\nWe have a guaranteed stable environment that gets provisioned and cleaned up on demand and is separated from other jobs.\nThe orchestration is automated and supervised so that users need not think about installing Docker, Terraform or any other tool that\nwould otherwise be required and we have the freedom to change the process (provided that we stay compatible).\nThe Good\nFrom my point of view the good parts are what every engineer likes about a solution.\nEase of use\nExtendability\nClean and repeatable deployments\nObservability and debuggability\nWe achieved that by packaging the deployment into a couple of simple, decoupled steps.\nWe based the solution on an existing process for microservices, which should already look familiar to everyone at Allegro.\nWe provide extensive documentation, support for all people that use our deployment process, and try to exhaustively test every change\nso that users can focus on what’s important in their day to day tasks and think of Cloud as just another data center.\nThe Bad\nThere is no free lunch and that is also the case with provisioning infrastructure.\nAlthough we did our best to create a coherent and enjoyable environment there are shortcomings that could not be eliminated.\nWe need to acknowledge that Cloud is as fickle as the wind.\nThough everyone does their best to navigate its torrents, there is no question that we can’t completely hide the hardware.\nThus we sometimes land on an island of incoherent state. Occasionally, the automatic processes fail to apply changes.\nThe runtime thinks that the infrastructure should look different than it is actually provisioned, reports that\nit can’t reconcile the state automatically and fails. This requires manual intervention which always worsens the user experience.\nAt the end of the day Cloud uses different primitives than software does and Infrastructure as Code can’t address that.\nYou don’t have atomic operations so provisioning a service can fail or land in an unknown state.\nYou also can’t run unit tests for infrastructure without actually running a deployment.\nIn essence you have a Schrödingers Cloud - you won’t be sure what will happen until you execute your change.\nThis contrasts with all that we know and came to love about software which we try to test in all possible scenarios.\nConclusion\nOur migration to Cloud is an ongoing process. This may be a never ending challenge as both Cloud and our organization evolve.\nWe needed to create a whole new environment that would be both flexible and invisible to the users.\nBy using some simple patterns and tools we encapsulated infrastructure provisioning in components used for microservices.\nAdditionally these components are testable and extendable which helps adapt to changes and users’ feedback.\nAt the moment of writing this the solution has been running in production for six months.\nMore than one thousand deployments have been made to production and countless more to dev and test.\nI hope this post will spark your creativity and inspire new ways of thinking about Cloud provisioning.","guid":"https://blog.allegro.tech/2023/03/provisioning-cloud-infrastructure.html","categories":["java","k8s","cloud","gcp","terraform","iac"],"isoDate":"2023-03-09T23:00:00.000Z","thumbnail":"images/post-headers/java.png"},{"title":"Onion Architecture","link":"https://blog.allegro.tech/2023/02/onion-architecture.html","pubDate":"Mon, 13 Feb 2023 00:00:00 +0100","authors":{"author":[{"name":["Tomasz Tarczyński"],"photo":["https://blog.allegro.tech/img/authors/tomasz.tarczynski.jpg"],"url":["https://blog.allegro.tech/authors/tomasz.tarczynski"]}]},"content":"<p>Software Architecture is an elusive thing which, if neglected, can lead to a hard-to-develop and maintain codebase, and\nin more drastic circumstances to the failure of a product. This article discusses one of the backend application\narchitecture styles which proved to be successful in providing a good foundation for building and maintaining an\napplication in the long run: Onion Architecture.</p>\n\n<h2 id=\"onion-architecture\">Onion Architecture</h2>\n\n<p>Onion Architecture is a software architectural style which strongly promotes the separation of concerns between the most\nimportant part of a business application — the domain code — and its technical aspects like HTTP or database. It does so\nwith ideas similar to <a href=\"https://en.wikipedia.org/wiki/Hexagonal_architecture_(software)\">Hexagonal Architecture</a>,\n<a href=\"/2021/12/clean-architecture-story.html\">Clean Architecture</a> and\n<a href=\"https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html\">other related architecture styles</a>.</p>\n\n<p>This post gives a description of the ideas of Onion Architecture and discusses a sample implementation which explicitly\ndefines layers in the code and build setup.</p>\n\n<p>Additional complexity to the build setup and extra learning curve introduced by the layered approach pays back during\ndevelopment. It reduces the cognitive load on the programmer by giving a more concrete structural foundation and guidance.</p>\n\n<h3 id=\"the-repository\">The Repository</h3>\n\n<p>The code samples are taken from an example repository, which you can find\non <a href=\"https://github.com/tarczynskitomek/onion-library\">GitHub</a>.</p>\n\n<h3 id=\"why-does-software-architecture-matter\">Why does Software Architecture matter?</h3>\n\n<p>During my Engineering career, I’ve worked on multiple projects using different architectural styles. From a happy-go-lucky\napproach without any obvious structure, through “classic”<sup id=\"fnref:1\" role=\"doc-noteref\"><a href=\"#fn:1\" class=\"footnote\" rel=\"footnote\">1</a></sup> three-tier enterprise style, to highly structured\narchitecture, reflected by the setup of the build tool and supported by the compiler.</p>\n\n<p>The experience of working on those projects was also very different. Having to introduce a change in a shapeless blob of\nspaghetti code was always a painful experience, connected with stressful moments of <em>Have I broken something?</em> Or <em>Oh\nno! A gazillion of unrelated tests broke…</em></p>\n\n<p>On the other hand, working in a more rigid, but at the same time more expressive, and structured environment of\na well-architected application, was a breeze and a real pleasure. Not to mention that the time required to introduce the\nchange was smaller, and the estimates were more precise and predictable.</p>\n\n<p>Good architecture guides the implementation makes it easy to introduce new changes, and — to some degree — prevents\nless experienced team members from making doubtful decisions. It allows developers to focus on the value-providing\nimplementation rather than thinking <em>Hmm where should I put this class?</em>.</p>\n\n<p>Last but not least, software architecture is often defined as <em>the things that are hard to change</em>, so choosing a proper\narchitectural approach to your new application is of key importance to its future development and maintenance.</p>\n\n<h3 id=\"about-the-onion\">About the Onion</h3>\n\n<p>The idea of Onion Architecture, first introduced by Jeffrey Palermo in\na <a href=\"https://jeffreypalermo.com/2008/07/the-onion-architecture-part-1/\">series of articles</a>, is similar to other clean\narchitecture approaches presented in Robert “Uncle Bob” Martin’s\n<a href=\"https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html\">blog post</a>, his book\n<a href=\"https://www.amazon.com/Clean-Architecture-Craftsmans-Software-Structure/dp/0134494164\">Clean Architecture</a>, and\nquite recently on our <a href=\"/2021/12/clean-architecture-story.html\">blog</a>. It can be successfully used as an alternative to a\npopular Hexagonal / Ports and Adapters architecture, and as such is predominantly used in the backend, business\napplications and services.</p>\n\n<p>The core concept in all the above styles is the same — to make the domain the most central part of the application, and\nremove all infrastructure concerns, such as talking via HTTP, messaging, database mapping, testing, etc., away from the\ndomain code. The core of the business logic should be free (in theory at least) from any of the technical, and\nframework-related problems, allowing for easy testing and rapid development.</p>\n\n<p>To put it using Uncle Bob’s words: <em>Though these architectures all vary somewhat in their details, they are very\nsimilar. They all have the same objective, which is the separation of concerns. They all achieve this separation by\ndividing the software into layers. Each has at least one layer for business rules, and another for interfaces</em>.</p>\n\n<p>The main difference I’ve found in the implementations of Hexagonal Architecture and Onion Architecture lies mostly in\nthe overall, more structured approach to the code layout of the latter. Both styles rely on the conscious usage of\ninterfaces, and the <code class=\"language-plaintext highlighter-rouge\">Dependency Inversion Principle</code>, which is the layer and encapsulation, but the Onion, like a real vegetable, has explicitly defined layers. Making the concept a\nfirst-class citizen represented in the code guides implementation and gives more clear overall structure to the\ncodebase.</p>\n\n<p>This Architecture style does have some learning curve for developers in the project, but once mastered, pays back many\ntimes. Finally, as with every solution in the IT industry, it is not a one-size-fits-all, and you should always consider\nif the architectural style matches your needs.</p>\n\n<h3 id=\"the-onion-has-layers\">The Onion has Layers</h3>\n\n<p>Onion Architecture is a form of layered architecture. The main difference between “the classic” three-tier architecture\nand the Onion, is that every outer layer sees classes from all inner layers, not only the one directly below. Moreover,\nthe dependency direction always goes from the outside to the inside, never the other way around.</p>\n\n<p>But wait, what are the layers of Onion Architecture, what do they describe, and why do they matter?</p>\n\n<p>There are three<sup id=\"fnref:3\" role=\"doc-noteref\"><a href=\"#fn:3\" class=\"footnote\" rel=\"footnote\">2</a></sup> main layers in Onion Architecture:</p>\n\n<ul>\n  <li>The domain layer</li>\n  <li>The application layer</li>\n  <li>The infrastructure layer\neach of which has its responsibilities.</li>\n</ul>\n\n<p><img src=\"/img/articles/2023-02-13-onion-architecture/onion-layers.png\" alt=\"Onion Architecture Layers\" /></p>\n\n<h4 id=\"the-domain-layer\">The Domain Layer</h4>\n\n<p>This is the layer where you place classes describing the core of your business.</p>\n\n<p>Let’s use a simple example. An application written to help manage a Library would most probably have classes like Book,\nReader, Copy and so on. The classes, relations and interactions between them describe the core of the domain of the\napplication, i.e. what business needs it fulfils and in what way. In the Library, there would be a process of adding new\ntitles to the catalogue, a process of borrowing and returning copies of a book, charging readers for overdue books, and\nmany more.</p>\n\n<p>A sample domain class could look like the one below:</p>\n\n<div class=\"language-java highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>\n<span class=\"nd\">@ToString</span>\n<span class=\"nd\">@EqualsAndHashCode</span><span class=\"o\">(</span><span class=\"n\">of</span> <span class=\"o\">=</span> <span class=\"s\">\"id\"</span><span class=\"o\">)</span>\n<span class=\"nd\">@AllArgsConstructor</span><span class=\"o\">(</span><span class=\"n\">access</span> <span class=\"o\">=</span> <span class=\"nc\">AccessLevel</span><span class=\"o\">.</span><span class=\"na\">PRIVATE</span><span class=\"o\">)</span>\n<span class=\"kd\">abstract</span> <span class=\"n\">sealed</span> <span class=\"kd\">class</span> <span class=\"nc\">Book</span> <span class=\"o\">{</span>\n\n    <span class=\"kd\">protected</span> <span class=\"kd\">final</span> <span class=\"nc\">BookId</span> <span class=\"n\">id</span><span class=\"o\">;</span>\n    <span class=\"kd\">protected</span> <span class=\"kd\">final</span> <span class=\"nc\">Version</span> <span class=\"n\">version</span><span class=\"o\">;</span>\n    <span class=\"kd\">protected</span> <span class=\"kd\">final</span> <span class=\"nc\">AuthorId</span> <span class=\"n\">author</span><span class=\"o\">;</span>\n    <span class=\"kd\">protected</span> <span class=\"kd\">final</span> <span class=\"nc\">Title</span> <span class=\"n\">title</span><span class=\"o\">;</span>\n    <span class=\"kd\">protected</span> <span class=\"kd\">final</span> <span class=\"nc\">CreatedAt</span> <span class=\"n\">createdAt</span><span class=\"o\">;</span>\n    <span class=\"kd\">protected</span> <span class=\"kd\">final</span> <span class=\"nc\">ApprovedAt</span> <span class=\"n\">approvedAt</span><span class=\"o\">;</span>\n    <span class=\"kd\">protected</span> <span class=\"kd\">final</span> <span class=\"nc\">RejectedAt</span> <span class=\"n\">rejectedAt</span><span class=\"o\">;</span>\n    <span class=\"kd\">protected</span> <span class=\"kd\">final</span> <span class=\"nc\">ArchivedAt</span> <span class=\"n\">archivedAt</span><span class=\"o\">;</span>\n\n    <span class=\"c1\">// static factory method for assembling a new instance of a Book — hides the internal representation</span>\n    <span class=\"kd\">static</span> <span class=\"nc\">Book</span> <span class=\"nf\">create</span><span class=\"o\">(</span><span class=\"nc\">AuthorId</span> <span class=\"n\">author</span><span class=\"o\">,</span> <span class=\"nc\">Title</span> <span class=\"n\">title</span><span class=\"o\">,</span> <span class=\"nc\">CreatedAt</span> <span class=\"n\">createdAt</span><span class=\"o\">)</span> <span class=\"o\">{</span>\n        <span class=\"k\">return</span> <span class=\"k\">new</span> <span class=\"nf\">NewBook</span><span class=\"o\">(</span><span class=\"nc\">BookId</span><span class=\"o\">.</span><span class=\"na\">next</span><span class=\"o\">(),</span> <span class=\"nc\">Version</span><span class=\"o\">.</span><span class=\"na\">first</span><span class=\"o\">(),</span> <span class=\"n\">author</span><span class=\"o\">,</span> <span class=\"n\">title</span><span class=\"o\">,</span> <span class=\"n\">createdAt</span><span class=\"o\">);</span>\n    <span class=\"o\">}</span>\n\n    <span class=\"c1\">// One of the subclasses representing the current state of the book entity</span>\n    <span class=\"c1\">// Other subclasses omitted for brevity.</span>\n    <span class=\"kd\">private</span> <span class=\"kd\">static</span> <span class=\"kd\">final</span> <span class=\"kd\">class</span> <span class=\"nc\">NewBook</span> <span class=\"kd\">extends</span> <span class=\"nc\">Book</span> <span class=\"o\">{</span>\n\n        <span class=\"kd\">private</span> <span class=\"nf\">NewBook</span><span class=\"o\">(</span><span class=\"nc\">BookId</span> <span class=\"n\">id</span><span class=\"o\">,</span> <span class=\"nc\">Version</span> <span class=\"n\">version</span><span class=\"o\">,</span> <span class=\"nc\">AuthorId</span> <span class=\"n\">author</span><span class=\"o\">,</span> <span class=\"nc\">Title</span> <span class=\"n\">title</span><span class=\"o\">,</span> <span class=\"nc\">CreatedAt</span> <span class=\"n\">createdAt</span><span class=\"o\">)</span> <span class=\"o\">{</span>\n            <span class=\"kd\">super</span><span class=\"o\">(</span><span class=\"n\">id</span><span class=\"o\">,</span> <span class=\"n\">version</span><span class=\"o\">,</span> <span class=\"n\">author</span><span class=\"o\">,</span> <span class=\"n\">title</span><span class=\"o\">,</span> <span class=\"n\">createdAt</span><span class=\"o\">,</span> <span class=\"kc\">null</span><span class=\"o\">,</span> <span class=\"kc\">null</span><span class=\"o\">,</span> <span class=\"kc\">null</span><span class=\"o\">);</span>\n        <span class=\"o\">}</span>\n\n        <span class=\"nd\">@Override</span>\n        <span class=\"kd\">protected</span> <span class=\"nc\">BookSnapshot</span><span class=\"o\">.</span><span class=\"na\">Status</span> <span class=\"nf\">status</span><span class=\"o\">()</span> <span class=\"o\">{</span>\n            <span class=\"k\">return</span> <span class=\"nc\">BookSnapshot</span><span class=\"o\">.</span><span class=\"na\">Status</span><span class=\"o\">.</span><span class=\"na\">AWAITING_APPROVAL</span><span class=\"o\">;</span>\n        <span class=\"o\">}</span>\n\n        <span class=\"nd\">@Override</span>\n        <span class=\"nc\">Book</span> <span class=\"nf\">approve</span><span class=\"o\">(</span><span class=\"nc\">ApprovedAt</span> <span class=\"n\">approvedAt</span><span class=\"o\">)</span> <span class=\"o\">{</span>\n            <span class=\"k\">return</span> <span class=\"k\">new</span> <span class=\"nf\">ApprovedBook</span><span class=\"o\">(</span><span class=\"n\">id</span><span class=\"o\">,</span> <span class=\"n\">version</span><span class=\"o\">,</span> <span class=\"n\">author</span><span class=\"o\">,</span> <span class=\"n\">title</span><span class=\"o\">,</span> <span class=\"n\">createdAt</span><span class=\"o\">,</span> <span class=\"n\">approvedAt</span><span class=\"o\">);</span>\n        <span class=\"o\">}</span>\n\n        <span class=\"nd\">@Override</span>\n        <span class=\"nc\">Book</span> <span class=\"nf\">reject</span><span class=\"o\">(</span><span class=\"nc\">RejectedAt</span> <span class=\"n\">rejectedAt</span><span class=\"o\">)</span> <span class=\"o\">{</span>\n            <span class=\"k\">return</span> <span class=\"k\">new</span> <span class=\"nf\">RejectedBook</span><span class=\"o\">(</span><span class=\"n\">id</span><span class=\"o\">,</span> <span class=\"n\">version</span><span class=\"o\">,</span> <span class=\"n\">author</span><span class=\"o\">,</span> <span class=\"n\">title</span><span class=\"o\">,</span> <span class=\"n\">createdAt</span><span class=\"o\">,</span> <span class=\"n\">rejectedAt</span><span class=\"o\">);</span>\n        <span class=\"o\">}</span>\n    <span class=\"o\">}</span>\n\n    <span class=\"c1\">// Available domain operations</span>\n    <span class=\"nc\">Book</span> <span class=\"nf\">approve</span><span class=\"o\">(</span><span class=\"nc\">ApprovedAt</span> <span class=\"n\">approvedAt</span><span class=\"o\">)</span> <span class=\"o\">{</span>\n        <span class=\"k\">throw</span> <span class=\"k\">new</span> <span class=\"nf\">UnsupportedOperationException</span><span class=\"o\">(</span><span class=\"s\">\"Unsupported state transition. Cannot approve book in state [%s]\"</span>\n                <span class=\"o\">.</span><span class=\"na\">formatted</span><span class=\"o\">(</span><span class=\"n\">status</span><span class=\"o\">()));</span>\n    <span class=\"o\">}</span>\n\n    <span class=\"nc\">Book</span> <span class=\"nf\">reject</span><span class=\"o\">(</span><span class=\"nc\">RejectedAt</span> <span class=\"n\">rejectedAt</span><span class=\"o\">)</span> <span class=\"o\">{</span>\n        <span class=\"k\">throw</span> <span class=\"k\">new</span> <span class=\"nf\">UnsupportedOperationException</span><span class=\"o\">(</span><span class=\"s\">\"Unsupported state transition. Cannot reject book in state [%s]\"</span>\n                <span class=\"o\">.</span><span class=\"na\">formatted</span><span class=\"o\">(</span><span class=\"n\">status</span><span class=\"o\">()));</span>\n    <span class=\"o\">}</span>\n\n    <span class=\"nc\">Book</span> <span class=\"nf\">archive</span><span class=\"o\">(</span><span class=\"nc\">ArchivedAt</span> <span class=\"n\">archivedAt</span><span class=\"o\">)</span> <span class=\"o\">{</span>\n        <span class=\"k\">throw</span> <span class=\"k\">new</span> <span class=\"nf\">UnsupportedOperationException</span><span class=\"o\">(</span>\n                <span class=\"s\">\"Unsupported state transition. Cannot archive book in state [%s]\"</span><span class=\"o\">.</span><span class=\"na\">formatted</span><span class=\"o\">(</span><span class=\"n\">status</span><span class=\"o\">())</span>\n        <span class=\"o\">);</span>\n    <span class=\"o\">}</span>\n<span class=\"o\">}</span>\n</code></pre></div></div>\n\n<p>Since the domain changes the most — here is the place where you put all the new features, and business requirements — it\nshould be as easy as possible to modify and test. Thus, it should not be concerned which database is used in the\nproject, nor should it know which communication style, synchronous RPC calls, asynchronous messaging, or a mix of is\nused to trigger the logic or maybe that it’s triggered by unit tests and not real user interactions. This doesn’t mean\nof course, that the domain classes can’t have any dependencies. Like it the example above — the code uses Lombok\nannotations, generating the boilerplate which otherwise needs to be written by the programmer.</p>\n\n<h4 id=\"the-application-layer\">The Application Layer</h4>\n\n<p>This is the layer where you place your classes, which describe the use cases of the application and coordinate the work\nof the domain classes. For example, we can imagine that a new title added to the library undergoes an approval process:\nthe book is fetched from the repository, a timestamp of approval is generated, the book state (only new books can be\napproved) is checked, and if it’s OK, a modified book is then saved using the repository.</p>\n\n<p>The code describing such a use case can look like this:</p>\n\n<div class=\"language-java highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kd\">class</span> <span class=\"nc\">Books</span> <span class=\"o\">{</span>\n    <span class=\"c1\">// other fields and methods omitted</span>\n    <span class=\"kd\">public</span> <span class=\"nc\">BookSnapshot</span> <span class=\"nf\">approve</span><span class=\"o\">(</span><span class=\"nc\">BookId</span> <span class=\"n\">id</span><span class=\"o\">)</span> <span class=\"o\">{</span>\n        <span class=\"k\">return</span> <span class=\"n\">transactions</span><span class=\"o\">.</span><span class=\"na\">execute</span><span class=\"o\">(()</span> <span class=\"o\">-&gt;</span> <span class=\"o\">{</span>\n            <span class=\"kd\">final</span> <span class=\"nc\">Book</span> <span class=\"n\">book</span> <span class=\"o\">=</span> <span class=\"n\">bookRepository</span><span class=\"o\">.</span><span class=\"na\">getById</span><span class=\"o\">(</span><span class=\"n\">id</span><span class=\"o\">);</span>\n            <span class=\"kd\">final</span> <span class=\"nc\">ApprovedAt</span> <span class=\"n\">approvedAt</span> <span class=\"o\">=</span> <span class=\"k\">new</span> <span class=\"nc\">ApprovedAt</span><span class=\"o\">(</span><span class=\"n\">timeMachine</span><span class=\"o\">.</span><span class=\"na\">now</span><span class=\"o\">());</span>\n            <span class=\"kd\">final</span> <span class=\"nc\">Book</span> <span class=\"n\">approved</span> <span class=\"o\">=</span> <span class=\"n\">book</span><span class=\"o\">.</span><span class=\"na\">approve</span><span class=\"o\">(</span><span class=\"n\">approvedAt</span><span class=\"o\">);</span>\n            <span class=\"k\">return</span> <span class=\"n\">bookRepository</span><span class=\"o\">.</span><span class=\"na\">update</span><span class=\"o\">(</span><span class=\"n\">approved</span><span class=\"o\">).</span><span class=\"na\">snapshot</span><span class=\"o\">();</span>\n        <span class=\"o\">});</span>\n    <span class=\"o\">}</span>\n<span class=\"o\">}</span>\n\n</code></pre></div></div>\n\n<p>This is also the layer that “knows” which operations should be performed atomically, thus the transaction-related code\nis placed here. Note, however, that in the example above, the <code class=\"language-plaintext highlighter-rouge\">transactions</code> field is actually an interface reference.</p>\n\n<div class=\"language-java highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>\n<span class=\"nd\">@FunctionalInterface</span>\n<span class=\"kd\">public</span> <span class=\"kd\">interface</span> <span class=\"nc\">Transactions</span> <span class=\"o\">{</span>\n\n    <span class=\"o\">&lt;</span><span class=\"no\">T</span><span class=\"o\">&gt;</span> <span class=\"no\">T</span> <span class=\"nf\">execute</span><span class=\"o\">(</span><span class=\"nc\">Supplier</span><span class=\"o\">&lt;</span><span class=\"no\">T</span><span class=\"o\">&gt;</span> <span class=\"n\">operation</span><span class=\"o\">);</span>\n<span class=\"o\">}</span>\n</code></pre></div></div>\n\n<p>The application uses the <em>behaviour</em> expressed by the interface, the details of how the behaviour is executed lie in the\ninfrastructure layer.</p>\n\n<h4 id=\"the-infrastructure-layer\">The Infrastructure Layer</h4>\n\n<p>This layer, the outermost layer of Onion, is a place where all framework and technology related stuff goes. It tends to\nbe the most “thick” since it contains the implementations of the interfaces defined in the inner layers. Need an\nHTTP controller, a message listener or a database adapter (an implementation of repository interface defined at the domain layer)? Infrastructure is the place to go.</p>\n\n<p>The domain, although the most important part of the application, tends to be also the smallest in terms of code size.\nThe reverse is true about the infrastructure code — all the supporting mechanisms, which are placed at the\ninfrastructure layer, are the backbone which animates the domain behaviour, and as such that part of the service should\nnot be neglected.</p>\n\n<p>Staying with the example of the <code class=\"language-plaintext highlighter-rouge\">Transactions</code> interface, let’s take a look at possible implementations. A simple approach\nusing Spring’s programmatic transaction handling could look like this:</p>\n\n<div class=\"language-java highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>\n<span class=\"nd\">@Component</span>\n<span class=\"nd\">@AllArgsConstructor</span>\n<span class=\"kd\">class</span> <span class=\"nc\">JdbcTransactions</span> <span class=\"kd\">implements</span> <span class=\"nc\">Transactions</span> <span class=\"o\">{</span>\n\n    <span class=\"kd\">private</span> <span class=\"kd\">final</span> <span class=\"nc\">TransactionTemplate</span> <span class=\"n\">transactionTemplate</span><span class=\"o\">;</span>\n\n    <span class=\"nd\">@Override</span>\n    <span class=\"kd\">public</span> <span class=\"o\">&lt;</span><span class=\"no\">T</span><span class=\"o\">&gt;</span> <span class=\"no\">T</span> <span class=\"nf\">execute</span><span class=\"o\">(</span><span class=\"nc\">Supplier</span><span class=\"o\">&lt;</span><span class=\"no\">T</span><span class=\"o\">&gt;</span> <span class=\"n\">operation</span><span class=\"o\">)</span> <span class=\"o\">{</span>\n        <span class=\"k\">return</span> <span class=\"n\">transactionTemplate</span><span class=\"o\">.</span><span class=\"na\">execute</span><span class=\"o\">(</span><span class=\"n\">status</span> <span class=\"o\">-&gt;</span> <span class=\"n\">operation</span><span class=\"o\">.</span><span class=\"na\">get</span><span class=\"o\">());</span>\n    <span class=\"o\">}</span>\n<span class=\"o\">}</span>\n</code></pre></div></div>\n\n<p>and for unit test, one can set up a fake, noop implementation:</p>\n\n<div class=\"language-java highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kd\">class</span> <span class=\"nc\">NoOpTransactionsFake</span> <span class=\"kd\">implements</span> <span class=\"nc\">Transactions</span> <span class=\"o\">{</span>\n\n    <span class=\"nd\">@Override</span>\n    <span class=\"o\">&lt;</span><span class=\"no\">T</span><span class=\"o\">&gt;</span> <span class=\"no\">T</span> <span class=\"nf\">execute</span><span class=\"o\">(</span><span class=\"nc\">Supplier</span><span class=\"o\">&lt;</span><span class=\"no\">T</span><span class=\"o\">&gt;</span> <span class=\"n\">operation</span><span class=\"o\">)</span> <span class=\"o\">{</span>\n        <span class=\"n\">operation</span><span class=\"o\">.</span><span class=\"na\">get</span><span class=\"o\">()</span>\n    <span class=\"o\">}</span>\n<span class=\"o\">}</span>\n</code></pre></div></div>\n\n<h2 id=\"the-flavours-of-the-onion-or-how-to-represent-layers-in-code\">The Flavours of The Onion or how to represent layers in code?</h2>\n\n<p>There are two basic approaches to representing the layers in the code. The one that we used in our most recent\nproject was to use a package naming convention.</p>\n\n<p><img src=\"/img/articles/2023-02-13-onion-architecture/onion-packages.png\" alt=\"onion packages\" /></p>\n\n<p>Every domain package has three subpackages: domain, application and infrastructure. This method is clear, easy to\nunderstand and navigate, and does not require changes to the build tool setup. The downside is that, except for the\nagreed convention, and Code Review process to check them, there is no mechanism preventing you from using a class\ndefined in the application layer in the domain layer, thus breaking the direction of the dependencies. One can always\nuse such tools as <a href=\"https://www.archunit.org/\">ArchUnit</a> to write tests checking if there are no “prohibited” imports,\nbut in my opinion, we can do better by employing build tool modules support.</p>\n\n<h3 id=\"build-tools-to-the-rescue\">Build tools to the rescue</h3>\n\n<p>The more involved approach is to define compilation modules representing the layers. Its disadvantage is a more\ncomplicated build structure and setup of your build tool of choice. On the other side though, having the compiler on\nyour side is very helpful, and prevents the above-mentioned issue. The direction of the dependencies between layers is\nclearly defined in the module build files.</p>\n\n<div class=\"language-groovy highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// settings.gradle</span>\n<span class=\"n\">rootProject</span><span class=\"o\">.</span><span class=\"na\">name</span> <span class=\"o\">=</span> <span class=\"s1\">'onion'</span>\n\n<span class=\"n\">include</span><span class=\"o\">(</span><span class=\"s1\">'domain'</span><span class=\"o\">,</span> <span class=\"s1\">'application'</span><span class=\"o\">,</span> <span class=\"s1\">'infrastructure'</span><span class=\"o\">)</span>\n</code></pre></div></div>\n\n<p>Using Gradle setup as an example, one can define three modules — domain, application, and infrastructure —\nin <code class=\"language-plaintext highlighter-rouge\">settings.gradle</code> file. Then, in the build files corresponding to each of the modules, declare their dependencies,\nclearly defining the direction of dependencies.</p>\n\n<div class=\"language-groovy highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c1\">// /application/build.gradle</span>\n<span class=\"n\">dependencies</span> <span class=\"o\">{</span>\n    <span class=\"n\">implementation</span><span class=\"o\">(</span><span class=\"n\">project</span><span class=\"o\">(</span><span class=\"s1\">':domain'</span><span class=\"o\">))</span>\n<span class=\"o\">}</span>\n<span class=\"c1\">// /infrastructure/build.gradle</span>\n<span class=\"n\">plugins</span> <span class=\"o\">{</span>\n    <span class=\"n\">id</span> <span class=\"s1\">'org.springframework.boot'</span>\n    <span class=\"n\">id</span> <span class=\"s1\">'io.spring.dependency-management'</span>\n    <span class=\"n\">id</span> <span class=\"s1\">'com.revolut.jooq-docker'</span> <span class=\"n\">version</span> <span class=\"s1\">'0.3.7'</span>\n<span class=\"o\">}</span>\n\n<span class=\"n\">dependencies</span> <span class=\"o\">{</span>\n    <span class=\"n\">implementation</span><span class=\"o\">(</span><span class=\"n\">project</span><span class=\"o\">(</span><span class=\"s1\">':domain'</span><span class=\"o\">))</span>\n    <span class=\"n\">implementation</span><span class=\"o\">(</span><span class=\"n\">project</span><span class=\"o\">(</span><span class=\"s1\">':application'</span><span class=\"o\">))</span>\n\n    <span class=\"n\">implementation</span><span class=\"o\">(</span><span class=\"s1\">'org.springframework.boot:spring-boot-starter-web'</span><span class=\"o\">)</span>\n    <span class=\"n\">implementation</span><span class=\"o\">(</span><span class=\"s1\">'org.springframework.boot:spring-boot-starter-jooq'</span><span class=\"o\">)</span>\n\n    <span class=\"c1\">// other dependencies and settings removed for brevity</span>\n<span class=\"o\">}</span>\n</code></pre></div></div>\n\n<p>Notice, that the biggest file is the one for the infrastructure layer. It should not be a surprise by now. The\ninfrastructure has all the framework — in this case Spring Boot — database driver, and other dependencies, and itself\ndepends on both domain and application. There’s of course nothing preventing you from declaring extra dependencies,\nsay Lombok. The most important thing to note here is that with this build setup, it will not be possible to reverse the\norder of dependencies between the layers.</p>\n\n<h2 id=\"final-thoughts\">Final Thoughts</h2>\n\n<p>Problems Onion Architecture solves</p>\n\n<ul>\n  <li>A more structured, layered layout of the code makes code navigation easier and makes the relationship between\ndifferent parts of the codebase more visible at first glance</li>\n  <li>Loose coupling between the domain and the infrastructure</li>\n  <li>Coupling is towards the centre of The Onion — expressed by the relationship between the layers</li>\n  <li>(Usually) No coupling between the domain and the infrastructure concerns of the application</li>\n  <li>Build tool support in enforcing layers</li>\n</ul>\n\n<p>Problems Onion Architecture creates</p>\n<ul>\n  <li>Additional learning curve for new developers, and those used to other architecture styles</li>\n  <li>Increased overall complexity of the codebase — especially with the flavour utilising the modularizing capabilities of build tools such as Gradle or Maven</li>\n  <li>Not everyone likes the smell of it</li>\n</ul>\n\n<p>As mentioned above at the beginning of the article, Onion Architecture is not a one-size-fits-all solution. It has its\nlearning curve and is best suited for services with a clear domain definition. This makes it a bad choice, for more\ntechnical-oriented services, e.g. a high-throughput proxy written in a reactive framework.</p>\n\n<h3 id=\"footnotes\">Footnotes</h3>\n\n<div class=\"footnotes\" role=\"doc-endnotes\">\n  <ol>\n    <li id=\"fn:1\" role=\"doc-endnote\">\n      <p>The typical, “classic” enterprise architecture, usually consists of three layers: the presentation layer, the domain layer and the persistence (data) layer. The dependency direction goes top-down, and in the strict approach a layer sees only its nearest neighbour. The clear advantage is the separation of concerns, and the reduction of the scope of responsibilities of each layer. There are two issues though — that architecture style often leads to a so-called <a href=\"https://martinfowler.com/bliki/AnemicDomainModel.html\">anemic domain model</a>, since most of the business logic is placed in service classes, because, and that’s the second issue, domain classes depend on the persistence layer — and often become only data carriers without behaviour. For a comparison of different software architecture styles, see <a href=\"https://www.oreilly.com/library/view/software-architecture-patterns/9781491971437/\">Software Architecture Patterns</a> (e-book, pdf) <a href=\"#fnref:1\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;</a></p>\n    </li>\n    <li id=\"fn:3\" role=\"doc-endnote\">\n      <p>The number of layers may differ. The three-tier division is usually called Simplified Onion Architecture. Another possible rendition of the division is to have five layers with a separate Repository layer above the domain and a service layer above the repositories. I find that division to be a step towards over-engineering and found that the 3-layered approach strikes the best balance. <a href=\"#fnref:3\" class=\"reversefootnote\" role=\"doc-backlink\">&#8617;</a></p>\n    </li>\n  </ol>\n</div>\n","contentSnippet":"Software Architecture is an elusive thing which, if neglected, can lead to a hard-to-develop and maintain codebase, and\nin more drastic circumstances to the failure of a product. This article discusses one of the backend application\narchitecture styles which proved to be successful in providing a good foundation for building and maintaining an\napplication in the long run: Onion Architecture.\nOnion Architecture\nOnion Architecture is a software architectural style which strongly promotes the separation of concerns between the most\nimportant part of a business application — the domain code — and its technical aspects like HTTP or database. It does so\nwith ideas similar to Hexagonal Architecture,\nClean Architecture and\nother related architecture styles.\nThis post gives a description of the ideas of Onion Architecture and discusses a sample implementation which explicitly\ndefines layers in the code and build setup.\nAdditional complexity to the build setup and extra learning curve introduced by the layered approach pays back during\ndevelopment. It reduces the cognitive load on the programmer by giving a more concrete structural foundation and guidance.\nThe Repository\nThe code samples are taken from an example repository, which you can find\non GitHub.\nWhy does Software Architecture matter?\nDuring my Engineering career, I’ve worked on multiple projects using different architectural styles. From a happy-go-lucky\napproach without any obvious structure, through “classic”1 three-tier enterprise style, to highly structured\narchitecture, reflected by the setup of the build tool and supported by the compiler.\nThe experience of working on those projects was also very different. Having to introduce a change in a shapeless blob of\nspaghetti code was always a painful experience, connected with stressful moments of Have I broken something? Or Oh\nno! A gazillion of unrelated tests broke…\nOn the other hand, working in a more rigid, but at the same time more expressive, and structured environment of\na well-architected application, was a breeze and a real pleasure. Not to mention that the time required to introduce the\nchange was smaller, and the estimates were more precise and predictable.\nGood architecture guides the implementation makes it easy to introduce new changes, and — to some degree — prevents\nless experienced team members from making doubtful decisions. It allows developers to focus on the value-providing\nimplementation rather than thinking Hmm where should I put this class?.\nLast but not least, software architecture is often defined as the things that are hard to change, so choosing a proper\narchitectural approach to your new application is of key importance to its future development and maintenance.\nAbout the Onion\nThe idea of Onion Architecture, first introduced by Jeffrey Palermo in\na series of articles, is similar to other clean\narchitecture approaches presented in Robert “Uncle Bob” Martin’s\nblog post, his book\nClean Architecture, and\nquite recently on our blog. It can be successfully used as an alternative to a\npopular Hexagonal / Ports and Adapters architecture, and as such is predominantly used in the backend, business\napplications and services.\nThe core concept in all the above styles is the same — to make the domain the most central part of the application, and\nremove all infrastructure concerns, such as talking via HTTP, messaging, database mapping, testing, etc., away from the\ndomain code. The core of the business logic should be free (in theory at least) from any of the technical, and\nframework-related problems, allowing for easy testing and rapid development.\nTo put it using Uncle Bob’s words: Though these architectures all vary somewhat in their details, they are very\nsimilar. They all have the same objective, which is the separation of concerns. They all achieve this separation by\ndividing the software into layers. Each has at least one layer for business rules, and another for interfaces.\nThe main difference I’ve found in the implementations of Hexagonal Architecture and Onion Architecture lies mostly in\nthe overall, more structured approach to the code layout of the latter. Both styles rely on the conscious usage of\ninterfaces, and the Dependency Inversion Principle, which is the layer and encapsulation, but the Onion, like a real vegetable, has explicitly defined layers. Making the concept a\nfirst-class citizen represented in the code guides implementation and gives more clear overall structure to the\ncodebase.\nThis Architecture style does have some learning curve for developers in the project, but once mastered, pays back many\ntimes. Finally, as with every solution in the IT industry, it is not a one-size-fits-all, and you should always consider\nif the architectural style matches your needs.\nThe Onion has Layers\nOnion Architecture is a form of layered architecture. The main difference between “the classic” three-tier architecture\nand the Onion, is that every outer layer sees classes from all inner layers, not only the one directly below. Moreover,\nthe dependency direction always goes from the outside to the inside, never the other way around.\nBut wait, what are the layers of Onion Architecture, what do they describe, and why do they matter?\nThere are three2 main layers in Onion Architecture:\nThe domain layer\nThe application layer\nThe infrastructure layer\neach of which has its responsibilities.\n\nThe Domain Layer\nThis is the layer where you place classes describing the core of your business.\nLet’s use a simple example. An application written to help manage a Library would most probably have classes like Book,\nReader, Copy and so on. The classes, relations and interactions between them describe the core of the domain of the\napplication, i.e. what business needs it fulfils and in what way. In the Library, there would be a process of adding new\ntitles to the catalogue, a process of borrowing and returning copies of a book, charging readers for overdue books, and\nmany more.\nA sample domain class could look like the one below:\n\n\n@ToString\n@EqualsAndHashCode(of = \"id\")\n@AllArgsConstructor(access = AccessLevel.PRIVATE)\nabstract sealed class Book {\n\n    protected final BookId id;\n    protected final Version version;\n    protected final AuthorId author;\n    protected final Title title;\n    protected final CreatedAt createdAt;\n    protected final ApprovedAt approvedAt;\n    protected final RejectedAt rejectedAt;\n    protected final ArchivedAt archivedAt;\n\n    // static factory method for assembling a new instance of a Book — hides the internal representation\n    static Book create(AuthorId author, Title title, CreatedAt createdAt) {\n        return new NewBook(BookId.next(), Version.first(), author, title, createdAt);\n    }\n\n    // One of the subclasses representing the current state of the book entity\n    // Other subclasses omitted for brevity.\n    private static final class NewBook extends Book {\n\n        private NewBook(BookId id, Version version, AuthorId author, Title title, CreatedAt createdAt) {\n            super(id, version, author, title, createdAt, null, null, null);\n        }\n\n        @Override\n        protected BookSnapshot.Status status() {\n            return BookSnapshot.Status.AWAITING_APPROVAL;\n        }\n\n        @Override\n        Book approve(ApprovedAt approvedAt) {\n            return new ApprovedBook(id, version, author, title, createdAt, approvedAt);\n        }\n\n        @Override\n        Book reject(RejectedAt rejectedAt) {\n            return new RejectedBook(id, version, author, title, createdAt, rejectedAt);\n        }\n    }\n\n    // Available domain operations\n    Book approve(ApprovedAt approvedAt) {\n        throw new UnsupportedOperationException(\"Unsupported state transition. Cannot approve book in state [%s]\"\n                .formatted(status()));\n    }\n\n    Book reject(RejectedAt rejectedAt) {\n        throw new UnsupportedOperationException(\"Unsupported state transition. Cannot reject book in state [%s]\"\n                .formatted(status()));\n    }\n\n    Book archive(ArchivedAt archivedAt) {\n        throw new UnsupportedOperationException(\n                \"Unsupported state transition. Cannot archive book in state [%s]\".formatted(status())\n        );\n    }\n}\n\n\nSince the domain changes the most — here is the place where you put all the new features, and business requirements — it\nshould be as easy as possible to modify and test. Thus, it should not be concerned which database is used in the\nproject, nor should it know which communication style, synchronous RPC calls, asynchronous messaging, or a mix of is\nused to trigger the logic or maybe that it’s triggered by unit tests and not real user interactions. This doesn’t mean\nof course, that the domain classes can’t have any dependencies. Like it the example above — the code uses Lombok\nannotations, generating the boilerplate which otherwise needs to be written by the programmer.\nThe Application Layer\nThis is the layer where you place your classes, which describe the use cases of the application and coordinate the work\nof the domain classes. For example, we can imagine that a new title added to the library undergoes an approval process:\nthe book is fetched from the repository, a timestamp of approval is generated, the book state (only new books can be\napproved) is checked, and if it’s OK, a modified book is then saved using the repository.\nThe code describing such a use case can look like this:\n\nclass Books {\n    // other fields and methods omitted\n    public BookSnapshot approve(BookId id) {\n        return transactions.execute(() -> {\n            final Book book = bookRepository.getById(id);\n            final ApprovedAt approvedAt = new ApprovedAt(timeMachine.now());\n            final Book approved = book.approve(approvedAt);\n            return bookRepository.update(approved).snapshot();\n        });\n    }\n}\n\n\n\nThis is also the layer that “knows” which operations should be performed atomically, thus the transaction-related code\nis placed here. Note, however, that in the example above, the transactions field is actually an interface reference.\n\n\n@FunctionalInterface\npublic interface Transactions {\n\n    <T> T execute(Supplier<T> operation);\n}\n\n\nThe application uses the behaviour expressed by the interface, the details of how the behaviour is executed lie in the\ninfrastructure layer.\nThe Infrastructure Layer\nThis layer, the outermost layer of Onion, is a place where all framework and technology related stuff goes. It tends to\nbe the most “thick” since it contains the implementations of the interfaces defined in the inner layers. Need an\nHTTP controller, a message listener or a database adapter (an implementation of repository interface defined at the domain layer)? Infrastructure is the place to go.\nThe domain, although the most important part of the application, tends to be also the smallest in terms of code size.\nThe reverse is true about the infrastructure code — all the supporting mechanisms, which are placed at the\ninfrastructure layer, are the backbone which animates the domain behaviour, and as such that part of the service should\nnot be neglected.\nStaying with the example of the Transactions interface, let’s take a look at possible implementations. A simple approach\nusing Spring’s programmatic transaction handling could look like this:\n\n\n@Component\n@AllArgsConstructor\nclass JdbcTransactions implements Transactions {\n\n    private final TransactionTemplate transactionTemplate;\n\n    @Override\n    public <T> T execute(Supplier<T> operation) {\n        return transactionTemplate.execute(status -> operation.get());\n    }\n}\n\n\nand for unit test, one can set up a fake, noop implementation:\n\nclass NoOpTransactionsFake implements Transactions {\n\n    @Override\n    <T> T execute(Supplier<T> operation) {\n        operation.get()\n    }\n}\n\n\nThe Flavours of The Onion or how to represent layers in code?\nThere are two basic approaches to representing the layers in the code. The one that we used in our most recent\nproject was to use a package naming convention.\n\nEvery domain package has three subpackages: domain, application and infrastructure. This method is clear, easy to\nunderstand and navigate, and does not require changes to the build tool setup. The downside is that, except for the\nagreed convention, and Code Review process to check them, there is no mechanism preventing you from using a class\ndefined in the application layer in the domain layer, thus breaking the direction of the dependencies. One can always\nuse such tools as ArchUnit to write tests checking if there are no “prohibited” imports,\nbut in my opinion, we can do better by employing build tool modules support.\nBuild tools to the rescue\nThe more involved approach is to define compilation modules representing the layers. Its disadvantage is a more\ncomplicated build structure and setup of your build tool of choice. On the other side though, having the compiler on\nyour side is very helpful, and prevents the above-mentioned issue. The direction of the dependencies between layers is\nclearly defined in the module build files.\n\n// settings.gradle\nrootProject.name = 'onion'\n\ninclude('domain', 'application', 'infrastructure')\n\n\nUsing Gradle setup as an example, one can define three modules — domain, application, and infrastructure —\nin settings.gradle file. Then, in the build files corresponding to each of the modules, declare their dependencies,\nclearly defining the direction of dependencies.\n\n// /application/build.gradle\ndependencies {\n    implementation(project(':domain'))\n}\n// /infrastructure/build.gradle\nplugins {\n    id 'org.springframework.boot'\n    id 'io.spring.dependency-management'\n    id 'com.revolut.jooq-docker' version '0.3.7'\n}\n\ndependencies {\n    implementation(project(':domain'))\n    implementation(project(':application'))\n\n    implementation('org.springframework.boot:spring-boot-starter-web')\n    implementation('org.springframework.boot:spring-boot-starter-jooq')\n\n    // other dependencies and settings removed for brevity\n}\n\n\nNotice, that the biggest file is the one for the infrastructure layer. It should not be a surprise by now. The\ninfrastructure has all the framework — in this case Spring Boot — database driver, and other dependencies, and itself\ndepends on both domain and application. There’s of course nothing preventing you from declaring extra dependencies,\nsay Lombok. The most important thing to note here is that with this build setup, it will not be possible to reverse the\norder of dependencies between the layers.\nFinal Thoughts\nProblems Onion Architecture solves\nA more structured, layered layout of the code makes code navigation easier and makes the relationship between\ndifferent parts of the codebase more visible at first glance\nLoose coupling between the domain and the infrastructure\nCoupling is towards the centre of The Onion — expressed by the relationship between the layers\n(Usually) No coupling between the domain and the infrastructure concerns of the application\nBuild tool support in enforcing layers\nProblems Onion Architecture creates\nAdditional learning curve for new developers, and those used to other architecture styles\nIncreased overall complexity of the codebase — especially with the flavour utilising the modularizing capabilities of build tools such as Gradle or Maven\nNot everyone likes the smell of it\nAs mentioned above at the beginning of the article, Onion Architecture is not a one-size-fits-all solution. It has its\nlearning curve and is best suited for services with a clear domain definition. This makes it a bad choice, for more\ntechnical-oriented services, e.g. a high-throughput proxy written in a reactive framework.\nFootnotes\nThe typical, “classic” enterprise architecture, usually consists of three layers: the presentation layer, the domain layer and the persistence (data) layer. The dependency direction goes top-down, and in the strict approach a layer sees only its nearest neighbour. The clear advantage is the separation of concerns, and the reduction of the scope of responsibilities of each layer. There are two issues though — that architecture style often leads to a so-called anemic domain model, since most of the business logic is placed in service classes, because, and that’s the second issue, domain classes depend on the persistence layer — and often become only data carriers without behaviour. For a comparison of different software architecture styles, see Software Architecture Patterns (e-book, pdf) ↩\nThe number of layers may differ. The three-tier division is usually called Simplified Onion Architecture. Another possible rendition of the division is to have five layers with a separate Repository layer above the domain and a service layer above the repositories. I find that division to be a step towards over-engineering and found that the 3-layered approach strikes the best balance. ↩","guid":"https://blog.allegro.tech/2023/02/onion-architecture.html","categories":["tech","architecture","software","engineering"],"isoDate":"2023-02-12T23:00:00.000Z","thumbnail":"images/post-headers/default.jpg"}],"jobs":[{"id":"743999897204913","name":"Senior Software Engineer - Technical Platform","uuid":"c2fc248f-b50f-484e-8cf5-06690f52e65c","jobAdId":"439627bc-f42f-4d4c-bfad-4b94b11fb5d9","defaultJobAd":false,"refNumber":"REF4072X","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2023-04-03T09:27:07.761Z","location":{"city":"Kraków, Warszawa, Wrocław, Poznań, Katowice, Gdańsk","region":"","country":"pl","address":"","postalCode":"","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572770","label":"IT - Software Development"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"id":"permanent","label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Recruitment Process","valueId":"ed4682c7-33c9-41c2-8d13-428ed39046f5","valueLabel":"Tech. Engineer - IC"},{"fieldId":"6406f92e638cbb2f415a94a9","fieldLabel":"Job Area","valueId":"e8731ea4-48a9-476d-ab1d-9a40eb3426f1","valueLabel":"Technology"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572770","valueLabel":"IT - Software Development"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro sp. z o.o."}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999897204913","creator":{"name":"Agnieszka Adamus"},"language":{"code":"en","label":"English","labelNative":"English (US)"}},{"id":"743999897161196","name":"Senior Software Engineer Java/Kotlin - Search&Personalization","uuid":"48436486-d9a4-4bfc-befb-6a6073830b57","jobAdId":"48cd2ec4-3db4-4215-afcc-64eea44a3d50","defaultJobAd":false,"refNumber":"REF4072X","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2023-04-03T07:17:44.171Z","location":{"city":"Poznań, Warszawa, Kraków, Toruń, Wrocław, Gdańsk, Katowice, Lublin","region":"","country":"pl","address":"","postalCode":"","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572770","label":"IT - Software Development"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"id":"permanent","label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Recruitment Process","valueId":"ed4682c7-33c9-41c2-8d13-428ed39046f5","valueLabel":"Tech. Engineer - IC"},{"fieldId":"6406f92e638cbb2f415a94a9","fieldLabel":"Job Area","valueId":"e8731ea4-48a9-476d-ab1d-9a40eb3426f1","valueLabel":"Technology"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572770","valueLabel":"IT - Software Development"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro sp. z o.o."}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999897161196","creator":{"name":"Natalia Glińska"},"language":{"code":"en","label":"English","labelNative":"English (US)"}},{"id":"743999897160748","name":"Software Engineer Java/Kotlin - Search&Personalization","uuid":"bad5db11-8dbd-416f-a1d9-8f165eca61cf","jobAdId":"550d9f6e-b309-45a7-9da0-e77dbb85e8a3","defaultJobAd":false,"refNumber":"REF4072X","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2023-04-03T07:15:55.900Z","location":{"city":"Poznań, Warszawa, Kraków, Toruń, Wrocław, Gdańsk, Katowice, Lublin","region":"","country":"pl","address":"","postalCode":"","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572770","label":"IT - Software Development"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"id":"permanent","label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Recruitment Process","valueId":"ed4682c7-33c9-41c2-8d13-428ed39046f5","valueLabel":"Tech. Engineer - IC"},{"fieldId":"6406f92e638cbb2f415a94a9","fieldLabel":"Job Area","valueId":"e8731ea4-48a9-476d-ab1d-9a40eb3426f1","valueLabel":"Technology"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572770","valueLabel":"IT - Software Development"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro sp. z o.o."}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999897160748","creator":{"name":"Natalia Glińska"},"language":{"code":"en","label":"English","labelNative":"English (US)"}},{"id":"743999896684277","name":"Software Engineer - Technical Platform","uuid":"72ce4283-b8eb-43c1-ba78-46b8bcf42678","jobAdId":"12fe8ef0-6882-45ed-88a6-2099fa085f68","defaultJobAd":false,"refNumber":"REF4072X","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2023-03-31T11:10:58.559Z","location":{"city":"Kraków, Warszawa, Wrocław, Poznań, Katowice, Gdańsk","region":"","country":"pl","address":"","postalCode":"","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572770","label":"IT - Software Development"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"id":"permanent","label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Recruitment Process","valueId":"ed4682c7-33c9-41c2-8d13-428ed39046f5","valueLabel":"Tech. Engineer - IC"},{"fieldId":"6406f92e638cbb2f415a94a9","fieldLabel":"Job Area","valueId":"e8731ea4-48a9-476d-ab1d-9a40eb3426f1","valueLabel":"Technology"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572770","valueLabel":"IT - Software Development"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro sp. z o.o."}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999896684277","creator":{"name":"Martyna Maziarska"},"language":{"code":"pl","label":"Polish","labelNative":"polski"}},{"id":"743999896681894","name":"Senior Software Engineer - Technical Platform","uuid":"a6b9f3b2-a773-4481-aa02-38b5fe4487b5","jobAdId":"6eb46886-909c-4ff4-b446-bc8b0e59d15f","defaultJobAd":false,"refNumber":"REF4072X","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2023-03-31T11:10:32.123Z","location":{"city":"Kraków, Warszawa, Wrocław, Poznań, Katowice, Gdańsk","region":"","country":"pl","address":"","postalCode":"","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572770","label":"IT - Software Development"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"id":"permanent","label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Recruitment Process","valueId":"ed4682c7-33c9-41c2-8d13-428ed39046f5","valueLabel":"Tech. Engineer - IC"},{"fieldId":"6406f92e638cbb2f415a94a9","fieldLabel":"Job Area","valueId":"e8731ea4-48a9-476d-ab1d-9a40eb3426f1","valueLabel":"Technology"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572770","valueLabel":"IT - Software Development"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro sp. z o.o."}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999896681894","creator":{"name":"Martyna Maziarska"},"language":{"code":"pl","label":"Polish","labelNative":"polski"}}],"events":[{"created":1678978572000,"duration":111600000,"id":"292278882","name":"UX Research Confetti - III edycja ","date_in_series_pattern":false,"status":"upcoming","time":1684915200000,"local_date":"2023-05-24","local_time":"10:00","updated":1678978600000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":16,"is_online_event":true,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/292278882/","description":"**Rejestracja na wydarzenie ➡ [https://app.evenea.pl/event/ux-research-confetti-3/]( https://app.evenea.pl/event/ux-research-confetti-3/ )**[ ]( https://app.evenea.pl/event/ux-research-confetti-3/ ) **🎉 Przedstawiamy 3. edycję UX Research Confetti organizowaną przez Allegro - bezpłatną, polską konferencję poświęconą badaniom…","visibility":"public","member_pay_fee":false},{"created":1680681153000,"duration":7200000,"id":"292699418","name":"Allegro Tech Talks #36 - Kotlin: korutyny i obsługa błędów","date_in_series_pattern":false,"status":"upcoming","time":1682006400000,"local_date":"2023-04-20","local_time":"18:00","updated":1680681153000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":6,"venue":{"id":27549223,"name":"Allegro Warsaw Office","lat":52.23224639892578,"lon":20.992111206054688,"repinned":false,"address_1":"ul. Żelazna 51/53","city":"Warszawa","country":"pl","localized_country_name":"Poland"},"is_online_event":false,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/292699418/","description":"**➡ Rejestracja:** [https://app.evenea.pl/event/allegro-tech-talk-36/](https://app.evenea.pl/event/allegro-tech-talk-36/) Ciąg dalszy naszych stacjonarnych spotkań z serii **Allegro Tech Talks**, na których dzielimy się wiedzą, wzajemnie inspirujemy oraz integrujemy podczas rozmów w…","how_to_find_us":"Biuro Allegro znajduje się w Fabryce Norblina (wejście Plater 3, od ul. Żelaznej). Szczegóły dojazdu (auotbusy, tramwaj, metro) możesz sprawdzić na: https://fabrykanorblina.pl/dojazd/","visibility":"public","member_pay_fee":false},{"created":1678100858000,"duration":7200000,"id":"292065334","name":"Allegro Tech Talks #35 - Development: o dokumentacji i wydajności kodu","date_in_series_pattern":false,"status":"past","time":1679590800000,"local_date":"2023-03-23","local_time":"18:00","updated":1679603511000,"utc_offset":3600000,"waitlist_count":0,"yes_rsvp_count":23,"venue":{"id":27528185,"name":"Allegro Kraków Office","lat":50.06517028808594,"lon":19.951927185058594,"repinned":true,"address_1":"Lubicz Park A (5 piętro)","address_2":"ul. Lubicz 23","city":"Kraków","country":"pl","localized_country_name":"Poland"},"is_online_event":false,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/292065334/","description":"**➡ Rejestracja:** [https://app.evenea.pl/event/allegro-tech-talk-35/](https://app.evenea.pl/event/allegro-tech-talk-35/) Wracamy do stacjonarnych spotkań Allegro Tech Talks, na których dzielimy się wiedzą, wzajemnie inspirujemy oraz integrujemy podczas rozmów w kuluarach. **Temat wydarzenia:**…","how_to_find_us":"Biuro Allegro znajduje się w Centrum Biurowym Lubicz. \n\nObok budynku znajduje się przystanek Lubicz. Przy przystanku zatrzymują się tramwaje 2, 4, 10, 14, 20, 52, 62, 64 oraz autobusy: 124, 152, 424, 601, 611, 662, 664.\n\n","visibility":"public","member_pay_fee":false},{"created":1675343646000,"duration":5400000,"id":"291357306","name":"Allegro Tech Live #34 - Cloud: duże dane = duży problem?","date_in_series_pattern":false,"status":"past","time":1676566800000,"local_date":"2023-02-16","local_time":"18:00","updated":1676576868000,"utc_offset":3600000,"waitlist_count":0,"yes_rsvp_count":58,"is_online_event":true,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/291357306/","description":"**➡ Transmisja i nagranie ze spotkania:** [https://www.youtube.com/watch?v=66ub1e8kPWg](https://www.youtube.com/watch?v=66ub1e8kPWg) **Allegro Tech Live** to w 100% zdalna odsłona naszych stacjonarnych meetupów Allegro Tech Talks. Zazwyczaj spotykaliśmy się w…","visibility":"public","member_pay_fee":false}],"podcasts":[{"title":"S03E12 - Alina Magowska, Agnieszka Jagusiak - O pracy liderek i liderów w Allegro","link":"https://podcast.allegro.tech/o-pracy-liderek-i-liderow-w-allegro/","pubDate":"Thu, 23 Feb 2023 00:00:00 GMT","content":"Jakimi umiejętnościami powinny wyróżniać się osoby na stanowiskach liderskich? Czy wykształcenie techniczne to “must have”, aby dołączyć do zespołów Tech & Data w Allegro? Czym charakteryzuje się praca liderek i liderów w Allegro oraz jak wspieramy ich rozwój? Jaki wpływ na produkt oraz organizację mają liderki i liderzy w Allegro? Jak zacząć budowanie swojej ścieżki kariery w roli liderskiej? Jakich wyzwań się spodziewać i jak sobie z nimi poradzić? Posłuchajcie rozmowy z udziałem Aliny Magowskiej - Dyrektorki obszaru User Experience i Agnieszki Jagusiak - Senior Managerki w zespole Group IT Services w Allegro.","contentSnippet":"Jakimi umiejętnościami powinny wyróżniać się osoby na stanowiskach liderskich? Czy wykształcenie techniczne to “must have”, aby dołączyć do zespołów Tech & Data w Allegro? Czym charakteryzuje się praca liderek i liderów w Allegro oraz jak wspieramy ich rozwój? Jaki wpływ na produkt oraz organizację mają liderki i liderzy w Allegro? Jak zacząć budowanie swojej ścieżki kariery w roli liderskiej? Jakich wyzwań się spodziewać i jak sobie z nimi poradzić? Posłuchajcie rozmowy z udziałem Aliny Magowskiej - Dyrektorki obszaru User Experience i Agnieszki Jagusiak - Senior Managerki w zespole Group IT Services w Allegro.","guid":"https://podcast.allegro.tech/o-pracy-liderek-i-liderow-w-allegro/","isoDate":"2023-02-23T00:00:00.000Z"},{"title":"S03E11 - Bartosz Kaczyński - O pracy i rozwoju w zespole IT Support","link":"https://podcast.allegro.tech/o-pracy-i-rozwoju-w-zespole-it-support/","pubDate":"Thu, 26 Jan 2023 00:00:00 GMT","content":"Jak wygląda praca w zespole, który zawsze udziela odpowiedzi na zadane pytania? Co można zautomatyzować w obszarze wsparcia IT i jaki to może mieć cel? Czy praca w zespole IT Support jest bramą do kariery w IT, może dawać możliwości rozwoju i przynosić satysfakcję? Jakie wyzwania przed tym zespołem w Allegro postawiła pandemia koronawirusa? O umożliwianiu pracownikom Grupy Allegro sprawnej pracy na narzędziach i usługach IT dostarczanych przez zespół Business Services & Automation opowiada Bartosz Kaczyński - IT Service Operations Manager w Allegro.","contentSnippet":"Jak wygląda praca w zespole, który zawsze udziela odpowiedzi na zadane pytania? Co można zautomatyzować w obszarze wsparcia IT i jaki to może mieć cel? Czy praca w zespole IT Support jest bramą do kariery w IT, może dawać możliwości rozwoju i przynosić satysfakcję? Jakie wyzwania przed tym zespołem w Allegro postawiła pandemia koronawirusa? O umożliwianiu pracownikom Grupy Allegro sprawnej pracy na narzędziach i usługach IT dostarczanych przez zespół Business Services & Automation opowiada Bartosz Kaczyński - IT Service Operations Manager w Allegro.","guid":"https://podcast.allegro.tech/o-pracy-i-rozwoju-w-zespole-it-support/","isoDate":"2023-01-26T00:00:00.000Z"},{"title":"S03E10 - Zosia Śmierzchalska, Jakub Dodot - O tym jak przygotowujemy rozwiązania dla klientów w oparciu o badania","link":"https://podcast.allegro.tech/o-rozwiazaniach-opartych-na-badaniach/","pubDate":"Thu, 12 Jan 2023 00:00:00 GMT","content":"W jaki sposób przygotowujemy rozwiązania dla klientów Allegro w oparciu o badania? Jak wygląda ścieżka projektu od eksploracji do wdrożenia i późniejszego monitorowania? Jaką korzyść dają badania usability? Dlaczego warto, aby badanie było prowadzone przez dwoje badaczy? O współpracy między badaczami i projektantami UX rozmawialiśmy z Zofią Śmierzchalską - Design Managerką i Jakubem Dodotem - Senior UX Research Managerem w Allegro.","contentSnippet":"W jaki sposób przygotowujemy rozwiązania dla klientów Allegro w oparciu o badania? Jak wygląda ścieżka projektu od eksploracji do wdrożenia i późniejszego monitorowania? Jaką korzyść dają badania usability? Dlaczego warto, aby badanie było prowadzone przez dwoje badaczy? O współpracy między badaczami i projektantami UX rozmawialiśmy z Zofią Śmierzchalską - Design Managerką i Jakubem Dodotem - Senior UX Research Managerem w Allegro.","guid":"https://podcast.allegro.tech/o-rozwiazaniach-opartych-na-badaniach/","isoDate":"2023-01-12T00:00:00.000Z"},{"title":"S03E09 - Adrianna Dworniak, Łukasz Gomółka - O Allegro Family","link":"https://podcast.allegro.tech/o-allegro-family/","pubDate":"Thu, 15 Dec 2022 00:00:00 GMT","content":"Czy współpraca dwóch Product Managerów przy jednym produkcie jest możliwa i jak zadbać o jej efektywność? Czym jest “churn” i na czym polega w branży e-commerce? Co wspólnego z błędnymi rekomendacjami zakupowymi mają maty do ćwiczeń? Jak rozwiązywać wielopłaszczyznowe problemy, dzięki kompleksowemu zrozumieniu perspektywy klienta i bez wykorzystywania restrykcji? Jak powstawało Allegro Family oraz dlaczego czasem warto zacząć weryfikację pomysłu na produkt od rozmowy z… teściową? Na te i inne pytania odpowiadają  Adrianna Dworniak - Senior Product Manager i Łukasz Gomółka - Product Team Manager w Allegro.","contentSnippet":"Czy współpraca dwóch Product Managerów przy jednym produkcie jest możliwa i jak zadbać o jej efektywność? Czym jest “churn” i na czym polega w branży e-commerce? Co wspólnego z błędnymi rekomendacjami zakupowymi mają maty do ćwiczeń? Jak rozwiązywać wielopłaszczyznowe problemy, dzięki kompleksowemu zrozumieniu perspektywy klienta i bez wykorzystywania restrykcji? Jak powstawało Allegro Family oraz dlaczego czasem warto zacząć weryfikację pomysłu na produkt od rozmowy z… teściową? Na te i inne pytania odpowiadają  Adrianna Dworniak - Senior Product Manager i Łukasz Gomółka - Product Team Manager w Allegro.","guid":"https://podcast.allegro.tech/o-allegro-family/","isoDate":"2022-12-15T00:00:00.000Z"}]},"__N_SSG":true}