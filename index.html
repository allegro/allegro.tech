<!DOCTYPE html><html lang="pl"><head><meta charSet="utf-8"/><link rel="prefetch" href="https://allegrotechio.disqus.com/count.js"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta name="description" content="Allegro Tech to miejsce, w którym nasi inżynierowie dzielą się wiedzą oraz case study z wybranych projektów w firmie - w formie artykułów, podcastów oraz eventów."/><title>Allegro Tech</title><meta property="og:site_name" content="allegro.tech"/><meta property="og:title" content="allegro.tech"/><meta property="og:url" content="https://allegro.tech"/><meta property="og:type" content="site"/><meta property="og:image" content="https://allegro.tech/images/allegro-tech.png"/><link rel="shortcut icon" href="favicon.ico"/><link rel="canonical" href="https://allegro.tech" itemProp="url"/><link rel="preload" href="images/splash.jpg" as="image"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-1M1FJ5PXWW"></script><script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){dataLayer.push(arguments);}
                    gtag('js', new Date());
                    gtag('config', 'G-1M1FJ5PXWW');
                </script><meta name="next-head-count" content="15"/><link rel="preload" href="/_next/static/css/66933eaa547aae51.css" as="style"/><link rel="stylesheet" href="/_next/static/css/66933eaa547aae51.css" data-n-g=""/><link rel="preload" href="/_next/static/css/79db8b1e27b0a093.css" as="style"/><link rel="stylesheet" href="/_next/static/css/79db8b1e27b0a093.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-69bfa6990bb9e155.js" defer=""></script><script src="/_next/static/chunks/framework-e70c6273bfe3f237.js" defer=""></script><script src="/_next/static/chunks/main-f635b472c367d1c7.js" defer=""></script><script src="/_next/static/chunks/pages/_app-179adf437ae674f2.js" defer=""></script><script src="/_next/static/chunks/206-3a56e5ded293e83e.js" defer=""></script><script src="/_next/static/chunks/pages/index-f037c91132ed6a0a.js" defer=""></script><script src="/_next/static/FA_mC8za_aWuIfp6tc6XU/_buildManifest.js" defer=""></script><script src="/_next/static/FA_mC8za_aWuIfp6tc6XU/_ssgManifest.js" defer=""></script><script src="/_next/static/FA_mC8za_aWuIfp6tc6XU/_middlewareManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><header class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card Header_navbar__Zc5aN m-color-bg_card"><nav class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-display-flex m-flex-justify-between m-flex-items-center"><a href="/"><img src="images/logo.svg" alt="Allegro Tech" width="205" height="45"/></a><div><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0 m-display-flex@lg m-display-none"><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://blog.allegro.tech">Blog</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://ml.allegro.tech">Machine Learning</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://podcast.allegro.tech">Podcast</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://github.com/Allegro">Open Source</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://www.meetup.com/allegrotech/events">Wydarzenia</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://praca.allegro.pl">Praca</a></li></ul><button class="m-display-none@lg m-height_40 m-line-height_40 m-border-style-top_none m-border-style-right_none m-border-style-bottom_none m-border-style-left_none m-border-radius-top-left_2 m-border-radius-top-right_2 m-border-radius-bottom-left_2 m-border-radius-bottom-right_2 m-cursor_pointer m-overflow_hidden m-appearance_none m-padding-left_4 m-padding-right_4 m-padding-top_4 m-padding-bottom_4 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button" style="background:transparent" aria-label="Otwórz menu"><img src="https://assets.allegrostatic.com/metrum/icon/menu-23e046bf68.svg" alt="" class="m-icon" width="32" height="32"/></button></div></nav></header><div class="Header_hero__PYE0B"><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-display-flex m-flex-column m-flex-justify-end Header_image__Cj6ZF"><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-color-bg_desk"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text  m-font-weight_100 m-font-size_32 m-font-size_43_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125">O nas</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">Allegro to jedna z najbardziej zaawansowanych technologicznie firm w naszej części Europy. Allegro to również ponad 1000 specjalistów IT, różnych specjalizacji, rozwijających nasz serwis. Unikatowa skala i złożoność problemów, które rozwiązujemy na co dzień, dają nam możliwość rozwoju przy bardzo różnorodnych projektach. Allegro Tech to miejsce, w którym nasi inżynierowie dzielą się wiedzą oraz case study z wybranych projektów w firmie – w formie artykułów, podcastów oraz eventów.</p></div></div></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24">Blog</h2><div class="m-display_flex m-flex-wrap_1 m-flex-grow_1 m-grid"><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://blog.allegro.tech/2022/06/graphql-perf-tradeoffs.html" title="Exploring GraphQL’s performance tradeoffs"><img width="388" src="images/post-headers/java.png" alt="Exploring GraphQL’s performance tradeoffs" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://blog.allegro.tech/2022/06/graphql-perf-tradeoffs.html" title="Exploring GraphQL’s performance tradeoffs" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Exploring GraphQL’s performance tradeoffs</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">10 dni temu</time><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0"><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/tech">#<!-- -->tech</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/backend">#<!-- -->backend</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/performance">#<!-- -->performance</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/graphql">#<!-- -->graphql</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/kotlin">#<!-- -->kotlin</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/java">#<!-- -->java</a></li></ul><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1 m-padding-top-16">At Allegro we decided to introduce GraphQL as our API Gateway for building several internal client systems.
By building such a solution we’ve learnt a lot…</p><div class="m-display-flex m-flex-justify-between m-padding-top-16 m-flex-items_center"><div class="m-display-flex m-flex-items_center"><div class="MuiAvatarGroup-root m-padding-right_16 Post_avatars__FHMgb"><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar" style="z-index:2"><img alt="Alicja Halamska" src="https://blog.allegro.tech/img/authors/alicja.halamska.jpg" class="MuiAvatar-img" width="32" height="32"/></div><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar" style="z-index:1"><img alt="Dawid Kubicki" src="https://blog.allegro.tech/img/authors/dawid.kubicki.jpg" class="MuiAvatar-img" width="32" height="32"/></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/authors/alicja.halamska">Alicja Halamska…</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/2022/06/graphql-perf-tradeoffs.html#disqus_thread">0 Comments</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech/2022/06/graphql-perf-tradeoffs.html">przejdź do wpisu</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://blog.allegro.tech/2022/06/debt-reduction-in-the-product-roadmap.html" title="How to include refactoring into product development roadmap? Reducing technical debt inspired by real options identification"><img width="388" src="images/post-headers/default.jpg" alt="How to include refactoring into product development roadmap? Reducing technical debt inspired by real options identification" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://blog.allegro.tech/2022/06/debt-reduction-in-the-product-roadmap.html" title="How to include refactoring into product development roadmap? Reducing technical debt inspired by real options identification" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">How to include refactoring into product development roadmap? Reducing technical debt inspired by real options identification</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">23 dni temu</time><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0"><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/tech">#<!-- -->tech</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/roadmaps">#<!-- -->roadmaps</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/tech debt">#<!-- -->tech debt</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/product">#<!-- -->product</a></li></ul><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1 m-padding-top-16">Nowadays, technical debt can be considered the bread and butter of most IT-powered enterprises around the world.
Almost every company that survived the startup phase and…</p><div class="m-display-flex m-flex-justify-between m-padding-top-16 m-flex-items_center"><div class="m-display-flex m-flex-items_center"><div class="MuiAvatarGroup-root m-padding-right_16 Post_avatars__FHMgb"><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar" style="z-index:1"><img alt="Olga Dudzik" src="https://blog.allegro.tech/img/authors/olga.dudzik.jpg" class="MuiAvatar-img" width="32" height="32"/></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/authors/olga.dudzik">Olga Dudzik</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/2022/06/debt-reduction-in-the-product-roadmap.html#disqus_thread">0 Comments</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech/2022/06/debt-reduction-in-the-product-roadmap.html">przejdź do wpisu</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://blog.allegro.tech/2022/04/turn-based-offline-rl.html" title="Turn-Based Offline Reinforcement Learning"><img width="388" src="images/post-headers/default.jpg" alt="Turn-Based Offline Reinforcement Learning" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://blog.allegro.tech/2022/04/turn-based-offline-rl.html" title="Turn-Based Offline Reinforcement Learning" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Turn-Based Offline Reinforcement Learning</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">3 miesiące temu</time><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0"><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/tech">#<!-- -->tech</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/mlr">#<!-- -->mlr</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/rl">#<!-- -->rl</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/research">#<!-- -->research</a></li></ul><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1 m-padding-top-16">This blogpost is the result of a research collaboration between the Allegro Machine Learning Research team and
the Institute of Mathematics of the Polish Academy of…</p><div class="m-display-flex m-flex-justify-between m-padding-top-16 m-flex-items_center"><div class="m-display-flex m-flex-items_center"><div class="MuiAvatarGroup-root m-padding-right_16 Post_avatars__FHMgb"><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar" style="z-index:5"><img alt="Riccardo Belluzzo" src="https://blog.allegro.tech/img/authors/riccardo.belluzzo.jpg" class="MuiAvatar-img" width="32" height="32"/></div><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar MuiAvatar-colorDefault" style="z-index:0">+<!-- -->4</div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/authors/riccardo.belluzzo">Riccardo Belluzzo…</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/2022/04/turn-based-offline-rl.html#disqus_thread">0 Comments</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech/2022/04/turn-based-offline-rl.html">przejdź do wpisu</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://blog.allegro.tech/2022/04/agile-team-natural-habitat.html" title="An Agile team in its natural habitat"><img width="388" src="images/post-headers/testing.png" alt="An Agile team in its natural habitat" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://blog.allegro.tech/2022/04/agile-team-natural-habitat.html" title="An Agile team in its natural habitat" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">An Agile team in its natural habitat</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">3 miesiące temu</time><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0"><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/tech">#<!-- -->tech</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/agile">#<!-- -->agile</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/testing">#<!-- -->testing</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/April 1st">#<!-- -->April 1st</a></li></ul><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1 m-padding-top-16">This post was published on April 1st, 2022, and should be taken with a grain of salt.
In this picture, we can see an Agile team…</p><div class="m-display-flex m-flex-justify-between m-padding-top-16 m-flex-items_center"><div class="m-display-flex m-flex-items_center"><div class="MuiAvatarGroup-root m-padding-right_16 Post_avatars__FHMgb"><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar" style="z-index:1"><img alt="Michał Kosmulski" src="https://blog.allegro.tech/img/authors/michal.kosmulski.jpg" class="MuiAvatar-img" width="32" height="32"/></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/authors/michal.kosmulski">Michał Kosmulski</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/2022/04/agile-team-natural-habitat.html#disqus_thread">0 Comments</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech/2022/04/agile-team-natural-habitat.html">przejdź do wpisu</a></div></article></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display_block m-margin-bottom_8 m-width_100 m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech">Zobacz więcej wpisów</a></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24">Podcasty</h2><div class="m-display_flex m-flex-wrap_1 m-flex-grow_1 m-grid"><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://podcast.allegro.tech/rola_architekta_w_allegro/" title="S02E12 - Piotr Betkier - Rola architekta w Allegro"><img src="images/podcast.png" alt="S02E12 - Piotr Betkier - Rola architekta w Allegro" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://podcast.allegro.tech/rola_architekta_w_allegro/" title="S02E12 - Piotr Betkier - Rola architekta w Allegro" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">S02E12 - Piotr Betkier - Rola architekta w Allegro</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">około rok temu</time><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1">Od kodowania do tworzenia strategii technicznej... Jak wygląda rola architekta w Allegro? Ile takich osób pracuje w naszej firmie i dlaczego ta rola jest tak różnorodna? Czym jest Andamio i jak rozwijamy naszą platformę – o tym wszystkim opowie Piotr Betkier – Inżynier, Architekt Platformy Technicznej w Allegro oraz twórca piosenek o IT :)</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech/rola_architekta_w_allegro/">Posłuchaj odcinka</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://podcast.allegro.tech/infrastruktura_Allegro/" title="S02E11 - Piotr Michoński - Infrastruktura Allegro"><img src="images/podcast.png" alt="S02E11 - Piotr Michoński - Infrastruktura Allegro" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://podcast.allegro.tech/infrastruktura_Allegro/" title="S02E11 - Piotr Michoński - Infrastruktura Allegro" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">S02E11 - Piotr Michoński - Infrastruktura Allegro</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">około rok temu</time><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1">Jak jest zbudowane środowisko uruchomienia aplikacji Allegro? Jak działają serwerownie firmy i ile ich potrzeba, a które elementy Allegro działają w chmurze publicznej? Jak przebiegała transformacja w Allegro i co zmieniało się przez lata? Jak wzrost biznesu wpływa na wielkość infrastruktury i jak infrastruktura Allegro odczuła przyjście pandemii? O tym, a także o rozwoju liderów technologii w Allegro oraz o historii powstania dżingla do naszych podcastów, opowie Piotr Michoński - menadżer Zespołów tworzących infrastrukturę Allegro.</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech/infrastruktura_Allegro/">Posłuchaj odcinka</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://podcast.allegro.tech/praca_architekta_ekosystemu_big_data_w_Allegro/" title="S02E10 - Dariusz Eliasz - Praca architekta ekosystemu big data w Allegro"><img src="images/podcast.png" alt="S02E10 - Dariusz Eliasz - Praca architekta ekosystemu big data w Allegro" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://podcast.allegro.tech/praca_architekta_ekosystemu_big_data_w_Allegro/" title="S02E10 - Dariusz Eliasz - Praca architekta ekosystemu big data w Allegro" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">S02E10 - Dariusz Eliasz - Praca architekta ekosystemu big data w Allegro</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">około rok temu</time><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1">Jak wygląda praca architekta ekosystemu big data w Allegro? Jakie zadania realizuje nasz zespół odpowiedzialny za narzędzia i infrastrukturę dla przetwarzania danych? Kiedy możemy mówić o dużych danych i ile petabajtów przetwarza Allegro? Skąd pochodzą dane Allegro i dlaczego jest ich tak dużo oraz z jakiego powodu dopiero teraz przenosimy się do chmury? O tym wszystkim opowie zdobywca statuetki Allegro Tech Hero - Dariusz Eliasz – Team Manager &amp; Platform Architect w Allegro.</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech/praca_architekta_ekosystemu_big_data_w_Allegro/">Posłuchaj odcinka</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://podcast.allegro.tech/od_inzyniera_do_lidera_w_allegro/" title="S02E09 - Bartosz Gałek - Od inżyniera do lidera w Allegro"><img src="images/podcast.png" alt="S02E09 - Bartosz Gałek - Od inżyniera do lidera w Allegro" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://podcast.allegro.tech/od_inzyniera_do_lidera_w_allegro/" title="S02E09 - Bartosz Gałek - Od inżyniera do lidera w Allegro" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">S02E09 - Bartosz Gałek - Od inżyniera do lidera w Allegro</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">około rok temu</time><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1">Czym jest Opbox i jakie wyzwania przed nim stoją? Jak w Allegro angażujemy się w rozwój kultury Open Source? Ile mamy projektów na GitHubie i jak świętujemy Hacktoberfest? W jaki sposób można rozwinąć się od inżyniera do lidera? Na te pytania w najnowszym Allegro Tech Podcast odpowie Bartek Gałek, Team Leader w Allegro.</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech/od_inzyniera_do_lidera_w_allegro/">Posłuchaj odcinka</a></div></article></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display_block m-margin-bottom_8 m-width_100 m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech">Zobacz więcej podcastów</a></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24">Wydarzenia</h2><div class="m-display_flex m-flex-wrap_1 m-flex-grow_1 m-grid"><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--6@xl m-display-flex m-flex-direction_column"><div class="m-margin-bottom_16 m-display-flex m-flex-direction_column m-flex-direction_row_sm m-padding-bottom_0"><a href="https://www.meetup.com/allegrotech/events/286545395/" title="Allegro Tech Live #29 - Wyzwania Product Managera" class="m-display_none m-display_block_lg" style="background-color:#fd4a02"><img width="218" src="images/event.png" alt="Allegro Tech Live #29 - Wyzwania Product Managera"/></a><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-direction_column m-padding-bottom_0 m-flex_1 m-flex-justify_between m-color-bg_card"><a href="https://www.meetup.com/allegrotech/events/286545395/" title="Allegro Tech Live #29 - Wyzwania Product Managera" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Allegro Tech Live #29 - Wyzwania Product Managera</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">za około 9 godzin</time><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-top-8">Allegro Tech Live to w 100% zdalna odsłona naszych stacjonarnych meetupów Allegro Tech Talks. Zazwyczaj spotykaliśmy się w naszych biurach, ale tym razem to my…</time><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/286545395/">Szczegóły</a></article></div></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--6@xl m-display-flex m-flex-direction_column"><div class="m-margin-bottom_16 m-display-flex m-flex-direction_column m-flex-direction_row_sm m-padding-bottom_0"><a href="https://www.meetup.com/allegrotech/events/285416318/" title="UX Research Confetti - II edycja" class="m-display_none m-display_block_lg" style="background-color:#fd4a02"><img width="218" src="images/event.png" alt="UX Research Confetti - II edycja"/></a><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-direction_column m-padding-bottom_0 m-flex_1 m-flex-justify_between m-color-bg_card"><a href="https://www.meetup.com/allegrotech/events/285416318/" title="UX Research Confetti - II edycja" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">UX Research Confetti - II edycja</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">około miesiąc temu</time><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-top-8">REJESTRACJA NA WYDARZENIE -&amp;gt; https://app.evenea.pl/event/ux-research-confetti-2/ 🎉 Niech ponownie rozsypie się confetti wiedzy o badaniach UX! 🎉 Szukaliśmy konferencji badawczej UX w Polsce i nie znaleźliśmy……</time><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/285416318/">Szczegóły</a></article></div></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--6@xl m-display-flex m-flex-direction_column"><div class="m-margin-bottom_16 m-display-flex m-flex-direction_column m-flex-direction_row_sm m-padding-bottom_0"><a href="https://www.meetup.com/allegrotech/events/285691203/" title="Allegro Tech Live #28 - Mobile: Architektura softu i architektura sprzętu" class="m-display_none m-display_block_lg" style="background-color:#fd4a02"><img width="218" src="images/event.png" alt="Allegro Tech Live #28 - Mobile: Architektura softu i architektura sprzętu"/></a><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-direction_column m-padding-bottom_0 m-flex_1 m-flex-justify_between m-color-bg_card"><a href="https://www.meetup.com/allegrotech/events/285691203/" title="Allegro Tech Live #28 - Mobile: Architektura softu i architektura sprzętu" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Allegro Tech Live #28 - Mobile: Architektura softu i architektura sprzętu</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">około miesiąc temu</time><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-top-8">**Allegro Tech Live** to w 100% zdalna odsłona naszych stacjonarnych meetupów Allegro Tech Talks. Kiedyś spotykaliśmy się w naszych biurach, a teraz to my gościmy…</time><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/285691203/">Szczegóły</a></article></div></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--6@xl m-display-flex m-flex-direction_column"><div class="m-margin-bottom_16 m-display-flex m-flex-direction_column m-flex-direction_row_sm m-padding-bottom_0"><a href="https://www.meetup.com/allegrotech/events/285245512/" title="Allegro Tech Live #27 - Java, Python i rozsądny development" class="m-display_none m-display_block_lg" style="background-color:#fd4a02"><img width="218" src="images/event.png" alt="Allegro Tech Live #27 - Java, Python i rozsądny development"/></a><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-direction_column m-padding-bottom_0 m-flex_1 m-flex-justify_between m-color-bg_card"><a href="https://www.meetup.com/allegrotech/events/285245512/" title="Allegro Tech Live #27 - Java, Python i rozsądny development" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Allegro Tech Live #27 - Java, Python i rozsądny development</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">2 miesiące temu</time><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-top-8">\-\-\-\-\-\-\&amp;gt; Na wydarzenie obowiązuje rejestracja: [https://app.evenea.pl/event/allegro-tech-live-27/](https://app.evenea.pl/event/allegro-tech-live-27/?fbclid=IwAR3QOef6CKKiuowl1Nto3Z4YEFMj7R7hdq_REpvY2a-3ETaJsWhvfnXDLxE) &amp;lt;----- Allegro Tech Live to w 100% zdalna odsłona naszych stacjonarnych meetupów Allegro Tech Talks. Kiedyś spotykaliśmy się w…</time><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/285245512/">Szczegóły</a></article></div></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display_block m-margin-bottom_8 m-width_100 m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/">Zobacz więcej wydarzeń</a></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24">Oferty pracy</h2><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto"><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm m-margin-bottom_0_sm m-flex-grow_1">Research Engineer - Machine Learning (Computer Vision)</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-font-size_21 m-font-size_25_sm m-font-weight_300 m-line-height_normal m-margin-top_16 m-text-align_left m-padding-right_16">Warszawa, Kraków, Poznań, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.smartrecruiters.com/Allegro/743999810853837-research-engineer-machine-learning-computer-vision?trid=de9dfdf3-7f9e-4ebf-8a64-49f6c69ad640">Sprawdź</a></article><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm m-margin-bottom_0_sm m-flex-grow_1">Research Engineer - Machine Learning (Ranking and Recommendations)</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-font-size_21 m-font-size_25_sm m-font-weight_300 m-line-height_normal m-margin-top_16 m-text-align_left m-padding-right_16">Warszawa, Poznań, Kraków, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.smartrecruiters.com/Allegro/743999785421861-research-engineer-machine-learning-ranking-and-recommendations?trid=de9dfdf3-7f9e-4ebf-8a64-49f6c69ad640">Sprawdź</a></article><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm m-margin-bottom_0_sm m-flex-grow_1">Research Engineer - Machine Learning (Ranking and Recommendations)</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-font-size_21 m-font-size_25_sm m-font-weight_300 m-line-height_normal m-margin-top_16 m-text-align_left m-padding-right_16">Warszawa, Poznań, Kraków, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.smartrecruiters.com/Allegro/743999779448676-research-engineer-machine-learning-ranking-and-recommendations?trid=de9dfdf3-7f9e-4ebf-8a64-49f6c69ad640">Sprawdź</a></article></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display_block m-margin-bottom_8 m-width_100 m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://allegro.pl/praca">Zobacz więcej ofert</a></div><footer class="m-color-bg_navy m-margin-top-32"><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24 m-padding-bottom-24 m-display-flex@sm m-flex-justify-between m-flex-items-center m-text-align_center"><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-color_white m-padding-left-24@sm">Proudly built by Allegro Tech engineers</p><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0 m-display-flex m-flex-justify-center"><li style="filter:brightness(0) invert(1);opacity:0.5" class="m-margin-right-8 m-margin-top-16 m-margin-top-0@sm m-color_white"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://github.com/allegro"><img src="https://assets.allegrostatic.com/metrum/icon/github-6a18df1729.svg" alt="Github" class="m-icon"/></a></li><li style="filter:brightness(0) invert(1);opacity:0.5" class="m-margin-right-8 m-margin-top-16 m-margin-top-0@sm m-color_white"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://www.facebook.com/allegro.tech/"><img src="https://assets.allegrostatic.com/metrum/icon/facebook-a2b92f9dcb.svg" alt="Facebook" class="m-icon"/></a></li><li style="filter:brightness(0) invert(1);opacity:0.5" class="m-margin-right-8 m-margin-top-16 m-margin-top-0@sm m-color_white"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/allegrotech"><img src="https://assets.allegrostatic.com/metrum/icon/twitter-25164a58aa.svg" alt="Twitter" class="m-icon"/></a></li></ul></div></footer><div style="visibility:hidden;height:0;overflow:hidden;position:relative"><img alt="doubleclick" width="1" height="1" style="position:absolute" src="https://pubads.g.doubleclick.net/activity;dc_iu=/21612525419/DFPAudiencePixel;ord=9856749912782.17;dc_seg=507368552?"/><img alt="fb" height="1" width="1" style="position:absolute" src="https://www.facebook.com/tr?id=1650870088530325&amp;ev=PageView&amp;noscript=1"/></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"Exploring GraphQL’s performance tradeoffs","link":"https://blog.allegro.tech/2022/06/graphql-perf-tradeoffs.html","pubDate":"Mon, 20 Jun 2022 00:00:00 +0200","authors":{"author":[{"name":["Alicja Halamska"],"photo":["https://blog.allegro.tech/img/authors/alicja.halamska.jpg"],"url":["https://blog.allegro.tech/authors/alicja.halamska"]},{"name":["Dawid Kubicki"],"photo":["https://blog.allegro.tech/img/authors/dawid.kubicki.jpg"],"url":["https://blog.allegro.tech/authors/dawid.kubicki"]}]},"content":"\u003cp\u003eAt \u003ca href=\"https://allegro.tech/\"\u003eAllegro\u003c/a\u003e we decided to introduce \u003ca href=\"https://graphql.org/\"\u003eGraphQL\u003c/a\u003e as our API Gateway for building several internal client systems.\nBy building such a solution we’ve learnt a lot about this technology\nand we would like to share it with you in this article.\u003c/p\u003e\n\n\u003ch2 id=\"whats-graphql-and-how-does-it-work\"\u003eWhat’s GraphQL and how does it work?\u003c/h2\u003e\n\u003cp\u003eTo understand how to increase GraphQL’s performance we need to understand how it works under the hood.\nWhy is it so important? In GraphQL most of the common ideas on how to speed up the communication are useless.\nOne of the things we usually do is introduce caching to our application, but you can often hear that GraphQL is not cacheable.\nIndeed it is not that simple in GraphQL and we hope to clarify it to you later in this article.\u003c/p\u003e\n\n\u003cp\u003eSo what is GraphQL? \u003ca href=\"https://graphql.org/\"\u003eGraphQL’s documentation\u003c/a\u003e says:\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003eGraphQL is a query language for APIs and a runtime for fulfilling those queries with your existing data.\nGraphQL provides a complete and understandable description of the data in your API,\ngives clients the power to ask for exactly what they need and nothing more […].\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eGraphQL sends the information through a standard TCP connection (mostly HTTP).\nThere is only one entry point and all needed information is sent in a request parameter or body.\nIn contrast to the REST API, where we often fetch fields that we won’t use, in GraphQL we can ask for and compute only the useful ones.\nThis key feature gives us the first and most important way to speed up our application: ask only for the information that you need.\u003c/p\u003e\n\n\u003cp\u003eThere are three key concepts that we should be aware of:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eSchema — description of your data in a JSON-like format.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cdiv class=\"language-graphql highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003etype\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eUser\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nb\"\u003eID\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nb\"\u003eString\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"n\"\u003eemail\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nb\"\u003eString\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"n\"\u003efriends\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eUser\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\u003cul\u003e\n  \u003cli\u003eQueries — the way we ask for processing information.\nWe provide information about which resources we want to fetch or mutate and which fields exactly we want to be returned.\nWe can fetch data with an operation called a query or change data with a mutation.\nBelow we query for the user’s name and his friends’ names.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cdiv class=\"language-graphql highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003equery\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n \u003c/span\u003e\u003cspan class=\"n\"\u003euser\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"1234\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"n\"\u003efriends\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\u003cul\u003e\n  \u003cli\u003eResolvers — fragments of code that serve information for specific parts of schema.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2 id=\"resolver-design-is-a-game-changer\"\u003eResolver design is a game changer!\u003c/h2\u003e\n\n\u003cp\u003eWe will spend the whole paragraph on making sure we are on the same page understanding how resolvers work.\nA schema consists of types definitions:\n— defined queries/mutations/subscriptions that we can ask (we can think of it as the root of the graph)\n— input objects that we take as arguments in queries/mutations/subscriptions\n— objects that we return from queries/mutations/subscriptions\n— scalars, the simplest types like int or string (which are always a leaf in a graph)\u003c/p\u003e\n\n\u003cp\u003eAs the schema is composed of queries and types, there are two kinds of resolvers. The first is obligatory and resolves the whole query.\nIt can return the complete result, but also only a part of it.\nThe second part is added by type resolvers. Let us show you an example: let’s say we want to get information about a user.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-06-20-graphql-perf-tradeoffs/resolvers.png\" alt=\"resolver\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eAt first we run \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eUserQueryResolver\u003c/code\u003e, which fetches user data from user domain logic. Only the ID of the user is returned.\nThen we call \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eUserTypeResolver\u003c/code\u003e with the ID resolved earlier.\nIt makes two calls: first one to user email service and second to user name service.\nWhen resolving is over, GraphQL returns the result.\n\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eUserQueryResolver\u003c/code\u003e might also have returned all information.\nOne of the main questions about optimizing GraphQL is when to use a query resolver, and when a type resolver.\nWe decided to use:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e\n    \u003cp\u003eA query resolver for fields that come from the same data source as the identifier field.\nWe may ask for information that we don’t need,\nbut we skip the unnecessary connection time overhead when we ask for more than one field.\nMoreover, most of the sources that are connected to our service are REST APIs and always compute all fields, so why shouldn’t we use them?\nAdding additional resolvers also complicates logic and makes the flow less clear.\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003eA type resolver when some parts of a query can be resolved independently, because those parts can run in parallel.\nTo achieve it, wrap the resolver’s functions with any of the asynchronous abstractions. We also use type resolvers when we ask for some part of the domain\nthat isn’t ours to avoid dependency crossing.\u003c/p\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2 id=\"the-metrics-war\"\u003eThe metrics war\u003c/h2\u003e\n\n\u003cp\u003eThere are different approaches to performance monitoring depending on the element whose performance we monitor:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003ePoor - HTTP endpoint (just one endpoint which always responds with 200 status code)\u003c/li\u003e\n  \u003cli\u003eBetter - GraphQL query/mutation (each query/mutation)\u003c/li\u003e\n  \u003cli\u003eAlmost great - Resolvers (access to data source)\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThe HTTP endpoint is the point at which we measured performance for a REST API.\nFor example one of the simplest ways of monitoring performance for API endpoints is response time.\nSome basic dashboards could look like this:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-06-20-graphql-perf-tradeoffs/p95-response-1.png\" alt=\"dashboard_1\" /\u003e\n\u003cimg src=\"/img/articles/2022-06-20-graphql-perf-tradeoffs/p95-response-2.png\" alt=\"dashboard_2\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eIn the GraphQL universe, there is usually only one endpoint. This approach has advantages and disadvantages.\nWhile we have low latency and no errors it is great for us as developers and business.\nWe have just one entry point and one failure point but if something goes wrong we have to dig deeper.\u003c/p\u003e\n\n\u003cp\u003eThe chart below, showing p95 response times for a single GraphQL endpoint, does not tell the whole story. In reality we have plenty of consumers which use different input data and ask us for variety of payload in extended scope.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-06-20-graphql-perf-tradeoffs/p95-response-3.png\" alt=\"dashboard_3\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eWe are using a simple metric configuration for measuring endpoints:\u003c/p\u003e\n\n\u003cdiv class=\"language-kotlin highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eMetricFilter\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eprivate\u003c/span\u003e \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003emeterRegistry\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eMeterRegistry\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eOncePerRequestFilter\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003eoverride\u003c/span\u003e \u003cspan class=\"k\"\u003efun\u003c/span\u003e \u003cspan class=\"nf\"\u003edoFilterInternal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n        \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eHttpServletRequest\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eHttpServletResponse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n        \u003cspan class=\"n\"\u003efilterChain\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eFilterChain\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n        \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003estart\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"nc\"\u003eSystem\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003enanoTime\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n        \u003cspan class=\"k\"\u003etry\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n            \u003cspan class=\"n\"\u003efilterChain\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003edoFilter\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003erequest\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e}\u003c/span\u003e \u003cspan class=\"k\"\u003efinally\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n            \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003efinish\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"nc\"\u003eSystem\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003enanoTime\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n            \u003cspan class=\"n\"\u003emeterRegistry\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003etimer\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n                \u003cspan class=\"s\"\u003e\"api.execution\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                \u003cspan class=\"s\"\u003e\"statusCode\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                \u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estatus\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003etoString\u003c/span\u003e\u003cspan class=\"p\"\u003e(),\u003c/span\u003e\n                \u003cspan class=\"s\"\u003e\"path\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erequestURI\u003c/span\u003e\n            \u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"nf\"\u003erecord\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003efinish\u003c/span\u003e \u003cspan class=\"p\"\u003e-\u003c/span\u003e \u003cspan class=\"n\"\u003estart\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nc\"\u003eTimeUnit\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nc\"\u003eMILLISECONDS\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\u003cp\u003eRemember that our queries can change in time, e.g. by extended business requirements. They can start from a simple query like this:\u003c/p\u003e\n\n\u003cdiv class=\"language-graphql highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003equery\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"n\"\u003euser\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n        \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eID\u003c/span\u003e\u003cspan class=\"w\"\u003e\n        \u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eString\u003c/span\u003e\u003cspan class=\"w\"\u003e\n        \u003c/span\u003e\u003cspan class=\"n\"\u003eemail\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eString\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eAfter a few new features are added, they can end up more complex like the one below. In the same query we ask for ten thousand additional objects from another data source.\nWe can imagine that the previous \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ep95\u003c/code\u003e dashboard doesn’t have much value now because it is perfectly normal that the\ncomputation time increases when we ask for additional data. The pagination plays a big role here, too.\nBoth of these queries can still be executed at the same time and shouldn’t be measured by the same metric.\u003c/p\u003e\n\n\u003cdiv class=\"language-graphql highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003equery\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\t\u003c/span\u003e\u003cspan class=\"n\"\u003euser\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n        \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eID\u003c/span\u003e\u003cspan class=\"w\"\u003e\n        \u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eString\u003c/span\u003e\u003cspan class=\"w\"\u003e\n        \u003c/span\u003e\u003cspan class=\"n\"\u003eemail\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eString\u003c/span\u003e\u003cspan class=\"w\"\u003e\n        \u003c/span\u003e\u003cspan class=\"n\"\u003efriends\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003elimit\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e10000\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eoffset\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e){\u003c/span\u003e\u003cspan class=\"w\"\u003e\n            \u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eString\u003c/span\u003e\u003cspan class=\"w\"\u003e\n            \u003c/span\u003e\u003cspan class=\"n\"\u003elastName\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eString\u003c/span\u003e\u003cspan class=\"w\"\u003e\n        \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch3 id=\"slow-query-log\"\u003eSlow query log\u003c/h3\u003e\n\n\u003cp\u003eAfter integrating a huge number of new APIs we realized that simple HTTP endpoint monitoring was not enough in our case.\nWe had been looking for a better approach. Slow query log is a simple concept -\nset a threshold at which we consider a query too slow.\nEach query that exceeds that threshold gets logged with all input parameters.\nMoreover we set up metrics which indicate that some problematic query appears.\nIs such an approach perfect?\nNo, we still have to analyze each query and answer the question if the query is slow because\nof query complexity or maybe because of other problems.\nAt the end of the day we can use this approach as a simple and effective tool to find slow queries quite fast.\u003c/p\u003e\n\n\u003cp\u003eAs an example we can show you the code below.\nWe created our own instrumentation at the beginning of each query to measure time and variables.\u003c/p\u003e\n\n\u003cdiv class=\"language-kotlin highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"nd\"\u003e@Component\u003c/span\u003e\n\u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eMonitoringInstrumentation\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eprivate\u003c/span\u003e \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003eclock\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eClock\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eprivate\u003c/span\u003e \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003emeterRegistry\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eMeterRegistry\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eSimpleInstrumentation\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003eoverride\u003c/span\u003e \u003cspan class=\"k\"\u003efun\u003c/span\u003e \u003cspan class=\"nf\"\u003einstrumentExecutionResult\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eexecutionResult\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eExecutionResult\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eparameters\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eInstrumentationExecutionParameters\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e):\u003c/span\u003e \u003cspan class=\"nc\"\u003eCompletableFuture\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nc\"\u003eExecutionResult\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n        \u003cspan class=\"k\"\u003etry\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n            \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003einstrumentationState\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eparameters\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003egetInstrumentationState\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nc\"\u003eMonitoringInstrumentationState\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;()\u003c/span\u003e\n            \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003estartTime\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003einstrumentationState\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estartTime\u003c/span\u003e\n            \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003eendTime\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"nf\"\u003egetTime\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n            \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003eexecutionTime\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003estartTime\u003c/span\u003e \u003cspan class=\"p\"\u003e-\u003c/span\u003e \u003cspan class=\"n\"\u003eendTime\u003c/span\u003e\n            \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eexecutionTime\u003c/span\u003e \u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"mi\"\u003e1000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n                \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003equery\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eparameters\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003equery\u003c/span\u003e\n                \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003evariables\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eparameters\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evariables\u003c/span\u003e\n                \u003cspan class=\"n\"\u003emetric\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eincrement\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n                    \u003cspan class=\"nc\"\u003eSLOW_QUERY_METRIC_NAME\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                    \u003cspan class=\"s\"\u003e\"duration\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                    \u003cspan class=\"n\"\u003eexecutionTime\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n                \u003cspan class=\"n\"\u003elogger\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003ewarn\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n                    \u003cspan class=\"s\"\u003e\"Slow query: $query with variables ${serializeVariables(variables)}.\"\u003c/span\u003e \u003cspan class=\"p\"\u003e+\u003c/span\u003e\n                        \u003cspan class=\"s\"\u003e\" Duration: ${executionTime.toMillis()} ms\"\u003c/span\u003e\n                \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n            \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"k\"\u003esuper\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003einstrumentExecutionResult\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eexecutionResult\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eparameters\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n  \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch3 id=\"per-field-monitoring\"\u003ePer field monitoring\u003c/h3\u003e\n\n\u003cp\u003eLast but not least, an interesting approach which we consider, and is almost out of the box for resolvers and supported by many libraries, is per field monitoring.\nIt is pretty nice for getting extra data to analyze our graph.\nHowever, it can be expensive to collect such a type of data.\nGathering metrics for each field can be more valuable than monitoring each query.\nMoreover, we can easily find the bottleneck of bits and pieces of our graph.\nResolvers monitoring can be achieved by using libraries built into our GraphQL server implementation such as\n\u003ccode class=\"language-plaintext highlighter-rouge\"\u003egraphql-java-server\u003c/code\u003e.\nOur implementation follows the Apollo proposed tracing format (\u003ca href=\"https://github.com/apollographql\"\u003eA community building flexible open source tools for GraphQL\u003c/a\u003e).\u003c/p\u003e\n\n\u003cdiv class=\"language-json highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"data\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n   \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"user\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n     \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"name\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"Javier\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n     \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"friends\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"w\"\u003e\n       \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n         \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"name\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"Clarisa\"\u003c/span\u003e\u003cspan class=\"w\"\u003e\n       \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n     \u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"w\"\u003e\n   \u003c/span\u003e\u003cspan class=\"p\"\u003e},\u003c/span\u003e\u003cspan class=\"w\"\u003e\n \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"extensions\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n   \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"tracing\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n     \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"version\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n     \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"startTime\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"2022-04-14T23:13:39.362Z\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n     \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"endTime\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"2022-04-14T23:13:39.497Z\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n     \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"duration\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e135589186\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n     \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"execution\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n       \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"resolvers\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"w\"\u003e\n         \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"path\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"w\"\u003e\n             \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"user\"\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"parentType\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"Query\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"returnType\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"Character\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"fieldName\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"user\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"startOffset\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e105697585\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"duration\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e79111240\u003c/span\u003e\u003cspan class=\"w\"\u003e\n         \u003c/span\u003e\u003cspan class=\"p\"\u003e},\u003c/span\u003e\u003cspan class=\"w\"\u003e\n         \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"path\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"w\"\u003e\n             \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"user\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n             \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"name\"\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"parentType\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"Girl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"returnType\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"String\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"fieldName\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"name\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"startOffset\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e125010028\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"duration\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e20213\u003c/span\u003e\u003cspan class=\"w\"\u003e\n         \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n       \u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"w\"\u003e\n     \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n   \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eBottom line of resolver monitoring is thinking about it as checking each data source,\nnot the internal mechanism of GraphQL implementation.\nIt is possible that our internal performance is not the limiting factor as I / O and external connections are often critical.\u003c/p\u003e\n\n\u003ch2 id=\"batching-requests-to-external-services\"\u003eBatching requests to external services\u003c/h2\u003e\n\n\u003cp\u003eIn the paragraph about resolvers we mentioned connecting to the same source many times to\nfetch all the type fields in case of using type resolvers. There is a solution for that, and it is called data loaders.\nHow does it work? It collects all requests from many parts of the schema and retrieves their data in one request.\nThis allows it to solve the N+1 problem, which is very well known in GraphQL.\nImagine the situation where we want to query for three users.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-06-20-graphql-perf-tradeoffs/no-loader.png\" alt=\"no-loader\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eAs the diagram says, we must ask external sources four times for three users – once to fetch all users and once per each user to fetch his name.\nMoreover we call user name service many times even if it has some batch method to get logins for many users.\nIntroducing a data loader solves this problem. The second diagram shows how it works.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-06-20-graphql-perf-tradeoffs/data-loader.png\" alt=\"data-loader\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eWe cumulate all requests and ask user name service only once. Let’s see what the code looks like.\nWe have \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eUserBatchDataLoader\u003c/code\u003e which asks \u003ccode class=\"language-plaintext highlighter-rouge\"\u003euserClient\u003c/code\u003e for users and maps the response to \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eUser\u003c/code\u003e object.\u003c/p\u003e\n\n\u003cdiv class=\"language-kotlin highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"nd\"\u003e@Component\u003c/span\u003e\n\u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eUserBatchDataLoader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n   \u003cspan class=\"n\"\u003euserClient\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eUserClient\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n   \u003cspan class=\"n\"\u003eexecutor\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eExecutor\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eBatchDataLoaderInfo\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nc\"\u003eString\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nc\"\u003eUserResponse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nc\"\u003eUser\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;(\u003c/span\u003e\n   \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"n\"\u003euserIds\u003c/span\u003e \u003cspan class=\"p\"\u003e-\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003euserClient\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eusers\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003euserIds\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e},\u003c/span\u003e\n   \u003cspan class=\"nc\"\u003eUserResponse\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003euserId\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n   \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"n\"\u003eit\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003etoUser\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e},\u003c/span\u003e\n   \u003cspan class=\"n\"\u003eexecutor\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eThere is also \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eUserTypeResolver\u003c/code\u003e that uses it while resolving user name.\u003c/p\u003e\n\n\u003cdiv class=\"language-kotlin highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\n\u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eUserTypeResolver\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n   \u003cspan class=\"k\"\u003eprivate\u003c/span\u003e \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003euserBatchDataLoader\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eUserBatchDataLoader\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eGraphQLResolver\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nc\"\u003eUser\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n   \u003cspan class=\"k\"\u003efun\u003c/span\u003e \u003cspan class=\"nf\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n       \u003cspan class=\"n\"\u003euser\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eUser\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n       \u003cspan class=\"n\"\u003edfe\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eDataFetchingEnvironment\u003c/span\u003e\n   \u003cspan class=\"p\"\u003e):\u003c/span\u003e \u003cspan class=\"nc\"\u003eCompletableFuture\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nc\"\u003eString\u003c/span\u003e\u003cspan class=\"err\"\u003e?\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e\n       \u003cspan class=\"nf\"\u003eextractDataLoader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003euserBatchDataLoader\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edfe\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n           \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003euser\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003euserId\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eraw\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n           \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003ethenApply\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"n\"\u003eit\u003c/span\u003e\u003cspan class=\"o\"\u003e?.\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eExactly the same can be done with \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eUser\u003c/code\u003e fields in the type resolver.\nWe can accumulate requests for each field and run it once if the source is the same.\nThere is a \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eUserDataLoader\u003c/code\u003e that asks \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eUserClient\u003c/code\u003e for the whole \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eUser\u003c/code\u003e object.\u003c/p\u003e\n\n\u003cdiv class=\"language-kotlin highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"nd\"\u003e@Component\u003c/span\u003e\n\u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eUserDataLoader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n   \u003cspan class=\"n\"\u003euserClient\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eUserClient\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n   \u003cspan class=\"n\"\u003eexecutor\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eExecutor\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eSimpleDataLoaderInfo\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nc\"\u003eString\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nc\"\u003eUserResponse\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;(\u003c/span\u003e\n   \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"n\"\u003euserId\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eString\u003c/span\u003e \u003cspan class=\"p\"\u003e-\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003euserClient\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003euser\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003euserId\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e},\u003c/span\u003e\n   \u003cspan class=\"n\"\u003eexecutor\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eIt is used in \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eUserTypeResolver\u003c/code\u003e while resolving first name and email.\u003c/p\u003e\n\n\u003cdiv class=\"language-kotlin highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"nd\"\u003e@Component\u003c/span\u003e\n\u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eUserTypeResolver\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n\u003cspan class=\"k\"\u003eprivate\u003c/span\u003e \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003edataLoaderInfo\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eUserDataLoader\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003cspan class=\"k\"\u003eprivate\u003c/span\u003e \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003eexecutor\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eExecutor\u003c/span\u003e\n\u003cspan class=\"p\"\u003e):\u003c/span\u003e \u003cspan class=\"nc\"\u003eGraphQLResolver\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nc\"\u003eUser\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\n\t\u003cspan class=\"k\"\u003efun\u003c/span\u003e \u003cspan class=\"nf\"\u003efirstName\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003euser\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eUser\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edfe\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eDataFetchingEnvironment\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e \u003cspan class=\"nc\"\u003eCompletableFuture\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nc\"\u003eString\u003c/span\u003e\u003cspan class=\"err\"\u003e?\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e\n   \u003cspan class=\"nf\"\u003eextractDataLoader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edataLoaderInfo\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edfe\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n       \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003euser\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003euserId\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eraw\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n       \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003ethenApply\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"n\"\u003eit\u003c/span\u003e\u003cspan class=\"o\"\u003e?.\u003c/span\u003e\u003cspan class=\"n\"\u003eperson\u003c/span\u003e\u003cspan class=\"o\"\u003e?.\u003c/span\u003e\u003cspan class=\"n\"\u003efirstName\u003c/span\u003e \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003efun\u003c/span\u003e \u003cspan class=\"nf\"\u003eemail\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003euser\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eUser\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edfe\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eDataFetchingEnvironment\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e \u003cspan class=\"nc\"\u003eCompletableFuture\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nc\"\u003eString\u003c/span\u003e\u003cspan class=\"err\"\u003e?\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e\n   \u003cspan class=\"nf\"\u003eextractDataLoader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edataLoaderInfo\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edfe\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n       \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003euser\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003euserId\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eraw\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n       \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003ethenApply\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"n\"\u003eit\u003c/span\u003e\u003cspan class=\"o\"\u003e?.\u003c/span\u003e\u003cspan class=\"n\"\u003econtacts\u003c/span\u003e\u003cspan class=\"o\"\u003e?.\u003c/span\u003e\u003cspan class=\"n\"\u003eemail\u003c/span\u003e \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch2 id=\"caching---why-is-it-so-troublesome\"\u003eCaching - why is it so troublesome?\u003c/h2\u003e\n\n\u003ch3 id=\"http-caching\"\u003eHTTP caching\u003c/h3\u003e\n\n\u003cp\u003eThe biggest problem that makes using HTTP caching less effective is plenty of different requests that we can make.\nWhen we ask for a user with his name and email the response is saved in cache.\nBut when we ask again without the information about email despite the fact that\nthe information is already available we cannot use it,\nbecause this is a different query (and HTTP cache cannot handle it without understanding GraphQL logic).\nTo make cache work best we should recognise at field level which user name is already in\nmemory and ask only for the rest of them.\u003c/p\u003e\n\n\u003ch3 id=\"server-side-caching\"\u003eServer-side caching\u003c/h3\u003e\n\u003cp\u003eLet’s put aside HTTP caching and focus more on how we can implement server cache that is more focused on GraphQL logic.\nWe could cache specific types from our schema or their fields. A good example of implemented server-side cache is\n\u003ca href=\"https://www.apollographql.com/docs/apollo-server/performance/caching/\"\u003eapollo-server\u003c/a\u003e.\nSo if we run the same type or query resolver with the same arguments it can be returned from cache.\nWith \u003ca href=\"https://github.com/graphql-java/java-dataloader#the-scope-of-a-data-loader-is-important\"\u003edata loaders\u003c/a\u003e you can also cache requests to external sources not only in one query,\nbut even between many queries by selecting a specific strategy. This solution is available out of the box, and can be used easily.\u003c/p\u003e\n\n\u003ch3 id=\"client-side-caching\"\u003eClient-side caching\u003c/h3\u003e\n\u003cp\u003eAnother common way to cache query response is client-side caching. It can be very beneficial, because one client may ask for the same information many times.\nAs an example we can take Apollo client and its solution. The cache uses the ID field to identify whether an object exists in memory.\nThen it checks if all fields that are to be returned are already in memory, if some are not it asks only for them.\u003c/p\u003e\n\n\u003ch3 id=\"our-caching-decisions\"\u003eOur caching decisions\u003c/h3\u003e\n\u003cp\u003eWe’ve decided not to use server-side caching with a global data loader because we have struggled with many clients of our graph and the graph’s data\nchanges frequently. That forced us to use a cache-per-request strategy.\nIf we are talking about caching on the client side we tackle the issue that some of our objects don’t have a unique \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eID\u003c/code\u003e so after a while we skipped this approach and we are not caching them on the client side either.\u003c/p\u003e\n\n\u003ch2 id=\"what-is-the-outcome-of-the-battle\"\u003eWhat is the outcome of the battle?\u003c/h2\u003e\n\n\u003cp\u003eWe have learned a lot about GraphQL’s trade offs while working with it, but there is still a lot to be discovered. The most important feature of it, fetching only those fields that we need, is a huge optimization itself, but also causes many problems with standard ways to make the application effective or even to measure that efficiency.\nThe ideas that we described above need to be implemented by the programmers (most libraries don’t provide that logic) and it’s really complex and time consuming.\u003c/p\u003e\n","contentSnippet":"At Allegro we decided to introduce GraphQL as our API Gateway for building several internal client systems.\nBy building such a solution we’ve learnt a lot about this technology\nand we would like to share it with you in this article.\nWhat’s GraphQL and how does it work?\nTo understand how to increase GraphQL’s performance we need to understand how it works under the hood.\nWhy is it so important? In GraphQL most of the common ideas on how to speed up the communication are useless.\nOne of the things we usually do is introduce caching to our application, but you can often hear that GraphQL is not cacheable.\nIndeed it is not that simple in GraphQL and we hope to clarify it to you later in this article.\nSo what is GraphQL? GraphQL’s documentation says:\nGraphQL is a query language for APIs and a runtime for fulfilling those queries with your existing data.\nGraphQL provides a complete and understandable description of the data in your API,\ngives clients the power to ask for exactly what they need and nothing more […].\nGraphQL sends the information through a standard TCP connection (mostly HTTP).\nThere is only one entry point and all needed information is sent in a request parameter or body.\nIn contrast to the REST API, where we often fetch fields that we won’t use, in GraphQL we can ask for and compute only the useful ones.\nThis key feature gives us the first and most important way to speed up our application: ask only for the information that you need.\nThere are three key concepts that we should be aware of:\nSchema — description of your data in a JSON-like format.\n\ntype User {\n    id: ID\n    name: String\n    email: String\n    friends: [User]\n}\n\n\nQueries — the way we ask for processing information.\nWe provide information about which resources we want to fetch or mutate and which fields exactly we want to be returned.\nWe can fetch data with an operation called a query or change data with a mutation.\nBelow we query for the user’s name and his friends’ names.\n\nquery {\n user(id: \"1234\") {\n    name\n    friends { name }\n }\n}\n\n\nResolvers — fragments of code that serve information for specific parts of schema.\nResolver design is a game changer!\nWe will spend the whole paragraph on making sure we are on the same page understanding how resolvers work.\nA schema consists of types definitions:\n— defined queries/mutations/subscriptions that we can ask (we can think of it as the root of the graph)\n— input objects that we take as arguments in queries/mutations/subscriptions\n— objects that we return from queries/mutations/subscriptions\n— scalars, the simplest types like int or string (which are always a leaf in a graph)\nAs the schema is composed of queries and types, there are two kinds of resolvers. The first is obligatory and resolves the whole query.\nIt can return the complete result, but also only a part of it.\nThe second part is added by type resolvers. Let us show you an example: let’s say we want to get information about a user.\n\nAt first we run UserQueryResolver, which fetches user data from user domain logic. Only the ID of the user is returned.\nThen we call UserTypeResolver with the ID resolved earlier.\nIt makes two calls: first one to user email service and second to user name service.\nWhen resolving is over, GraphQL returns the result.\nUserQueryResolver might also have returned all information.\nOne of the main questions about optimizing GraphQL is when to use a query resolver, and when a type resolver.\nWe decided to use:\nA query resolver for fields that come from the same data source as the identifier field.\nWe may ask for information that we don’t need,\nbut we skip the unnecessary connection time overhead when we ask for more than one field.\nMoreover, most of the sources that are connected to our service are REST APIs and always compute all fields, so why shouldn’t we use them?\nAdding additional resolvers also complicates logic and makes the flow less clear.\nA type resolver when some parts of a query can be resolved independently, because those parts can run in parallel.\nTo achieve it, wrap the resolver’s functions with any of the asynchronous abstractions. We also use type resolvers when we ask for some part of the domain\nthat isn’t ours to avoid dependency crossing.\nThe metrics war\nThere are different approaches to performance monitoring depending on the element whose performance we monitor:\nPoor - HTTP endpoint (just one endpoint which always responds with 200 status code)\nBetter - GraphQL query/mutation (each query/mutation)\nAlmost great - Resolvers (access to data source)\nThe HTTP endpoint is the point at which we measured performance for a REST API.\nFor example one of the simplest ways of monitoring performance for API endpoints is response time.\nSome basic dashboards could look like this:\n\n\nIn the GraphQL universe, there is usually only one endpoint. This approach has advantages and disadvantages.\nWhile we have low latency and no errors it is great for us as developers and business.\nWe have just one entry point and one failure point but if something goes wrong we have to dig deeper.\nThe chart below, showing p95 response times for a single GraphQL endpoint, does not tell the whole story. In reality we have plenty of consumers which use different input data and ask us for variety of payload in extended scope.\n\nWe are using a simple metric configuration for measuring endpoints:\n\nclass MetricFilter(\n    private val meterRegistry: MeterRegistry\n) : OncePerRequestFilter() {\n\n    override fun doFilterInternal(\n        request: HttpServletRequest,\n        response: HttpServletResponse,\n        filterChain: FilterChain\n    ) {\n        val start = System.nanoTime();\n        try {\n            filterChain.doFilter(request, response)\n        } finally {\n            val finish = System.nanoTime();\n            meterRegistry.timer(\n                \"api.execution\",\n                \"statusCode\",\n                response.status.toString(),\n                \"path\",\n                request.requestURI\n            ).record(finish - start, TimeUnit.MILLISECONDS)\n        }\n    }\n}\n\n\nRemember that our queries can change in time, e.g. by extended business requirements. They can start from a simple query like this:\n\nquery {\n    user {\n        id: ID\n        name: String\n        email: String\n    }\n}\n\n\nAfter a few new features are added, they can end up more complex like the one below. In the same query we ask for ten thousand additional objects from another data source.\nWe can imagine that the previous p95 dashboard doesn’t have much value now because it is perfectly normal that the\ncomputation time increases when we ask for additional data. The pagination plays a big role here, too.\nBoth of these queries can still be executed at the same time and shouldn’t be measured by the same metric.\n\nquery {\n\tuser {\n        id: ID\n        name: String\n        email: String\n        friends(limit: 10000, offset: 1){\n            name: String\n            lastName: String\n        }\n    }\n}\n\n\nSlow query log\nAfter integrating a huge number of new APIs we realized that simple HTTP endpoint monitoring was not enough in our case.\nWe had been looking for a better approach. Slow query log is a simple concept -\nset a threshold at which we consider a query too slow.\nEach query that exceeds that threshold gets logged with all input parameters.\nMoreover we set up metrics which indicate that some problematic query appears.\nIs such an approach perfect?\nNo, we still have to analyze each query and answer the question if the query is slow because\nof query complexity or maybe because of other problems.\nAt the end of the day we can use this approach as a simple and effective tool to find slow queries quite fast.\nAs an example we can show you the code below.\nWe created our own instrumentation at the beginning of each query to measure time and variables.\n\n@Component\nclass MonitoringInstrumentation(\n    private val clock: Clock,\n    private val meterRegistry: MeterRegistry,\n) : SimpleInstrumentation() {\n\n    override fun instrumentExecutionResult(\n        executionResult: ExecutionResult,\n        parameters: InstrumentationExecutionParameters\n    ): CompletableFuture\u003cExecutionResult\u003e {\n        try {\n            val instrumentationState = parameters.getInstrumentationState\u003cMonitoringInstrumentationState\u003e()\n            val startTime = instrumentationState.startTime\n            val endTime = getTime()\n            val executionTime = startTime - endTime\n            if (executionTime \u003e 1000) {\n                val query = parameters.query\n                val variables = parameters.variables\n                metric.increment(\n                    SLOW_QUERY_METRIC_NAME,\n                    \"duration\",\n                    executionTime)\n                logger.warn {\n                    \"Slow query: $query with variables ${serializeVariables(variables)}.\" +\n                        \" Duration: ${executionTime.toMillis()} ms\"\n                }\n            }\n        }\n        return super.instrumentExecutionResult(executionResult, parameters)\n    }\n  }\n\n\nPer field monitoring\nLast but not least, an interesting approach which we consider, and is almost out of the box for resolvers and supported by many libraries, is per field monitoring.\nIt is pretty nice for getting extra data to analyze our graph.\nHowever, it can be expensive to collect such a type of data.\nGathering metrics for each field can be more valuable than monitoring each query.\nMoreover, we can easily find the bottleneck of bits and pieces of our graph.\nResolvers monitoring can be achieved by using libraries built into our GraphQL server implementation such as\ngraphql-java-server.\nOur implementation follows the Apollo proposed tracing format (A community building flexible open source tools for GraphQL).\n\n{\n \"data\":\n   \"user\": {\n     \"name\": \"Javier\",\n     \"friends\": [\n       {\n         \"name\": \"Clarisa\"\n       }\n     ]\n   },\n \"extensions\": {\n   \"tracing\": {\n     \"version\": 1,\n     \"startTime\": \"2022-04-14T23:13:39.362Z\",\n     \"endTime\": \"2022-04-14T23:13:39.497Z\",\n     \"duration\": 135589186,\n     \"execution\": {\n       \"resolvers\": [\n         {\n           \"path\": [\n             \"user\"\n           ],\n           \"parentType\": \"Query\",\n           \"returnType\": \"Character\",\n           \"fieldName\": \"user\",\n           \"startOffset\": 105697585,\n           \"duration\": 79111240\n         },\n         {\n           \"path\": [\n             \"user\",\n             \"name\"\n           ],\n           \"parentType\": \"Girl\",\n           \"returnType\": \"String\",\n           \"fieldName\": \"name\",\n           \"startOffset\": 125010028,\n           \"duration\": 20213\n         }\n       ]\n     }\n   }\n }\n}\n\n\nBottom line of resolver monitoring is thinking about it as checking each data source,\nnot the internal mechanism of GraphQL implementation.\nIt is possible that our internal performance is not the limiting factor as I / O and external connections are often critical.\nBatching requests to external services\nIn the paragraph about resolvers we mentioned connecting to the same source many times to\nfetch all the type fields in case of using type resolvers. There is a solution for that, and it is called data loaders.\nHow does it work? It collects all requests from many parts of the schema and retrieves their data in one request.\nThis allows it to solve the N+1 problem, which is very well known in GraphQL.\nImagine the situation where we want to query for three users.\n\nAs the diagram says, we must ask external sources four times for three users – once to fetch all users and once per each user to fetch his name.\nMoreover we call user name service many times even if it has some batch method to get logins for many users.\nIntroducing a data loader solves this problem. The second diagram shows how it works.\n\nWe cumulate all requests and ask user name service only once. Let’s see what the code looks like.\nWe have UserBatchDataLoader which asks userClient for users and maps the response to User object.\n\n@Component\nclass UserBatchDataLoader(\n   userClient: UserClient,\n   executor: Executor\n) : BatchDataLoaderInfo\u003cString, UserResponse, User\u003e(\n   { userIds -\u003e userClient.users(userIds) },\n   UserResponse::userId,\n   { it.toUser() },\n   executor\n)\n\n\nThere is also UserTypeResolver that uses it while resolving user name.\n\n\nclass UserTypeResolver(\n   private val userBatchDataLoader: UserBatchDataLoader\n) : GraphQLResolver\u003cUser\u003e {\n   fun name(\n       user: User,\n       dfe: DataFetchingEnvironment\n   ): CompletableFuture\u003cString?\u003e =\n       extractDataLoader(userBatchDataLoader, dfe)\n           .load(user.userId.raw)\n           .thenApply { it?.name }\n}\n\n\n\nExactly the same can be done with User fields in the type resolver.\nWe can accumulate requests for each field and run it once if the source is the same.\nThere is a UserDataLoader that asks UserClient for the whole User object.\n\n@Component\nclass UserDataLoader(\n   userClient: UserClient,\n   executor: Executor\n) : SimpleDataLoaderInfo\u003cString, UserResponse\u003e(\n   { userId: String -\u003e userClient.user(userId) },\n   executor\n)\n\n\nIt is used in UserTypeResolver while resolving first name and email.\n\n@Component\nclass UserTypeResolver(\nprivate val dataLoaderInfo: UserDataLoader,\nprivate val executor: Executor\n): GraphQLResolver\u003cUser\u003e {\n\n\tfun firstName(user: User, dfe: DataFetchingEnvironment): CompletableFuture\u003cString?\u003e =\n   extractDataLoader(dataLoaderInfo, dfe)\n       .load(user.userId.raw)\n       .thenApply { it?.person?.firstName }\n\nfun email(user: User, dfe: DataFetchingEnvironment): CompletableFuture\u003cString?\u003e =\n   extractDataLoader(dataLoaderInfo, dfe)\n       .load(user.userId.raw)\n       .thenApply { it?.contacts?.email }\n}\n\n\n\nCaching - why is it so troublesome?\nHTTP caching\nThe biggest problem that makes using HTTP caching less effective is plenty of different requests that we can make.\nWhen we ask for a user with his name and email the response is saved in cache.\nBut when we ask again without the information about email despite the fact that\nthe information is already available we cannot use it,\nbecause this is a different query (and HTTP cache cannot handle it without understanding GraphQL logic).\nTo make cache work best we should recognise at field level which user name is already in\nmemory and ask only for the rest of them.\nServer-side caching\nLet’s put aside HTTP caching and focus more on how we can implement server cache that is more focused on GraphQL logic.\nWe could cache specific types from our schema or their fields. A good example of implemented server-side cache is\napollo-server.\nSo if we run the same type or query resolver with the same arguments it can be returned from cache.\nWith data loaders you can also cache requests to external sources not only in one query,\nbut even between many queries by selecting a specific strategy. This solution is available out of the box, and can be used easily.\nClient-side caching\nAnother common way to cache query response is client-side caching. It can be very beneficial, because one client may ask for the same information many times.\nAs an example we can take Apollo client and its solution. The cache uses the ID field to identify whether an object exists in memory.\nThen it checks if all fields that are to be returned are already in memory, if some are not it asks only for them.\nOur caching decisions\nWe’ve decided not to use server-side caching with a global data loader because we have struggled with many clients of our graph and the graph’s data\nchanges frequently. That forced us to use a cache-per-request strategy.\nIf we are talking about caching on the client side we tackle the issue that some of our objects don’t have a unique ID so after a while we skipped this approach and we are not caching them on the client side either.\nWhat is the outcome of the battle?\nWe have learned a lot about GraphQL’s trade offs while working with it, but there is still a lot to be discovered. The most important feature of it, fetching only those fields that we need, is a huge optimization itself, but also causes many problems with standard ways to make the application effective or even to measure that efficiency.\nThe ideas that we described above need to be implemented by the programmers (most libraries don’t provide that logic) and it’s really complex and time consuming.","guid":"https://blog.allegro.tech/2022/06/graphql-perf-tradeoffs.html","categories":["tech","backend","performance","graphql","kotlin","java"],"isoDate":"2022-06-19T22:00:00.000Z","thumbnail":"images/post-headers/java.png"},{"title":"How to include refactoring into product development roadmap? Reducing technical debt inspired by real options identification","link":"https://blog.allegro.tech/2022/06/debt-reduction-in-the-product-roadmap.html","pubDate":"Tue, 07 Jun 2022 00:00:00 +0200","authors":{"author":[{"name":["Olga Dudzik"],"photo":["https://blog.allegro.tech/img/authors/olga.dudzik.jpg"],"url":["https://blog.allegro.tech/authors/olga.dudzik"]}]},"content":"\u003cp\u003eNowadays, technical debt can be considered the bread and butter of most IT-powered enterprises around the world.\nAlmost every company that survived the startup phase and managed to deliver its first products to customers will face at some point technical challenges related to past architectural decisions. Although code engineering gets better every year, we cannot argue with the obvious fact of life: the market will always force many of us to deliver tech products faster than we wish. Time To Market has always been a key success factor for many product companies and it puts a lot of pressure on Engineering to keep up with challenging deadlines.\u003c/p\u003e\n\n\u003cp\u003eStatistics explicitly show the scale of the problem. According to the survey conducted in 2020 by McKinsey\u003csup id=\"fnref:1\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:1\" class=\"footnote\" rel=\"footnote\"\u003e1\u003c/a\u003e\u003c/sup\u003e, tech debt can reach up to as much as 40% of the whole technology value. On average 10-20% of IT budget is ultimately consumed by tech debt management and most CIOs interviewed consider the problem significantly increasing over past years, especially in enterprise-size companies\u003csup id=\"fnref:2\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:2\" class=\"footnote\" rel=\"footnote\"\u003e2\u003c/a\u003e\u003c/sup\u003e.\u003c/p\u003e\n\n\u003cp\u003eAs disturbing as it sounds, acknowledging the magnitude of the problem is the first step to dealing with it.\u003c/p\u003e\n\n\u003cp\u003eSo, here we get to the Product Management reality. Even if we are lucky and after a product discovery we manage to navigate a perfect niche where we can provide a long-awaited, successful product, we still can fail having technology adjusted to our plans and needs. And that would be a real PM tragedy, wouldn’t it? To cap it all, it might be hard to even talk about innovative solutions when maneuvering around limitations imposed by the legacy code. So any further development of our product may become increasingly tricky and take more time which eventually poses a threat to staying competitive.\u003c/p\u003e\n\n\u003cp\u003eBearing that in mind, no reasonable Product Manager can afford ignoring the gravity of code complexity and shady legacy.\u003c/p\u003e\n\n\u003cp\u003eToday is the day to start a crusade against technical debt in your products. Nonetheless before we start we must all admit: building a yearly roadmap consisting mostly of incomprehensible technical deliveries that cannot be easily attributed to business value will not make us most popular Product Managers out there, to put it mildly. In most companies proposing such a backlog will result in heated discussions about targets, KPIs and wasting team’s capacity. Work that does not end up with a significant increment is hard to defend. At the end technical product development is mostly not a charity effort and it is supposed to deliver financial outcomes - the sooner, the better.\u003c/p\u003e\n\n\u003cp\u003eThe situation gets even more complicated in publicly listed companies that report to stakeholders on a regular basis. Declaring work without making any explicit promise of near-future apparent return on investment may seem unexplainable. Technical debt reduction on its own is strictly connected with vast uncertainty as long as it is not presented holistically in a broader context. So how can we approach Roadmaps to make debt reduction more appealing for our audience?\u003c/p\u003e\n\n\u003ch2 id=\"take-a-look-outside-of-the-it-world\"\u003eTake a look outside of the IT world.\u003c/h2\u003e\n\n\u003cp\u003eI believe that especially in Product Management we appreciate inspirations from other industries. And this case should not be an exception. Financial industry and analysts working on companies’ valuations have been struggling with a similar challenge for decades. Is it worth investing in a company that may not seem to be an appealing opportunity now in terms of near-future ROI? How to assess potential profits from innovative ideas on the table? How can we, in general, assess long-term impact of work at the grass roots? And which tech company is a good investment opportunity? Our development backlogs should answer similar questions - which of these debt-reduction tasks are worth pursuing and what can we achieve? Which of them are really good opportunities for us? And finally - how to prove to stakeholders the real value of such initiatives? To approach these questions we can use the idea of real options.\u003c/p\u003e\n\n\u003cp\u003eLet us discover together the roots of real options. The idea itself dates back to 1977. Stewart Myers coined this term describing real options as “opportunities to purchase real assets on possibly favorable terms”\u003csup id=\"fnref:3\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:3\" class=\"footnote\" rel=\"footnote\"\u003e3\u003c/a\u003e\u003c/sup\u003e and declaring that each company should be aware of its real assets and real options. Since then, the idea has evolved significantly and has been used in multiple methodologies not only for financial valuations, but also for determining value drivers in a variety of industries. It has been particularly attractive to IT enterprises as it embraces dealing with high uncertainty.\u003c/p\u003e\n\n\u003cp\u003eInspired by real options theory, I reckon that we should stop considering technical debt in terms of short-term Profit and Loss accounting.\u003c/p\u003e\n\n\u003cp\u003eLooking only at the nearest future, refactoring activities will mostly look as cost centers without any outlook on further potential profits. However, once we change the perspective and start considering current refactoring investments as enablers for future product options, we are able to grasp the full range of benefits to be gained. Real options perspective should open our roadmaps for long-term thinking and it can allow us to optimize our decision-making process.\u003c/p\u003e\n\n\u003cp\u003eHowever, currently existing academic and financial models are mostly complex and time-consuming to perform. Therefore the idea of real options will serve here mostly as an inspiration for a really simple exercise that will aim to transform the general approach towards technical debt.\u003c/p\u003e\n\n\u003cp\u003eBearing in mind the PM’s reality of limited time and resources, the aim is to keep the analysis quick. Moreover, we would like the output to be as easy and understandable as possible, so it can be fitting for the broad audience. Following real options terminology, we can assume that each resolved technical debt issue is our “real option” - a potential value driver and opportunity to create or improve some products (“real assets”). This exercise will focus on identifying and mapping options to future assets.\u003c/p\u003e\n\n\u003cp\u003eIn the Product Management case, investments (time of our developers) will be made to remove some technical obstacles and they will become product enablers. Opportunities on the other hand will be translated into tangible deliveries and potentially attractive positions in our future Roadmaps. And in the best case, these opportunities may even open some new doors to further developments into currently unknown and unreachable areas. Our ultimate goal is to maximize opportunities while minimizing effort required to enable them.\u003c/p\u003e\n\n\u003cp\u003eI strongly believe that it is really tricky to evaluate analyzed efforts and hopes from the financial perspective at an early stage of analysis. Calculating ROI moneywise can be extremely time-consuming and tends to be based heavily on “guesstimates” (“an approximate calculation of the size or amount of something when you do not know all the facts”\u003csup id=\"fnref:4\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:4\" class=\"footnote\" rel=\"footnote\"\u003e4\u003c/a\u003e\u003c/sup\u003e) . Nonetheless, at the same time it should be fairly possible and informative to at least roughly estimate our potential works vs. hopes in T-shirt sizing method (or any other preferred manner, up to you) and I would strongly recommend to follow this path at the beginning. As it is fairly simple and flexible, we can use the same concept to evaluate profits or attractivity of products or opportunities.\u003c/p\u003e\n\n\u003ch2 id=\"where-should-we-start-tech-debt---value-mapping\"\u003eWhere should we start tech debt - value mapping?\u003c/h2\u003e\n\n\u003cp\u003eLet us go through the process step by step. I would recommend going through this discovery process together with your technical team and to transform it into collaborative work. It can be a rewarding exercise for the whole team and it should boost the sense of agency.\u003c/p\u003e\n\n\u003cp\u003eFirst of all we should list all services/topics touched by our technical debt. They can be grouped into areas that will be addressed together to achieve the best efficiency. Depending on the specifics of the system, the granularity or nature of issues can differ. The main aim here is to review the general current state of tech without doing long and costly deep-dives. Our aim is to detect problematic areas avoiding major investments in solution analysis. In this exercise the technical team is the key. The more experienced our engineers are and the better they know their code, the more reliable outcome we get.\u003c/p\u003e\n\n\u003cp\u003eThe second step is ideation. Let’s determine our real options. Each of the listed services or areas, while solved, should be considered as an enabler for further system development. So this is the time to brainstorm together: assuming that problem A is resolved, what kind of new capabilities will be available for us? What kind of services or products can we build then? Or maybe there are some meaningful improvements that will make our product more convenient and should attract more users? We can and should go even further: what can we build assuming that more than one of the detected issues is closed? This is a perfect moment for the Product Manager to step in and to present the broad vision for the Product as inspiration. Wishful thinking, benchmarking, research and UX studies - all of these tools will prove to be useful in this workshop.\u003c/p\u003e\n\n\u003cp\u003eAt the end of step two we should be able to draw a tree diagram presenting clearly technical blockers as potential new opportunity enablers:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-06-07-debt-reduction-in-the-product-roadmap/img1.png\" alt=\"Figure 1\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eTree diagram mapping technical debt areas to related product/business opportunities.\u003c/p\u003e\n\n\u003cp\u003eStep three is all about evaluation. As mentioned before, I recommend using T-shirt sizing as it brings simplicity into very complex situations. I find T-shirt sizing an attractive estimation technique as it is quite intuitive and introduces relativity between analyzed entities. Sizes that we know from T-shirt labels (XS-XXL) are used to assess work needed to deliver a given task. At this stage our problems are not deeply analyzed and they are not broken down into particular stories/development tasks. We are working with high-level problems and ideas as we do not have time to spend weeks on analysis of topics that may not end up on our roadmap. In this step we can split into two work groups: a technical one and a business one. Technical team should focus on assessing the complexity of each detected technical task - both from debt-areas but also from prospective product opportunities (they require some work too!). If given problem seems to be fairly simple, it can be evaluated as an S. If something requires a major rebuild and redesigning the basics - it could be an XL. Let us just bear in mind that assessment should cover end-to-end work so the complexity of E2E \u0026amp; regression testing should be a vital part of this estimation too. What is more, covering the uncertainty factor in this exercise can be useful so I would not hesitate to assign bigger values for more vague areas. Effort estimation will be presented on the diagram below as purple boxes.\u003c/p\u003e\n\n\u003cp\u003eBusiness team (product managers and business stakeholders) will work on evaluating all the listed capabilities. As always, they should be considered in the broader context, so any product validation tools are handy. Apart from the business impact of each solution, we should also bear in mind if it fits into expected company strategy and if we can see it bringing us any competitive advantage when delivered in the more or less distant future (we have some issues to be resolved first!). Opportunities will be marked on the diagram as green boxes.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-06-07-debt-reduction-in-the-product-roadmap/img2.png\" alt=\"Figure 2\" /\u003e\u003c/p\u003e\n\n\u003ch2 id=\"roadmapping\"\u003eRoadmapping\u003c/h2\u003e\n\n\u003cp\u003eHaving this analysis in hand, we can pick our best candidates for the roadmap depending on the team’s capacity available. While it will never be easy to choose the best path, it should be possible to navigate works that have the best potential to bring us noticeable benefits. While pitching the idea of technical debt reduction for the management team, we usually rely on financial aspects of reducing maintenance costs of old code (e.g. we can get potential savings based on maintenance work reports from previous months). After this analysis we should be additionally equipped with the reliable documentation of new business opportunities enabled.\u003c/p\u003e\n\n\u003cp\u003eThere are at least two approaches to include refactoring on the roadmap, depending on the company’s specifics. Presenting detected technical-debt tasks as a stage zero of your product development may prove to be handy for organizations that are particularly reluctant to acknowledge refactoring as opportunities. In such a case debt reduction could be ‘hidden’ in the Opportunity roadmap item represented by longer actual delivery time. It is worth noting that this approach gives less clarity when it comes to presenting dependencies:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-06-07-debt-reduction-in-the-product-roadmap/img3.png\" alt=\"Figure 3\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eFor companies that are more open to the refactoring idea, putting technical tasks as “business enablers” on the roadmap can give more clarity. In this approach, it is also easier to include multiple enablers and opportunities on one graph. Cause and effect sequence would explain interdependencies between deliveries and make it easier to understand overlapping items:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-06-07-debt-reduction-in-the-product-roadmap/img4.png\" alt=\"Figure 4\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eI strongly believe that introducing analysis described in this article can be a good starting point for the discussion about reducing technical debt in IT-driven products. It can be further developed and supported by a variety of financial analysis methods available for real options valuations or other approaches applicable for IT. There is a necessity to change general mindset and industry’s way of thinking about code refactoring to make the process sustainable and successful. Becoming aware of new opportunities resulting from the technical debt reduction is a good first step towards this goal.\u003c/p\u003e\n\n\u003cdiv class=\"footnotes\" role=\"doc-endnotes\"\u003e\n  \u003col\u003e\n    \u003cli id=\"fn:1\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca href=\"https://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/tech-debt-reclaiming-tech-equity\"\u003ehttps://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/tech-debt-reclaiming-tech-equity\u003c/a\u003e \u003ca href=\"#fnref:1\" class=\"reversefootnote\" role=\"doc-backlink\"\u003e\u0026#8617;\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:2\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca href=\"https://www.computerweekly.com/news/252504654/Technical-debt-is-holding-back-innovation\"\u003ehttps://www.computerweekly.com/news/252504654/Technical-debt-is-holding-back-innovation\u003c/a\u003e \u003ca href=\"#fnref:2\" class=\"reversefootnote\" role=\"doc-backlink\"\u003e\u0026#8617;\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:3\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca href=\"https://onlinelibrary.wiley.com/doi/10.1111/emre.12324\"\u003ehttps://onlinelibrary.wiley.com/doi/10.1111/emre.12324\u003c/a\u003e \u003ca href=\"#fnref:3\" class=\"reversefootnote\" role=\"doc-backlink\"\u003e\u0026#8617;\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:4\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca href=\"https://dictionary.cambridge.org/dictionary/english/guesstimate\"\u003ehttps://dictionary.cambridge.org/dictionary/english/guesstimate\u003c/a\u003e \u003ca href=\"#fnref:4\" class=\"reversefootnote\" role=\"doc-backlink\"\u003e\u0026#8617;\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n  \u003c/ol\u003e\n\u003c/div\u003e\n","contentSnippet":"Nowadays, technical debt can be considered the bread and butter of most IT-powered enterprises around the world.\nAlmost every company that survived the startup phase and managed to deliver its first products to customers will face at some point technical challenges related to past architectural decisions. Although code engineering gets better every year, we cannot argue with the obvious fact of life: the market will always force many of us to deliver tech products faster than we wish. Time To Market has always been a key success factor for many product companies and it puts a lot of pressure on Engineering to keep up with challenging deadlines.\nStatistics explicitly show the scale of the problem. According to the survey conducted in 2020 by McKinsey1, tech debt can reach up to as much as 40% of the whole technology value. On average 10-20% of IT budget is ultimately consumed by tech debt management and most CIOs interviewed consider the problem significantly increasing over past years, especially in enterprise-size companies2.\nAs disturbing as it sounds, acknowledging the magnitude of the problem is the first step to dealing with it.\nSo, here we get to the Product Management reality. Even if we are lucky and after a product discovery we manage to navigate a perfect niche where we can provide a long-awaited, successful product, we still can fail having technology adjusted to our plans and needs. And that would be a real PM tragedy, wouldn’t it? To cap it all, it might be hard to even talk about innovative solutions when maneuvering around limitations imposed by the legacy code. So any further development of our product may become increasingly tricky and take more time which eventually poses a threat to staying competitive.\nBearing that in mind, no reasonable Product Manager can afford ignoring the gravity of code complexity and shady legacy.\nToday is the day to start a crusade against technical debt in your products. Nonetheless before we start we must all admit: building a yearly roadmap consisting mostly of incomprehensible technical deliveries that cannot be easily attributed to business value will not make us most popular Product Managers out there, to put it mildly. In most companies proposing such a backlog will result in heated discussions about targets, KPIs and wasting team’s capacity. Work that does not end up with a significant increment is hard to defend. At the end technical product development is mostly not a charity effort and it is supposed to deliver financial outcomes - the sooner, the better.\nThe situation gets even more complicated in publicly listed companies that report to stakeholders on a regular basis. Declaring work without making any explicit promise of near-future apparent return on investment may seem unexplainable. Technical debt reduction on its own is strictly connected with vast uncertainty as long as it is not presented holistically in a broader context. So how can we approach Roadmaps to make debt reduction more appealing for our audience?\nTake a look outside of the IT world.\nI believe that especially in Product Management we appreciate inspirations from other industries. And this case should not be an exception. Financial industry and analysts working on companies’ valuations have been struggling with a similar challenge for decades. Is it worth investing in a company that may not seem to be an appealing opportunity now in terms of near-future ROI? How to assess potential profits from innovative ideas on the table? How can we, in general, assess long-term impact of work at the grass roots? And which tech company is a good investment opportunity? Our development backlogs should answer similar questions - which of these debt-reduction tasks are worth pursuing and what can we achieve? Which of them are really good opportunities for us? And finally - how to prove to stakeholders the real value of such initiatives? To approach these questions we can use the idea of real options.\nLet us discover together the roots of real options. The idea itself dates back to 1977. Stewart Myers coined this term describing real options as “opportunities to purchase real assets on possibly favorable terms”3 and declaring that each company should be aware of its real assets and real options. Since then, the idea has evolved significantly and has been used in multiple methodologies not only for financial valuations, but also for determining value drivers in a variety of industries. It has been particularly attractive to IT enterprises as it embraces dealing with high uncertainty.\nInspired by real options theory, I reckon that we should stop considering technical debt in terms of short-term Profit and Loss accounting.\nLooking only at the nearest future, refactoring activities will mostly look as cost centers without any outlook on further potential profits. However, once we change the perspective and start considering current refactoring investments as enablers for future product options, we are able to grasp the full range of benefits to be gained. Real options perspective should open our roadmaps for long-term thinking and it can allow us to optimize our decision-making process.\nHowever, currently existing academic and financial models are mostly complex and time-consuming to perform. Therefore the idea of real options will serve here mostly as an inspiration for a really simple exercise that will aim to transform the general approach towards technical debt.\nBearing in mind the PM’s reality of limited time and resources, the aim is to keep the analysis quick. Moreover, we would like the output to be as easy and understandable as possible, so it can be fitting for the broad audience. Following real options terminology, we can assume that each resolved technical debt issue is our “real option” - a potential value driver and opportunity to create or improve some products (“real assets”). This exercise will focus on identifying and mapping options to future assets.\nIn the Product Management case, investments (time of our developers) will be made to remove some technical obstacles and they will become product enablers. Opportunities on the other hand will be translated into tangible deliveries and potentially attractive positions in our future Roadmaps. And in the best case, these opportunities may even open some new doors to further developments into currently unknown and unreachable areas. Our ultimate goal is to maximize opportunities while minimizing effort required to enable them.\nI strongly believe that it is really tricky to evaluate analyzed efforts and hopes from the financial perspective at an early stage of analysis. Calculating ROI moneywise can be extremely time-consuming and tends to be based heavily on “guesstimates” (“an approximate calculation of the size or amount of something when you do not know all the facts”4) . Nonetheless, at the same time it should be fairly possible and informative to at least roughly estimate our potential works vs. hopes in T-shirt sizing method (or any other preferred manner, up to you) and I would strongly recommend to follow this path at the beginning. As it is fairly simple and flexible, we can use the same concept to evaluate profits or attractivity of products or opportunities.\nWhere should we start tech debt - value mapping?\nLet us go through the process step by step. I would recommend going through this discovery process together with your technical team and to transform it into collaborative work. It can be a rewarding exercise for the whole team and it should boost the sense of agency.\nFirst of all we should list all services/topics touched by our technical debt. They can be grouped into areas that will be addressed together to achieve the best efficiency. Depending on the specifics of the system, the granularity or nature of issues can differ. The main aim here is to review the general current state of tech without doing long and costly deep-dives. Our aim is to detect problematic areas avoiding major investments in solution analysis. In this exercise the technical team is the key. The more experienced our engineers are and the better they know their code, the more reliable outcome we get.\nThe second step is ideation. Let’s determine our real options. Each of the listed services or areas, while solved, should be considered as an enabler for further system development. So this is the time to brainstorm together: assuming that problem A is resolved, what kind of new capabilities will be available for us? What kind of services or products can we build then? Or maybe there are some meaningful improvements that will make our product more convenient and should attract more users? We can and should go even further: what can we build assuming that more than one of the detected issues is closed? This is a perfect moment for the Product Manager to step in and to present the broad vision for the Product as inspiration. Wishful thinking, benchmarking, research and UX studies - all of these tools will prove to be useful in this workshop.\nAt the end of step two we should be able to draw a tree diagram presenting clearly technical blockers as potential new opportunity enablers:\n\nTree diagram mapping technical debt areas to related product/business opportunities.\nStep three is all about evaluation. As mentioned before, I recommend using T-shirt sizing as it brings simplicity into very complex situations. I find T-shirt sizing an attractive estimation technique as it is quite intuitive and introduces relativity between analyzed entities. Sizes that we know from T-shirt labels (XS-XXL) are used to assess work needed to deliver a given task. At this stage our problems are not deeply analyzed and they are not broken down into particular stories/development tasks. We are working with high-level problems and ideas as we do not have time to spend weeks on analysis of topics that may not end up on our roadmap. In this step we can split into two work groups: a technical one and a business one. Technical team should focus on assessing the complexity of each detected technical task - both from debt-areas but also from prospective product opportunities (they require some work too!). If given problem seems to be fairly simple, it can be evaluated as an S. If something requires a major rebuild and redesigning the basics - it could be an XL. Let us just bear in mind that assessment should cover end-to-end work so the complexity of E2E \u0026 regression testing should be a vital part of this estimation too. What is more, covering the uncertainty factor in this exercise can be useful so I would not hesitate to assign bigger values for more vague areas. Effort estimation will be presented on the diagram below as purple boxes.\nBusiness team (product managers and business stakeholders) will work on evaluating all the listed capabilities. As always, they should be considered in the broader context, so any product validation tools are handy. Apart from the business impact of each solution, we should also bear in mind if it fits into expected company strategy and if we can see it bringing us any competitive advantage when delivered in the more or less distant future (we have some issues to be resolved first!). Opportunities will be marked on the diagram as green boxes.\n\nRoadmapping\nHaving this analysis in hand, we can pick our best candidates for the roadmap depending on the team’s capacity available. While it will never be easy to choose the best path, it should be possible to navigate works that have the best potential to bring us noticeable benefits. While pitching the idea of technical debt reduction for the management team, we usually rely on financial aspects of reducing maintenance costs of old code (e.g. we can get potential savings based on maintenance work reports from previous months). After this analysis we should be additionally equipped with the reliable documentation of new business opportunities enabled.\nThere are at least two approaches to include refactoring on the roadmap, depending on the company’s specifics. Presenting detected technical-debt tasks as a stage zero of your product development may prove to be handy for organizations that are particularly reluctant to acknowledge refactoring as opportunities. In such a case debt reduction could be ‘hidden’ in the Opportunity roadmap item represented by longer actual delivery time. It is worth noting that this approach gives less clarity when it comes to presenting dependencies:\n\nFor companies that are more open to the refactoring idea, putting technical tasks as “business enablers” on the roadmap can give more clarity. In this approach, it is also easier to include multiple enablers and opportunities on one graph. Cause and effect sequence would explain interdependencies between deliveries and make it easier to understand overlapping items:\n\nI strongly believe that introducing analysis described in this article can be a good starting point for the discussion about reducing technical debt in IT-driven products. It can be further developed and supported by a variety of financial analysis methods available for real options valuations or other approaches applicable for IT. There is a necessity to change general mindset and industry’s way of thinking about code refactoring to make the process sustainable and successful. Becoming aware of new opportunities resulting from the technical debt reduction is a good first step towards this goal.\nhttps://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/tech-debt-reclaiming-tech-equity ↩\nhttps://www.computerweekly.com/news/252504654/Technical-debt-is-holding-back-innovation ↩\nhttps://onlinelibrary.wiley.com/doi/10.1111/emre.12324 ↩\nhttps://dictionary.cambridge.org/dictionary/english/guesstimate ↩","guid":"https://blog.allegro.tech/2022/06/debt-reduction-in-the-product-roadmap.html","categories":["tech","roadmaps","tech debt","product"],"isoDate":"2022-06-06T22:00:00.000Z","thumbnail":"images/post-headers/default.jpg"},{"title":"Turn-Based Offline Reinforcement Learning","link":"https://blog.allegro.tech/2022/04/turn-based-offline-rl.html","pubDate":"Thu, 14 Apr 2022 00:00:00 +0200","authors":{"author":[{"name":["Riccardo Belluzzo"],"photo":["https://blog.allegro.tech/img/authors/riccardo.belluzzo.jpg"],"url":["https://blog.allegro.tech/authors/riccardo.belluzzo"]},{"name":["Tomasz Bocheński"],"photo":["https://blog.allegro.tech/img/authors/tomasz.bochenski.jpg"],"url":["https://blog.allegro.tech/authors/tomasz.bochenski"]},{"name":["Michał Zając"],"photo":["https://blog.allegro.tech/img/authors/michal.zajac.jpg"],"url":["https://blog.allegro.tech/authors/michal.zajac"]},{"name":["Łukasz Kuciński"],"photo":["https://blog.allegro.tech/img/authors/lukasz.kucinski.jpg"],"url":["https://blog.allegro.tech/authors/lukasz.kucinski"]},{"name":["Piotr Miłoś"],"photo":["https://blog.allegro.tech/img/authors/piotr.milos.jpg"],"url":["https://blog.allegro.tech/authors/piotr.milos"]}]},"content":"\u003cp\u003eThis blogpost is the result of a research collaboration between the Allegro Machine Learning Research team and\nthe Institute of Mathematics of the Polish Academy of Sciences (IMPAN), Warsaw.\u003c/p\u003e\n\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eImagine the following scenario: you work in a company as a Research Engineer, and your manager is asking you to design\na state-of-the-art algorithm to control a robot arm that should perform a critical task.\nYou perform some research to find out that Reinforcement Learning (RL) would work really well in this case.\nHowever, you have the following limitations:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eThe robot arm is built with poor hardware and can’t afford long and extensive usage.\u003c/li\u003e\n  \u003cli\u003eThe robot arm can often be physically unavailable, and you may have access to it only for a limited period of time.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eIn addition to the aforementioned constraints, you also have another big problem: you don’t have any huge dataset\ncontaining past offline behavior of the robotic arm available. What can you do? Should you give up on applying RL\nto this problem? Is the problem even solvable with RL?\u003c/p\u003e\n\n\u003cp\u003eDon’t worry! We are here to help you! And to do so, we will walk you through the concept of “Turn-based Offline RL”.\nSo let’s dive into it!\u003c/p\u003e\n\n\u003ch2 id=\"standing-between-online-rl-and-offline-rl\"\u003eStanding between “Online RL” and “Offline RL”\u003c/h2\u003e\n\n\u003cp\u003eIn Online RL, we normally have an agent that interacts with the environment, which is assumed to be always available.\nFor each interaction, the agent will get a reward signal that assesses the quality of the action performed.\nThe possibility of constant interaction with the environment marks the difference between the\nonline and offline RL setting: in the latter, we break the environment-agent interaction loop,\nand we only have a buffer of transitions previously gathered using one or multiple unknown policies.\nThus, in Offline RL, since there is no interaction with the environment, the buffer can be thought of as a\nstatic dataset that cannot be extended by any further exploration.\u003c/p\u003e\n\n\u003cp\u003eThe idea behind “Turn-based Offline RL” falls exactly halfway between these two lines of thinking.\nImagine yourself being able to build an initial static dataset filled with transitions generated by a\nrandom policy. Now that you have a static dataset, you can use it to train an agent using a preferred\nOffline RL algorithm. Then, suppose you have access to the target environment for a limited period of time.\nYou have a (random) agent already trained! You can deploy it, interact with the environment,\ngather new experiences based on the policy learned so far, and enrich your static dataset.\nNow, having an updated (and better) dataset, you can re-train your Offline RL agent and repeat this process every time\nyou are accessing the environment. Well, what we have described is exactly what we mean by “Turn-based Offline RL”.\nLet’s sum up the description in a few points:\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003eStart with a random policy and generate an initial static dataset.\u003c/li\u003e\n  \u003cli\u003eTrain an agent using a preferred Offline RL algorithm using the dataset built in 1). We can call this phase “turn 0”.\u003c/li\u003e\n  \u003cli\u003eAccess the environment the first time: collect transitions using the policy learned so far and extend the dataset\nwith new data.\u003c/li\u003e\n  \u003cli\u003eTrain your Offline RL agent again with a static dataset now composed of old (random) transitions and new (better)\ntransitions (“turn 1”).\u003c/li\u003e\n  \u003cli\u003eAccess the environment once again and collect new transitions.\u003c/li\u003e\n  \u003cli\u003eTrain again your Offline agent (“turn 2”).\u003c/li\u003e\n  \u003cli\u003eRepeat the above steps as many “turns” as you can, i.e. as many times as you have the possibility to access the\nenvironment.\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003eThe main idea behind the turn-based procedure is that after each “turn” we will extend our dataset with “better”\ntransitions, i.e transitions generated by more expert-like agents, and use Offline RL algorithms to train an even better\n(or at least similar) policy than the one used to generate those transitions.\nWith the “Turn-based Offline RL” framework you can now see how you could possibly overcome the constraints for\nyour hypothetical robot arm application: you could build a random dataset using some simulator; train an Offline RL\nagent with it; deploy the agent to interact with the robot arm for a limited period of time; extend the dataset\nwith better data; re-train the agent, and repeat the process.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-04-14-turn-based-offline-rl/diagram.png\" alt=\"Figure 1\" /\u003e\n\u003cem\u003eFig.1 — Schematic comparison between Online RL (a), Offline RL (b), and Turn-Based Offline RL (c). For this diagram\nwe took inspiration from the paper Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems\n(Levine et al. 2020)\u003c/em\u003e\u003c/p\u003e\n\n\u003ch2 id=\"turn-based-offline-rl-in-practice\"\u003eTurn-based Offline RL in practice\u003c/h2\u003e\n\n\u003cp\u003eIn this blog post, we want to show you how you could make use of the “Turn-based Offline RL” framework to leverage\nthe advances in Offline RL in applications where you could have the possibility of accessing the environment “in turns”.\nFortunately, we don’t need any fancy robotic arm to do so! We have prepared for you a more comprehensive use case\nin order to explain the general idea behind it.\u003c/p\u003e\n\n\u003ch3 id=\"experimental-setup\"\u003eExperimental setup\u003c/h3\u003e\n\n\u003cp\u003eTo showcase our idea, we are going to make use of a simplified environment.\nThis tutorial will be in fact inspired by the\n\u003ca href=\"https://colab.research.google.com/drive/1oJOYlAIOl9d1JjlutPY66KmfPkwPCgEE?usp=sharing#scrollTo=4i64GqsO83mA\"\u003eNeurIPS 2020 Offline RL Tutorial Colab Exercise\u003c/a\u003e\nwhere the authors designed a simple GridWorld environment to test different ideas related to Offline RL.\u003c/p\u003e\n\n\u003cp\u003eGridWorld is a standard environment used in the RL community to test if algorithms can work in relatively\neasy situations or simply to debug them. In GridWorld, the agent starts at a starting point (“S”) and aims to\nreach a target point, sometimes called the reward (“R”) cell. The agent can either step up, down, left, or right,\nor stay still. Only empty cells can be stepped in, while non-empty cells, like the ones containing obstacles\n(walls), are not. The authors of the notebook provide an easy way to build such an environment from a string.\u003c/p\u003e\n\n\u003cp\u003eFor the sake of this tutorial, we will work with a fixed 18x20 grid like the one specified by the string below.\nThe “O” letter indicates empty spaces, “#” stands for walls, “S” is the starting state and “R” the target one.\nFor clarity, we have drawn the grid for you.\u003c/p\u003e\n\n\u003cdiv class=\"language-python highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003egrid\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOOOOOOOOOOOOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOOOOOOOOOOOOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOOOSOOOOOOOOOO#\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOO##OOOOOOOOOO#\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOO#O#OOOOOOOOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOOOOOO#OO#OOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOOOOOOOOOOOOO#O\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOO#OOOOOOOOOOOOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'##OOOOOOOO#OOOOOOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOOOOOO#OOOOO#OO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOOOOOOOOOO####O\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOOOOOOOOOOOOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OO#OOO#OOOOOO#OOOROO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOO##OO#OOOOOOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOO#OOOOOOOOOOOO##O#\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOO#OOOOOOOOOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOOOOOOOOOOOOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'##OOOOO##OOOOOOOOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOOOOOO#OOO#OOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOO##OOOO#O#OOOOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-04-14-turn-based-offline-rl/gridworld_reduced.png\" alt=\"Figure 2\" /\u003e\n\u003cem\u003eFig.2 — The chosen grid for our experiments: the green cell (S) is the starting point; the\nyellow cell (R) is the target point; white cells are empty while red cells contain walls.\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003ePlease note that in our experiments we have tested different grid configurations and dimensions and we believe\nthat the chosen dimensionality and obstacle distribution presented for this tutorial do represent a\ngood experimental setup in order to arrive at reasonable conclusions. Indeed, the grid is small enough\nfor the algorithm to be able to quickly iterate through different runs, and its configuration\nis complicated enough to lead to non-trivial results.\nIn general, from our experience, things start to get interesting with grids NxM where N,M \u0026gt;= 12.\u003c/p\u003e\n\n\u003ch3 id=\"agents-visualizations\"\u003eAgent’s visualizations\u003c/h3\u003e\n\n\u003cp\u003eIn RL, it’s sometimes beneficial to visualize the policy your agents are learning. Since the environment\nwe are playing with is relatively small, we can actually enumerate all possible state-action (s,a) pairs.\nWhen a specific algorithm runs, we are able to count how many times each of these pairs was visited, and we are\nable to visualize it as a heatmap, superimposed on the grid.\u003c/p\u003e\n\n\u003cp\u003eIn our case, such heatmaps (that we call state-action visitation maps)\ncan be really useful to understand, for example, the quality of a specific policy:\na good state-action visitation map is created only by applying a good policy.\u003c/p\u003e\n\n\u003cp\u003eHow would a map built using the optimal policy look like?\nAgain, it’s a question we can answer only because we are in the ideal case of using a simple environment where we can\nknow and do everything, like finding the optimal policy.\nWe can use tabular Q-iteration to find an optimal solution for our case,\nhence producing the optimal state-action map that looks as follows:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-04-14-turn-based-offline-rl/optimal_policy_heatmap_reduced.png\" alt=\"Figure 3\" /\u003e\n\u003cem\u003eFig.3 — State-action visitation heatmap generated by the optimal policy. Most of the time the agent reaches the target\ncell in a few steps and then, it just stays idle without performing any further step.\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003eAs you can see, in this case, almost every (s,a) pair has a value approaching zero, apart from the reward (“R”) state\nwhich has a big value. This is happening because once the agent knows the optimal policy, it will take very few steps\nfor it to reach the target cell and once it’s reached, it will spend most of the time just waiting, without performing\nany further action. More precisely, the agent will spend the majority of the time in the (s,a) = (“R”, NOOP),\nwhere NOOP stands for “no operation”.\u003c/p\u003e\n\n\u003cp\u003eLet’s now visualize the heatmap generated by the uniform policy,\ni.e an agent that decides at random (with uniform probability) which action to take when being in a specific state.\nThis approach would be the way to go in the majority of the cases and is the closest to the real case example.\nSuppose you don’t know anything about the environment you are going to interact with: the best you can do is to\nperform random exploration!\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-04-14-turn-based-offline-rl/random_policy_heatmap_reduced.png\" alt=\"Figure 4\" /\u003e\n\u003cem\u003eFig.4 — State-action visitation heatmap generated by the random policy. The agent performs random exploration. As a\nresult of the random behaviour, cells in the surroundings of the initial state are visited on average more often than\nfurther cells.\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003eSince we start from the “S” cell at every episode, we have the highest probability of visiting the “S” state and all\nits surroundings. As we go further from it, the agent will start to pick different states depending on the run,\nand thus values on farther cells start to normalize and approach 0.0.\u003c/p\u003e\n\n\u003cp\u003eIn the following, we will describe the algorithm in detail, and we will make use of these visualizations to understand\nif the turn-based approach is beneficial for learning a good policy when starting from a random one.\u003c/p\u003e\n\n\u003ch3 id=\"algorithm\"\u003eAlgorithm\u003c/h3\u003e\n\n\u003cp\u003eNow let’s dive into the algorithm itself. Recalling the steps indicated in the previous section,\nwe can describe the turn-based learning algorithm with the following pythonic pseudocode:\u003c/p\u003e\n\n\u003cdiv class=\"language-python highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003erun_turn_based_algorithm\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003einit_policy\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                             \u003cspan class=\"n\"\u003enum_turns\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                             \u003cspan class=\"n\"\u003enum_seeds\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                             \u003cspan class=\"n\"\u003edataset_size\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                             \u003cspan class=\"n\"\u003enum_iters\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eoffline_dataset\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[]\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecurrent_policy\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003einit_policy\u003c/span\u003e\n    \u003cspan class=\"n\"\u003enum_of_trajectories_per_turn\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edataset_size\u003c/span\u003e \u003cspan class=\"o\"\u003e/\u003c/span\u003e \u003cspan class=\"n\"\u003enum_turns\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003eturn\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"nb\"\u003erange\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003enum_turns\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eruns\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[]\u003c/span\u003e\n        \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003eseed\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"nb\"\u003erange\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003enum_seeds\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n            \u003cspan class=\"n\"\u003etemp_dataset\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eoffline_dataset\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecopy\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n            \u003cspan class=\"n\"\u003etrajectories_from_new_policy\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edeploy_and_sample\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecurrent_policy\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003enum_of_trajectories_per_turn\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n            \u003cspan class=\"n\"\u003etemp_dataset\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eextend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etrajectories_from_new_policy\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n            \u003cspan class=\"n\"\u003epolicy\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eperformances\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erun_offline_rl_algorithm\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etemp_dataset\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003enum_iters\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n            \u003cspan class=\"n\"\u003eruns\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eappend\u003c/span\u003e\u003cspan class=\"p\"\u003e((\u003c/span\u003e\u003cspan class=\"n\"\u003epolicy\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eperformances\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etrajectories_from_new_policy\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\n        \u003cspan class=\"n\"\u003ebest_policy\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ebest_trajectories\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003efind_best_run\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eruns\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ecurrent_policy\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ebest_policy\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eoffline_dataset\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eextend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ebest_trajectories\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eLet’s explain each step involved in the algorithm.  First, let’s define what the main parameters expected by\nthe algorithm are:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003einit_policy\u003c/code\u003e — it’s the starting policy, most likely the random policy.\u003c/li\u003e\n  \u003cli\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003enum_turns\u003c/code\u003e — this is simply the total number of turns for which you will run the algorithm.\u003c/li\u003e\n  \u003cli\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003enum_seeds\u003c/code\u003e — if you work in RL you will be familiar with this argument: RL algorithms\n(and especially Offline RL ones) present large variability in the results due to their stochastic nature.\nThat’s why instead of having one single run of the Offline RL algorithm,\nwe will have several of them. For each run, we will produce the best policy and the best\n“new set of trajectories” to be used later in the algorithm (more on this step in the following).\u003c/li\u003e\n  \u003cli\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003enum_iters\u003c/code\u003e — this is simply the number of iterations we will run our Offline RL algorithm.\u003c/li\u003e\n  \u003cli\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003edataset_size\u003c/code\u003e — as a design choice, we assume that the final dataset size has been fixed beforehand,\nas we do with the number of turns. However, both of these two conditions could be relaxed and one could run\nthe algorithm as many turns as needed, getting a final offline dataset with an undefined size.\nHowever, please remember that in the real scenario you will probably not have the privilege of\naccessing the environment so often! You must do your best with a reasonable number of turns!\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eNow, following the logic of the pseudo-code, let’s describe the algorithm:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eInitially, we don’t have any transitions to train our Offline RL algorithm, so we initialize our \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eoffline_dataset\u003c/code\u003e\nas an empty list.\u003c/li\u003e\n  \u003cli\u003eWe also initialize \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ecurrent_policy\u003c/code\u003e with \u003ccode class=\"language-plaintext highlighter-rouge\"\u003einit_policy\u003c/code\u003e, which most likely will be the random policy\n(an agent that has previously interacted with the environment taking actions uniformly at random).\u003c/li\u003e\n  \u003cli\u003eNow, for each turn we run \u003ccode class=\"language-plaintext highlighter-rouge\"\u003enum_seeds\u003c/code\u003e times the following procedure:\n    \u003cul\u003e\n      \u003cli\u003eWe create a copy of \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eoffline_dataset\u003c/code\u003e (\u003ccode class=\"language-plaintext highlighter-rouge\"\u003etemp_dataset\u003c/code\u003e) to train the current agent with the dataset collected\nso far.\u003c/li\u003e\n      \u003cli\u003eWe deploy the agent to the environment, in order to generate a new set of transitions using the current policy\n(\u003ccode class=\"language-plaintext highlighter-rouge\"\u003etrajectories_from_new_policy\u003c/code\u003e).\u003c/li\u003e\n      \u003cli\u003eWe extend the temporary dataset by \u003ccode class=\"language-plaintext highlighter-rouge\"\u003etrajectories_from_new_policy\u003c/code\u003e and train an agent with it,\nusing the preferred Offline RL algorithm and getting its corresponding \u003ccode class=\"language-plaintext highlighter-rouge\"\u003epolicy\u003c/code\u003e and \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eperformances\u003c/code\u003e.\u003c/li\u003e\n      \u003cli\u003eWe append the results to \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eruns\u003c/code\u003e list.\u003c/li\u003e\n      \u003cli\u003eOnce we have collected all the results, we pick the best policy and best-generated trajectories\nout of the pool of runs (\u003ccode class=\"language-plaintext highlighter-rouge\"\u003efind_best_run\u003c/code\u003e).\u003c/li\u003e\n      \u003cli\u003eThe \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ebest_policy\u003c/code\u003e is now our \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ecurrent_policy\u003c/code\u003e that will be used for the next turn.\u003c/li\u003e\n      \u003cli\u003eThe \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ebest_trajectories\u003c/code\u003e will are appended to \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eoffline_dataset\u003c/code\u003e that will is going to be used for the next turn.\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eWe repeat this procedure until we are satisfied with the performance or as many times (turns)\nwe are able to access the environment.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eNow, hoping the algorithm is clear to you, we need to answer two important questions.\u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003eWhich Offline RL algorithm should be run?\u003c/em\u003e\nActually here the choice is yours! In our case, we opted for\nusing \u003ca href=\"https://arxiv.org/abs/2006.04779\"\u003eConservative Q-Learning (CQL)\u003c/a\u003e.\nAny algorithm may have its pros and cons. In our case we find it hard to set the CQL global parameters only once\nto be good for all the runs. What is happening is that initially our dataset will be full of random transitions,\nbut as long as you proceed in turns, it will become richer in “more-expert” transitions.\nThus, parameters like alpha for the CQL loss should be somehow adjusted in time.\nWhile in this tutorial we did not investigate this aspect, we found that for this very simplistic environment\neven CQL with alpha = 0 (equivalent to offline Q iteration) would work sufficiently.\u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003eHow to aggregate results in order to get a representative policy and dataset for the next turn?\u003c/em\u003e\nThat’s a hard question. For the sake of this tutorial, we have opted for the simplest of the approaches:\nout of the N runs, we will pick the one that gave us the best results (in terms of average reward).\nHowever, please note that this may be too optimistic and could lead to unexpected behavior in production.\nA better approach would actually be the one that takes into account the “average policy”. But, to “average out”\npolicies is not a trivial task. We discuss this aspect in detail in the final section.\u003c/p\u003e\n\n\u003ch2 id=\"results\"\u003eResults\u003c/h2\u003e\n\n\u003ch3 id=\"visualizing-the-agent-in-turns\"\u003eVisualizing the agent “in turns”\u003c/h3\u003e\n\n\u003cp\u003eFirst, we ask ourselves the following question: does the agent learn “in turns”? We can check this\nby visualizing subsequent state-action visitation maps:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-04-14-turn-based-offline-rl/agent_learns_in_turns_reduced.png\" alt=\"Figure 5\" /\u003e\n\u003cem\u003eFig.5 — Visualization of subsequent state-action visitation heatmaps. Here we visualize 4 subsequent turns — after one\nsingle turn the agent learns the fastest path to reach the target cell. As long as we proceed in turns, the agent\nimproves its performance, eventually approaching a behaviour comparable to the optimal policy.\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003eOur algorithm seems to work! When starting with a uniform policy, we can see that even after a\nsingle turn the agent quickly learns the fastest path to reach the target cell. As long as we proceed in turns, the model will\nconsistently improve its performance, by quickly getting to the “R” cell even more often. In this sense, visitation\nmaps get closer to the optimal one where the agent basically reaches the target in a few steps and then just stays\nthere, without performing any further steps.\u003c/p\u003e\n\n\u003ch3 id=\"does-the-agent-improve-its-performance-over-time\"\u003eDoes the agent improve its performance over time?\u003c/h3\u003e\n\n\u003cp\u003eHow many turns are needed to start having results comparable to\nthe optimal policy? In other words, how much better are we performing if compared to not doing any turn at all?\u003c/p\u003e\n\n\u003cp\u003eLet’s analyze the plot below. In this figure we are plotting the algorithm’s performance, measured in\n“averaged reward” (the higher, the better), as the amount of data available offline increases. In general, we expect\nthe curve obtained by running the optimal policy (violet curve) to represent an upper bound: it’s the best we\ncan achieve! On the other hand, we expect the curve obtained by running the random policy without any “turn”\n(green curve), to be our lower bound. Also, generally speaking, we expect that the more offline data is available,\nthe better the achieved scores will be, since our chosen Offline RL will have more data coverage and possibility\nto converge to the optimal policy. Given this, we can observe that the performance of the turn-based procedure falls\nin the middle between the aforementioned upper and lower bounds: as the number of turns increases, the closer we get\nto the upper bound. However, we can observe that 3 turns are already enough to start having better performance than\nthe lower bound. This plot confirms our hypothesis: “Turn-based Offline RL” stands exactly between Online RL\n(upper bound) and Offline RL (lower bound).\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-04-14-turn-based-offline-rl/learning_curves_reduced.png\" alt=\"Figure 6\" /\u003e\n\u003cem\u003eFig.6 — This plot shows the comparison between baselines and the turn-based procedure in terms of average reward (the higher,\nthe better) as the size of the collected data used to train the algorithm offline grows. To obtain this figure,\nwe have run each of the algorithms for 30 seeds. For the optimal policy we run Q-iteration, while for the rest we\napplied CQL with fixed alpha=0. For each run, CQL was fitted for 300 iterations.\u003c/em\u003e\u003c/p\u003e\n\n\u003ch2 id=\"conclusions-and-future-work\"\u003eConclusions and Future Work\u003c/h2\u003e\n\n\u003cp\u003eIn this blog post we have presented a practical approach you could use to address cases where you have temporary\nand limited access to an environment, and you have computational resources at your disposal to train your RL algorithm\n“offline” only.\u003c/p\u003e\n\n\u003cp\u003eIn fact, the proposed solution falls halfway between Online RL and Offline RL: our agent is warmed up\nby training it via Offline RL on a dataset generated by running the uniform random policy and then\nsubsequently improved by accessing the environment in “turns”, thus partially simulating what you would get on a\nstandard online RL scenario.\u003c/p\u003e\n\n\u003cp\u003eIn particular, we show that:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eThe turn-based procedure is effective since the policy learned in subsequent turns consistently improves as\nturns increase, matching the expectations. This result is demonstrated through some visualizations, showing how\nthe agent chooses a better and faster path to target turn after turn.\u003c/li\u003e\n  \u003cli\u003eThe turn-based procedure allows getting an agent that is better than a random one, even after a small number of turns.\nThe performance of the turn-based agent will be upper-bounded by the performance of the optimal policy.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eMoreover, we provide an easy-to-understand framework to prove the aforementioned hypothesis.\u003c/p\u003e\n\n\u003cp\u003eFinally, we want to point out some limitations of our work that could be addressed as future work:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eFrom one turn to the other, we pick the “best policy” as the one that achieves the best performance between all\nthe runs via the “max” operator. This single policy is then propagated through the algorithm and used to generate\nthe best new extension of the dataset. The inherent limitation of this approach is that by using the “max” we are\nnot robust to the noise and we do not account for fluctuations in the performance of the Offline RL algorithm.\nA better approach would be aggregating policies by doing, for example, an ensemble of policies, and using this\nas the selected policy that is propagated forward in the algorithm.\u003c/li\u003e\n  \u003cli\u003eRunning a fixed Offline RL algorithm on a dataset that keeps changing its distribution of states and actions\nin time could be really challenging since a lot of algorithms in the literature require accurate hypertuning\nof the parameters. In future work, we would like to address this problem, proposing, for example, a way one\ncould compute new hyper-parameters using the dataset size and some other properties as parameters for the computation.\u003c/li\u003e\n  \u003cli\u003eOne could argue that our hypothesis can work only on simplistic environments like GridWorlds.\nEven though we tested different configurations of grids, stressing more or less the algorithms,\nwe admit that a more complete work would require the re-visitation of our hypothesis on a more diverse\nsuite of environments. We plan to investigate this in the future.\u003c/li\u003e\n\u003c/ul\u003e\n\n","contentSnippet":"This blogpost is the result of a research collaboration between the Allegro Machine Learning Research team and\nthe Institute of Mathematics of the Polish Academy of Sciences (IMPAN), Warsaw.\nIntroduction\nImagine the following scenario: you work in a company as a Research Engineer, and your manager is asking you to design\na state-of-the-art algorithm to control a robot arm that should perform a critical task.\nYou perform some research to find out that Reinforcement Learning (RL) would work really well in this case.\nHowever, you have the following limitations:\nThe robot arm is built with poor hardware and can’t afford long and extensive usage.\nThe robot arm can often be physically unavailable, and you may have access to it only for a limited period of time.\nIn addition to the aforementioned constraints, you also have another big problem: you don’t have any huge dataset\ncontaining past offline behavior of the robotic arm available. What can you do? Should you give up on applying RL\nto this problem? Is the problem even solvable with RL?\nDon’t worry! We are here to help you! And to do so, we will walk you through the concept of “Turn-based Offline RL”.\nSo let’s dive into it!\nStanding between “Online RL” and “Offline RL”\nIn Online RL, we normally have an agent that interacts with the environment, which is assumed to be always available.\nFor each interaction, the agent will get a reward signal that assesses the quality of the action performed.\nThe possibility of constant interaction with the environment marks the difference between the\nonline and offline RL setting: in the latter, we break the environment-agent interaction loop,\nand we only have a buffer of transitions previously gathered using one or multiple unknown policies.\nThus, in Offline RL, since there is no interaction with the environment, the buffer can be thought of as a\nstatic dataset that cannot be extended by any further exploration.\nThe idea behind “Turn-based Offline RL” falls exactly halfway between these two lines of thinking.\nImagine yourself being able to build an initial static dataset filled with transitions generated by a\nrandom policy. Now that you have a static dataset, you can use it to train an agent using a preferred\nOffline RL algorithm. Then, suppose you have access to the target environment for a limited period of time.\nYou have a (random) agent already trained! You can deploy it, interact with the environment,\ngather new experiences based on the policy learned so far, and enrich your static dataset.\nNow, having an updated (and better) dataset, you can re-train your Offline RL agent and repeat this process every time\nyou are accessing the environment. Well, what we have described is exactly what we mean by “Turn-based Offline RL”.\nLet’s sum up the description in a few points:\nStart with a random policy and generate an initial static dataset.\nTrain an agent using a preferred Offline RL algorithm using the dataset built in 1). We can call this phase “turn 0”.\nAccess the environment the first time: collect transitions using the policy learned so far and extend the dataset\nwith new data.\nTrain your Offline RL agent again with a static dataset now composed of old (random) transitions and new (better)\ntransitions (“turn 1”).\nAccess the environment once again and collect new transitions.\nTrain again your Offline agent (“turn 2”).\nRepeat the above steps as many “turns” as you can, i.e. as many times as you have the possibility to access the\nenvironment.\nThe main idea behind the turn-based procedure is that after each “turn” we will extend our dataset with “better”\ntransitions, i.e transitions generated by more expert-like agents, and use Offline RL algorithms to train an even better\n(or at least similar) policy than the one used to generate those transitions.\nWith the “Turn-based Offline RL” framework you can now see how you could possibly overcome the constraints for\nyour hypothetical robot arm application: you could build a random dataset using some simulator; train an Offline RL\nagent with it; deploy the agent to interact with the robot arm for a limited period of time; extend the dataset\nwith better data; re-train the agent, and repeat the process.\n\nFig.1 — Schematic comparison between Online RL (a), Offline RL (b), and Turn-Based Offline RL (c). For this diagram\nwe took inspiration from the paper Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems\n(Levine et al. 2020)\nTurn-based Offline RL in practice\nIn this blog post, we want to show you how you could make use of the “Turn-based Offline RL” framework to leverage\nthe advances in Offline RL in applications where you could have the possibility of accessing the environment “in turns”.\nFortunately, we don’t need any fancy robotic arm to do so! We have prepared for you a more comprehensive use case\nin order to explain the general idea behind it.\nExperimental setup\nTo showcase our idea, we are going to make use of a simplified environment.\nThis tutorial will be in fact inspired by the\nNeurIPS 2020 Offline RL Tutorial Colab Exercise\nwhere the authors designed a simple GridWorld environment to test different ideas related to Offline RL.\nGridWorld is a standard environment used in the RL community to test if algorithms can work in relatively\neasy situations or simply to debug them. In GridWorld, the agent starts at a starting point (“S”) and aims to\nreach a target point, sometimes called the reward (“R”) cell. The agent can either step up, down, left, or right,\nor stay still. Only empty cells can be stepped in, while non-empty cells, like the ones containing obstacles\n(walls), are not. The authors of the notebook provide an easy way to build such an environment from a string.\nFor the sake of this tutorial, we will work with a fixed 18x20 grid like the one specified by the string below.\nThe “O” letter indicates empty spaces, “#” stands for walls, “S” is the starting state and “R” the target one.\nFor clarity, we have drawn the grid for you.\n\ngrid = (\n    'OOOOOOOOOOOOOOOOOOOO\\\\'\n    'OOOOOOOOOOOOOOOOOOOO\\\\'\n    'OOOOOOOOSOOOOOOOOOO#\\\\'\n    'OOOOOOO##OOOOOOOOOO#\\\\'\n    'OOOOOO#O#OOOOOOOOOOO\\\\'\n    'OOOOOOOOOOO#OO#OOOOO\\\\'\n    'OOOOOOOOOOOOOOOOOO#O\\\\'\n    'OOOO#OOOOOOOOOOOOOOO\\\\'\n    '##OOOOOOOO#OOOOOOOOO\\\\'\n    'OOOOOOOOOOO#OOOOO#OO\\\\'\n    'OOOOOOOOOOOOOOO####O\\\\'\n    'OOOOOOOOOOOOOOOOOOOO\\\\'\n    'OO#OOO#OOOOOO#OOOROO\\\\'\n    'OOOOOO##OO#OOOOOOOOO\\\\'\n    'OOO#OOOOOOOOOOOO##O#\\\\'\n    'OOOOOOO#OOOOOOOOOOOO\\\\'\n    'OOOOOOOOOOOOOOOOOOOO\\\\'\n    '##OOOOO##OOOOOOOOOOO\\\\'\n    'OOOOOOOOOOO#OOO#OOOO\\\\'\n    'OOOO##OOOO#O#OOOOOOO\\\\'\n)\n\n\n\nFig.2 — The chosen grid for our experiments: the green cell (S) is the starting point; the\nyellow cell (R) is the target point; white cells are empty while red cells contain walls.\nPlease note that in our experiments we have tested different grid configurations and dimensions and we believe\nthat the chosen dimensionality and obstacle distribution presented for this tutorial do represent a\ngood experimental setup in order to arrive at reasonable conclusions. Indeed, the grid is small enough\nfor the algorithm to be able to quickly iterate through different runs, and its configuration\nis complicated enough to lead to non-trivial results.\nIn general, from our experience, things start to get interesting with grids NxM where N,M \u003e= 12.\nAgent’s visualizations\nIn RL, it’s sometimes beneficial to visualize the policy your agents are learning. Since the environment\nwe are playing with is relatively small, we can actually enumerate all possible state-action (s,a) pairs.\nWhen a specific algorithm runs, we are able to count how many times each of these pairs was visited, and we are\nable to visualize it as a heatmap, superimposed on the grid.\nIn our case, such heatmaps (that we call state-action visitation maps)\ncan be really useful to understand, for example, the quality of a specific policy:\na good state-action visitation map is created only by applying a good policy.\nHow would a map built using the optimal policy look like?\nAgain, it’s a question we can answer only because we are in the ideal case of using a simple environment where we can\nknow and do everything, like finding the optimal policy.\nWe can use tabular Q-iteration to find an optimal solution for our case,\nhence producing the optimal state-action map that looks as follows:\n\nFig.3 — State-action visitation heatmap generated by the optimal policy. Most of the time the agent reaches the target\ncell in a few steps and then, it just stays idle without performing any further step.\nAs you can see, in this case, almost every (s,a) pair has a value approaching zero, apart from the reward (“R”) state\nwhich has a big value. This is happening because once the agent knows the optimal policy, it will take very few steps\nfor it to reach the target cell and once it’s reached, it will spend most of the time just waiting, without performing\nany further action. More precisely, the agent will spend the majority of the time in the (s,a) = (“R”, NOOP),\nwhere NOOP stands for “no operation”.\nLet’s now visualize the heatmap generated by the uniform policy,\ni.e an agent that decides at random (with uniform probability) which action to take when being in a specific state.\nThis approach would be the way to go in the majority of the cases and is the closest to the real case example.\nSuppose you don’t know anything about the environment you are going to interact with: the best you can do is to\nperform random exploration!\n\nFig.4 — State-action visitation heatmap generated by the random policy. The agent performs random exploration. As a\nresult of the random behaviour, cells in the surroundings of the initial state are visited on average more often than\nfurther cells.\nSince we start from the “S” cell at every episode, we have the highest probability of visiting the “S” state and all\nits surroundings. As we go further from it, the agent will start to pick different states depending on the run,\nand thus values on farther cells start to normalize and approach 0.0.\nIn the following, we will describe the algorithm in detail, and we will make use of these visualizations to understand\nif the turn-based approach is beneficial for learning a good policy when starting from a random one.\nAlgorithm\nNow let’s dive into the algorithm itself. Recalling the steps indicated in the previous section,\nwe can describe the turn-based learning algorithm with the following pythonic pseudocode:\n\ndef run_turn_based_algorithm(init_policy,\n                             num_turns,\n                             num_seeds,\n                             dataset_size,\n                             num_iters):\n    offline_dataset = []\n    current_policy = init_policy\n    num_of_trajectories_per_turn = dataset_size / num_turns\n\n    for turn in range(num_turns):\n        runs = []\n        for seed in range(num_seeds):\n            temp_dataset = offline_dataset.copy()\n            trajectories_from_new_policy = deploy_and_sample(current_policy, num_of_trajectories_per_turn)\n            temp_dataset.extend(trajectories_from_new_policy)\n            policy, performances = run_offline_rl_algorithm(temp_dataset, num_iters)\n            runs.append((policy, performances, trajectories_from_new_policy))\n\n        best_policy, best_trajectories = find_best_run(runs)\n        current_policy = best_policy\n        offline_dataset.extend(best_trajectories)\n\n\nLet’s explain each step involved in the algorithm.  First, let’s define what the main parameters expected by\nthe algorithm are:\ninit_policy — it’s the starting policy, most likely the random policy.\nnum_turns — this is simply the total number of turns for which you will run the algorithm.\nnum_seeds — if you work in RL you will be familiar with this argument: RL algorithms\n(and especially Offline RL ones) present large variability in the results due to their stochastic nature.\nThat’s why instead of having one single run of the Offline RL algorithm,\nwe will have several of them. For each run, we will produce the best policy and the best\n“new set of trajectories” to be used later in the algorithm (more on this step in the following).\nnum_iters — this is simply the number of iterations we will run our Offline RL algorithm.\ndataset_size — as a design choice, we assume that the final dataset size has been fixed beforehand,\nas we do with the number of turns. However, both of these two conditions could be relaxed and one could run\nthe algorithm as many turns as needed, getting a final offline dataset with an undefined size.\nHowever, please remember that in the real scenario you will probably not have the privilege of\naccessing the environment so often! You must do your best with a reasonable number of turns!\nNow, following the logic of the pseudo-code, let’s describe the algorithm:\nInitially, we don’t have any transitions to train our Offline RL algorithm, so we initialize our offline_dataset\nas an empty list.\nWe also initialize current_policy with init_policy, which most likely will be the random policy\n(an agent that has previously interacted with the environment taking actions uniformly at random).\nNow, for each turn we run num_seeds times the following procedure:\n    \nWe create a copy of offline_dataset (temp_dataset) to train the current agent with the dataset collected\nso far.\nWe deploy the agent to the environment, in order to generate a new set of transitions using the current policy\n(trajectories_from_new_policy).\nWe extend the temporary dataset by trajectories_from_new_policy and train an agent with it,\nusing the preferred Offline RL algorithm and getting its corresponding policy and performances.\nWe append the results to runs list.\nOnce we have collected all the results, we pick the best policy and best-generated trajectories\nout of the pool of runs (find_best_run).\nThe best_policy is now our current_policy that will be used for the next turn.\nThe best_trajectories will are appended to offline_dataset that will is going to be used for the next turn.\nWe repeat this procedure until we are satisfied with the performance or as many times (turns)\nwe are able to access the environment.\nNow, hoping the algorithm is clear to you, we need to answer two important questions.\nWhich Offline RL algorithm should be run?\nActually here the choice is yours! In our case, we opted for\nusing Conservative Q-Learning (CQL).\nAny algorithm may have its pros and cons. In our case we find it hard to set the CQL global parameters only once\nto be good for all the runs. What is happening is that initially our dataset will be full of random transitions,\nbut as long as you proceed in turns, it will become richer in “more-expert” transitions.\nThus, parameters like alpha for the CQL loss should be somehow adjusted in time.\nWhile in this tutorial we did not investigate this aspect, we found that for this very simplistic environment\neven CQL with alpha = 0 (equivalent to offline Q iteration) would work sufficiently.\nHow to aggregate results in order to get a representative policy and dataset for the next turn?\nThat’s a hard question. For the sake of this tutorial, we have opted for the simplest of the approaches:\nout of the N runs, we will pick the one that gave us the best results (in terms of average reward).\nHowever, please note that this may be too optimistic and could lead to unexpected behavior in production.\nA better approach would actually be the one that takes into account the “average policy”. But, to “average out”\npolicies is not a trivial task. We discuss this aspect in detail in the final section.\nResults\nVisualizing the agent “in turns”\nFirst, we ask ourselves the following question: does the agent learn “in turns”? We can check this\nby visualizing subsequent state-action visitation maps:\n\nFig.5 — Visualization of subsequent state-action visitation heatmaps. Here we visualize 4 subsequent turns — after one\nsingle turn the agent learns the fastest path to reach the target cell. As long as we proceed in turns, the agent\nimproves its performance, eventually approaching a behaviour comparable to the optimal policy.\nOur algorithm seems to work! When starting with a uniform policy, we can see that even after a\nsingle turn the agent quickly learns the fastest path to reach the target cell. As long as we proceed in turns, the model will\nconsistently improve its performance, by quickly getting to the “R” cell even more often. In this sense, visitation\nmaps get closer to the optimal one where the agent basically reaches the target in a few steps and then just stays\nthere, without performing any further steps.\nDoes the agent improve its performance over time?\nHow many turns are needed to start having results comparable to\nthe optimal policy? In other words, how much better are we performing if compared to not doing any turn at all?\nLet’s analyze the plot below. In this figure we are plotting the algorithm’s performance, measured in\n“averaged reward” (the higher, the better), as the amount of data available offline increases. In general, we expect\nthe curve obtained by running the optimal policy (violet curve) to represent an upper bound: it’s the best we\ncan achieve! On the other hand, we expect the curve obtained by running the random policy without any “turn”\n(green curve), to be our lower bound. Also, generally speaking, we expect that the more offline data is available,\nthe better the achieved scores will be, since our chosen Offline RL will have more data coverage and possibility\nto converge to the optimal policy. Given this, we can observe that the performance of the turn-based procedure falls\nin the middle between the aforementioned upper and lower bounds: as the number of turns increases, the closer we get\nto the upper bound. However, we can observe that 3 turns are already enough to start having better performance than\nthe lower bound. This plot confirms our hypothesis: “Turn-based Offline RL” stands exactly between Online RL\n(upper bound) and Offline RL (lower bound).\n\nFig.6 — This plot shows the comparison between baselines and the turn-based procedure in terms of average reward (the higher,\nthe better) as the size of the collected data used to train the algorithm offline grows. To obtain this figure,\nwe have run each of the algorithms for 30 seeds. For the optimal policy we run Q-iteration, while for the rest we\napplied CQL with fixed alpha=0. For each run, CQL was fitted for 300 iterations.\nConclusions and Future Work\nIn this blog post we have presented a practical approach you could use to address cases where you have temporary\nand limited access to an environment, and you have computational resources at your disposal to train your RL algorithm\n“offline” only.\nIn fact, the proposed solution falls halfway between Online RL and Offline RL: our agent is warmed up\nby training it via Offline RL on a dataset generated by running the uniform random policy and then\nsubsequently improved by accessing the environment in “turns”, thus partially simulating what you would get on a\nstandard online RL scenario.\nIn particular, we show that:\nThe turn-based procedure is effective since the policy learned in subsequent turns consistently improves as\nturns increase, matching the expectations. This result is demonstrated through some visualizations, showing how\nthe agent chooses a better and faster path to target turn after turn.\nThe turn-based procedure allows getting an agent that is better than a random one, even after a small number of turns.\nThe performance of the turn-based agent will be upper-bounded by the performance of the optimal policy.\nMoreover, we provide an easy-to-understand framework to prove the aforementioned hypothesis.\nFinally, we want to point out some limitations of our work that could be addressed as future work:\nFrom one turn to the other, we pick the “best policy” as the one that achieves the best performance between all\nthe runs via the “max” operator. This single policy is then propagated through the algorithm and used to generate\nthe best new extension of the dataset. The inherent limitation of this approach is that by using the “max” we are\nnot robust to the noise and we do not account for fluctuations in the performance of the Offline RL algorithm.\nA better approach would be aggregating policies by doing, for example, an ensemble of policies, and using this\nas the selected policy that is propagated forward in the algorithm.\nRunning a fixed Offline RL algorithm on a dataset that keeps changing its distribution of states and actions\nin time could be really challenging since a lot of algorithms in the literature require accurate hypertuning\nof the parameters. In future work, we would like to address this problem, proposing, for example, a way one\ncould compute new hyper-parameters using the dataset size and some other properties as parameters for the computation.\nOne could argue that our hypothesis can work only on simplistic environments like GridWorlds.\nEven though we tested different configurations of grids, stressing more or less the algorithms,\nwe admit that a more complete work would require the re-visitation of our hypothesis on a more diverse\nsuite of environments. We plan to investigate this in the future.","guid":"https://blog.allegro.tech/2022/04/turn-based-offline-rl.html","categories":["tech","mlr","rl","research"],"isoDate":"2022-04-13T22:00:00.000Z","thumbnail":"images/post-headers/default.jpg"},{"title":"An Agile team in its natural habitat","link":"https://blog.allegro.tech/2022/04/agile-team-natural-habitat.html","pubDate":"Fri, 01 Apr 2022 00:00:00 +0200","authors":{"author":[{"name":["Michał Kosmulski"],"photo":["https://blog.allegro.tech/img/authors/michal.kosmulski.jpg"],"url":["https://blog.allegro.tech/authors/michal.kosmulski"]}]},"content":"\u003cblockquote\u003e\n  \u003cp\u003eThis post was published on April 1st, 2022, and should be taken with a grain of salt.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eIn this picture, we can see an Agile team in its natural habitat at Allegro:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-04-01-agile-team-natural-habitat/allegro-agile-team-natural-habitat.jpg\" alt=\"An Agile team in its natural habitat at Allegro\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eLearning and development are very important to us at \u003ca href=\"https://allegro.tech/\"\u003eAllegro\u003c/a\u003e. This absolutely not staged photo\nshows Piotr (right) reading out loud from a book about a newfangled language called BASIC. Piotr is a Product Owner,\nand he knows the development team needs to keep learning all the time in order to stay current with technology. He\nhimself has amassed a personal collection of 8-bit machines in order to hone his technical skills, and now he’s sharing\nwhat he has learned with others.\u003c/p\u003e\n\n\u003cp\u003eListening with great attention are two software engineers, Artur (left) and Kacper (center). Until recently, Artur was\nthe most junior member of the team. Nonetheless, when new people were joining us, he was their \u003cem\u003ebuddy\u003c/em\u003e, the go-to\ncontact for any questions, whose role is to put them on track as efficiently as possible. He did so well, and liked\nthis role so much, that at one point we literally had to stop him in order to give others a chance to try their hand\nat being buddies, too. But nothing is lost, since the whole team, not just the buddy, helps onboard new people. Artur\nis already thinking deeply about teaching BASIC to our future teammates.\u003c/p\u003e\n\n\u003cp\u003eKacper, in contrast, is one of the senior team members. He was already there when we started introducing Kotlin in our\nprojects a few years ago. Learning a new language is great fun, and you can already see Kacper smile at the thought\nof replacing all those complex functional constructs with a few simple GOTO statements. Keen observers will also notice\non the desk Kacper’s stopwatch he uses for timing performance-critical pieces of code. Many of our systems have\ndemanding performance requirements, and it’s thanks to experienced people like him that we are able to meet them.\u003c/p\u003e\n\n\u003cp\u003eObviously, this is not even the whole team, so you can easily imagine that anything is possible with such people\nand attitude. Happy April!\u003c/p\u003e\n","contentSnippet":"This post was published on April 1st, 2022, and should be taken with a grain of salt.\nIn this picture, we can see an Agile team in its natural habitat at Allegro:\n\nLearning and development are very important to us at Allegro. This absolutely not staged photo\nshows Piotr (right) reading out loud from a book about a newfangled language called BASIC. Piotr is a Product Owner,\nand he knows the development team needs to keep learning all the time in order to stay current with technology. He\nhimself has amassed a personal collection of 8-bit machines in order to hone his technical skills, and now he’s sharing\nwhat he has learned with others.\nListening with great attention are two software engineers, Artur (left) and Kacper (center). Until recently, Artur was\nthe most junior member of the team. Nonetheless, when new people were joining us, he was their buddy, the go-to\ncontact for any questions, whose role is to put them on track as efficiently as possible. He did so well, and liked\nthis role so much, that at one point we literally had to stop him in order to give others a chance to try their hand\nat being buddies, too. But nothing is lost, since the whole team, not just the buddy, helps onboard new people. Artur\nis already thinking deeply about teaching BASIC to our future teammates.\nKacper, in contrast, is one of the senior team members. He was already there when we started introducing Kotlin in our\nprojects a few years ago. Learning a new language is great fun, and you can already see Kacper smile at the thought\nof replacing all those complex functional constructs with a few simple GOTO statements. Keen observers will also notice\non the desk Kacper’s stopwatch he uses for timing performance-critical pieces of code. Many of our systems have\ndemanding performance requirements, and it’s thanks to experienced people like him that we are able to meet them.\nObviously, this is not even the whole team, so you can easily imagine that anything is possible with such people\nand attitude. Happy April!","guid":"https://blog.allegro.tech/2022/04/agile-team-natural-habitat.html","categories":["tech","agile","testing","April 1st"],"isoDate":"2022-03-31T22:00:00.000Z","thumbnail":"images/post-headers/testing.png"}],"jobs":[{"id":"743999810853837","name":"Research Engineer - Machine Learning (Computer Vision)","uuid":"98abcad8-b820-4402-85a6-b6b6e03cfdaa","refNumber":"REF2880R","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2022-03-09T12:55:28.000Z","location":{"city":"Warszawa, Kraków, Poznań, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572821","label":"IT - Machine Learning"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"606235fe248e6f5bea0815ed","fieldLabel":"Katowice","valueId":"185eb5a9-b884-4ee8-8ebc-0e5f3e852b27","valueLabel":"Tak"},{"fieldId":"58c1575ee4b01d4b19ddf797","fieldLabel":"Kraków","valueId":"2cfcfcc1-da44-43f7-8eaa-3907faf2797c","valueLabel":"Tak"},{"fieldId":"606235bcefbac7156d6a470a","fieldLabel":"Łódź","valueId":"7d33e23d-3fa7-4d7d-86ae-7d7caff54fa9","valueLabel":"Tak"},{"fieldId":"58c158e9e4b0614667d5973e","fieldLabel":"Więcej lokalizacji","valueId":"3a186e8d-a82c-4955-af81-fcef9a63928a","valueLabel":"Tak"},{"fieldId":"58c1576ee4b0614667d59732","fieldLabel":"Toruń","valueId":"987e8884-bad1-4a8f-b149-99e4184cc221","valueLabel":"Tak"},{"fieldId":"6165609ee6b46b6506c66b63","fieldLabel":"Gdańsk","valueId":"cde0f8e7-5c9d-4d78-9f5c-e1c17ee499a8","valueLabel":"Tak"},{"fieldId":"58c156e6e4b01d4b19ddf793","fieldLabel":"Warszawa","valueId":"6a428533-1586-4372-89ec-65fb45366363","valueLabel":"Tak"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Proces rekrutacji","valueId":"c807eec2-8a53-4b55-b7c5-c03180f2059b","valueLabel":"(Archive) IT Allegro"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c15788e4b0614667d59733","fieldLabel":"Błonie","valueId":"25f6cb8c-81b3-434a-93ec-6dc851d5808d","valueLabel":"Nie"},{"fieldId":"58c15798e4b01d4b19ddf79b","fieldLabel":"Wrocław","valueId":"64818201-cdba-422e-8e8c-8ec633b0d327","valueLabel":"Tak"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572821","valueLabel":"IT - Machine Learning"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro.pl sp. z o.o."},{"fieldId":"61656102a169ed164d546c31","fieldLabel":"Lublin","valueId":"02d54f00-48b9-4669-b7b3-10c16ac4bada","valueLabel":"Tak"},{"fieldId":"58c156b9e4b01d4b19ddf792","fieldLabel":"Poznań","valueId":"ac20917b-cb6a-4280-aff3-4fae2532a33e","valueLabel":"Tak"},{"fieldId":"5cdab2c84cedfd0006e7758c","fieldLabel":"Key words","valueLabel":"CV, Computer Vision, ML, AI, DS, Machine Learning, PyTorch, Python, Deep Learning"}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999810853837","creator":{"name":"Maciej Matwiejczyk"},"language":{"code":"pl","label":"Polish","labelNative":"polski"}},{"id":"743999785421861","name":"Research Engineer - Machine Learning (Ranking and Recommendations)","uuid":"a6b2b59e-28e3-4bfa-89ab-b13ab97f06c8","refNumber":"REF2990T","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2021-11-08T09:54:52.000Z","location":{"city":"Warszawa, Poznań, Kraków, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572821","label":"IT - Machine Learning"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"58c1575ee4b01d4b19ddf797","fieldLabel":"Kraków","valueId":"2cfcfcc1-da44-43f7-8eaa-3907faf2797c","valueLabel":"Tak"},{"fieldId":"58c158e9e4b0614667d5973e","fieldLabel":"Więcej lokalizacji","valueId":"3a186e8d-a82c-4955-af81-fcef9a63928a","valueLabel":"Tak"},{"fieldId":"58c1576ee4b0614667d59732","fieldLabel":"Toruń","valueId":"987e8884-bad1-4a8f-b149-99e4184cc221","valueLabel":"Tak"},{"fieldId":"58c156e6e4b01d4b19ddf793","fieldLabel":"Warszawa","valueId":"6a428533-1586-4372-89ec-65fb45366363","valueLabel":"Tak"},{"fieldId":"60cb31a9c87e511299a3a050","fieldLabel":"Department II","valueId":"b8a4596e-d9ce-42bb-8de5-10995e9ccf99","valueLabel":"IT - Machine Learning"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Proces rekrutacji","valueId":"c807eec2-8a53-4b55-b7c5-c03180f2059b","valueLabel":"(Archive) IT Allegro"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c15788e4b0614667d59733","fieldLabel":"Błonie","valueId":"25f6cb8c-81b3-434a-93ec-6dc851d5808d","valueLabel":"Nie"},{"fieldId":"58c15798e4b01d4b19ddf79b","fieldLabel":"Wrocław","valueId":"64818201-cdba-422e-8e8c-8ec633b0d327","valueLabel":"Tak"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572821","valueLabel":"IT - Machine Learning"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro.pl sp. z o.o."},{"fieldId":"58c156b9e4b01d4b19ddf792","fieldLabel":"Poznań","valueId":"ac20917b-cb6a-4280-aff3-4fae2532a33e","valueLabel":"Tak"},{"fieldId":"5cdab2c84cedfd0006e7758c","fieldLabel":"Key words","valueLabel":"ML, AI, Ranking, Research, Machine Learning"}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999785421861","creator":{"name":"Maciej Matwiejczyk"},"language":{"code":"en","label":"English","labelNative":"English (US)"}},{"id":"743999779448676","name":"Research Engineer - Machine Learning (Ranking and Recommendations)","uuid":"7cb35dfc-f53c-4b51-81ac-61b683060f4c","refNumber":"REF2990T","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2021-10-14T10:29:00.000Z","location":{"city":"Warszawa, Poznań, Kraków, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572821","label":"IT - Machine Learning"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"58c1575ee4b01d4b19ddf797","fieldLabel":"Kraków","valueId":"2cfcfcc1-da44-43f7-8eaa-3907faf2797c","valueLabel":"Tak"},{"fieldId":"58c158e9e4b0614667d5973e","fieldLabel":"Więcej lokalizacji","valueId":"3a186e8d-a82c-4955-af81-fcef9a63928a","valueLabel":"Tak"},{"fieldId":"58c1576ee4b0614667d59732","fieldLabel":"Toruń","valueId":"987e8884-bad1-4a8f-b149-99e4184cc221","valueLabel":"Tak"},{"fieldId":"58c156e6e4b01d4b19ddf793","fieldLabel":"Warszawa","valueId":"6a428533-1586-4372-89ec-65fb45366363","valueLabel":"Tak"},{"fieldId":"60cb31a9c87e511299a3a050","fieldLabel":"Department II","valueId":"b8a4596e-d9ce-42bb-8de5-10995e9ccf99","valueLabel":"IT - Machine Learning"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Proces rekrutacji","valueId":"c807eec2-8a53-4b55-b7c5-c03180f2059b","valueLabel":"(Archive) IT Allegro"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c15788e4b0614667d59733","fieldLabel":"Błonie","valueId":"25f6cb8c-81b3-434a-93ec-6dc851d5808d","valueLabel":"Nie"},{"fieldId":"58c15798e4b01d4b19ddf79b","fieldLabel":"Wrocław","valueId":"64818201-cdba-422e-8e8c-8ec633b0d327","valueLabel":"Tak"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572821","valueLabel":"IT - Machine Learning"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro.pl sp. z o.o."},{"fieldId":"58c156b9e4b01d4b19ddf792","fieldLabel":"Poznań","valueId":"ac20917b-cb6a-4280-aff3-4fae2532a33e","valueLabel":"Tak"},{"fieldId":"5cdab2c84cedfd0006e7758c","fieldLabel":"Key words","valueLabel":"ML, AI, Ranking, Research, Machine Learning"}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999779448676","creator":{"name":"Maciej Matwiejczyk"},"language":{"code":"pl","label":"Polish","labelNative":"polski"}}],"events":[{"created":1655131243000,"duration":5400000,"id":"286545395","name":"Allegro Tech Live #29 - Wyzwania Product Managera","date_in_series_pattern":false,"status":"upcoming","time":1656604800000,"local_date":"2022-06-30","local_time":"18:00","updated":1655816092000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":84,"is_online_event":false,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/286545395/","description":"Allegro Tech Live to w 100% zdalna odsłona naszych stacjonarnych meetupów Allegro Tech Talks. Zazwyczaj spotykaliśmy się w naszych biurach, ale tym razem to my…","visibility":"public","member_pay_fee":false},{"created":1650552918000,"duration":100800000,"id":"285416318","name":"UX Research Confetti - II edycja","date_in_series_pattern":false,"status":"past","time":1653562800000,"local_date":"2022-05-26","local_time":"13:00","updated":1653666063000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":48,"is_online_event":true,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/285416318/","description":"REJESTRACJA NA WYDARZENIE -\u0026gt; https://app.evenea.pl/event/ux-research-confetti-2/ 🎉 Niech ponownie rozsypie się confetti wiedzy o badaniach UX! 🎉 Szukaliśmy konferencji badawczej UX w Polsce i nie znaleźliśmy……","visibility":"public","member_pay_fee":false},{"created":1651656994000,"duration":7200000,"id":"285691203","name":"Allegro Tech Live #28 - Mobile: Architektura softu i architektura sprzętu","date_in_series_pattern":false,"status":"past","time":1652976000000,"local_date":"2022-05-19","local_time":"18:00","updated":1652985850000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":48,"is_online_event":true,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/285691203/","description":"**Allegro Tech Live** to w 100% zdalna odsłona naszych stacjonarnych meetupów Allegro Tech Talks. Kiedyś spotykaliśmy się w naszych biurach, a teraz to my gościmy…","visibility":"public","member_pay_fee":false},{"created":1649842904000,"duration":5400000,"id":"285245512","name":"Allegro Tech Live #27 - Java, Python i rozsądny development","date_in_series_pattern":false,"status":"past","time":1651161600000,"local_date":"2022-04-28","local_time":"18:00","updated":1651169097000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":41,"is_online_event":true,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/285245512/","description":"\\-\\-\\-\\-\\-\\-\\\u0026gt; Na wydarzenie obowiązuje rejestracja: [https://app.evenea.pl/event/allegro-tech-live-27/](https://app.evenea.pl/event/allegro-tech-live-27/?fbclid=IwAR3QOef6CKKiuowl1Nto3Z4YEFMj7R7hdq_REpvY2a-3ETaJsWhvfnXDLxE) \u0026lt;----- Allegro Tech Live to w 100% zdalna odsłona naszych stacjonarnych meetupów Allegro Tech Talks. Kiedyś spotykaliśmy się w…","visibility":"public","member_pay_fee":false}],"podcasts":[{"title":"S02E12 - Piotr Betkier - Rola architekta w Allegro","link":"https://podcast.allegro.tech/rola_architekta_w_allegro/","pubDate":"Wed, 16 Jun 2021 00:00:00 GMT","content":"Od kodowania do tworzenia strategii technicznej... Jak wygląda rola architekta w Allegro? Ile takich osób pracuje w naszej firmie i dlaczego ta rola jest tak różnorodna? Czym jest Andamio i jak rozwijamy naszą platformę – o tym wszystkim opowie Piotr Betkier – Inżynier, Architekt Platformy Technicznej w Allegro oraz twórca piosenek o IT :)","contentSnippet":"Od kodowania do tworzenia strategii technicznej... Jak wygląda rola architekta w Allegro? Ile takich osób pracuje w naszej firmie i dlaczego ta rola jest tak różnorodna? Czym jest Andamio i jak rozwijamy naszą platformę – o tym wszystkim opowie Piotr Betkier – Inżynier, Architekt Platformy Technicznej w Allegro oraz twórca piosenek o IT :)","guid":"https://podcast.allegro.tech/rola_architekta_w_allegro/","isoDate":"2021-06-16T00:00:00.000Z"},{"title":"S02E11 - Piotr Michoński - Infrastruktura Allegro","link":"https://podcast.allegro.tech/infrastruktura_Allegro/","pubDate":"Tue, 01 Jun 2021 00:00:00 GMT","content":"Jak jest zbudowane środowisko uruchomienia aplikacji Allegro? Jak działają serwerownie firmy i ile ich potrzeba, a które elementy Allegro działają w chmurze publicznej? Jak przebiegała transformacja w Allegro i co zmieniało się przez lata? Jak wzrost biznesu wpływa na wielkość infrastruktury i jak infrastruktura Allegro odczuła przyjście pandemii? O tym, a także o rozwoju liderów technologii w Allegro oraz o historii powstania dżingla do naszych podcastów, opowie Piotr Michoński - menadżer Zespołów tworzących infrastrukturę Allegro.","contentSnippet":"Jak jest zbudowane środowisko uruchomienia aplikacji Allegro? Jak działają serwerownie firmy i ile ich potrzeba, a które elementy Allegro działają w chmurze publicznej? Jak przebiegała transformacja w Allegro i co zmieniało się przez lata? Jak wzrost biznesu wpływa na wielkość infrastruktury i jak infrastruktura Allegro odczuła przyjście pandemii? O tym, a także o rozwoju liderów technologii w Allegro oraz o historii powstania dżingla do naszych podcastów, opowie Piotr Michoński - menadżer Zespołów tworzących infrastrukturę Allegro.","guid":"https://podcast.allegro.tech/infrastruktura_Allegro/","isoDate":"2021-06-01T00:00:00.000Z"},{"title":"S02E10 - Dariusz Eliasz - Praca architekta ekosystemu big data w Allegro","link":"https://podcast.allegro.tech/praca_architekta_ekosystemu_big_data_w_Allegro/","pubDate":"Thu, 20 May 2021 00:00:00 GMT","content":"Jak wygląda praca architekta ekosystemu big data w Allegro? Jakie zadania realizuje nasz zespół odpowiedzialny za narzędzia i infrastrukturę dla przetwarzania danych? Kiedy możemy mówić o dużych danych i ile petabajtów przetwarza Allegro? Skąd pochodzą dane Allegro i dlaczego jest ich tak dużo oraz z jakiego powodu dopiero teraz przenosimy się do chmury? O tym wszystkim opowie zdobywca statuetki Allegro Tech Hero - Dariusz Eliasz – Team Manager \u0026 Platform Architect w Allegro.","contentSnippet":"Jak wygląda praca architekta ekosystemu big data w Allegro? Jakie zadania realizuje nasz zespół odpowiedzialny za narzędzia i infrastrukturę dla przetwarzania danych? Kiedy możemy mówić o dużych danych i ile petabajtów przetwarza Allegro? Skąd pochodzą dane Allegro i dlaczego jest ich tak dużo oraz z jakiego powodu dopiero teraz przenosimy się do chmury? O tym wszystkim opowie zdobywca statuetki Allegro Tech Hero - Dariusz Eliasz – Team Manager \u0026 Platform Architect w Allegro.","guid":"https://podcast.allegro.tech/praca_architekta_ekosystemu_big_data_w_Allegro/","isoDate":"2021-05-20T00:00:00.000Z"},{"title":"S02E09 - Bartosz Gałek - Od inżyniera do lidera w Allegro","link":"https://podcast.allegro.tech/od_inzyniera_do_lidera_w_allegro/","pubDate":"Thu, 06 May 2021 00:00:00 GMT","content":"Czym jest Opbox i jakie wyzwania przed nim stoją? Jak w Allegro angażujemy się w rozwój kultury Open Source? Ile mamy projektów na GitHubie i jak świętujemy Hacktoberfest? W jaki sposób można rozwinąć się od inżyniera do lidera? Na te pytania w najnowszym Allegro Tech Podcast odpowie Bartek Gałek, Team Leader w Allegro.","contentSnippet":"Czym jest Opbox i jakie wyzwania przed nim stoją? Jak w Allegro angażujemy się w rozwój kultury Open Source? Ile mamy projektów na GitHubie i jak świętujemy Hacktoberfest? W jaki sposób można rozwinąć się od inżyniera do lidera? Na te pytania w najnowszym Allegro Tech Podcast odpowie Bartek Gałek, Team Leader w Allegro.","guid":"https://podcast.allegro.tech/od_inzyniera_do_lidera_w_allegro/","isoDate":"2021-05-06T00:00:00.000Z"}]},"__N_SSG":true},"page":"/","query":{},"buildId":"FA_mC8za_aWuIfp6tc6XU","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>