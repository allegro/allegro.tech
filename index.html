<!DOCTYPE html><html lang="pl"><head><meta charSet="utf-8"/><link rel="prefetch" href="https://allegrotechio.disqus.com/count.js"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta name="description" content="Allegro Tech to miejsce, w którym nasi inżynierowie dzielą się wiedzą oraz case study z wybranych projektów w firmie - w formie artykułów, podcastów oraz eventów."/><title>Allegro Tech</title><meta property="og:site_name" content="allegro.tech"/><meta property="og:title" content="allegro.tech"/><meta property="og:url" content="https://allegro.tech"/><meta property="og:type" content="site"/><meta property="og:image" content="https://allegro.tech/images/allegro-tech.png"/><link rel="shortcut icon" href="favicon.ico"/><link rel="canonical" href="https://allegro.tech" itemProp="url"/><link rel="preload" href="images/splash.jpg" as="image"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-1M1FJ5PXWW"></script><script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){dataLayer.push(arguments);}
                    gtag('js', new Date());
                    gtag('config', 'G-1M1FJ5PXWW');
                </script><meta name="next-head-count" content="15"/><link rel="preload" href="/_next/static/css/66933eaa547aae51.css" as="style"/><link rel="stylesheet" href="/_next/static/css/66933eaa547aae51.css" data-n-g=""/><link rel="preload" href="/_next/static/css/79db8b1e27b0a093.css" as="style"/><link rel="stylesheet" href="/_next/static/css/79db8b1e27b0a093.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-69bfa6990bb9e155.js" defer=""></script><script src="/_next/static/chunks/framework-e70c6273bfe3f237.js" defer=""></script><script src="/_next/static/chunks/main-f635b472c367d1c7.js" defer=""></script><script src="/_next/static/chunks/pages/_app-179adf437ae674f2.js" defer=""></script><script src="/_next/static/chunks/206-3a56e5ded293e83e.js" defer=""></script><script src="/_next/static/chunks/pages/index-f037c91132ed6a0a.js" defer=""></script><script src="/_next/static/5O5PfW0B7gehiXUxIndCZ/_buildManifest.js" defer=""></script><script src="/_next/static/5O5PfW0B7gehiXUxIndCZ/_ssgManifest.js" defer=""></script><script src="/_next/static/5O5PfW0B7gehiXUxIndCZ/_middlewareManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><header class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card Header_navbar__Zc5aN m-color-bg_card"><nav class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-display-flex m-flex-justify-between m-flex-items-center"><a href="/"><img src="images/logo.svg" alt="Allegro Tech" width="205" height="45"/></a><div><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0 m-display-flex@lg m-display-none"><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://blog.allegro.tech">Blog</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://ml.allegro.tech">Machine Learning</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://podcast.allegro.tech">Podcast</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://github.com/Allegro">Open Source</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://www.meetup.com/allegrotech/events">Wydarzenia</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://praca.allegro.pl">Praca</a></li></ul><button class="m-display-none@lg m-height_40 m-line-height_40 m-border-style-top_none m-border-style-right_none m-border-style-bottom_none m-border-style-left_none m-border-radius-top-left_2 m-border-radius-top-right_2 m-border-radius-bottom-left_2 m-border-radius-bottom-right_2 m-cursor_pointer m-overflow_hidden m-appearance_none m-padding-left_4 m-padding-right_4 m-padding-top_4 m-padding-bottom_4 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button" style="background:transparent" aria-label="Otwórz menu"><img src="https://assets.allegrostatic.com/metrum/icon/menu-23e046bf68.svg" alt="" class="m-icon" width="32" height="32"/></button></div></nav></header><div class="Header_hero__PYE0B"><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-display-flex m-flex-column m-flex-justify-end Header_image__Cj6ZF"><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-color-bg_desk"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text  m-font-weight_100 m-font-size_32 m-font-size_43_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125">O nas</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">Allegro to jedna z najbardziej zaawansowanych technologicznie firm w naszej części Europy. Allegro to również ponad 1000 specjalistów IT, różnych specjalizacji, rozwijających nasz serwis. Unikatowa skala i złożoność problemów, które rozwiązujemy na co dzień, dają nam możliwość rozwoju przy bardzo różnorodnych projektach. Allegro Tech to miejsce, w którym nasi inżynierowie dzielą się wiedzą oraz case study z wybranych projektów w firmie – w formie artykułów, podcastów oraz eventów.</p></div></div></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24">Blog</h2><div class="m-display_flex m-flex-wrap_1 m-flex-grow_1 m-grid"><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://blog.allegro.tech/2022/04/turn-based-offline-rl.html" title="Turn-Based Offline Reinforcement Learning"><img width="388" src="images/post-headers/default.jpg" alt="Turn-Based Offline Reinforcement Learning" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://blog.allegro.tech/2022/04/turn-based-offline-rl.html" title="Turn-Based Offline Reinforcement Learning" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Turn-Based Offline Reinforcement Learning</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">około 11 godzin temu</time><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0"><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/tech">#<!-- -->tech</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/mlr">#<!-- -->mlr</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/rl">#<!-- -->rl</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/research">#<!-- -->research</a></li></ul><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1 m-padding-top-16">This blogpost is the result of a research collaboration between the Allegro Machine Learning Research team and
the Institute of Mathematics of the Polish Academy of…</p><div class="m-display-flex m-flex-justify-between m-padding-top-16 m-flex-items_center"><div class="m-display-flex m-flex-items_center"><div class="MuiAvatarGroup-root m-padding-right_16 Post_avatars__FHMgb"><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar" style="z-index:5"><img alt="Riccardo Belluzzo" src="https://blog.allegro.tech/img/authors/riccardo.belluzzo.jpg" class="MuiAvatar-img" width="32" height="32"/></div><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar MuiAvatar-colorDefault" style="z-index:0">+<!-- -->4</div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/authors/riccardo.belluzzo">Riccardo Belluzzo…</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/2022/04/turn-based-offline-rl.html#disqus_thread">0 Comments</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech/2022/04/turn-based-offline-rl.html">przejdź do wpisu</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://blog.allegro.tech/2022/04/agile-team-natural-habitat.html" title="An Agile team in its natural habitat"><img width="388" src="images/post-headers/testing.png" alt="An Agile team in its natural habitat" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://blog.allegro.tech/2022/04/agile-team-natural-habitat.html" title="An Agile team in its natural habitat" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">An Agile team in its natural habitat</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">13 dni temu</time><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0"><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/tech">#<!-- -->tech</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/agile">#<!-- -->agile</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/testing">#<!-- -->testing</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/April 1st">#<!-- -->April 1st</a></li></ul><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1 m-padding-top-16">This post was published on April 1st, 2022, and should be taken with a grain of salt.
In this picture, we can see an Agile team…</p><div class="m-display-flex m-flex-justify-between m-padding-top-16 m-flex-items_center"><div class="m-display-flex m-flex-items_center"><div class="MuiAvatarGroup-root m-padding-right_16 Post_avatars__FHMgb"><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar" style="z-index:1"><img alt="Michał Kosmulski" src="https://blog.allegro.tech/img/authors/michal.kosmulski.jpg" class="MuiAvatar-img" width="32" height="32"/></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/authors/michal.kosmulski">Michał Kosmulski</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/2022/04/agile-team-natural-habitat.html#disqus_thread">0 Comments</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech/2022/04/agile-team-natural-habitat.html">przejdź do wpisu</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://blog.allegro.tech/2022/03/visual-thinking.html" title="Visual thinking"><img width="388" src="images/post-headers/default.jpg" alt="Visual thinking" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://blog.allegro.tech/2022/03/visual-thinking.html" title="Visual thinking" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Visual thinking</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">15 dni temu</time><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0"><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/tech">#<!-- -->tech</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/communication">#<!-- -->communication</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/visualization">#<!-- -->visualization</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/planning">#<!-- -->planning</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/creativity">#<!-- -->creativity</a></li></ul><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1 m-padding-top-16">We use written (source code) language to express our intentions in a machine-readable form. We use spoken language to
communicate with other people. We pride ourselves…</p><div class="m-display-flex m-flex-justify-between m-padding-top-16 m-flex-items_center"><div class="m-display-flex m-flex-items_center"><div class="MuiAvatarGroup-root m-padding-right_16 Post_avatars__FHMgb"><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar" style="z-index:1"><img alt="Michał Kowalcze" src="https://blog.allegro.tech/img/authors/michal.kowalcze.jpg" class="MuiAvatar-img" width="32" height="32"/></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/authors/michal.kowalcze">Michał Kowalcze</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/2022/03/visual-thinking.html#disqus_thread">0 Comments</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech/2022/03/visual-thinking.html">przejdź do wpisu</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://blog.allegro.tech/2022/03/android-ui-testing-in-allegro-pay-organization.html" title="Android UI testing in Allegro Pay organization"><img width="388" src="images/post-headers/default.jpg" alt="Android UI testing in Allegro Pay organization" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://blog.allegro.tech/2022/03/android-ui-testing-in-allegro-pay-organization.html" title="Android UI testing in Allegro Pay organization" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Android UI testing in Allegro Pay organization</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">około miesiąc temu</time><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0"><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/tech">#<!-- -->tech</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/kotlin">#<!-- -->kotlin</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/android">#<!-- -->android</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/ui-testing">#<!-- -->ui-testing</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/allegro-pay">#<!-- -->allegro-pay</a></li></ul><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1 m-padding-top-16">Will automatic UI tests be able to replace manual testers as artificial intelligence will try to replace
programmers? I’ll show you how we write automatic UI…</p><div class="m-display-flex m-flex-justify-between m-padding-top-16 m-flex-items_center"><div class="m-display-flex m-flex-items_center"><div class="MuiAvatarGroup-root m-padding-right_16 Post_avatars__FHMgb"><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar" style="z-index:1"><img alt="Michał Kwiatek" src="https://blog.allegro.tech/img/authors/michal.kwiatek.jpg" class="MuiAvatar-img" width="32" height="32"/></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/authors/michal.kwiatek">Michał Kwiatek</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/2022/03/android-ui-testing-in-allegro-pay-organization.html#disqus_thread">0 Comments</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech/2022/03/android-ui-testing-in-allegro-pay-organization.html">przejdź do wpisu</a></div></article></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display_block m-margin-bottom_8 m-width_100 m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech">Zobacz więcej wpisów</a></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24">Podcasty</h2><div class="m-display_flex m-flex-wrap_1 m-flex-grow_1 m-grid"><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://podcast.allegro.tech/rola_architekta_w_allegro/" title="S02E12 - Piotr Betkier - Rola architekta w Allegro"><img src="images/podcast.png" alt="S02E12 - Piotr Betkier - Rola architekta w Allegro" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://podcast.allegro.tech/rola_architekta_w_allegro/" title="S02E12 - Piotr Betkier - Rola architekta w Allegro" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">S02E12 - Piotr Betkier - Rola architekta w Allegro</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">10 miesięcy temu</time><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1">Od kodowania do tworzenia strategii technicznej... Jak wygląda rola architekta w Allegro? Ile takich osób pracuje w naszej firmie i dlaczego ta rola jest tak różnorodna? Czym jest Andamio i jak rozwijamy naszą platformę – o tym wszystkim opowie Piotr Betkier – Inżynier, Architekt Platformy Technicznej w Allegro oraz twórca piosenek o IT :)</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech/rola_architekta_w_allegro/">Posłuchaj odcinka</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://podcast.allegro.tech/infrastruktura_Allegro/" title="S02E11 - Piotr Michoński - Infrastruktura Allegro"><img src="images/podcast.png" alt="S02E11 - Piotr Michoński - Infrastruktura Allegro" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://podcast.allegro.tech/infrastruktura_Allegro/" title="S02E11 - Piotr Michoński - Infrastruktura Allegro" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">S02E11 - Piotr Michoński - Infrastruktura Allegro</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">11 miesięcy temu</time><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1">Jak jest zbudowane środowisko uruchomienia aplikacji Allegro? Jak działają serwerownie firmy i ile ich potrzeba, a które elementy Allegro działają w chmurze publicznej? Jak przebiegała transformacja w Allegro i co zmieniało się przez lata? Jak wzrost biznesu wpływa na wielkość infrastruktury i jak infrastruktura Allegro odczuła przyjście pandemii? O tym, a także o rozwoju liderów technologii w Allegro oraz o historii powstania dżingla do naszych podcastów, opowie Piotr Michoński - menadżer Zespołów tworzących infrastrukturę Allegro.</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech/infrastruktura_Allegro/">Posłuchaj odcinka</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://podcast.allegro.tech/praca_architekta_ekosystemu_big_data_w_Allegro/" title="S02E10 - Dariusz Eliasz - Praca architekta ekosystemu big data w Allegro"><img src="images/podcast.png" alt="S02E10 - Dariusz Eliasz - Praca architekta ekosystemu big data w Allegro" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://podcast.allegro.tech/praca_architekta_ekosystemu_big_data_w_Allegro/" title="S02E10 - Dariusz Eliasz - Praca architekta ekosystemu big data w Allegro" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">S02E10 - Dariusz Eliasz - Praca architekta ekosystemu big data w Allegro</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">11 miesięcy temu</time><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1">Jak wygląda praca architekta ekosystemu big data w Allegro? Jakie zadania realizuje nasz zespół odpowiedzialny za narzędzia i infrastrukturę dla przetwarzania danych? Kiedy możemy mówić o dużych danych i ile petabajtów przetwarza Allegro? Skąd pochodzą dane Allegro i dlaczego jest ich tak dużo oraz z jakiego powodu dopiero teraz przenosimy się do chmury? O tym wszystkim opowie zdobywca statuetki Allegro Tech Hero - Dariusz Eliasz – Team Manager &amp; Platform Architect w Allegro.</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech/praca_architekta_ekosystemu_big_data_w_Allegro/">Posłuchaj odcinka</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://podcast.allegro.tech/od_inzyniera_do_lidera_w_allegro/" title="S02E09 - Bartosz Gałek - Od inżyniera do lidera w Allegro"><img src="images/podcast.png" alt="S02E09 - Bartosz Gałek - Od inżyniera do lidera w Allegro" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://podcast.allegro.tech/od_inzyniera_do_lidera_w_allegro/" title="S02E09 - Bartosz Gałek - Od inżyniera do lidera w Allegro" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">S02E09 - Bartosz Gałek - Od inżyniera do lidera w Allegro</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">11 miesięcy temu</time><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1">Czym jest Opbox i jakie wyzwania przed nim stoją? Jak w Allegro angażujemy się w rozwój kultury Open Source? Ile mamy projektów na GitHubie i jak świętujemy Hacktoberfest? W jaki sposób można rozwinąć się od inżyniera do lidera? Na te pytania w najnowszym Allegro Tech Podcast odpowie Bartek Gałek, Team Leader w Allegro.</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech/od_inzyniera_do_lidera_w_allegro/">Posłuchaj odcinka</a></div></article></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display_block m-margin-bottom_8 m-width_100 m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech">Zobacz więcej podcastów</a></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24">Wydarzenia</h2><div class="m-display_flex m-flex-wrap_1 m-flex-grow_1 m-grid"><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--6@xl m-display-flex m-flex-direction_column"><div class="m-margin-bottom_16 m-display-flex m-flex-direction_column m-flex-direction_row_sm m-padding-bottom_0"><a href="https://www.meetup.com/allegrotech/events/285245512/" title="Allegro Tech Live #27 - Java, Python i rozsądny development" class="m-display_none m-display_block_lg" style="background-color:#fd4a02"><img width="218" src="images/event.png" alt="Allegro Tech Live #27 - Java, Python i rozsądny development"/></a><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-direction_column m-padding-bottom_0 m-flex_1 m-flex-justify_between m-color-bg_card"><a href="https://www.meetup.com/allegrotech/events/285245512/" title="Allegro Tech Live #27 - Java, Python i rozsądny development" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Allegro Tech Live #27 - Java, Python i rozsądny development</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">za 14 dni<!-- -->, Online event</time><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-top-8">\-\-\-\-\-\-\&amp;gt; Na wydarzenie obowiązuje rejestracja: [https://app.evenea.pl/event/allegro-tech-live-27/](https://app.evenea.pl/event/allegro-tech-live-27/?fbclid=IwAR3QOef6CKKiuowl1Nto3Z4YEFMj7R7hdq_REpvY2a-3ETaJsWhvfnXDLxE) &amp;lt;----- Allegro Tech Live to w 100% zdalna odsłona naszych stacjonarnych meetupów Allegro Tech Talks. Kiedyś spotykaliśmy się w…</time><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/285245512/">Szczegóły</a></article></div></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--6@xl m-display-flex m-flex-direction_column"><div class="m-margin-bottom_16 m-display-flex m-flex-direction_column m-flex-direction_row_sm m-padding-bottom_0"><a href="https://www.meetup.com/allegrotech/events/284843205/" title="Allegro Tech Live #26 - Summer e-Xperience 2022 - Praca na start" class="m-display_none m-display_block_lg" style="background-color:#fd4a02"><img width="218" src="images/event.png" alt="Allegro Tech Live #26 - Summer e-Xperience 2022 - Praca na start"/></a><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-direction_column m-padding-bottom_0 m-flex_1 m-flex-justify_between m-color-bg_card"><a href="https://www.meetup.com/allegrotech/events/284843205/" title="Allegro Tech Live #26 - Summer e-Xperience 2022 - Praca na start" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Allegro Tech Live #26 - Summer e-Xperience 2022 - Praca na start</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">7 dni temu<!-- -->, Online event</time><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-top-8">OBOWIĄZUJE REJESTRACJA NA WYDARZENIE: [https://app.evenea.pl/event/allegro-tech-live-26/](https://app.evenea.pl/event/allegro-tech-live-26/?fbclid=IwAR0b1mViAvW5FnJYTRmstdxOtMA_7jlWRYIAtortrhPFJk1PtHw1xIw5rBk) Allegro Tech Live to w 100% zdalna odsłona naszych stacjonarnych meetupów Allegro Tech Talks. Kiedyś spotykaliśmy się w naszych biurach,…</time><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/284843205/">Szczegóły</a></article></div></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--6@xl m-display-flex m-flex-direction_column"><div class="m-margin-bottom_16 m-display-flex m-flex-direction_column m-flex-direction_row_sm m-padding-bottom_0"><a href="https://www.meetup.com/allegrotech/events/284469437/" title="Allegro Tech Live #25 - Przetwarzanie danych w ogromnej skali" class="m-display_none m-display_block_lg" style="background-color:#fd4a02"><img width="218" src="images/event.png" alt="Allegro Tech Live #25 - Przetwarzanie danych w ogromnej skali"/></a><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-direction_column m-padding-bottom_0 m-flex_1 m-flex-justify_between m-color-bg_card"><a href="https://www.meetup.com/allegrotech/events/284469437/" title="Allegro Tech Live #25 - Przetwarzanie danych w ogromnej skali" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Allegro Tech Live #25 - Przetwarzanie danych w ogromnej skali</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">28 dni temu</time><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-top-8">Wydarzenie przełożone z 24 lutego. OBOWIĄZUJE REJESTRACJA: https://app.evenea.pl/event/allegro-tech-live-25/ Allegro Tech Live to w 100% zdalna odsłona naszych stacjonarnych meetupów Allegro Tech Talks. Kiedyś spotykaliśmy się…</time><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/284469437/">Szczegóły</a></article></div></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--6@xl m-display-flex m-flex-direction_column"><div class="m-margin-bottom_16 m-display-flex m-flex-direction_column m-flex-direction_row_sm m-padding-bottom_0"><a href="https://www.meetup.com/allegrotech/events/283913049/" title="Allegro Tech Live #25 - Przetwarzanie danych w ogromnej skali" class="m-display_none m-display_block_lg" style="background-color:#fd4a02"><img width="218" src="images/event.png" alt="Allegro Tech Live #25 - Przetwarzanie danych w ogromnej skali"/></a><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-direction_column m-padding-bottom_0 m-flex_1 m-flex-justify_between m-color-bg_card"><a href="https://www.meetup.com/allegrotech/events/283913049/" title="Allegro Tech Live #25 - Przetwarzanie danych w ogromnej skali" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Allegro Tech Live #25 - Przetwarzanie danych w ogromnej skali</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">około 2 miesiące temu</time><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-top-8">Ze względu na obecną sytuację polityczną pewnie dzisiaj wszyscy jesteśmy myślami z mieszkańcami Ukrainy, dlatego postanowiliśmy odwołać dzisiejszy Allegro Tech Live. Obiecujemy, że wrócimy z…</time><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/283913049/">Szczegóły</a></article></div></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display_block m-margin-bottom_8 m-width_100 m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/">Zobacz więcej wydarzeń</a></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24">Oferty pracy</h2><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto"><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm m-margin-bottom_0_sm m-flex-grow_1">Research Engineer - Machine Learning (Computer Vision)</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-font-size_21 m-font-size_25_sm m-font-weight_300 m-line-height_normal m-margin-top_16 m-text-align_left m-padding-right_16">Warszawa, Kraków, Poznań, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.smartrecruiters.com/Allegro/743999810853837-research-engineer-machine-learning-computer-vision?trid=de9dfdf3-7f9e-4ebf-8a64-49f6c69ad640">Sprawdź</a></article><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm m-margin-bottom_0_sm m-flex-grow_1">Research Engineer - Machine Learning (Reinforcement Learning)</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-font-size_21 m-font-size_25_sm m-font-weight_300 m-line-height_normal m-margin-top_16 m-text-align_left m-padding-right_16">Warszawa, Kraków, Poznań, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.smartrecruiters.com/Allegro/743999785422127-research-engineer-machine-learning-reinforcement-learning?trid=de9dfdf3-7f9e-4ebf-8a64-49f6c69ad640">Sprawdź</a></article><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm m-margin-bottom_0_sm m-flex-grow_1">Research Engineer - Machine Learning (Ranking and Recommendations)</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-font-size_21 m-font-size_25_sm m-font-weight_300 m-line-height_normal m-margin-top_16 m-text-align_left m-padding-right_16">Warszawa, Poznań, Kraków, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.smartrecruiters.com/Allegro/743999785421861-research-engineer-machine-learning-ranking-and-recommendations?trid=de9dfdf3-7f9e-4ebf-8a64-49f6c69ad640">Sprawdź</a></article><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm m-margin-bottom_0_sm m-flex-grow_1">Research Engineer - Machine Learning (Reinforcement Learning)</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-font-size_21 m-font-size_25_sm m-font-weight_300 m-line-height_normal m-margin-top_16 m-text-align_left m-padding-right_16">Warszawa, Kraków, Poznań, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.smartrecruiters.com/Allegro/743999779448775-research-engineer-machine-learning-reinforcement-learning?trid=de9dfdf3-7f9e-4ebf-8a64-49f6c69ad640">Sprawdź</a></article><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm m-margin-bottom_0_sm m-flex-grow_1">Research Engineer - Machine Learning (Ranking and Recommendations)</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-font-size_21 m-font-size_25_sm m-font-weight_300 m-line-height_normal m-margin-top_16 m-text-align_left m-padding-right_16">Warszawa, Poznań, Kraków, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.smartrecruiters.com/Allegro/743999779448676-research-engineer-machine-learning-ranking-and-recommendations?trid=de9dfdf3-7f9e-4ebf-8a64-49f6c69ad640">Sprawdź</a></article></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display_block m-margin-bottom_8 m-width_100 m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://allegro.pl/praca">Zobacz więcej ofert</a></div><footer class="m-color-bg_navy m-margin-top-32"><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24 m-padding-bottom-24 m-display-flex@sm m-flex-justify-between m-flex-items-center m-text-align_center"><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-color_white m-padding-left-24@sm">Proudly built by Allegro Tech engineers</p><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0 m-display-flex m-flex-justify-center"><li style="filter:brightness(0) invert(1);opacity:0.5" class="m-margin-right-8 m-margin-top-16 m-margin-top-0@sm m-color_white"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://github.com/allegro"><img src="https://assets.allegrostatic.com/metrum/icon/github-6a18df1729.svg" alt="Github" class="m-icon"/></a></li><li style="filter:brightness(0) invert(1);opacity:0.5" class="m-margin-right-8 m-margin-top-16 m-margin-top-0@sm m-color_white"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://www.facebook.com/allegro.tech/"><img src="https://assets.allegrostatic.com/metrum/icon/facebook-a2b92f9dcb.svg" alt="Facebook" class="m-icon"/></a></li><li style="filter:brightness(0) invert(1);opacity:0.5" class="m-margin-right-8 m-margin-top-16 m-margin-top-0@sm m-color_white"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/allegrotech"><img src="https://assets.allegrostatic.com/metrum/icon/twitter-25164a58aa.svg" alt="Twitter" class="m-icon"/></a></li></ul></div></footer><div style="visibility:hidden;height:0;overflow:hidden;position:relative"><img alt="doubleclick" width="1" height="1" style="position:absolute" src="https://pubads.g.doubleclick.net/activity;dc_iu=/21612525419/DFPAudiencePixel;ord=6458893656074.729;dc_seg=507368552?"/><img alt="fb" height="1" width="1" style="position:absolute" src="https://www.facebook.com/tr?id=1650870088530325&amp;ev=PageView&amp;noscript=1"/></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"Turn-Based Offline Reinforcement Learning","link":"https://blog.allegro.tech/2022/04/turn-based-offline-rl.html","pubDate":"Thu, 14 Apr 2022 00:00:00 +0200","authors":{"author":[{"name":["Riccardo Belluzzo"],"photo":["https://blog.allegro.tech/img/authors/riccardo.belluzzo.jpg"],"url":["https://blog.allegro.tech/authors/riccardo.belluzzo"]},{"name":["Tomasz Bocheński"],"photo":["https://blog.allegro.tech/img/authors/tomasz.bochenski.jpg"],"url":["https://blog.allegro.tech/authors/tomasz.bochenski"]},{"name":["Michał Zając"],"photo":["https://blog.allegro.tech/img/authors/michal.zajac.jpg"],"url":["https://blog.allegro.tech/authors/michal.zajac"]},{"name":["Łukasz Kuciński"],"photo":["https://blog.allegro.tech/img/authors/lukasz.kucinski.jpg"],"url":["https://blog.allegro.tech/authors/lukasz.kucinski"]},{"name":["Piotr Miłoś"],"photo":["https://blog.allegro.tech/img/authors/piotr.milos.jpg"],"url":["https://blog.allegro.tech/authors/piotr.milos"]}]},"content":"\u003cp\u003eThis blogpost is the result of a research collaboration between the Allegro Machine Learning Research team and\nthe Institute of Mathematics of the Polish Academy of Sciences (IMPAN), Warsaw.\u003c/p\u003e\n\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\n\u003cp\u003eImagine the following scenario: you work in a company as a Research Engineer, and your manager is asking you to design\na state-of-the-art algorithm to control a robot arm that should perform a critical task.\nYou perform some research to find out that Reinforcement Learning (RL) would work really well in this case.\nHowever, you have the following limitations:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eThe robot arm is built with poor hardware and can’t afford long and extensive usage.\u003c/li\u003e\n  \u003cli\u003eThe robot arm can often be physically unavailable, and you may have access to it only for a limited period of time.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eIn addition to the aforementioned constraints, you also have another big problem: you don’t have any huge dataset\ncontaining past offline behavior of the robotic arm available. What can you do? Should you give up on applying RL\nto this problem? Is the problem even solvable with RL?\u003c/p\u003e\n\n\u003cp\u003eDon’t worry! We are here to help you! And to do so, we will walk you through the concept of “Turn-based Offline RL”.\nSo let’s dive into it!\u003c/p\u003e\n\n\u003ch2 id=\"standing-between-online-rl-and-offline-rl\"\u003eStanding between “Online RL” and “Offline RL”\u003c/h2\u003e\n\n\u003cp\u003eIn Online RL, we normally have an agent that interacts with the environment, which is assumed to be always available.\nFor each interaction, the agent will get a reward signal that assesses the quality of the action performed.\nThe possibility of constant interaction with the environment marks the difference between the\nonline and offline RL setting: in the latter, we break the environment-agent interaction loop,\nand we only have a buffer of transitions previously gathered using one or multiple unknown policies.\nThus, in Offline RL, since there is no interaction with the environment, the buffer can be thought of as a\nstatic dataset that cannot be extended by any further exploration.\u003c/p\u003e\n\n\u003cp\u003eThe idea behind “Turn-based Offline RL” falls exactly halfway between these two lines of thinking.\nImagine yourself being able to build an initial static dataset filled with transitions generated by a\nrandom policy. Now that you have a static dataset, you can use it to train an agent using a preferred\nOffline RL algorithm. Then, suppose you have access to the target environment for a limited period of time.\nYou have a (random) agent already trained! You can deploy it, interact with the environment,\ngather new experiences based on the policy learned so far, and enrich your static dataset.\nNow, having an updated (and better) dataset, you can re-train your Offline RL agent and repeat this process every time\nyou are accessing the environment. Well, what we have described is exactly what we mean by “Turn-based Offline RL”.\nLet’s sum up the description in a few points:\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003eStart with a random policy and generate an initial static dataset.\u003c/li\u003e\n  \u003cli\u003eTrain an agent using a preferred Offline RL algorithm using the dataset built in 1). We can call this phase “turn 0”.\u003c/li\u003e\n  \u003cli\u003eAccess the environment the first time: collect transitions using the policy learned so far and extend the dataset\nwith new data.\u003c/li\u003e\n  \u003cli\u003eTrain your Offline RL agent again with a static dataset now composed of old (random) transitions and new (better)\ntransitions (“turn 1”).\u003c/li\u003e\n  \u003cli\u003eAccess the environment once again and collect new transitions.\u003c/li\u003e\n  \u003cli\u003eTrain again your Offline agent (“turn 2”).\u003c/li\u003e\n  \u003cli\u003eRepeat the above steps as many “turns” as you can, i.e. as many times as you have the possibility to access the\nenvironment.\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003eThe main idea behind the turn-based procedure is that after each “turn” we will extend our dataset with “better”\ntransitions, i.e transitions generated by more expert-like agents, and use Offline RL algorithms to train an even better\n(or at least similar) policy than the one used to generate those transitions.\nWith the “Turn-based Offline RL” framework you can now see how you could possibly overcome the constraints for\nyour hypothetical robot arm application: you could build a random dataset using some simulator; train an Offline RL\nagent with it; deploy the agent to interact with the robot arm for a limited period of time; extend the dataset\nwith better data; re-train the agent, and repeat the process.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-04-14-turn-based-offline-rl/diagram.png\" alt=\"Figure 1\" /\u003e\n\u003cem\u003eFig.1 — Schematic comparison between Online RL (a), Offline RL (b), and Turn-Based Offline RL (c). For this diagram\nwe took inspiration from the paper Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems\n(Levine et al. 2020)\u003c/em\u003e\u003c/p\u003e\n\n\u003ch2 id=\"turn-based-offline-rl-in-practice\"\u003eTurn-based Offline RL in practice\u003c/h2\u003e\n\n\u003cp\u003eIn this blog post, we want to show you how you could make use of the “Turn-based Offline RL” framework to leverage\nthe advances in Offline RL in applications where you could have the possibility of accessing the environment “in turns”.\nFortunately, we don’t need any fancy robotic arm to do so! We have prepared for you a more comprehensive use case\nin order to explain the general idea behind it.\u003c/p\u003e\n\n\u003ch3 id=\"experimental-setup\"\u003eExperimental setup\u003c/h3\u003e\n\n\u003cp\u003eTo showcase our idea, we are going to make use of a simplified environment.\nThis tutorial will be in fact inspired by the\n\u003ca href=\"https://colab.research.google.com/drive/1oJOYlAIOl9d1JjlutPY66KmfPkwPCgEE?usp=sharing#scrollTo=4i64GqsO83mA\"\u003eNeurIPS 2020 Offline RL Tutorial Colab Exercise\u003c/a\u003e\nwhere the authors designed a simple GridWorld environment to test different ideas related to Offline RL.\u003c/p\u003e\n\n\u003cp\u003eGridWorld is a standard environment used in the RL community to test if algorithms can work in relatively\neasy situations or simply to debug them. In GridWorld, the agent starts at a starting point (“S”) and aims to\nreach a target point, sometimes called the reward (“R”) cell. The agent can either step up, down, left, or right,\nor stay still. Only empty cells can be stepped in, while non-empty cells, like the ones containing obstacles\n(walls), are not. The authors of the notebook provide an easy way to build such an environment from a string.\u003c/p\u003e\n\n\u003cp\u003eFor the sake of this tutorial, we will work with a fixed 18x20 grid like the one specified by the string below.\nThe “O” letter indicates empty spaces, “#” stands for walls, “S” is the starting state and “R” the target one.\nFor clarity, we have drawn the grid for you.\u003c/p\u003e\n\n\u003cdiv class=\"language-python highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003egrid\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOOOOOOOOOOOOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOOOOOOOOOOOOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOOOSOOOOOOOOOO#\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOO##OOOOOOOOOO#\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOO#O#OOOOOOOOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOOOOOO#OO#OOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOOOOOOOOOOOOO#O\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOO#OOOOOOOOOOOOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'##OOOOOOOO#OOOOOOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOOOOOO#OOOOO#OO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOOOOOOOOOO####O\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOOOOOOOOOOOOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OO#OOO#OOOOOO#OOOROO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOO##OO#OOOOOOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOO#OOOOOOOOOOOO##O#\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOO#OOOOOOOOOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOOOOOOOOOOOOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'##OOOOO##OOOOOOOOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOOOOOOOOO#OOO#OOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n    \u003cspan class=\"s\"\u003e'OOOO##OOOO#O#OOOOOOO\u003c/span\u003e\u003cspan class=\"se\"\u003e\\\\\u003c/span\u003e\u003cspan class=\"s\"\u003e'\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-04-14-turn-based-offline-rl/gridworld_reduced.png\" alt=\"Figure 2\" /\u003e\n\u003cem\u003eFig.2 — The chosen grid for our experiments: the green cell (S) is the starting point; the\nyellow cell (R) is the target point; white cells are empty while red cells contain walls.\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003ePlease note that in our experiments we have tested different grid configurations and dimensions and we believe\nthat the chosen dimensionality and obstacle distribution presented for this tutorial do represent a\ngood experimental setup in order to arrive at reasonable conclusions. Indeed, the grid is small enough\nfor the algorithm to be able to quickly iterate through different runs, and its configuration\nis complicated enough to lead to non-trivial results.\nIn general, from our experience, things start to get interesting with grids NxM where N,M \u0026gt;= 12.\u003c/p\u003e\n\n\u003ch3 id=\"agents-visualizations\"\u003eAgent’s visualizations\u003c/h3\u003e\n\n\u003cp\u003eIn RL, it’s sometimes beneficial to visualize the policy your agents are learning. Since the environment\nwe are playing with is relatively small, we can actually enumerate all possible state-action (s,a) pairs.\nWhen a specific algorithm runs, we are able to count how many times each of these pairs was visited, and we are\nable to visualize it as a heatmap, superimposed on the grid.\u003c/p\u003e\n\n\u003cp\u003eIn our case, such heatmaps (that we call state-action visitation maps)\ncan be really useful to understand, for example, the quality of a specific policy:\na good state-action visitation map is created only by applying a good policy.\u003c/p\u003e\n\n\u003cp\u003eHow would a map built using the optimal policy look like?\nAgain, it’s a question we can answer only because we are in the ideal case of using a simple environment where we can\nknow and do everything, like finding the optimal policy.\nWe can use tabular Q-iteration to find an optimal solution for our case,\nhence producing the optimal state-action map that looks as follows:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-04-14-turn-based-offline-rl/optimal_policy_heatmap_reduced.png\" alt=\"Figure 3\" /\u003e\n\u003cem\u003eFig.3 — State-action visitation heatmap generated by the optimal policy. Most of the time the agent reaches the target\ncell in a few steps and then, it just stays idle without performing any further step.\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003eAs you can see, in this case, almost every (s,a) pair has a value approaching zero, apart from the reward (“R”) state\nwhich has a big value. This is happening because once the agent knows the optimal policy, it will take very few steps\nfor it to reach the target cell and once it’s reached, it will spend most of the time just waiting, without performing\nany further action. More precisely, the agent will spend the majority of the time in the (s,a) = (“R”, NOOP),\nwhere NOOP stands for “no operation”.\u003c/p\u003e\n\n\u003cp\u003eLet’s now visualize the heatmap generated by the uniform policy,\ni.e an agent that decides at random (with uniform probability) which action to take when being in a specific state.\nThis approach would be the way to go in the majority of the cases and is the closest to the real case example.\nSuppose you don’t know anything about the environment you are going to interact with: the best you can do is to\nperform random exploration!\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-04-14-turn-based-offline-rl/random_policy_heatmap_reduced.png\" alt=\"Figure 4\" /\u003e\n\u003cem\u003eFig.4 — State-action visitation heatmap generated by the random policy. The agent performs random exploration. As a\nresult of the random behaviour, cells in the surroundings of the initial state are visited on average more often than\nfurther cells.\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003eSince we start from the “S” cell at every episode, we have the highest probability of visiting the “S” state and all\nits surroundings. As we go further from it, the agent will start to pick different states depending on the run,\nand thus values on farther cells start to normalize and approach 0.0.\u003c/p\u003e\n\n\u003cp\u003eIn the following, we will describe the algorithm in detail, and we will make use of these visualizations to understand\nif the turn-based approach is beneficial for learning a good policy when starting from a random one.\u003c/p\u003e\n\n\u003ch3 id=\"algorithm\"\u003eAlgorithm\u003c/h3\u003e\n\n\u003cp\u003eNow let’s dive into the algorithm itself. Recalling the steps indicated in the previous section,\nwe can describe the turn-based learning algorithm with the following pythonic pseudocode:\u003c/p\u003e\n\n\u003cdiv class=\"language-python highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"nf\"\u003erun_turn_based_algorithm\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003einit_policy\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                             \u003cspan class=\"n\"\u003enum_turns\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                             \u003cspan class=\"n\"\u003enum_seeds\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                             \u003cspan class=\"n\"\u003edataset_size\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                             \u003cspan class=\"n\"\u003enum_iters\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eoffline_dataset\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[]\u003c/span\u003e\n    \u003cspan class=\"n\"\u003ecurrent_policy\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003einit_policy\u003c/span\u003e\n    \u003cspan class=\"n\"\u003enum_of_trajectories_per_turn\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edataset_size\u003c/span\u003e \u003cspan class=\"o\"\u003e/\u003c/span\u003e \u003cspan class=\"n\"\u003enum_turns\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003eturn\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"nb\"\u003erange\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003enum_turns\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eruns\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"p\"\u003e[]\u003c/span\u003e\n        \u003cspan class=\"k\"\u003efor\u003c/span\u003e \u003cspan class=\"n\"\u003eseed\u003c/span\u003e \u003cspan class=\"ow\"\u003ein\u003c/span\u003e \u003cspan class=\"nb\"\u003erange\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003enum_seeds\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\n            \u003cspan class=\"n\"\u003etemp_dataset\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eoffline_dataset\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ecopy\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n            \u003cspan class=\"n\"\u003etrajectories_from_new_policy\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edeploy_and_sample\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ecurrent_policy\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003enum_of_trajectories_per_turn\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n            \u003cspan class=\"n\"\u003etemp_dataset\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eextend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etrajectories_from_new_policy\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n            \u003cspan class=\"n\"\u003epolicy\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eperformances\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003erun_offline_rl_algorithm\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003etemp_dataset\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003enum_iters\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n            \u003cspan class=\"n\"\u003eruns\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eappend\u003c/span\u003e\u003cspan class=\"p\"\u003e((\u003c/span\u003e\u003cspan class=\"n\"\u003epolicy\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eperformances\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003etrajectories_from_new_policy\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n\n        \u003cspan class=\"n\"\u003ebest_policy\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ebest_trajectories\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003efind_best_run\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eruns\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"n\"\u003ecurrent_policy\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003ebest_policy\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eoffline_dataset\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eextend\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ebest_trajectories\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eLet’s explain each step involved in the algorithm.  First, let’s define what the main parameters expected by\nthe algorithm are:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003einit_policy\u003c/code\u003e — it’s the starting policy, most likely the random policy.\u003c/li\u003e\n  \u003cli\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003enum_turns\u003c/code\u003e — this is simply the total number of turns for which you will run the algorithm.\u003c/li\u003e\n  \u003cli\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003enum_seeds\u003c/code\u003e — if you work in RL you will be familiar with this argument: RL algorithms\n(and especially Offline RL ones) present large variability in the results due to their stochastic nature.\nThat’s why instead of having one single run of the Offline RL algorithm,\nwe will have several of them. For each run, we will produce the best policy and the best\n“new set of trajectories” to be used later in the algorithm (more on this step in the following).\u003c/li\u003e\n  \u003cli\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003enum_iters\u003c/code\u003e — this is simply the number of iterations we will run our Offline RL algorithm.\u003c/li\u003e\n  \u003cli\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003edataset_size\u003c/code\u003e — as a design choice, we assume that the final dataset size has been fixed beforehand,\nas we do with the number of turns. However, both of these two conditions could be relaxed and one could run\nthe algorithm as many turns as needed, getting a final offline dataset with an undefined size.\nHowever, please remember that in the real scenario you will probably not have the privilege of\naccessing the environment so often! You must do your best with a reasonable number of turns!\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eNow, following the logic of the pseudo-code, let’s describe the algorithm:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eInitially, we don’t have any transitions to train our Offline RL algorithm, so we initialize our \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eoffline_dataset\u003c/code\u003e\nas an empty list.\u003c/li\u003e\n  \u003cli\u003eWe also initialize \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ecurrent_policy\u003c/code\u003e with \u003ccode class=\"language-plaintext highlighter-rouge\"\u003einit_policy\u003c/code\u003e, which most likely will be the random policy\n(an agent that has previously interacted with the environment taking actions uniformly at random).\u003c/li\u003e\n  \u003cli\u003eNow, for each turn we run \u003ccode class=\"language-plaintext highlighter-rouge\"\u003enum_seeds\u003c/code\u003e times the following procedure:\n    \u003cul\u003e\n      \u003cli\u003eWe create a copy of \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eoffline_dataset\u003c/code\u003e (\u003ccode class=\"language-plaintext highlighter-rouge\"\u003etemp_dataset\u003c/code\u003e) to train the current agent with the dataset collected\nso far.\u003c/li\u003e\n      \u003cli\u003eWe deploy the agent to the environment, in order to generate a new set of transitions using the current policy\n(\u003ccode class=\"language-plaintext highlighter-rouge\"\u003etrajectories_from_new_policy\u003c/code\u003e).\u003c/li\u003e\n      \u003cli\u003eWe extend the temporary dataset by \u003ccode class=\"language-plaintext highlighter-rouge\"\u003etrajectories_from_new_policy\u003c/code\u003e and train an agent with it,\nusing the preferred Offline RL algorithm and getting its corresponding \u003ccode class=\"language-plaintext highlighter-rouge\"\u003epolicy\u003c/code\u003e and \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eperformances\u003c/code\u003e.\u003c/li\u003e\n      \u003cli\u003eWe append the results to \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eruns\u003c/code\u003e list.\u003c/li\u003e\n      \u003cli\u003eOnce we have collected all the results, we pick the best policy and best-generated trajectories\nout of the pool of runs (\u003ccode class=\"language-plaintext highlighter-rouge\"\u003efind_best_run\u003c/code\u003e).\u003c/li\u003e\n      \u003cli\u003eThe \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ebest_policy\u003c/code\u003e is now our \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ecurrent_policy\u003c/code\u003e that will be used for the next turn.\u003c/li\u003e\n      \u003cli\u003eThe \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ebest_trajectories\u003c/code\u003e will are appended to \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eoffline_dataset\u003c/code\u003e that will is going to be used for the next turn.\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eWe repeat this procedure until we are satisfied with the performance or as many times (turns)\nwe are able to access the environment.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eNow, hoping the algorithm is clear to you, we need to answer two important questions.\u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003eWhich Offline RL algorithm should be run?\u003c/em\u003e\nActually here the choice is yours! In our case, we opted for\nusing \u003ca href=\"https://arxiv.org/abs/2006.04779\"\u003eConservative Q-Learning (CQL)\u003c/a\u003e.\nAny algorithm may have its pros and cons. In our case we find it hard to set the CQL global parameters only once\nto be good for all the runs. What is happening is that initially our dataset will be full of random transitions,\nbut as long as you proceed in turns, it will become richer in “more-expert” transitions.\nThus, parameters like alpha for the CQL loss should be somehow adjusted in time.\nWhile in this tutorial we did not investigate this aspect, we found that for this very simplistic environment\neven CQL with alpha = 0 (equivalent to offline Q iteration) would work sufficiently.\u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003eHow to aggregate results in order to get a representative policy and dataset for the next turn?\u003c/em\u003e\nThat’s a hard question. For the sake of this tutorial, we have opted for the simplest of the approaches:\nout of the N runs, we will pick the one that gave us the best results (in terms of average reward).\nHowever, please note that this may be too optimistic and could lead to unexpected behavior in production.\nA better approach would actually be the one that takes into account the “average policy”. But, to “average out”\npolicies is not a trivial task. We discuss this aspect in detail in the final section.\u003c/p\u003e\n\n\u003ch2 id=\"results\"\u003eResults\u003c/h2\u003e\n\n\u003ch3 id=\"visualizing-the-agent-in-turns\"\u003eVisualizing the agent “in turns”\u003c/h3\u003e\n\n\u003cp\u003eFirst, we ask ourselves the following question: does the agent learn “in turns”? We can check this\nby visualizing subsequent state-action visitation maps:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-04-14-turn-based-offline-rl/agent_learns_in_turns_reduced.png\" alt=\"Figure 5\" /\u003e\n\u003cem\u003eFig.5 — Visualization of subsequent state-action visitation heatmaps. Here we visualize 4 subsequent turns — after one\nsingle turn the agent learns the fastest path to reach the target cell. As long as we proceed in turns, the agent\nimproves its performance, eventually approaching a behaviour comparable to the optimal policy.\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003eOur algorithm seems to work! When starting with a uniform policy, we can see that even after a\nsingle turn the agent quickly learns the fastest path to reach the target cell. As long as we proceed in turns, the model will\nconsistently improve its performance, by quickly getting to the “R” cell even more often. In this sense, visitation\nmaps get closer to the optimal one where the agent basically reaches the target in a few steps and then just stays\nthere, without performing any further steps.\u003c/p\u003e\n\n\u003ch3 id=\"does-the-agent-improve-its-performance-over-time\"\u003eDoes the agent improve its performance over time?\u003c/h3\u003e\n\n\u003cp\u003eHow many turns are needed to start having results comparable to\nthe optimal policy? In other words, how much better are we performing if compared to not doing any turn at all?\u003c/p\u003e\n\n\u003cp\u003eLet’s analyze the plot below. In this figure we are plotting the algorithm’s performance, measured in\n“averaged reward” (the higher, the better), as the amount of data available offline increases. In general, we expect\nthe curve obtained by running the optimal policy (violet curve) to represent an upper bound: it’s the best we\ncan achieve! On the other hand, we expect the curve obtained by running the random policy without any “turn”\n(green curve), to be our lower bound. Also, generally speaking, we expect that the more offline data is available,\nthe better the achieved scores will be, since our chosen Offline RL will have more data coverage and possibility\nto converge to the optimal policy. Given this, we can observe that the performance of the turn-based procedure falls\nin the middle between the aforementioned upper and lower bounds: as the number of turns increases, the closer we get\nto the upper bound. However, we can observe that 3 turns are already enough to start having better performance than\nthe lower bound. This plot confirms our hypothesis: “Turn-based Offline RL” stands exactly between Online RL\n(upper bound) and Offline RL (lower bound).\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-04-14-turn-based-offline-rl/learning_curves_reduced.png\" alt=\"Figure 6\" /\u003e\n\u003cem\u003eFig.6 — This plot shows the comparison between baselines and the turn-based procedure in terms of average reward (the higher,\nthe better) as the size of the collected data used to train the algorithm offline grows. To obtain this figure,\nwe have run each of the algorithms for 30 seeds. For the optimal policy we run Q-iteration, while for the rest we\napplied CQL with fixed alpha=0. For each run, CQL was fitted for 300 iterations.\u003c/em\u003e\u003c/p\u003e\n\n\u003ch2 id=\"conclusions-and-future-work\"\u003eConclusions and Future Work\u003c/h2\u003e\n\n\u003cp\u003eIn this blog post we have presented a practical approach you could use to address cases where you have temporary\nand limited access to an environment, and you have computational resources at your disposal to train your RL algorithm\n“offline” only.\u003c/p\u003e\n\n\u003cp\u003eIn fact, the proposed solution falls halfway between Online RL and Offline RL: our agent is warmed up\nby training it via Offline RL on a dataset generated by running the uniform random policy and then\nsubsequently improved by accessing the environment in “turns”, thus partially simulating what you would get on a\nstandard online RL scenario.\u003c/p\u003e\n\n\u003cp\u003eIn particular, we show that:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eThe turn-based procedure is effective since the policy learned in subsequent turns consistently improves as\nturns increase, matching the expectations. This result is demonstrated through some visualizations, showing how\nthe agent chooses a better and faster path to target turn after turn.\u003c/li\u003e\n  \u003cli\u003eThe turn-based procedure allows getting an agent that is better than a random one, even after a small number of turns.\nThe performance of the turn-based agent will be upper-bounded by the performance of the optimal policy.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eMoreover, we provide an easy-to-understand framework to prove the aforementioned hypothesis.\u003c/p\u003e\n\n\u003cp\u003eFinally, we want to point out some limitations of our work that could be addressed as future work:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eFrom one turn to the other, we pick the “best policy” as the one that achieves the best performance between all\nthe runs via the “max” operator. This single policy is then propagated through the algorithm and used to generate\nthe best new extension of the dataset. The inherent limitation of this approach is that by using the “max” we are\nnot robust to the noise and we do not account for fluctuations in the performance of the Offline RL algorithm.\nA better approach would be aggregating policies by doing, for example, an ensemble of policies, and using this\nas the selected policy that is propagated forward in the algorithm.\u003c/li\u003e\n  \u003cli\u003eRunning a fixed Offline RL algorithm on a dataset that keeps changing its distribution of states and actions\nin time could be really challenging since a lot of algorithms in the literature require accurate hypertuning\nof the parameters. In future work, we would like to address this problem, proposing, for example, a way one\ncould compute new hyper-parameters using the dataset size and some other properties as parameters for the computation.\u003c/li\u003e\n  \u003cli\u003eOne could argue that our hypothesis can work only on simplistic environments like GridWorlds.\nEven though we tested different configurations of grids, stressing more or less the algorithms,\nwe admit that a more complete work would require the re-visitation of our hypothesis on a more diverse\nsuite of environments. We plan to investigate this in the future.\u003c/li\u003e\n\u003c/ul\u003e\n\n","contentSnippet":"This blogpost is the result of a research collaboration between the Allegro Machine Learning Research team and\nthe Institute of Mathematics of the Polish Academy of Sciences (IMPAN), Warsaw.\nIntroduction\nImagine the following scenario: you work in a company as a Research Engineer, and your manager is asking you to design\na state-of-the-art algorithm to control a robot arm that should perform a critical task.\nYou perform some research to find out that Reinforcement Learning (RL) would work really well in this case.\nHowever, you have the following limitations:\nThe robot arm is built with poor hardware and can’t afford long and extensive usage.\nThe robot arm can often be physically unavailable, and you may have access to it only for a limited period of time.\nIn addition to the aforementioned constraints, you also have another big problem: you don’t have any huge dataset\ncontaining past offline behavior of the robotic arm available. What can you do? Should you give up on applying RL\nto this problem? Is the problem even solvable with RL?\nDon’t worry! We are here to help you! And to do so, we will walk you through the concept of “Turn-based Offline RL”.\nSo let’s dive into it!\nStanding between “Online RL” and “Offline RL”\nIn Online RL, we normally have an agent that interacts with the environment, which is assumed to be always available.\nFor each interaction, the agent will get a reward signal that assesses the quality of the action performed.\nThe possibility of constant interaction with the environment marks the difference between the\nonline and offline RL setting: in the latter, we break the environment-agent interaction loop,\nand we only have a buffer of transitions previously gathered using one or multiple unknown policies.\nThus, in Offline RL, since there is no interaction with the environment, the buffer can be thought of as a\nstatic dataset that cannot be extended by any further exploration.\nThe idea behind “Turn-based Offline RL” falls exactly halfway between these two lines of thinking.\nImagine yourself being able to build an initial static dataset filled with transitions generated by a\nrandom policy. Now that you have a static dataset, you can use it to train an agent using a preferred\nOffline RL algorithm. Then, suppose you have access to the target environment for a limited period of time.\nYou have a (random) agent already trained! You can deploy it, interact with the environment,\ngather new experiences based on the policy learned so far, and enrich your static dataset.\nNow, having an updated (and better) dataset, you can re-train your Offline RL agent and repeat this process every time\nyou are accessing the environment. Well, what we have described is exactly what we mean by “Turn-based Offline RL”.\nLet’s sum up the description in a few points:\nStart with a random policy and generate an initial static dataset.\nTrain an agent using a preferred Offline RL algorithm using the dataset built in 1). We can call this phase “turn 0”.\nAccess the environment the first time: collect transitions using the policy learned so far and extend the dataset\nwith new data.\nTrain your Offline RL agent again with a static dataset now composed of old (random) transitions and new (better)\ntransitions (“turn 1”).\nAccess the environment once again and collect new transitions.\nTrain again your Offline agent (“turn 2”).\nRepeat the above steps as many “turns” as you can, i.e. as many times as you have the possibility to access the\nenvironment.\nThe main idea behind the turn-based procedure is that after each “turn” we will extend our dataset with “better”\ntransitions, i.e transitions generated by more expert-like agents, and use Offline RL algorithms to train an even better\n(or at least similar) policy than the one used to generate those transitions.\nWith the “Turn-based Offline RL” framework you can now see how you could possibly overcome the constraints for\nyour hypothetical robot arm application: you could build a random dataset using some simulator; train an Offline RL\nagent with it; deploy the agent to interact with the robot arm for a limited period of time; extend the dataset\nwith better data; re-train the agent, and repeat the process.\n\nFig.1 — Schematic comparison between Online RL (a), Offline RL (b), and Turn-Based Offline RL (c). For this diagram\nwe took inspiration from the paper Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems\n(Levine et al. 2020)\nTurn-based Offline RL in practice\nIn this blog post, we want to show you how you could make use of the “Turn-based Offline RL” framework to leverage\nthe advances in Offline RL in applications where you could have the possibility of accessing the environment “in turns”.\nFortunately, we don’t need any fancy robotic arm to do so! We have prepared for you a more comprehensive use case\nin order to explain the general idea behind it.\nExperimental setup\nTo showcase our idea, we are going to make use of a simplified environment.\nThis tutorial will be in fact inspired by the\nNeurIPS 2020 Offline RL Tutorial Colab Exercise\nwhere the authors designed a simple GridWorld environment to test different ideas related to Offline RL.\nGridWorld is a standard environment used in the RL community to test if algorithms can work in relatively\neasy situations or simply to debug them. In GridWorld, the agent starts at a starting point (“S”) and aims to\nreach a target point, sometimes called the reward (“R”) cell. The agent can either step up, down, left, or right,\nor stay still. Only empty cells can be stepped in, while non-empty cells, like the ones containing obstacles\n(walls), are not. The authors of the notebook provide an easy way to build such an environment from a string.\nFor the sake of this tutorial, we will work with a fixed 18x20 grid like the one specified by the string below.\nThe “O” letter indicates empty spaces, “#” stands for walls, “S” is the starting state and “R” the target one.\nFor clarity, we have drawn the grid for you.\n\ngrid = (\n    'OOOOOOOOOOOOOOOOOOOO\\\\'\n    'OOOOOOOOOOOOOOOOOOOO\\\\'\n    'OOOOOOOOSOOOOOOOOOO#\\\\'\n    'OOOOOOO##OOOOOOOOOO#\\\\'\n    'OOOOOO#O#OOOOOOOOOOO\\\\'\n    'OOOOOOOOOOO#OO#OOOOO\\\\'\n    'OOOOOOOOOOOOOOOOOO#O\\\\'\n    'OOOO#OOOOOOOOOOOOOOO\\\\'\n    '##OOOOOOOO#OOOOOOOOO\\\\'\n    'OOOOOOOOOOO#OOOOO#OO\\\\'\n    'OOOOOOOOOOOOOOO####O\\\\'\n    'OOOOOOOOOOOOOOOOOOOO\\\\'\n    'OO#OOO#OOOOOO#OOOROO\\\\'\n    'OOOOOO##OO#OOOOOOOOO\\\\'\n    'OOO#OOOOOOOOOOOO##O#\\\\'\n    'OOOOOOO#OOOOOOOOOOOO\\\\'\n    'OOOOOOOOOOOOOOOOOOOO\\\\'\n    '##OOOOO##OOOOOOOOOOO\\\\'\n    'OOOOOOOOOOO#OOO#OOOO\\\\'\n    'OOOO##OOOO#O#OOOOOOO\\\\'\n)\n\n\n\nFig.2 — The chosen grid for our experiments: the green cell (S) is the starting point; the\nyellow cell (R) is the target point; white cells are empty while red cells contain walls.\nPlease note that in our experiments we have tested different grid configurations and dimensions and we believe\nthat the chosen dimensionality and obstacle distribution presented for this tutorial do represent a\ngood experimental setup in order to arrive at reasonable conclusions. Indeed, the grid is small enough\nfor the algorithm to be able to quickly iterate through different runs, and its configuration\nis complicated enough to lead to non-trivial results.\nIn general, from our experience, things start to get interesting with grids NxM where N,M \u003e= 12.\nAgent’s visualizations\nIn RL, it’s sometimes beneficial to visualize the policy your agents are learning. Since the environment\nwe are playing with is relatively small, we can actually enumerate all possible state-action (s,a) pairs.\nWhen a specific algorithm runs, we are able to count how many times each of these pairs was visited, and we are\nable to visualize it as a heatmap, superimposed on the grid.\nIn our case, such heatmaps (that we call state-action visitation maps)\ncan be really useful to understand, for example, the quality of a specific policy:\na good state-action visitation map is created only by applying a good policy.\nHow would a map built using the optimal policy look like?\nAgain, it’s a question we can answer only because we are in the ideal case of using a simple environment where we can\nknow and do everything, like finding the optimal policy.\nWe can use tabular Q-iteration to find an optimal solution for our case,\nhence producing the optimal state-action map that looks as follows:\n\nFig.3 — State-action visitation heatmap generated by the optimal policy. Most of the time the agent reaches the target\ncell in a few steps and then, it just stays idle without performing any further step.\nAs you can see, in this case, almost every (s,a) pair has a value approaching zero, apart from the reward (“R”) state\nwhich has a big value. This is happening because once the agent knows the optimal policy, it will take very few steps\nfor it to reach the target cell and once it’s reached, it will spend most of the time just waiting, without performing\nany further action. More precisely, the agent will spend the majority of the time in the (s,a) = (“R”, NOOP),\nwhere NOOP stands for “no operation”.\nLet’s now visualize the heatmap generated by the uniform policy,\ni.e an agent that decides at random (with uniform probability) which action to take when being in a specific state.\nThis approach would be the way to go in the majority of the cases and is the closest to the real case example.\nSuppose you don’t know anything about the environment you are going to interact with: the best you can do is to\nperform random exploration!\n\nFig.4 — State-action visitation heatmap generated by the random policy. The agent performs random exploration. As a\nresult of the random behaviour, cells in the surroundings of the initial state are visited on average more often than\nfurther cells.\nSince we start from the “S” cell at every episode, we have the highest probability of visiting the “S” state and all\nits surroundings. As we go further from it, the agent will start to pick different states depending on the run,\nand thus values on farther cells start to normalize and approach 0.0.\nIn the following, we will describe the algorithm in detail, and we will make use of these visualizations to understand\nif the turn-based approach is beneficial for learning a good policy when starting from a random one.\nAlgorithm\nNow let’s dive into the algorithm itself. Recalling the steps indicated in the previous section,\nwe can describe the turn-based learning algorithm with the following pythonic pseudocode:\n\ndef run_turn_based_algorithm(init_policy,\n                             num_turns,\n                             num_seeds,\n                             dataset_size,\n                             num_iters):\n    offline_dataset = []\n    current_policy = init_policy\n    num_of_trajectories_per_turn = dataset_size / num_turns\n\n    for turn in range(num_turns):\n        runs = []\n        for seed in range(num_seeds):\n            temp_dataset = offline_dataset.copy()\n            trajectories_from_new_policy = deploy_and_sample(current_policy, num_of_trajectories_per_turn)\n            temp_dataset.extend(trajectories_from_new_policy)\n            policy, performances = run_offline_rl_algorithm(temp_dataset, num_iters)\n            runs.append((policy, performances, trajectories_from_new_policy))\n\n        best_policy, best_trajectories = find_best_run(runs)\n        current_policy = best_policy\n        offline_dataset.extend(best_trajectories)\n\n\nLet’s explain each step involved in the algorithm.  First, let’s define what the main parameters expected by\nthe algorithm are:\ninit_policy — it’s the starting policy, most likely the random policy.\nnum_turns — this is simply the total number of turns for which you will run the algorithm.\nnum_seeds — if you work in RL you will be familiar with this argument: RL algorithms\n(and especially Offline RL ones) present large variability in the results due to their stochastic nature.\nThat’s why instead of having one single run of the Offline RL algorithm,\nwe will have several of them. For each run, we will produce the best policy and the best\n“new set of trajectories” to be used later in the algorithm (more on this step in the following).\nnum_iters — this is simply the number of iterations we will run our Offline RL algorithm.\ndataset_size — as a design choice, we assume that the final dataset size has been fixed beforehand,\nas we do with the number of turns. However, both of these two conditions could be relaxed and one could run\nthe algorithm as many turns as needed, getting a final offline dataset with an undefined size.\nHowever, please remember that in the real scenario you will probably not have the privilege of\naccessing the environment so often! You must do your best with a reasonable number of turns!\nNow, following the logic of the pseudo-code, let’s describe the algorithm:\nInitially, we don’t have any transitions to train our Offline RL algorithm, so we initialize our offline_dataset\nas an empty list.\nWe also initialize current_policy with init_policy, which most likely will be the random policy\n(an agent that has previously interacted with the environment taking actions uniformly at random).\nNow, for each turn we run num_seeds times the following procedure:\n    \nWe create a copy of offline_dataset (temp_dataset) to train the current agent with the dataset collected\nso far.\nWe deploy the agent to the environment, in order to generate a new set of transitions using the current policy\n(trajectories_from_new_policy).\nWe extend the temporary dataset by trajectories_from_new_policy and train an agent with it,\nusing the preferred Offline RL algorithm and getting its corresponding policy and performances.\nWe append the results to runs list.\nOnce we have collected all the results, we pick the best policy and best-generated trajectories\nout of the pool of runs (find_best_run).\nThe best_policy is now our current_policy that will be used for the next turn.\nThe best_trajectories will are appended to offline_dataset that will is going to be used for the next turn.\nWe repeat this procedure until we are satisfied with the performance or as many times (turns)\nwe are able to access the environment.\nNow, hoping the algorithm is clear to you, we need to answer two important questions.\nWhich Offline RL algorithm should be run?\nActually here the choice is yours! In our case, we opted for\nusing Conservative Q-Learning (CQL).\nAny algorithm may have its pros and cons. In our case we find it hard to set the CQL global parameters only once\nto be good for all the runs. What is happening is that initially our dataset will be full of random transitions,\nbut as long as you proceed in turns, it will become richer in “more-expert” transitions.\nThus, parameters like alpha for the CQL loss should be somehow adjusted in time.\nWhile in this tutorial we did not investigate this aspect, we found that for this very simplistic environment\neven CQL with alpha = 0 (equivalent to offline Q iteration) would work sufficiently.\nHow to aggregate results in order to get a representative policy and dataset for the next turn?\nThat’s a hard question. For the sake of this tutorial, we have opted for the simplest of the approaches:\nout of the N runs, we will pick the one that gave us the best results (in terms of average reward).\nHowever, please note that this may be too optimistic and could lead to unexpected behavior in production.\nA better approach would actually be the one that takes into account the “average policy”. But, to “average out”\npolicies is not a trivial task. We discuss this aspect in detail in the final section.\nResults\nVisualizing the agent “in turns”\nFirst, we ask ourselves the following question: does the agent learn “in turns”? We can check this\nby visualizing subsequent state-action visitation maps:\n\nFig.5 — Visualization of subsequent state-action visitation heatmaps. Here we visualize 4 subsequent turns — after one\nsingle turn the agent learns the fastest path to reach the target cell. As long as we proceed in turns, the agent\nimproves its performance, eventually approaching a behaviour comparable to the optimal policy.\nOur algorithm seems to work! When starting with a uniform policy, we can see that even after a\nsingle turn the agent quickly learns the fastest path to reach the target cell. As long as we proceed in turns, the model will\nconsistently improve its performance, by quickly getting to the “R” cell even more often. In this sense, visitation\nmaps get closer to the optimal one where the agent basically reaches the target in a few steps and then just stays\nthere, without performing any further steps.\nDoes the agent improve its performance over time?\nHow many turns are needed to start having results comparable to\nthe optimal policy? In other words, how much better are we performing if compared to not doing any turn at all?\nLet’s analyze the plot below. In this figure we are plotting the algorithm’s performance, measured in\n“averaged reward” (the higher, the better), as the amount of data available offline increases. In general, we expect\nthe curve obtained by running the optimal policy (violet curve) to represent an upper bound: it’s the best we\ncan achieve! On the other hand, we expect the curve obtained by running the random policy without any “turn”\n(green curve), to be our lower bound. Also, generally speaking, we expect that the more offline data is available,\nthe better the achieved scores will be, since our chosen Offline RL will have more data coverage and possibility\nto converge to the optimal policy. Given this, we can observe that the performance of the turn-based procedure falls\nin the middle between the aforementioned upper and lower bounds: as the number of turns increases, the closer we get\nto the upper bound. However, we can observe that 3 turns are already enough to start having better performance than\nthe lower bound. This plot confirms our hypothesis: “Turn-based Offline RL” stands exactly between Online RL\n(upper bound) and Offline RL (lower bound).\n\nFig.6 — This plot shows the comparison between baselines and the turn-based procedure in terms of average reward (the higher,\nthe better) as the size of the collected data used to train the algorithm offline grows. To obtain this figure,\nwe have run each of the algorithms for 30 seeds. For the optimal policy we run Q-iteration, while for the rest we\napplied CQL with fixed alpha=0. For each run, CQL was fitted for 300 iterations.\nConclusions and Future Work\nIn this blog post we have presented a practical approach you could use to address cases where you have temporary\nand limited access to an environment, and you have computational resources at your disposal to train your RL algorithm\n“offline” only.\nIn fact, the proposed solution falls halfway between Online RL and Offline RL: our agent is warmed up\nby training it via Offline RL on a dataset generated by running the uniform random policy and then\nsubsequently improved by accessing the environment in “turns”, thus partially simulating what you would get on a\nstandard online RL scenario.\nIn particular, we show that:\nThe turn-based procedure is effective since the policy learned in subsequent turns consistently improves as\nturns increase, matching the expectations. This result is demonstrated through some visualizations, showing how\nthe agent chooses a better and faster path to target turn after turn.\nThe turn-based procedure allows getting an agent that is better than a random one, even after a small number of turns.\nThe performance of the turn-based agent will be upper-bounded by the performance of the optimal policy.\nMoreover, we provide an easy-to-understand framework to prove the aforementioned hypothesis.\nFinally, we want to point out some limitations of our work that could be addressed as future work:\nFrom one turn to the other, we pick the “best policy” as the one that achieves the best performance between all\nthe runs via the “max” operator. This single policy is then propagated through the algorithm and used to generate\nthe best new extension of the dataset. The inherent limitation of this approach is that by using the “max” we are\nnot robust to the noise and we do not account for fluctuations in the performance of the Offline RL algorithm.\nA better approach would be aggregating policies by doing, for example, an ensemble of policies, and using this\nas the selected policy that is propagated forward in the algorithm.\nRunning a fixed Offline RL algorithm on a dataset that keeps changing its distribution of states and actions\nin time could be really challenging since a lot of algorithms in the literature require accurate hypertuning\nof the parameters. In future work, we would like to address this problem, proposing, for example, a way one\ncould compute new hyper-parameters using the dataset size and some other properties as parameters for the computation.\nOne could argue that our hypothesis can work only on simplistic environments like GridWorlds.\nEven though we tested different configurations of grids, stressing more or less the algorithms,\nwe admit that a more complete work would require the re-visitation of our hypothesis on a more diverse\nsuite of environments. We plan to investigate this in the future.","guid":"https://blog.allegro.tech/2022/04/turn-based-offline-rl.html","categories":["tech","mlr","rl","research"],"isoDate":"2022-04-13T22:00:00.000Z","thumbnail":"images/post-headers/default.jpg"},{"title":"An Agile team in its natural habitat","link":"https://blog.allegro.tech/2022/04/agile-team-natural-habitat.html","pubDate":"Fri, 01 Apr 2022 00:00:00 +0200","authors":{"author":[{"name":["Michał Kosmulski"],"photo":["https://blog.allegro.tech/img/authors/michal.kosmulski.jpg"],"url":["https://blog.allegro.tech/authors/michal.kosmulski"]}]},"content":"\u003cblockquote\u003e\n  \u003cp\u003eThis post was published on April 1st, 2022, and should be taken with a grain of salt.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eIn this picture, we can see an Agile team in its natural habitat at Allegro:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-04-01-agile-team-natural-habitat/allegro-agile-team-natural-habitat.jpg\" alt=\"An Agile team in its natural habitat at Allegro\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eLearning and development are very important to us at \u003ca href=\"https://allegro.tech/\"\u003eAllegro\u003c/a\u003e. This absolutely not staged photo\nshows Piotr (right) reading out loud from a book about a newfangled language called BASIC. Piotr is a Product Owner,\nand he knows the development team needs to keep learning all the time in order to stay current with technology. He\nhimself has amassed a personal collection of 8-bit machines in order to hone his technical skills, and now he’s sharing\nwhat he has learned with others.\u003c/p\u003e\n\n\u003cp\u003eListening with great attention are two software engineers, Artur (left) and Kacper (center). Until recently, Artur was\nthe most junior member of the team. Nonetheless, when new people were joining us, he was their \u003cem\u003ebuddy\u003c/em\u003e, the go-to\ncontact for any questions, whose role is to put them on track as efficiently as possible. He did so well, and liked\nthis role so much, that at one point we literally had to stop him in order to give others a chance to try their hand\nat being buddies, too. But nothing is lost, since the whole team, not just the buddy, helps onboard new people. Artur\nis already thinking deeply about teaching BASIC to our future teammates.\u003c/p\u003e\n\n\u003cp\u003eKacper, in contrast, is one of the senior team members. He was already there when we started introducing Kotlin in our\nprojects a few years ago. Learning a new language is great fun, and you can already see Kacper smile at the thought\nof replacing all those complex functional constructs with a few simple GOTO statements. Keen observers will also notice\non the desk Kacper’s stopwatch he uses for timing performance-critical pieces of code. Many of our systems have\ndemanding performance requirements, and it’s thanks to experienced people like him that we are able to meet them.\u003c/p\u003e\n\n\u003cp\u003eObviously, this is not even the whole team, so you can easily imagine that anything is possible with such people\nand attitude. Happy April!\u003c/p\u003e\n","contentSnippet":"This post was published on April 1st, 2022, and should be taken with a grain of salt.\nIn this picture, we can see an Agile team in its natural habitat at Allegro:\n\nLearning and development are very important to us at Allegro. This absolutely not staged photo\nshows Piotr (right) reading out loud from a book about a newfangled language called BASIC. Piotr is a Product Owner,\nand he knows the development team needs to keep learning all the time in order to stay current with technology. He\nhimself has amassed a personal collection of 8-bit machines in order to hone his technical skills, and now he’s sharing\nwhat he has learned with others.\nListening with great attention are two software engineers, Artur (left) and Kacper (center). Until recently, Artur was\nthe most junior member of the team. Nonetheless, when new people were joining us, he was their buddy, the go-to\ncontact for any questions, whose role is to put them on track as efficiently as possible. He did so well, and liked\nthis role so much, that at one point we literally had to stop him in order to give others a chance to try their hand\nat being buddies, too. But nothing is lost, since the whole team, not just the buddy, helps onboard new people. Artur\nis already thinking deeply about teaching BASIC to our future teammates.\nKacper, in contrast, is one of the senior team members. He was already there when we started introducing Kotlin in our\nprojects a few years ago. Learning a new language is great fun, and you can already see Kacper smile at the thought\nof replacing all those complex functional constructs with a few simple GOTO statements. Keen observers will also notice\non the desk Kacper’s stopwatch he uses for timing performance-critical pieces of code. Many of our systems have\ndemanding performance requirements, and it’s thanks to experienced people like him that we are able to meet them.\nObviously, this is not even the whole team, so you can easily imagine that anything is possible with such people\nand attitude. Happy April!","guid":"https://blog.allegro.tech/2022/04/agile-team-natural-habitat.html","categories":["tech","agile","testing","April 1st"],"isoDate":"2022-03-31T22:00:00.000Z","thumbnail":"images/post-headers/testing.png"},{"title":"Visual thinking","link":"https://blog.allegro.tech/2022/03/visual-thinking.html","pubDate":"Wed, 30 Mar 2022 00:00:00 +0200","authors":{"author":[{"name":["Michał Kowalcze"],"photo":["https://blog.allegro.tech/img/authors/michal.kowalcze.jpg"],"url":["https://blog.allegro.tech/authors/michal.kowalcze"]}]},"content":"\u003cp\u003eWe use written (source code) language to express our intentions in a machine-readable form. We use spoken language to\ncommunicate with other people. We pride ourselves as ones choosing a programming language optimized to the task at hand.\nDo we use the optimal way to express our ideas?\u003c/p\u003e\n\n\u003ch2 id=\"the-story\"\u003eThe Story\u003c/h2\u003e\n\n\u003ch3 id=\"spoken-planning\"\u003eSpoken planning\u003c/h3\u003e\n\n\u003cp\u003e— Josh, could you summarize what we are going to implement, please?\u003c/p\u003e\n\n\u003cp\u003eThat was a bit unexpected. He was just trying to match what he already knew from onboarding days with what was just\nsaid. It was really difficult to follow team discussion at the same time. It was a standard planning session, held over\nZoom, with his distributed team. Someone was already sharing their screen and the story summary, along with acceptance\ncriteria, was visible. They were developing an online store and the current topic was: basket price reduction for active\nusers. In short: users who spent more than 50€ for the last 7 days should have a discount applied during the checkout\nprocess.\u003c/p\u003e\n\n\u003cp\u003e— Well, we are going to add a new service which is going to hold this discount logic. We will provide an API for the\ncart service to call us and we will check the transactions store for recent orders.\u003cbr /\u003e\n— Is that all?\u003cbr /\u003e\n— I didn’t catch more changes.\u003cbr /\u003e\n— What about customers willing to check if they are eligible for a discount?\u003cbr /\u003e\n— Oh, so it seems we need to change the “My Account” page as well.\u003cbr /\u003e\n— And the checkout service? We have to both display discount and use it.\u003cbr /\u003e\n— You’re right! I was trying to picture the main change in my mind and wasn’t paying attention to the whole\ndiscussion.\u003cbr /\u003e\n— Guys, checkout stays the same. The cart is providing everything the checkout requires.\u003c/p\u003e\n\n\u003ch3 id=\"retrospective\"\u003eRetrospective\u003c/h3\u003e\n\n\u003cp\u003eLet’s stop here for a moment. Have you ever been in a situation, when you were forced to do two things at the same time?\nFor example, listening to what is being said and trying to actively participate in the discussion regarding a not exactly\nwell-known topic? Was it a demanding experience? I had such an opportunity and I remember these sessions as quite\ndemanding. Usually, after an hourly session, I was exhausted and in need of a break. Not to mention that it required a\nsignificant amount of writing to capture everything that was said — just to have an option of referring back to this\nduring the sprint. What if this session looked differently?\u003c/p\u003e\n\n\u003ch3 id=\"visual-planning\"\u003eVisual planning\u003c/h3\u003e\n\n\u003cp\u003e— Josh, could you summarize what we are going to implement, please?\u003c/p\u003e\n\n\u003cp\u003eThat was a bit unexpected, however, it was a no-brainer.\n\u003cimg src=\"/img/articles/2022-03-30-visual-thinking/planning_services.png\" alt=\"planning services\" /\u003e\n“As we can see in the picture we are going to add a new service, discounts. This service will be called by the current\ncart service to display a reduced price (if applicable). Also, the “My Account” page is going to call us to retrieve the\ncurrent rebate for the logged user”.\u003c/p\u003e\n\n\u003ch3 id=\"the-difference\"\u003eThe difference\u003c/h3\u003e\n\n\u003cp\u003eWhat is the main difference between the first scenario and the second one? To me, it is about a common model. In the first\ncase, I am building an individual model of a change. I need a significant amount of energy to translate speech to my model\nand to explain my model to others. What is more — everyone involved in the discussion is building a mental model on\ntheir own with a similar amount of energy spent on synchronization.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-03-30-visual-thinking/private_models.png\" alt=\"private models\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eIn the case of the second scenario, the model is shared. There is no need to maintain private models. It is easy to\nunderstand changed elements and to refer to discussed changes later. “A picture is worth a thousand words” after all.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-03-30-visual-thinking/common_model.png\" alt=\"common model\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eOutput from a visual planning is something that can be used further during a sprint. Depending on the tool it is\npossible to use it instead of an issue-tracking tool. Sticky notes can indicate actions, tasks, TODOs. They can be\narranged in a tree and display the scope of a pull request. They can be connected by a dotted line to indicate dependencies.\nAnd in the worst case, when you do not have any idea how to visualize something, you can always use a block of text and\ndescribe it using words.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-03-30-visual-thinking/planning_tasks.png\" alt=\"planning tasks\" /\u003e\u003c/p\u003e\n\n\u003ch2 id=\"the-background\"\u003eThe background\u003c/h2\u003e\n\n\u003cp\u003eWhy switching to a drawing board has such an effect? To answer this question we have to check some facts.\u003c/p\u003e\n\n\u003cp\u003eOn a daily basis, a spoken (or written) language is our standard way of communication. Children, however, need some time\nto develop such a skill. Earlier they are able to:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eregister movement (at 2 months of age)\u003c/li\u003e\n  \u003cli\u003etry to grab things by hand (5 months)\u003c/li\u003e\n  \u003cli\u003efollow movement with their eyes, find hidden things (7 months)\u003c/li\u003e\n  \u003cli\u003eexploit cause-effect — drop a toy and watch it fall (8 months)\u003c/li\u003e\n  \u003cli\u003estart to use words in a proper context (11 months)\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eSuch spatial skills are something all creatures need to develop to survive. Even plants, to some extent, exhibit\nspatial-aware behavior — they move to follow the sun.\u003c/p\u003e\n\n\u003cp\u003eIt is worth noting that spatial-related terms\nlike \u003ca href=\"https://en.wikipedia.org/wiki/Natural_semantic_metalanguage\"\u003e“where, here, near, etc.”\u003c/a\u003e\ncan be translated to any language in the world.\u003c/p\u003e\n\n\u003cp\u003eOn the other hand, what language do we use to express ideas-related actions? As Barbara Tversky listed in her\n\u003ca href=\"https://www.youtube.com/watch?v=gmc4wEL2aPQ\"\u003e“Mind in motion”\u003c/a\u003e lecture we can:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eraise ideas\u003c/li\u003e\n  \u003cli\u003epull them together\u003c/li\u003e\n  \u003cli\u003etear apart\u003c/li\u003e\n  \u003cli\u003eturn inside out\u003c/li\u003e\n  \u003cli\u003epush forward\u003c/li\u003e\n  \u003cli\u003etoss out\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-03-30-visual-thinking/ideas_and_actions.png\" alt=\"ideas and actions\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eWe talk about ideas in the same way as about any space-related topic!\u003c/p\u003e\n\n\u003cp\u003eHow could it happen? Scientists have been trying to understand the functions of different parts of the brain for some time\nalready. In the seventies, they have identified the so-called \u003cstrong\u003eplace cells\u003c/strong\u003e — neurons that are activated at a specific\nlocation. It took some time to identify another layer of neurons on top of these: \u003cstrong\u003egrid cells\u003c/strong\u003e, working as our inner\nGPS, activated when switching locations. The latter discovery was\nawarded a \u003ca href=\"https://www.nobelprize.org/prizes/medicine/2014/press-release/\"\u003eNobel Prize in 2014\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eTests on human beings resulted in another finding: place cells are activated not only in specific locations. They are\nalso activated by events, people, ideas. The grid cells are activated by thinking about the consequences of events, by\nsocial interactions, and by connecting ideas together. We are using the same brain structures for spatial orientation,\nfor ideas, and for social interactions. This is the reason why Barbara Tversky issued an audacious thesis that “all\nthoughts begin as spatial thoughts”.\u003c/p\u003e\n\n\u003ch3 id=\"map-elements\"\u003eMap elements\u003c/h3\u003e\n\n\u003cp\u003eNowadays we have a GPS sensor in almost any smartphone, so it is rather difficult to get lost. Basic GPS information -\ncurrent coordinate — is not very useful by itself. It is much more convenient to display our current location over a map\nlayer. What is a map? According to \u003ca href=\"https://en.wikipedia.org/wiki/Map\"\u003ewikipedia\u003c/a\u003e, it is “[..] a symbolic depiction\nemphasizing relationships between elements of some space [..]”.\u003c/p\u003e\n\n\u003cp\u003eAs our ideas — and imaginary concepts like services — are treated by our brains as spatial elements we simply use known\nconcepts of space visualization to present imagined beings and relations among them.\u003c/p\u003e\n\n\u003ch3 id=\"arrows\"\u003eArrows\u003c/h3\u003e\n\n\u003cp\u003eSo far we used several symbols in our planning diagrams. Almost all of them can be found in maps as well, except one.\nThis element is an arrow — a significant element of our drawings. According to Barbara Tversky in the already\nmentioned \u003ca href=\"https://www.youtube.com/watch?v=gmc4wEL2aPQ\"\u003e“Mind in motion” lecture\u003c/a\u003e\narrows as visual elements started to appear in the 20th century. Before that symbols of feet or fingers had been used to\nindicate direction. The addition of arrows changes our perception of diagrams: without them, it is usually a structural\ndrawing, that requires additional labels to understand. Arrows transform such a structural diagram into a functional\ndiagram: we can trace arrows to their origin, we see how things are connected and how they cooperate. Check the\nexample below — the left-hand side version is static, only describes elements and the right-hand side version shows the movement\nof particular elements without using a single word.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-03-30-visual-thinking/clock.png\" alt=\"static and dynamic clock\" /\u003e\u003c/p\u003e\n\n\u003ch2 id=\"messy-lines\"\u003eMessy lines\u003c/h2\u003e\n\n\u003cp\u003eAll these well-known elements are our means of communication with other people, or even ourselves, at a different point\nin time. Sometimes we draw to discover, we sketch shapes to find inspiration, an idea. This seems to be important in\na different creative profession: architecture. Architects discover ideas in sketches. The ambiguity of non-obvious shapes\npromotes creativity. It is so important in this profession that sketches from private collections are sold as books. One\nof such books\nis \u003ca href=\"https://www.designboom.com/architecture/sou-fujimoto-sketchbook-lars-muller-publishers/\"\u003eSou Fujimoto sketchbook\u003c/a\u003e. I\nwould like to leave you with one quote from it, found\nat \u003ca href=\"https://colorandstory.medium.com/drawing-for-discovery-7e47ae6943da\"\u003e“Drawing for Discovery” post\u003c/a\u003e:\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003eThe lines are never certain, never knowing where the next will lead to. Never knowing, but continuing to draw.\nAnd for this very reason, there is always an opportunity for something new. From the infinite dialogues of the brain,\neyes, hand, paper, and space, new architecture is born.\u003c/p\u003e\n\u003c/blockquote\u003e\n","contentSnippet":"We use written (source code) language to express our intentions in a machine-readable form. We use spoken language to\ncommunicate with other people. We pride ourselves as ones choosing a programming language optimized to the task at hand.\nDo we use the optimal way to express our ideas?\nThe Story\nSpoken planning\n— Josh, could you summarize what we are going to implement, please?\nThat was a bit unexpected. He was just trying to match what he already knew from onboarding days with what was just\nsaid. It was really difficult to follow team discussion at the same time. It was a standard planning session, held over\nZoom, with his distributed team. Someone was already sharing their screen and the story summary, along with acceptance\ncriteria, was visible. They were developing an online store and the current topic was: basket price reduction for active\nusers. In short: users who spent more than 50€ for the last 7 days should have a discount applied during the checkout\nprocess.\n— Well, we are going to add a new service which is going to hold this discount logic. We will provide an API for the\ncart service to call us and we will check the transactions store for recent orders.\nRetrospective\nLet’s stop here for a moment. Have you ever been in a situation, when you were forced to do two things at the same time?\nFor example, listening to what is being said and trying to actively participate in the discussion regarding a not exactly\nwell-known topic? Was it a demanding experience? I had such an opportunity and I remember these sessions as quite\ndemanding. Usually, after an hourly session, I was exhausted and in need of a break. Not to mention that it required a\nsignificant amount of writing to capture everything that was said — just to have an option of referring back to this\nduring the sprint. What if this session looked differently?\nVisual planning\n— Josh, could you summarize what we are going to implement, please?\nThat was a bit unexpected, however, it was a no-brainer.\n\n“As we can see in the picture we are going to add a new service, discounts. This service will be called by the current\ncart service to display a reduced price (if applicable). Also, the “My Account” page is going to call us to retrieve the\ncurrent rebate for the logged user”.\nThe difference\nWhat is the main difference between the first scenario and the second one? To me, it is about a common model. In the first\ncase, I am building an individual model of a change. I need a significant amount of energy to translate speech to my model\nand to explain my model to others. What is more — everyone involved in the discussion is building a mental model on\ntheir own with a similar amount of energy spent on synchronization.\n\nIn the case of the second scenario, the model is shared. There is no need to maintain private models. It is easy to\nunderstand changed elements and to refer to discussed changes later. “A picture is worth a thousand words” after all.\n\nOutput from a visual planning is something that can be used further during a sprint. Depending on the tool it is\npossible to use it instead of an issue-tracking tool. Sticky notes can indicate actions, tasks, TODOs. They can be\narranged in a tree and display the scope of a pull request. They can be connected by a dotted line to indicate dependencies.\nAnd in the worst case, when you do not have any idea how to visualize something, you can always use a block of text and\ndescribe it using words.\n\nThe background\nWhy switching to a drawing board has such an effect? To answer this question we have to check some facts.\nOn a daily basis, a spoken (or written) language is our standard way of communication. Children, however, need some time\nto develop such a skill. Earlier they are able to:\nregister movement (at 2 months of age)\ntry to grab things by hand (5 months)\nfollow movement with their eyes, find hidden things (7 months)\nexploit cause-effect — drop a toy and watch it fall (8 months)\nstart to use words in a proper context (11 months)\nSuch spatial skills are something all creatures need to develop to survive. Even plants, to some extent, exhibit\nspatial-aware behavior — they move to follow the sun.\nIt is worth noting that spatial-related terms\nlike “where, here, near, etc.”\ncan be translated to any language in the world.\nOn the other hand, what language do we use to express ideas-related actions? As Barbara Tversky listed in her\n“Mind in motion” lecture we can:\nraise ideas\npull them together\ntear apart\nturn inside out\npush forward\ntoss out\n\nWe talk about ideas in the same way as about any space-related topic!\nHow could it happen? Scientists have been trying to understand the functions of different parts of the brain for some time\nalready. In the seventies, they have identified the so-called place cells — neurons that are activated at a specific\nlocation. It took some time to identify another layer of neurons on top of these: grid cells, working as our inner\nGPS, activated when switching locations. The latter discovery was\nawarded a Nobel Prize in 2014.\nTests on human beings resulted in another finding: place cells are activated not only in specific locations. They are\nalso activated by events, people, ideas. The grid cells are activated by thinking about the consequences of events, by\nsocial interactions, and by connecting ideas together. We are using the same brain structures for spatial orientation,\nfor ideas, and for social interactions. This is the reason why Barbara Tversky issued an audacious thesis that “all\nthoughts begin as spatial thoughts”.\nMap elements\nNowadays we have a GPS sensor in almost any smartphone, so it is rather difficult to get lost. Basic GPS information -\ncurrent coordinate — is not very useful by itself. It is much more convenient to display our current location over a map\nlayer. What is a map? According to wikipedia, it is “[..] a symbolic depiction\nemphasizing relationships between elements of some space [..]”.\nAs our ideas — and imaginary concepts like services — are treated by our brains as spatial elements we simply use known\nconcepts of space visualization to present imagined beings and relations among them.\nArrows\nSo far we used several symbols in our planning diagrams. Almost all of them can be found in maps as well, except one.\nThis element is an arrow — a significant element of our drawings. According to Barbara Tversky in the already\nmentioned “Mind in motion” lecture\narrows as visual elements started to appear in the 20th century. Before that symbols of feet or fingers had been used to\nindicate direction. The addition of arrows changes our perception of diagrams: without them, it is usually a structural\ndrawing, that requires additional labels to understand. Arrows transform such a structural diagram into a functional\ndiagram: we can trace arrows to their origin, we see how things are connected and how they cooperate. Check the\nexample below — the left-hand side version is static, only describes elements and the right-hand side version shows the movement\nof particular elements without using a single word.\n\nMessy lines\nAll these well-known elements are our means of communication with other people, or even ourselves, at a different point\nin time. Sometimes we draw to discover, we sketch shapes to find inspiration, an idea. This seems to be important in\na different creative profession: architecture. Architects discover ideas in sketches. The ambiguity of non-obvious shapes\npromotes creativity. It is so important in this profession that sketches from private collections are sold as books. One\nof such books\nis Sou Fujimoto sketchbook. I\nwould like to leave you with one quote from it, found\nat “Drawing for Discovery” post:\nThe lines are never certain, never knowing where the next will lead to. Never knowing, but continuing to draw.\nAnd for this very reason, there is always an opportunity for something new. From the infinite dialogues of the brain,\neyes, hand, paper, and space, new architecture is born.","guid":"https://blog.allegro.tech/2022/03/visual-thinking.html","categories":["tech","communication","visualization","planning","creativity"],"isoDate":"2022-03-29T22:00:00.000Z","thumbnail":"images/post-headers/default.jpg"},{"title":"Android UI testing in Allegro Pay organization","link":"https://blog.allegro.tech/2022/03/android-ui-testing-in-allegro-pay-organization.html","pubDate":"Wed, 09 Mar 2022 00:00:00 +0100","authors":{"author":[{"name":["Michał Kwiatek"],"photo":["https://blog.allegro.tech/img/authors/michal.kwiatek.jpg"],"url":["https://blog.allegro.tech/authors/michal.kwiatek"]}]},"content":"\u003cp\u003eWill automatic UI tests be able to replace manual testers as artificial intelligence will try to replace\nprogrammers? I’ll show you how we write automatic UI tests on Android in Allegro Pay.\u003c/p\u003e\n\n\u003ch2 id=\"the-introduction\"\u003eThe Introduction\u003c/h2\u003e\n\u003cp\u003eTests are designed to check whether the user interface is working properly. For example they verify\nif users see an appropriate screen with correct data and don’t encounter an unexpected behavior.\nThese tests, apart from checking the correctness of displayed screen, should also check whether the\nuser sees the appropriate screen after clicking a button. They allow to check the business process\nin a controlled manner. At Allegro Pay, we have several critical processes, such as onboarding a new\ncustomer or repayment of liabilities. Until now, these processes have been tested manually. Automating\nthese tests allows us to save the tester’s time and eliminates possible human errors.\u003c/p\u003e\n\n\u003ch2 id=\"the-application-class\"\u003eThe Application Class\u003c/h2\u003e\n\u003cp\u003eYou can have your tests running the whole \u003ca href=\"https://play.google.com/store/apps/details?id=pl.allegro\"\u003eapplication\u003c/a\u003e\nor go for partial coverage only. In our case, they run only single module, namely Allegro Pay. This solution\nis associated with certain changes that needed to be made. The \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eAllegroPayTestApplication\u003c/code\u003e class has been created\ninheriting from the \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eTestApplication\u003c/code\u003e class. It contains dependencies needed to run our module as a separate\napplication. Apart from this class, you need to prepare a manifest so that it has references to all activities\navailable in our module.\u003c/p\u003e\n\n\u003cdiv class=\"language-kotlin highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eAllegroPayTestApplication\u003c/span\u003e \u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eTestApplication\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\n   \u003cspan class=\"k\"\u003eoverride\u003c/span\u003e \u003cspan class=\"k\"\u003efun\u003c/span\u003e \u003cspan class=\"nf\"\u003eonCreate\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n       \u003cspan class=\"k\"\u003esuper\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eonCreate\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n       \u003cspan class=\"nf\"\u003einitKoin\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n   \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n   \u003cspan class=\"k\"\u003eprivate\u003c/span\u003e \u003cspan class=\"k\"\u003efun\u003c/span\u003e \u003cspan class=\"nf\"\u003einitKoin\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n       \u003cspan class=\"nf\"\u003eloadKoinModules\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n           \u003cspan class=\"n\"\u003eloadNeededModulesHere\u003c/span\u003e\n       \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n   \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch2 id=\"the-tool-framework-and-pattern\"\u003eThe Tool, Framework And Pattern\u003c/h2\u003e\n\u003cp\u003eTools and frameworks used in the process of adding tests are Espresso and Wiremock Stubbing\nand the PageObject pattern.\n\u003cimg src=\"/img/articles/2022-03-09-android-ui-testing-in-allegro-pay-organization/espresso_and_wiremock.png\" alt=\"Espresso and Wiremock logos\" /\u003e\u003c/p\u003e\n\n\u003ch3 id=\"wiremock\"\u003eWiremock\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://wiremock.org/\"\u003eWiremock\u003c/a\u003e is a tool which allows mocking the response for\na given endpoint with a declared data example. In addition, it can also record requests, map responses, edit\nresponse data, and act as a transparent proxy. This solution supports testing of edge cases and different response\nstatuses that are difficult or impossible to automatically simulate in a real test environment. Another big\nreason for using this tool is stability. Since the test environment to which these tests need to connect doesn’t\nalways work, running the test would not bring any benefits. This would be wasting resources and generating costs.\nThanks to Wiremock, it is possible to obtain the same answer each time. Here is an example stub:\u003c/p\u003e\n\n\u003cdiv class=\"language-kotlin highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003eopen\u003c/span\u003e \u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eStub\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003emappingBuilder\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eMappingBuilder\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003einternal\u003c/span\u003e \u003cspan class=\"kd\"\u003eobject\u003c/span\u003e \u003cspan class=\"nc\"\u003eGreetingStub\u003c/span\u003e \u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eStub\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n   \u003cspan class=\"k\"\u003eget\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n       \u003cspan class=\"nf\"\u003eurlEqualTo\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"/allegropay/greeting\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n   \u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"nf\"\u003ewillReturn\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n       \u003cspan class=\"nf\"\u003eaResponse\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n           \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003ewithStatus\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e200\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n           \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003ewithBody\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nc\"\u003eGREETING_STUB\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n   \u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e// \u0026lt;editor-fold defaultstate=collapsed desc=\"GreetingStub\"\u0026gt;\u003c/span\u003e\n\n\u003cspan class=\"nd\"\u003e@Language\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"json\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003eGREETING_STUB\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"s\"\u003e\"\"\"\n {\n   \"greeting\": \"hello\"\n }\n\"\"\"\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e// \u0026lt;/editor-fold\u0026gt;\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eThe above code shows a stub, that allows any query to \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e/allegropay/greeting\u003c/code\u003e to respond with a status\nof 200 and data entered in the \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eGREETING_STUB\u003c/code\u003e field.\u003c/p\u003e\n\n\u003ch3 id=\"espresso\"\u003eEspresso\u003c/h3\u003e\n\u003cp\u003eAnother tool which I would like to present is \u003ca href=\"https://developer.android.com/training/testing/espresso\"\u003eEspresso\u003c/a\u003e.\nIt allows describing what we want to test in our activity. You can simulate the operation of the application as\nif it was used by the customer. This tool provides several simple methods for ensuring the interaction and\nassertion of the view state. I put a cheat sheet with the most needed and most used matchers, actions,\nassertions, etc. below. Espresso provides management of the main thread, what significantly speeds up and\nfacilitates writing tests. An important consideration when using this tool is that \u003cstrong\u003e\u003cem\u003esystem animations and\n“don’t keep activities” function cannot be enabled on the test device\u003c/em\u003e\u003c/strong\u003e.\n\u003cimg src=\"/img/articles/2022-03-09-android-ui-testing-in-allegro-pay-organization/espresso_cheatsheet.png\" alt=\"Espresso cheat sheet\" /\u003e\u003c/p\u003e\n\n\u003ch3 id=\"pageobject-pattern\"\u003ePageObject Pattern\u003c/h3\u003e\n\u003cp\u003eThe last thing needed to write perfect tests is the \u003ca href=\"https://martinfowler.com/bliki/PageObject.html\"\u003ePageObject\u003c/a\u003e pattern\nwhich allows you to store the interactions and assertions in one place in the context of each screen. According to\nMartin Fowler (if you haven’t read his books, you should!):\u003c/p\u003e\n\u003cblockquote\u003e\n  \u003cp\u003eThe basic rule of thumb for a page object is that it should allow a software client to do anything and\nsee anything that a human can.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch2 id=\"the-test\"\u003eThe test\u003c/h2\u003e\n\u003cp\u003eBelow is one of the tests written for the Dashboard screen:\u003c/p\u003e\n\n\u003cdiv class=\"language-kotlin highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"nd\"\u003e@Test\u003c/span\u003e\n\u003cspan class=\"nd\"\u003e@Stubs\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n   \u003cspan class=\"nc\"\u003eStub1\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n   \u003cspan class=\"nc\"\u003eStub2\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n   \u003cspan class=\"nc\"\u003eStub3\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n   \u003cspan class=\"nc\"\u003eStub4\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n   \u003cspan class=\"nc\"\u003eStub5\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"k\"\u003efun\u003c/span\u003e \u003cspan class=\"nf\"\u003etestUserCanSeeDashboardThenSettingsThenOverpaymentThenGoBackToDashboard\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"nf\"\u003elaunchDashboardActivity\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n   \u003cspan class=\"nf\"\u003einDashboard\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n       \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003etoolbarPage\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"n\"\u003etoolbar\u003c/span\u003e \u003cspan class=\"p\"\u003e-\u0026gt;\u003c/span\u003e\n           \u003cspan class=\"n\"\u003etoolbar\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003echeckName\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nc\"\u003eDASHBOARD_TOOLBAR_NAME_RES_ID\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n               \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003edashboardMenuItemPage\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"n\"\u003emenuItem\u003c/span\u003e \u003cspan class=\"p\"\u003e-\u0026gt;\u003c/span\u003e\n                   \u003cspan class=\"n\"\u003emenuItem\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003etapOnOptionsButton\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n               \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n       \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n   \u003cspan class=\"nf\"\u003einSettings\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n       \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003etoolbarPage\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"n\"\u003etoolbar\u003c/span\u003e \u003cspan class=\"p\"\u003e-\u0026gt;\u003c/span\u003e\n           \u003cspan class=\"n\"\u003etoolbar\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003echeckName\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nc\"\u003eSETTINGS_TOOLBAR_NAME_RES_ID\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n       \u003cspan class=\"p\"\u003e}.\u003c/span\u003e\u003cspan class=\"nf\"\u003eoverpaymentItemPage\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eposition\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"n\"\u003eitem\u003c/span\u003e \u003cspan class=\"p\"\u003e-\u0026gt;\u003c/span\u003e\n           \u003cspan class=\"n\"\u003eitem\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003etapOnOverpayment\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n       \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n   \u003cspan class=\"nf\"\u003einOverpayment\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nf\"\u003eparseOverpaymentData\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nc\"\u003eOVERPAYMENT_WITHOUT_IBAN_POSITIVE\u003c/span\u003e\u003cspan class=\"p\"\u003e))\u003c/span\u003e\n       \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003etoolbarPage\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"n\"\u003etoolbar\u003c/span\u003e \u003cspan class=\"p\"\u003e-\u0026gt;\u003c/span\u003e\n           \u003cspan class=\"n\"\u003etoolbar\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003echeckName\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nc\"\u003eOVERPAYMENT_TOOLBAR_NAME_RES_ID\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n               \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003etapToolbarBack\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n       \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n   \u003cspan class=\"nf\"\u003einSettings\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n       \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003etoolbarPage\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"n\"\u003etoolbar\u003c/span\u003e \u003cspan class=\"p\"\u003e-\u0026gt;\u003c/span\u003e\n           \u003cspan class=\"n\"\u003etoolbar\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003echeckName\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nc\"\u003eSETTINGS_TOOLBAR_NAME_RES_ID\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n               \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003etapToolbarBack\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n       \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n   \u003cspan class=\"nf\"\u003einDashboard\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n       \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003etoolbarPage\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"n\"\u003etoolbar\u003c/span\u003e \u003cspan class=\"p\"\u003e-\u0026gt;\u003c/span\u003e\n           \u003cspan class=\"n\"\u003etoolbar\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003echeckName\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nc\"\u003eDASHBOARD_TOOLBAR_NAME_RES_ID\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n       \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eThe above test allows you to check the path followed by the user who wants to see the overpayment screen\nfrom the dashboard and then return. Methods with the \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ein\u003c/code\u003e prefix contain a page object that provides the\nnecessary interactions and assertions to check the view. By running this test on the test device, you can\nsee the start of the application with the dashboard screen, where the title of the toolbar is checked\nand the button that takes you to the options screen is clicked. In the options screen, the title of\nthe toolbar is checked and you click on the option that takes you to the overpayment screen.\nThe toolbar title also is checked in the overpayment screen and the back arrow is clicked. The\napplication returns to the options screen, the title of the toolbar is checked and the back arrow\nis clicked. The last screen that is checked is the dashboard screen. And then the test\npasses.\u003c/p\u003e\n\n\u003cp\u003eThe class fragment presented below has the method that was used in the previous test. This method allows\nto create settings page object and run check on toolbar page and overpayment item page. Toolbar page object\nlets us check name by string resource defined in \u003ccode class=\"language-plaintext highlighter-rouge\"\u003estrings.xml\u003c/code\u003e file. Whereas \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eoverpaymentItemPage()\u003c/code\u003e method\nsearches for item on the first position on the recycler view. After that it clicks on overpayment option on screen.\nThis means that the methods can be used for other tests without unnecessarily duplicating it.\u003c/p\u003e\n\n\u003cdiv class=\"language-kotlin highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"nf\"\u003einSettings\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n   \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003etoolbarPage\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"n\"\u003etoolbar\u003c/span\u003e \u003cspan class=\"p\"\u003e-\u0026gt;\u003c/span\u003e\n       \u003cspan class=\"n\"\u003etoolbar\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003echeckName\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nc\"\u003eSETTINGS_TOOLBAR_NAME_RES_ID\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n   \u003cspan class=\"p\"\u003e}.\u003c/span\u003e\u003cspan class=\"nf\"\u003eoverpaymentItemPage\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eposition\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"n\"\u003eitem\u003c/span\u003e \u003cspan class=\"p\"\u003e-\u0026gt;\u003c/span\u003e\n       \u003cspan class=\"n\"\u003eitem\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003etapOnOverpayment\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n   \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch2 id=\"the-future\"\u003eThe Future\u003c/h2\u003e\n\u003cp\u003eOur test team proposed to provide test scenarios that should be implemented in addition to the so-called\nhappy paths. These were be the most frequently reported problems by our customers regarding the display\nof data or switching between screens. However, it should also be noted that the number of these tests\nshouldn’t be too large, because running one test usually takes a few seconds, what may cause queues in the\ntest environment. Additionally, the tests need to be merged into the main branch. The 10 sample tests took\nalmost 30 seconds to complete, but the entire procedure took almost a minute.\n\u003cimg src=\"/img/articles/2022-03-09-android-ui-testing-in-allegro-pay-organization/10_tests.png\" alt=\"10 sample tests\" /\u003e\u003c/p\u003e\n\n\u003ch2 id=\"the-end\"\u003eThe End\u003c/h2\u003e\n\u003cp\u003eWe expect that the addition of tests will reduce the work of manual testers. Testing cases that require simulating\na specific, very rare behavior or response from the backend takes the longest time. Reducing it by any value is\na profit. Happy paths and paths with standard errors can be easily programmed in tests. Additionally, programmers\nat an earlier stage are able to catch and correct errors resulting from regression. We are already working on\nadding tests to further processes such as onboarding a new customer, consolidation or repayment. We will also\nextend our test scenarios with additional cases. And the question posed at the very beginning of this article\nis still open.\u003c/p\u003e\n","contentSnippet":"Will automatic UI tests be able to replace manual testers as artificial intelligence will try to replace\nprogrammers? I’ll show you how we write automatic UI tests on Android in Allegro Pay.\nThe Introduction\nTests are designed to check whether the user interface is working properly. For example they verify\nif users see an appropriate screen with correct data and don’t encounter an unexpected behavior.\nThese tests, apart from checking the correctness of displayed screen, should also check whether the\nuser sees the appropriate screen after clicking a button. They allow to check the business process\nin a controlled manner. At Allegro Pay, we have several critical processes, such as onboarding a new\ncustomer or repayment of liabilities. Until now, these processes have been tested manually. Automating\nthese tests allows us to save the tester’s time and eliminates possible human errors.\nThe Application Class\nYou can have your tests running the whole application\nor go for partial coverage only. In our case, they run only single module, namely Allegro Pay. This solution\nis associated with certain changes that needed to be made. The AllegroPayTestApplication class has been created\ninheriting from the TestApplication class. It contains dependencies needed to run our module as a separate\napplication. Apart from this class, you need to prepare a manifest so that it has references to all activities\navailable in our module.\n\nclass AllegroPayTestApplication : TestApplication() {\n\n   override fun onCreate() {\n       super.onCreate()\n       initKoin()\n   }\n\n   private fun initKoin() {\n       loadKoinModules(\n           loadNeededModulesHere\n       )\n   }\n}\n\n\nThe Tool, Framework And Pattern\nTools and frameworks used in the process of adding tests are Espresso and Wiremock Stubbing\nand the PageObject pattern.\n\nWiremock\nWiremock is a tool which allows mocking the response for\na given endpoint with a declared data example. In addition, it can also record requests, map responses, edit\nresponse data, and act as a transparent proxy. This solution supports testing of edge cases and different response\nstatuses that are difficult or impossible to automatically simulate in a real test environment. Another big\nreason for using this tool is stability. Since the test environment to which these tests need to connect doesn’t\nalways work, running the test would not bring any benefits. This would be wasting resources and generating costs.\nThanks to Wiremock, it is possible to obtain the same answer each time. Here is an example stub:\n\nopen class Stub(val mappingBuilder: MappingBuilder)\n\ninternal object GreetingStub : Stub(\n   get(\n       urlEqualTo(\"/allegropay/greeting\")\n   ).willReturn(\n       aResponse()\n           .withStatus(200)\n           .withBody(GREETING_STUB)\n   )\n)\n\n// \u003ceditor-fold defaultstate=collapsed desc=\"GreetingStub\"\u003e\n\n@Language(\"json\")\nval GREETING_STUB = \"\"\"\n {\n   \"greeting\": \"hello\"\n }\n\"\"\"\n\n// \u003c/editor-fold\u003e\n\n\nThe above code shows a stub, that allows any query to /allegropay/greeting to respond with a status\nof 200 and data entered in the GREETING_STUB field.\nEspresso\nAnother tool which I would like to present is Espresso.\nIt allows describing what we want to test in our activity. You can simulate the operation of the application as\nif it was used by the customer. This tool provides several simple methods for ensuring the interaction and\nassertion of the view state. I put a cheat sheet with the most needed and most used matchers, actions,\nassertions, etc. below. Espresso provides management of the main thread, what significantly speeds up and\nfacilitates writing tests. An important consideration when using this tool is that system animations and\n“don’t keep activities” function cannot be enabled on the test device.\n\nPageObject Pattern\nThe last thing needed to write perfect tests is the PageObject pattern\nwhich allows you to store the interactions and assertions in one place in the context of each screen. According to\nMartin Fowler (if you haven’t read his books, you should!):\nThe basic rule of thumb for a page object is that it should allow a software client to do anything and\nsee anything that a human can.\nThe test\nBelow is one of the tests written for the Dashboard screen:\n\n@Test\n@Stubs(\n   Stub1::class,\n   Stub2::class,\n   Stub3::class,\n   Stub4::class,\n   Stub5::class\n)\nfun testUserCanSeeDashboardThenSettingsThenOverpaymentThenGoBackToDashboard() = launchDashboardActivity {\n   inDashboard()\n       .toolbarPage { toolbar -\u003e\n           toolbar.checkName(DASHBOARD_TOOLBAR_NAME_RES_ID)\n               .dashboardMenuItemPage { menuItem -\u003e\n                   menuItem.tapOnOptionsButton()\n               }\n       }\n\n   inSettings()\n       .toolbarPage { toolbar -\u003e\n           toolbar.checkName(SETTINGS_TOOLBAR_NAME_RES_ID)\n       }.overpaymentItemPage(position = 1) { item -\u003e\n           item.tapOnOverpayment()\n       }\n\n   inOverpayment(parseOverpaymentData(OVERPAYMENT_WITHOUT_IBAN_POSITIVE))\n       .toolbarPage { toolbar -\u003e\n           toolbar.checkName(OVERPAYMENT_TOOLBAR_NAME_RES_ID)\n               .tapToolbarBack()\n       }\n\n   inSettings()\n       .toolbarPage { toolbar -\u003e\n           toolbar.checkName(SETTINGS_TOOLBAR_NAME_RES_ID)\n               .tapToolbarBack()\n       }\n\n   inDashboard()\n       .toolbarPage { toolbar -\u003e\n           toolbar.checkName(DASHBOARD_TOOLBAR_NAME_RES_ID)\n       }\n}\n\n\nThe above test allows you to check the path followed by the user who wants to see the overpayment screen\nfrom the dashboard and then return. Methods with the in prefix contain a page object that provides the\nnecessary interactions and assertions to check the view. By running this test on the test device, you can\nsee the start of the application with the dashboard screen, where the title of the toolbar is checked\nand the button that takes you to the options screen is clicked. In the options screen, the title of\nthe toolbar is checked and you click on the option that takes you to the overpayment screen.\nThe toolbar title also is checked in the overpayment screen and the back arrow is clicked. The\napplication returns to the options screen, the title of the toolbar is checked and the back arrow\nis clicked. The last screen that is checked is the dashboard screen. And then the test\npasses.\nThe class fragment presented below has the method that was used in the previous test. This method allows\nto create settings page object and run check on toolbar page and overpayment item page. Toolbar page object\nlets us check name by string resource defined in strings.xml file. Whereas overpaymentItemPage() method\nsearches for item on the first position on the recycler view. After that it clicks on overpayment option on screen.\nThis means that the methods can be used for other tests without unnecessarily duplicating it.\n\ninSettings()\n   .toolbarPage { toolbar -\u003e\n       toolbar.checkName(SETTINGS_TOOLBAR_NAME_RES_ID)\n   }.overpaymentItemPage(position = 1) { item -\u003e\n       item.tapOnOverpayment()\n   }\n\n\nThe Future\nOur test team proposed to provide test scenarios that should be implemented in addition to the so-called\nhappy paths. These were be the most frequently reported problems by our customers regarding the display\nof data or switching between screens. However, it should also be noted that the number of these tests\nshouldn’t be too large, because running one test usually takes a few seconds, what may cause queues in the\ntest environment. Additionally, the tests need to be merged into the main branch. The 10 sample tests took\nalmost 30 seconds to complete, but the entire procedure took almost a minute.\n\nThe End\nWe expect that the addition of tests will reduce the work of manual testers. Testing cases that require simulating\na specific, very rare behavior or response from the backend takes the longest time. Reducing it by any value is\na profit. Happy paths and paths with standard errors can be easily programmed in tests. Additionally, programmers\nat an earlier stage are able to catch and correct errors resulting from regression. We are already working on\nadding tests to further processes such as onboarding a new customer, consolidation or repayment. We will also\nextend our test scenarios with additional cases. And the question posed at the very beginning of this article\nis still open.","guid":"https://blog.allegro.tech/2022/03/android-ui-testing-in-allegro-pay-organization.html","categories":["tech","kotlin","android","ui-testing","allegro-pay"],"isoDate":"2022-03-08T23:00:00.000Z","thumbnail":"images/post-headers/default.jpg"}],"jobs":[{"id":"743999810853837","name":"Research Engineer - Machine Learning (Computer Vision)","uuid":"98abcad8-b820-4402-85a6-b6b6e03cfdaa","refNumber":"REF2880R","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2022-03-09T12:55:28.000Z","location":{"city":"Warszawa, Kraków, Poznań, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572821","label":"IT - Machine Learning"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"606235fe248e6f5bea0815ed","fieldLabel":"Katowice","valueId":"185eb5a9-b884-4ee8-8ebc-0e5f3e852b27","valueLabel":"Tak"},{"fieldId":"58c1575ee4b01d4b19ddf797","fieldLabel":"Kraków","valueId":"2cfcfcc1-da44-43f7-8eaa-3907faf2797c","valueLabel":"Tak"},{"fieldId":"606235bcefbac7156d6a470a","fieldLabel":"Łódź","valueId":"7d33e23d-3fa7-4d7d-86ae-7d7caff54fa9","valueLabel":"Tak"},{"fieldId":"58c158e9e4b0614667d5973e","fieldLabel":"Więcej lokalizacji","valueId":"3a186e8d-a82c-4955-af81-fcef9a63928a","valueLabel":"Tak"},{"fieldId":"58c1576ee4b0614667d59732","fieldLabel":"Toruń","valueId":"987e8884-bad1-4a8f-b149-99e4184cc221","valueLabel":"Tak"},{"fieldId":"6165609ee6b46b6506c66b63","fieldLabel":"Gdańsk","valueId":"cde0f8e7-5c9d-4d78-9f5c-e1c17ee499a8","valueLabel":"Tak"},{"fieldId":"58c156e6e4b01d4b19ddf793","fieldLabel":"Warszawa","valueId":"6a428533-1586-4372-89ec-65fb45366363","valueLabel":"Tak"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Proces rekrutacji","valueId":"c807eec2-8a53-4b55-b7c5-c03180f2059b","valueLabel":"(Archive) IT Allegro"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c15788e4b0614667d59733","fieldLabel":"Błonie","valueId":"25f6cb8c-81b3-434a-93ec-6dc851d5808d","valueLabel":"Nie"},{"fieldId":"58c15798e4b01d4b19ddf79b","fieldLabel":"Wrocław","valueId":"64818201-cdba-422e-8e8c-8ec633b0d327","valueLabel":"Tak"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572821","valueLabel":"IT - Machine Learning"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro.pl sp. z o.o."},{"fieldId":"61656102a169ed164d546c31","fieldLabel":"Lublin","valueId":"02d54f00-48b9-4669-b7b3-10c16ac4bada","valueLabel":"Tak"},{"fieldId":"58c156b9e4b01d4b19ddf792","fieldLabel":"Poznań","valueId":"ac20917b-cb6a-4280-aff3-4fae2532a33e","valueLabel":"Tak"},{"fieldId":"5cdab2c84cedfd0006e7758c","fieldLabel":"Key words","valueLabel":"CV, Computer Vision, ML, AI, DS, Machine Learning, PyTorch, Python, Deep Learning"}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999810853837","creator":{"name":"Maciej Matwiejczyk"},"language":{"code":"pl","label":"Polish","labelNative":"polski"}},{"id":"743999785422127","name":"Research Engineer - Machine Learning (Reinforcement Learning)","uuid":"229d607a-333b-431b-9abe-78137730f5fd","refNumber":"REF2881V","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2021-11-08T09:56:17.000Z","location":{"city":"Warszawa, Kraków, Poznań, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572821","label":"IT - Machine Learning"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"606235fe248e6f5bea0815ed","fieldLabel":"Katowice","valueId":"185eb5a9-b884-4ee8-8ebc-0e5f3e852b27","valueLabel":"Tak"},{"fieldId":"58c1575ee4b01d4b19ddf797","fieldLabel":"Kraków","valueId":"2cfcfcc1-da44-43f7-8eaa-3907faf2797c","valueLabel":"Tak"},{"fieldId":"606235bcefbac7156d6a470a","fieldLabel":"Łódź","valueId":"7d33e23d-3fa7-4d7d-86ae-7d7caff54fa9","valueLabel":"Tak"},{"fieldId":"58c158e9e4b0614667d5973e","fieldLabel":"Więcej lokalizacji","valueId":"3a186e8d-a82c-4955-af81-fcef9a63928a","valueLabel":"Tak"},{"fieldId":"58c1576ee4b0614667d59732","fieldLabel":"Toruń","valueId":"987e8884-bad1-4a8f-b149-99e4184cc221","valueLabel":"Tak"},{"fieldId":"6165609ee6b46b6506c66b63","fieldLabel":"Gdańsk","valueId":"cde0f8e7-5c9d-4d78-9f5c-e1c17ee499a8","valueLabel":"Tak"},{"fieldId":"58c156e6e4b01d4b19ddf793","fieldLabel":"Warszawa","valueId":"6a428533-1586-4372-89ec-65fb45366363","valueLabel":"Tak"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Proces rekrutacji","valueId":"c807eec2-8a53-4b55-b7c5-c03180f2059b","valueLabel":"(Archive) IT Allegro"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c15788e4b0614667d59733","fieldLabel":"Błonie","valueId":"25f6cb8c-81b3-434a-93ec-6dc851d5808d","valueLabel":"Nie"},{"fieldId":"58c15798e4b01d4b19ddf79b","fieldLabel":"Wrocław","valueId":"64818201-cdba-422e-8e8c-8ec633b0d327","valueLabel":"Tak"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572821","valueLabel":"IT - Machine Learning"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro.pl sp. z o.o."},{"fieldId":"61656102a169ed164d546c31","fieldLabel":"Lublin","valueId":"02d54f00-48b9-4669-b7b3-10c16ac4bada","valueLabel":"Tak"},{"fieldId":"58c156b9e4b01d4b19ddf792","fieldLabel":"Poznań","valueId":"ac20917b-cb6a-4280-aff3-4fae2532a33e","valueLabel":"Tak"},{"fieldId":"5cdab2c84cedfd0006e7758c","fieldLabel":"Key words","valueLabel":"ML, Machine Learning, Python, Deep Learning, AI, Artificial Intelligence"}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999785422127","creator":{"name":"Maciej Matwiejczyk"},"language":{"code":"en","label":"English","labelNative":"English (US)"}},{"id":"743999785421861","name":"Research Engineer - Machine Learning (Ranking and Recommendations)","uuid":"a6b2b59e-28e3-4bfa-89ab-b13ab97f06c8","refNumber":"REF2990T","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2021-11-08T09:54:52.000Z","location":{"city":"Warszawa, Poznań, Kraków, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572821","label":"IT - Machine Learning"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"58c1575ee4b01d4b19ddf797","fieldLabel":"Kraków","valueId":"2cfcfcc1-da44-43f7-8eaa-3907faf2797c","valueLabel":"Tak"},{"fieldId":"58c158e9e4b0614667d5973e","fieldLabel":"Więcej lokalizacji","valueId":"3a186e8d-a82c-4955-af81-fcef9a63928a","valueLabel":"Tak"},{"fieldId":"58c1576ee4b0614667d59732","fieldLabel":"Toruń","valueId":"987e8884-bad1-4a8f-b149-99e4184cc221","valueLabel":"Tak"},{"fieldId":"58c156e6e4b01d4b19ddf793","fieldLabel":"Warszawa","valueId":"6a428533-1586-4372-89ec-65fb45366363","valueLabel":"Tak"},{"fieldId":"60cb31a9c87e511299a3a050","fieldLabel":"Department II","valueId":"b8a4596e-d9ce-42bb-8de5-10995e9ccf99","valueLabel":"IT - Machine Learning"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Proces rekrutacji","valueId":"c807eec2-8a53-4b55-b7c5-c03180f2059b","valueLabel":"(Archive) IT Allegro"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c15788e4b0614667d59733","fieldLabel":"Błonie","valueId":"25f6cb8c-81b3-434a-93ec-6dc851d5808d","valueLabel":"Nie"},{"fieldId":"58c15798e4b01d4b19ddf79b","fieldLabel":"Wrocław","valueId":"64818201-cdba-422e-8e8c-8ec633b0d327","valueLabel":"Tak"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572821","valueLabel":"IT - Machine Learning"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro.pl sp. z o.o."},{"fieldId":"58c156b9e4b01d4b19ddf792","fieldLabel":"Poznań","valueId":"ac20917b-cb6a-4280-aff3-4fae2532a33e","valueLabel":"Tak"},{"fieldId":"5cdab2c84cedfd0006e7758c","fieldLabel":"Key words","valueLabel":"ML, AI, Ranking, Research, Machine Learning"}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999785421861","creator":{"name":"Maciej Matwiejczyk"},"language":{"code":"en","label":"English","labelNative":"English (US)"}},{"id":"743999779448775","name":"Research Engineer - Machine Learning (Reinforcement Learning)","uuid":"c8e577cc-c93a-43e7-8e73-e430989798d7","refNumber":"REF2881V","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2021-10-14T10:29:36.000Z","location":{"city":"Warszawa, Kraków, Poznań, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572821","label":"IT - Machine Learning"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"606235fe248e6f5bea0815ed","fieldLabel":"Katowice","valueId":"185eb5a9-b884-4ee8-8ebc-0e5f3e852b27","valueLabel":"Tak"},{"fieldId":"58c1575ee4b01d4b19ddf797","fieldLabel":"Kraków","valueId":"2cfcfcc1-da44-43f7-8eaa-3907faf2797c","valueLabel":"Tak"},{"fieldId":"606235bcefbac7156d6a470a","fieldLabel":"Łódź","valueId":"7d33e23d-3fa7-4d7d-86ae-7d7caff54fa9","valueLabel":"Tak"},{"fieldId":"58c158e9e4b0614667d5973e","fieldLabel":"Więcej lokalizacji","valueId":"3a186e8d-a82c-4955-af81-fcef9a63928a","valueLabel":"Tak"},{"fieldId":"58c1576ee4b0614667d59732","fieldLabel":"Toruń","valueId":"987e8884-bad1-4a8f-b149-99e4184cc221","valueLabel":"Tak"},{"fieldId":"6165609ee6b46b6506c66b63","fieldLabel":"Gdańsk","valueId":"cde0f8e7-5c9d-4d78-9f5c-e1c17ee499a8","valueLabel":"Tak"},{"fieldId":"58c156e6e4b01d4b19ddf793","fieldLabel":"Warszawa","valueId":"6a428533-1586-4372-89ec-65fb45366363","valueLabel":"Tak"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Proces rekrutacji","valueId":"c807eec2-8a53-4b55-b7c5-c03180f2059b","valueLabel":"(Archive) IT Allegro"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c15788e4b0614667d59733","fieldLabel":"Błonie","valueId":"25f6cb8c-81b3-434a-93ec-6dc851d5808d","valueLabel":"Nie"},{"fieldId":"58c15798e4b01d4b19ddf79b","fieldLabel":"Wrocław","valueId":"64818201-cdba-422e-8e8c-8ec633b0d327","valueLabel":"Tak"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572821","valueLabel":"IT - Machine Learning"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro.pl sp. z o.o."},{"fieldId":"61656102a169ed164d546c31","fieldLabel":"Lublin","valueId":"02d54f00-48b9-4669-b7b3-10c16ac4bada","valueLabel":"Tak"},{"fieldId":"58c156b9e4b01d4b19ddf792","fieldLabel":"Poznań","valueId":"ac20917b-cb6a-4280-aff3-4fae2532a33e","valueLabel":"Tak"},{"fieldId":"5cdab2c84cedfd0006e7758c","fieldLabel":"Key words","valueLabel":"ML, Machine Learning, Python, Deep Learning, AI, Artificial Intelligence"}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999779448775","creator":{"name":"Maciej Matwiejczyk"},"language":{"code":"pl","label":"Polish","labelNative":"polski"}},{"id":"743999779448676","name":"Research Engineer - Machine Learning (Ranking and Recommendations)","uuid":"7cb35dfc-f53c-4b51-81ac-61b683060f4c","refNumber":"REF2990T","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2021-10-14T10:29:00.000Z","location":{"city":"Warszawa, Poznań, Kraków, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572821","label":"IT - Machine Learning"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"58c1575ee4b01d4b19ddf797","fieldLabel":"Kraków","valueId":"2cfcfcc1-da44-43f7-8eaa-3907faf2797c","valueLabel":"Tak"},{"fieldId":"58c158e9e4b0614667d5973e","fieldLabel":"Więcej lokalizacji","valueId":"3a186e8d-a82c-4955-af81-fcef9a63928a","valueLabel":"Tak"},{"fieldId":"58c1576ee4b0614667d59732","fieldLabel":"Toruń","valueId":"987e8884-bad1-4a8f-b149-99e4184cc221","valueLabel":"Tak"},{"fieldId":"58c156e6e4b01d4b19ddf793","fieldLabel":"Warszawa","valueId":"6a428533-1586-4372-89ec-65fb45366363","valueLabel":"Tak"},{"fieldId":"60cb31a9c87e511299a3a050","fieldLabel":"Department II","valueId":"b8a4596e-d9ce-42bb-8de5-10995e9ccf99","valueLabel":"IT - Machine Learning"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Proces rekrutacji","valueId":"c807eec2-8a53-4b55-b7c5-c03180f2059b","valueLabel":"(Archive) IT Allegro"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c15788e4b0614667d59733","fieldLabel":"Błonie","valueId":"25f6cb8c-81b3-434a-93ec-6dc851d5808d","valueLabel":"Nie"},{"fieldId":"58c15798e4b01d4b19ddf79b","fieldLabel":"Wrocław","valueId":"64818201-cdba-422e-8e8c-8ec633b0d327","valueLabel":"Tak"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572821","valueLabel":"IT - Machine Learning"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro.pl sp. z o.o."},{"fieldId":"58c156b9e4b01d4b19ddf792","fieldLabel":"Poznań","valueId":"ac20917b-cb6a-4280-aff3-4fae2532a33e","valueLabel":"Tak"},{"fieldId":"5cdab2c84cedfd0006e7758c","fieldLabel":"Key words","valueLabel":"ML, AI, Ranking, Research, Machine Learning"}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999779448676","creator":{"name":"Maciej Matwiejczyk"},"language":{"code":"pl","label":"Polish","labelNative":"polski"}}],"events":[{"created":1649842904000,"duration":5400000,"id":"285245512","name":"Allegro Tech Live #27 - Java, Python i rozsądny development","date_in_series_pattern":false,"status":"upcoming","time":1651161600000,"local_date":"2022-04-28","local_time":"18:00","updated":1649843198000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":18,"venue":{"id":26906060,"name":"Online event","repinned":false,"country":"","localized_country_name":""},"is_online_event":true,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/285245512/","description":"\\-\\-\\-\\-\\-\\-\\\u0026gt; Na wydarzenie obowiązuje rejestracja: [https://app.evenea.pl/event/allegro-tech-live-27/](https://app.evenea.pl/event/allegro-tech-live-27/?fbclid=IwAR3QOef6CKKiuowl1Nto3Z4YEFMj7R7hdq_REpvY2a-3ETaJsWhvfnXDLxE) \u0026lt;----- Allegro Tech Live to w 100% zdalna odsłona naszych stacjonarnych meetupów Allegro Tech Talks. Kiedyś spotykaliśmy się w…","how_to_find_us":"https://app.evenea.pl/event/allegro-tech-live-27/","visibility":"public","member_pay_fee":false},{"created":1648205510000,"duration":5400000,"id":"284843205","name":"Allegro Tech Live #26 - Summer e-Xperience 2022 - Praca na start","date_in_series_pattern":false,"status":"past","time":1649347200000,"local_date":"2022-04-07","local_time":"18:00","updated":1649354220000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":18,"venue":{"id":26906060,"name":"Online event","repinned":false,"country":"","localized_country_name":""},"is_online_event":true,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/284843205/","description":"OBOWIĄZUJE REJESTRACJA NA WYDARZENIE: [https://app.evenea.pl/event/allegro-tech-live-26/](https://app.evenea.pl/event/allegro-tech-live-26/?fbclid=IwAR0b1mViAvW5FnJYTRmstdxOtMA_7jlWRYIAtortrhPFJk1PtHw1xIw5rBk) Allegro Tech Live to w 100% zdalna odsłona naszych stacjonarnych meetupów Allegro Tech Talks. Kiedyś spotykaliśmy się w naszych biurach,…","how_to_find_us":"https://youtu.be/0lzCjTR-Ylk","visibility":"public","member_pay_fee":false},{"created":1646677211000,"duration":7200000,"id":"284469437","name":"Allegro Tech Live #25 - Przetwarzanie danych w ogromnej skali","date_in_series_pattern":false,"status":"past","time":1647536400000,"local_date":"2022-03-17","local_time":"18:00","updated":1647544907000,"utc_offset":3600000,"waitlist_count":0,"yes_rsvp_count":56,"is_online_event":false,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/284469437/","description":"Wydarzenie przełożone z 24 lutego. OBOWIĄZUJE REJESTRACJA: https://app.evenea.pl/event/allegro-tech-live-25/ Allegro Tech Live to w 100% zdalna odsłona naszych stacjonarnych meetupów Allegro Tech Talks. Kiedyś spotykaliśmy się…","visibility":"public","member_pay_fee":false},{"created":1644580206000,"duration":7200000,"id":"283913049","name":"Allegro Tech Live #25 - Przetwarzanie danych w ogromnej skali","date_in_series_pattern":false,"status":"past","time":1645722000000,"local_date":"2022-02-24","local_time":"18:00","updated":1645733471000,"utc_offset":3600000,"waitlist_count":0,"yes_rsvp_count":104,"is_online_event":false,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/283913049/","description":"Ze względu na obecną sytuację polityczną pewnie dzisiaj wszyscy jesteśmy myślami z mieszkańcami Ukrainy, dlatego postanowiliśmy odwołać dzisiejszy Allegro Tech Live. Obiecujemy, że wrócimy z…","visibility":"public","member_pay_fee":false}],"podcasts":[{"title":"S02E12 - Piotr Betkier - Rola architekta w Allegro","link":"https://podcast.allegro.tech/rola_architekta_w_allegro/","pubDate":"Wed, 16 Jun 2021 00:00:00 GMT","content":"Od kodowania do tworzenia strategii technicznej... Jak wygląda rola architekta w Allegro? Ile takich osób pracuje w naszej firmie i dlaczego ta rola jest tak różnorodna? Czym jest Andamio i jak rozwijamy naszą platformę – o tym wszystkim opowie Piotr Betkier – Inżynier, Architekt Platformy Technicznej w Allegro oraz twórca piosenek o IT :)","contentSnippet":"Od kodowania do tworzenia strategii technicznej... Jak wygląda rola architekta w Allegro? Ile takich osób pracuje w naszej firmie i dlaczego ta rola jest tak różnorodna? Czym jest Andamio i jak rozwijamy naszą platformę – o tym wszystkim opowie Piotr Betkier – Inżynier, Architekt Platformy Technicznej w Allegro oraz twórca piosenek o IT :)","guid":"https://podcast.allegro.tech/rola_architekta_w_allegro/","isoDate":"2021-06-16T00:00:00.000Z"},{"title":"S02E11 - Piotr Michoński - Infrastruktura Allegro","link":"https://podcast.allegro.tech/infrastruktura_Allegro/","pubDate":"Tue, 01 Jun 2021 00:00:00 GMT","content":"Jak jest zbudowane środowisko uruchomienia aplikacji Allegro? Jak działają serwerownie firmy i ile ich potrzeba, a które elementy Allegro działają w chmurze publicznej? Jak przebiegała transformacja w Allegro i co zmieniało się przez lata? Jak wzrost biznesu wpływa na wielkość infrastruktury i jak infrastruktura Allegro odczuła przyjście pandemii? O tym, a także o rozwoju liderów technologii w Allegro oraz o historii powstania dżingla do naszych podcastów, opowie Piotr Michoński - menadżer Zespołów tworzących infrastrukturę Allegro.","contentSnippet":"Jak jest zbudowane środowisko uruchomienia aplikacji Allegro? Jak działają serwerownie firmy i ile ich potrzeba, a które elementy Allegro działają w chmurze publicznej? Jak przebiegała transformacja w Allegro i co zmieniało się przez lata? Jak wzrost biznesu wpływa na wielkość infrastruktury i jak infrastruktura Allegro odczuła przyjście pandemii? O tym, a także o rozwoju liderów technologii w Allegro oraz o historii powstania dżingla do naszych podcastów, opowie Piotr Michoński - menadżer Zespołów tworzących infrastrukturę Allegro.","guid":"https://podcast.allegro.tech/infrastruktura_Allegro/","isoDate":"2021-06-01T00:00:00.000Z"},{"title":"S02E10 - Dariusz Eliasz - Praca architekta ekosystemu big data w Allegro","link":"https://podcast.allegro.tech/praca_architekta_ekosystemu_big_data_w_Allegro/","pubDate":"Thu, 20 May 2021 00:00:00 GMT","content":"Jak wygląda praca architekta ekosystemu big data w Allegro? Jakie zadania realizuje nasz zespół odpowiedzialny za narzędzia i infrastrukturę dla przetwarzania danych? Kiedy możemy mówić o dużych danych i ile petabajtów przetwarza Allegro? Skąd pochodzą dane Allegro i dlaczego jest ich tak dużo oraz z jakiego powodu dopiero teraz przenosimy się do chmury? O tym wszystkim opowie zdobywca statuetki Allegro Tech Hero - Dariusz Eliasz – Team Manager \u0026 Platform Architect w Allegro.","contentSnippet":"Jak wygląda praca architekta ekosystemu big data w Allegro? Jakie zadania realizuje nasz zespół odpowiedzialny za narzędzia i infrastrukturę dla przetwarzania danych? Kiedy możemy mówić o dużych danych i ile petabajtów przetwarza Allegro? Skąd pochodzą dane Allegro i dlaczego jest ich tak dużo oraz z jakiego powodu dopiero teraz przenosimy się do chmury? O tym wszystkim opowie zdobywca statuetki Allegro Tech Hero - Dariusz Eliasz – Team Manager \u0026 Platform Architect w Allegro.","guid":"https://podcast.allegro.tech/praca_architekta_ekosystemu_big_data_w_Allegro/","isoDate":"2021-05-20T00:00:00.000Z"},{"title":"S02E09 - Bartosz Gałek - Od inżyniera do lidera w Allegro","link":"https://podcast.allegro.tech/od_inzyniera_do_lidera_w_allegro/","pubDate":"Thu, 06 May 2021 00:00:00 GMT","content":"Czym jest Opbox i jakie wyzwania przed nim stoją? Jak w Allegro angażujemy się w rozwój kultury Open Source? Ile mamy projektów na GitHubie i jak świętujemy Hacktoberfest? W jaki sposób można rozwinąć się od inżyniera do lidera? Na te pytania w najnowszym Allegro Tech Podcast odpowie Bartek Gałek, Team Leader w Allegro.","contentSnippet":"Czym jest Opbox i jakie wyzwania przed nim stoją? Jak w Allegro angażujemy się w rozwój kultury Open Source? Ile mamy projektów na GitHubie i jak świętujemy Hacktoberfest? W jaki sposób można rozwinąć się od inżyniera do lidera? Na te pytania w najnowszym Allegro Tech Podcast odpowie Bartek Gałek, Team Leader w Allegro.","guid":"https://podcast.allegro.tech/od_inzyniera_do_lidera_w_allegro/","isoDate":"2021-05-06T00:00:00.000Z"}]},"__N_SSG":true},"page":"/","query":{},"buildId":"5O5PfW0B7gehiXUxIndCZ","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>