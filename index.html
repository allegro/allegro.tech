<!DOCTYPE html><html lang="pl"><head><meta charSet="utf-8"/><link rel="prefetch" href="https://allegrotechio.disqus.com/count.js"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta name="description" content="Allegro Tech to miejsce, w którym nasi inżynierowie dzielą się wiedzą oraz case study z wybranych projektów w firmie - w formie artykułów, podcastów oraz eventów."/><title>Allegro Tech</title><meta property="og:site_name" content="allegro.tech"/><meta property="og:title" content="allegro.tech"/><meta property="og:url" content="https://allegro.tech"/><meta property="og:type" content="site"/><meta property="og:image" content="https://allegro.tech/images/allegro-tech.png"/><link rel="shortcut icon" href="favicon.ico"/><link rel="canonical" href="https://allegro.tech" itemProp="url"/><link rel="preload" href="images/splash.jpg" as="image"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-1M1FJ5PXWW"></script><script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){dataLayer.push(arguments);}
                    gtag('js', new Date());
                    gtag('config', 'G-1M1FJ5PXWW');
                </script><meta name="next-head-count" content="15"/><link rel="preload" href="/_next/static/css/66933eaa547aae51.css" as="style"/><link rel="stylesheet" href="/_next/static/css/66933eaa547aae51.css" data-n-g=""/><link rel="preload" href="/_next/static/css/79db8b1e27b0a093.css" as="style"/><link rel="stylesheet" href="/_next/static/css/79db8b1e27b0a093.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-69bfa6990bb9e155.js" defer=""></script><script src="/_next/static/chunks/framework-e70c6273bfe3f237.js" defer=""></script><script src="/_next/static/chunks/main-f635b472c367d1c7.js" defer=""></script><script src="/_next/static/chunks/pages/_app-179adf437ae674f2.js" defer=""></script><script src="/_next/static/chunks/206-3a56e5ded293e83e.js" defer=""></script><script src="/_next/static/chunks/pages/index-f037c91132ed6a0a.js" defer=""></script><script src="/_next/static/Iiqoilz9LV1eXVRDdWcZX/_buildManifest.js" defer=""></script><script src="/_next/static/Iiqoilz9LV1eXVRDdWcZX/_ssgManifest.js" defer=""></script><script src="/_next/static/Iiqoilz9LV1eXVRDdWcZX/_middlewareManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><header class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card Header_navbar__Zc5aN m-color-bg_card"><nav class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-display-flex m-flex-justify-between m-flex-items-center"><a href="/"><img src="images/logo.svg" alt="Allegro Tech" width="205" height="45"/></a><div><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0 m-display-flex@lg m-display-none"><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://blog.allegro.tech">Blog</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://ml.allegro.tech">Machine Learning</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://podcast.allegro.tech">Podcast</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://github.com/Allegro">Open Source</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://www.meetup.com/allegrotech/events">Wydarzenia</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://praca.allegro.pl">Praca</a></li></ul><button class="m-display-none@lg m-height_40 m-line-height_40 m-border-style-top_none m-border-style-right_none m-border-style-bottom_none m-border-style-left_none m-border-radius-top-left_2 m-border-radius-top-right_2 m-border-radius-bottom-left_2 m-border-radius-bottom-right_2 m-cursor_pointer m-overflow_hidden m-appearance_none m-padding-left_4 m-padding-right_4 m-padding-top_4 m-padding-bottom_4 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button" style="background:transparent" aria-label="Otwórz menu"><img src="https://assets.allegrostatic.com/metrum/icon/menu-23e046bf68.svg" alt="" class="m-icon" width="32" height="32"/></button></div></nav></header><div class="Header_hero__PYE0B"><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-display-flex m-flex-column m-flex-justify-end Header_image__Cj6ZF"><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-color-bg_desk"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text  m-font-weight_100 m-font-size_32 m-font-size_43_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125">O nas</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">Allegro to jedna z najbardziej zaawansowanych technologicznie firm w naszej części Europy. Allegro to również ponad 1000 specjalistów IT, różnych specjalizacji, rozwijających nasz serwis. Unikatowa skala i złożoność problemów, które rozwiązujemy na co dzień, dają nam możliwość rozwoju przy bardzo różnorodnych projektach. Allegro Tech to miejsce, w którym nasi inżynierowie dzielą się wiedzą oraz case study z wybranych projektów w firmie – w formie artykułów, podcastów oraz eventów.</p></div></div></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24">Blog</h2><div class="m-display_flex m-flex-wrap_1 m-flex-grow_1 m-grid"><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://blog.allegro.tech/2022/09/example-of-modularization-in-allegro-pay-android-application.html" title="Example of modularization in Allegro Pay Android application"><img width="388" src="images/post-headers/default.jpg" alt="Example of modularization in Allegro Pay Android application" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://blog.allegro.tech/2022/09/example-of-modularization-in-allegro-pay-android-application.html" title="Example of modularization in Allegro Pay Android application" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Example of modularization in Allegro Pay Android application</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">dzień temu</time><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0"><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/tech">#<!-- -->tech</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/kotlin">#<!-- -->kotlin</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/mobile">#<!-- -->mobile</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/android">#<!-- -->android</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/modularization">#<!-- -->modularization</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/gradle">#<!-- -->gradle</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/allegro-pay">#<!-- -->allegro-pay</a></li></ul><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1 m-padding-top-16">Currently, in the Android world, the topic of modularization is very popular. Many bloggers describe their experiences
with it and analyze what Google recommends. Our team
started…</p><div class="m-display-flex m-flex-justify-between m-padding-top-16 m-flex-items_center"><div class="m-display-flex m-flex-items_center"><div class="MuiAvatarGroup-root m-padding-right_16 Post_avatars__FHMgb"><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar" style="z-index:1"><img alt="Michał Kwiatek" src="https://blog.allegro.tech/img/authors/michal.kwiatek.jpg" class="MuiAvatar-img" width="32" height="32"/></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/authors/michal.kwiatek">Michał Kwiatek</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/2022/09/example-of-modularization-in-allegro-pay-android-application.html#disqus_thread">0 Comments</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech/2022/09/example-of-modularization-in-allegro-pay-android-application.html">przejdź do wpisu</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://blog.allegro.tech/2022/09/azure-cosmosdb-case-study.html" title="How to efficiently write millions of records in the cloud and not go bankrupt — an Azure CosmosDB case study"><img width="388" src="images/post-headers/default.jpg" alt="How to efficiently write millions of records in the cloud and not go bankrupt — an Azure CosmosDB case study" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://blog.allegro.tech/2022/09/azure-cosmosdb-case-study.html" title="How to efficiently write millions of records in the cloud and not go bankrupt — an Azure CosmosDB case study" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">How to efficiently write millions of records in the cloud and not go bankrupt — an Azure CosmosDB case study</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">15 dni temu</time><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0"><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/tech">#<!-- -->tech</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/cloud">#<!-- -->cloud</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/azure">#<!-- -->azure</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/cosmosdb">#<!-- -->cosmosdb</a></li></ul><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1 m-padding-top-16">Cloud providers like to brag about high availability and unlimited scaling of their services – and they are correct,
as these features are indeed significant advantages…</p><div class="m-display-flex m-flex-justify-between m-padding-top-16 m-flex-items_center"><div class="m-display-flex m-flex-items_center"><div class="MuiAvatarGroup-root m-padding-right_16 Post_avatars__FHMgb"><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar" style="z-index:1"><img alt="Kamil Starczak" src="https://blog.allegro.tech/img/authors/kamil.starczak.jpg" class="MuiAvatar-img" width="32" height="32"/></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/authors/kamil.starczak">Kamil Starczak</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/2022/09/azure-cosmosdb-case-study.html#disqus_thread">0 Comments</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech/2022/09/azure-cosmosdb-case-study.html">przejdź do wpisu</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://blog.allegro.tech/2022/08/mbox-server-driven-ui-for-mobile-apps.html" title="MBox: server-driven UI for mobile apps"><img width="388" src="images/post-headers/default.jpg" alt="MBox: server-driven UI for mobile apps" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://blog.allegro.tech/2022/08/mbox-server-driven-ui-for-mobile-apps.html" title="MBox: server-driven UI for mobile apps" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">MBox: server-driven UI for mobile apps</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">około 2 miesiące temu</time><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0"><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/tech">#<!-- -->tech</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/Server-driven UI">#<!-- -->Server-driven UI</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/mobile">#<!-- -->mobile</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/mbox">#<!-- -->mbox</a></li></ul><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1 m-padding-top-16">In this article, we want to share our approach to using server-driven UI in native mobile apps. In 2019 we created the
first version of the…</p><div class="m-display-flex m-flex-justify-between m-padding-top-16 m-flex-items_center"><div class="m-display-flex m-flex-items_center"><div class="MuiAvatarGroup-root m-padding-right_16 Post_avatars__FHMgb"><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar" style="z-index:1"><img alt="Paulina Sadowska" src="https://blog.allegro.tech/img/authors/paulina.sadowska.jpg" class="MuiAvatar-img" width="32" height="32"/></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/authors/paulina.sadowska">Paulina Sadowska</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/2022/08/mbox-server-driven-ui-for-mobile-apps.html#disqus_thread">0 Comments</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech/2022/08/mbox-server-driven-ui-for-mobile-apps.html">przejdź do wpisu</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://blog.allegro.tech/2022/07/event-storming-workshops.html" title="How to facilitate EventStorming workshops"><img width="388" src="images/post-headers/eventstorming.png" alt="How to facilitate EventStorming workshops" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://blog.allegro.tech/2022/07/event-storming-workshops.html" title="How to facilitate EventStorming workshops" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">How to facilitate EventStorming workshops</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">2 miesiące temu</time><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0"><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/eventstorming">#<!-- -->eventstorming</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/tech">#<!-- -->tech</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/communication">#<!-- -->communication</a></li></ul><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1 m-padding-top-16">With this article, I would like to introduce you to EventStorming and explain to you how to get started. I am not discovering
anything new, just…</p><div class="m-display-flex m-flex-justify-between m-padding-top-16 m-flex-items_center"><div class="m-display-flex m-flex-items_center"><div class="MuiAvatarGroup-root m-padding-right_16 Post_avatars__FHMgb"><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar" style="z-index:1"><img alt="Krzysztof Przychodzki" src="https://blog.allegro.tech/img/authors/krzysztof.przychodzki.jpg" class="MuiAvatar-img" width="32" height="32"/></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/authors/krzysztof.przychodzki">Krzysztof Przychodzki</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/2022/07/event-storming-workshops.html#disqus_thread">0 Comments</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech/2022/07/event-storming-workshops.html">przejdź do wpisu</a></div></article></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display_block m-margin-bottom_8 m-width_100 m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech">Zobacz więcej wpisów</a></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24">Podcasty</h2><div class="m-display_flex m-flex-wrap_1 m-flex-grow_1 m-grid"><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://podcast.allegro.tech/o-data-i-ai-w-allegro-pay/" title="S03E03 - Paweł Marcinkowski - O Data &amp; AI w Allegro Pay"><img src="images/podcast.png" alt="S03E03 - Paweł Marcinkowski - O Data &amp; AI w Allegro Pay" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://podcast.allegro.tech/o-data-i-ai-w-allegro-pay/" title="S03E03 - Paweł Marcinkowski - O Data &amp; AI w Allegro Pay" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">S03E03 - Paweł Marcinkowski - O Data &amp; AI w Allegro Pay</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">5 dni temu</time><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1">Jak zbudowany jest obszar Data &amp; AI w Allegro Pay i jak (współ)pracują w nim ze sobą poszczególne role oraz zespoły? Jak działa decision engine, kluczowy komponent, od którego zależy sukces Allegro Pay? Jak wyglądałby proces wprowadzenia zupełnie nowej funkcjonalności lub nowego produktu w Allegro Pay? Kim jest i za co odpowiada Data Product Manager? Jak w modelach Machine Learning do predykcji ryzyka kredytowego Allegro Pay wykorzystuje kontekst otoczenia? Na te i inne pytania związane z pracą w największym fintechu w Europie Środkowej odpowiada Paweł Marcinkowski - lider obszaru Data &amp; AI w Allegro Pay.</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech/o-data-i-ai-w-allegro-pay/">Posłuchaj odcinka</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://podcast.allegro.tech/o-tym-jak-powstawaly-zielone-automaty-paczkowe-allegro-one-box/" title="S03E02 - Barbara Kaczorek, Jakub Kwietko - O tym jak powstawały zielone automaty paczkowe Allegro One Box"><img src="images/podcast.png" alt="S03E02 - Barbara Kaczorek, Jakub Kwietko - O tym jak powstawały zielone automaty paczkowe Allegro One Box" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://podcast.allegro.tech/o-tym-jak-powstawaly-zielone-automaty-paczkowe-allegro-one-box/" title="S03E02 - Barbara Kaczorek, Jakub Kwietko - O tym jak powstawały zielone automaty paczkowe Allegro One Box" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">S03E02 - Barbara Kaczorek, Jakub Kwietko - O tym jak powstawały zielone automaty paczkowe Allegro One Box</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">19 dni temu</time><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1">Jak wyglądała współpraca ponad 350 osób przy tak dużym i złożonym projekcie jak uruchomienie Allegro One Box?  Z jakimi wyzwaniami zmierzyły się osoby, które przy nim pracowały? Jak można mierzyć efekty swojej pracy w projektach takich, jak ten? Dlaczego Product Manager musi czasem siedzieć z laptopem za prototypem urządzenia? Na te i inne pytania odpowiadają Barbara Kaczorek - Product Manager w obszarze Delivery Experience w Allegro i Jakub Kwietko - lider zespołów developerskich OpenNet zaangażowanych w powstawanie Allegro One Box. Dobrze wiedzieć: OpenNet to wiodący dostawca rozwiązań technologicznych dla branży logistycznej w Polsce i za granicą, od 2021 roku jest częścią Grupy Allegro.</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech/o-tym-jak-powstawaly-zielone-automaty-paczkowe-allegro-one-box/">Posłuchaj odcinka</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://podcast.allegro.tech/o-quality-assurance-w-allegro/" title="S03E01 - Ewa Ludwiczak - O Quality Assurance w Allegro"><img src="images/podcast.png" alt="S03E01 - Ewa Ludwiczak - O Quality Assurance w Allegro" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://podcast.allegro.tech/o-quality-assurance-w-allegro/" title="S03E01 - Ewa Ludwiczak - O Quality Assurance w Allegro" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">S03E01 - Ewa Ludwiczak - O Quality Assurance w Allegro</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">około miesiąc temu</time><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1">Na czym polega rola testera w Allegro? Dlaczego testerzy w Allegro są blisko technologii i produktu? Jak może rozwinąć się kariera testera, gdzie szukać aktualnej wiedzy i kim jest “Full Stack Tester”? Czy pierwsze kroki w branży IT muszą być trudne i jak programowania uczą się dzieci? Na te i inne pytania odpowiada Ewa Ludwiczak - liderka i testerka w Allegro.</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech/o-quality-assurance-w-allegro/">Posłuchaj odcinka</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://podcast.allegro.tech/rola_architekta_w_allegro/" title="S02E12 - Piotr Betkier - Rola architekta w Allegro"><img src="images/podcast.png" alt="S02E12 - Piotr Betkier - Rola architekta w Allegro" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://podcast.allegro.tech/rola_architekta_w_allegro/" title="S02E12 - Piotr Betkier - Rola architekta w Allegro" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">S02E12 - Piotr Betkier - Rola architekta w Allegro</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">ponad rok temu</time><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1">Od kodowania do tworzenia strategii technicznej... Jak wygląda rola architekta w Allegro? Ile takich osób pracuje w naszej firmie i dlaczego ta rola jest tak różnorodna? Czym jest Andamio i jak rozwijamy naszą platformę – o tym wszystkim opowie Piotr Betkier – Inżynier, Architekt Platformy Technicznej w Allegro oraz twórca piosenek o IT :)</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech/rola_architekta_w_allegro/">Posłuchaj odcinka</a></div></article></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display_block m-margin-bottom_8 m-width_100 m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech">Zobacz więcej podcastów</a></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24">Wydarzenia</h2><div class="m-display_flex m-flex-wrap_1 m-flex-grow_1 m-grid"><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--6@xl m-display-flex m-flex-direction_column"><div class="m-margin-bottom_16 m-display-flex m-flex-direction_column m-flex-direction_row_sm m-padding-bottom_0"><a href="https://www.meetup.com/allegrotech/events/288748190/" title="Allegro Tech Talk #30 - Toruń" class="m-display_none m-display_block_lg" style="background-color:#fd4a02"><img width="218" src="images/event.png" alt="Allegro Tech Talk #30 - Toruń"/></a><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-direction_column m-padding-bottom_0 m-flex_1 m-flex-justify_between m-color-bg_card"><a href="https://www.meetup.com/allegrotech/events/288748190/" title="Allegro Tech Talk #30 - Toruń" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Allegro Tech Talk #30 - Toruń</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">za 16 dni</time><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-top-8">**➡ Obowiązkowa rejestracja na udział offline:** [https://app.evenea.pl/event/allegro-tech-talk-30](https://app.evenea.pl/event/allegro-tech-talk-30) Mamy dla Was dobrą wiadomość! Wracamy do stacjonarnych spotkań Allegro Tech Talks, na których dzielimy się wiedzą, wzajemnie…</time><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/288748190/">Szczegóły</a></article></div></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--6@xl m-display-flex m-flex-direction_column"><div class="m-margin-bottom_16 m-display-flex m-flex-direction_column m-flex-direction_row_sm m-padding-bottom_0"><a href="https://www.meetup.com/allegrotech/events/287035383/" title="Allegro Tech Labs #10 Online: Poskromić stan w React" class="m-display_none m-display_block_lg" style="background-color:#fd4a02"><img width="218" src="images/event.png" alt="Allegro Tech Labs #10 Online: Poskromić stan w React"/></a><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-direction_column m-padding-bottom_0 m-flex_1 m-flex-justify_between m-color-bg_card"><a href="https://www.meetup.com/allegrotech/events/287035383/" title="Allegro Tech Labs #10 Online: Poskromić stan w React" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Allegro Tech Labs #10 Online: Poskromić stan w React</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">2 miesiące temu</time><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-top-8">❗NA WYDARZENIE OBOWIĄZUJE REJESTRACJA: Liczba miejsc jest organiczona: [https://app.evenea.pl/event/allegro-tech-labs-10/](https://app.evenea.pl/event/allegro-tech-labs-10/?fbclid=IwAR1Zj3sIcfx3WEWiFfS_hgiW6BJQD6stYouSGuSqfxDq9YVeom8fTFcrE1Q) ❗ **Allegro Tech Labs** to w 100% zdalna odsłona naszych stacjonarnych spotkań warsztatowych. Zazwyczaj spotykaliśmy się…</time><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/287035383/">Szczegóły</a></article></div></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--6@xl m-display-flex m-flex-direction_column"><div class="m-margin-bottom_16 m-display-flex m-flex-direction_column m-flex-direction_row_sm m-padding-bottom_0"><a href="https://www.meetup.com/allegrotech/events/286545395/" title="Allegro Tech Live #29 - Wyzwania Product Managera" class="m-display_none m-display_block_lg" style="background-color:#fd4a02"><img width="218" src="images/event.png" alt="Allegro Tech Live #29 - Wyzwania Product Managera"/></a><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-direction_column m-padding-bottom_0 m-flex_1 m-flex-justify_between m-color-bg_card"><a href="https://www.meetup.com/allegrotech/events/286545395/" title="Allegro Tech Live #29 - Wyzwania Product Managera" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Allegro Tech Live #29 - Wyzwania Product Managera</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">3 miesiące temu</time><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-top-8">Allegro Tech Live to w 100% zdalna odsłona naszych stacjonarnych meetupów Allegro Tech Talks. Zazwyczaj spotykaliśmy się w naszych biurach, ale tym razem to my…</time><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/286545395/">Szczegóły</a></article></div></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--6@xl m-display-flex m-flex-direction_column"><div class="m-margin-bottom_16 m-display-flex m-flex-direction_column m-flex-direction_row_sm m-padding-bottom_0"><a href="https://www.meetup.com/allegrotech/events/285416318/" title="UX Research Confetti - II edycja" class="m-display_none m-display_block_lg" style="background-color:#fd4a02"><img width="218" src="images/event.png" alt="UX Research Confetti - II edycja"/></a><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-direction_column m-padding-bottom_0 m-flex_1 m-flex-justify_between m-color-bg_card"><a href="https://www.meetup.com/allegrotech/events/285416318/" title="UX Research Confetti - II edycja" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">UX Research Confetti - II edycja</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">4 miesiące temu</time><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-top-8">REJESTRACJA NA WYDARZENIE -&amp;gt; https://app.evenea.pl/event/ux-research-confetti-2/ 🎉 Niech ponownie rozsypie się confetti wiedzy o badaniach UX! 🎉 Szukaliśmy konferencji badawczej UX w Polsce i nie znaleźliśmy……</time><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/285416318/">Szczegóły</a></article></div></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display_block m-margin-bottom_8 m-width_100 m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/">Zobacz więcej wydarzeń</a></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24">Oferty pracy</h2><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto"></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display_block m-margin-bottom_8 m-width_100 m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://allegro.pl/praca">Zobacz więcej ofert</a></div><footer class="m-color-bg_navy m-margin-top-32"><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24 m-padding-bottom-24 m-display-flex@sm m-flex-justify-between m-flex-items-center m-text-align_center"><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-color_white m-padding-left-24@sm">Proudly built by Allegro Tech engineers</p><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0 m-display-flex m-flex-justify-center"><li style="filter:brightness(0) invert(1);opacity:0.5" class="m-margin-right-8 m-margin-top-16 m-margin-top-0@sm m-color_white"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://github.com/allegro"><img src="https://assets.allegrostatic.com/metrum/icon/github-6a18df1729.svg" alt="Github" class="m-icon"/></a></li><li style="filter:brightness(0) invert(1);opacity:0.5" class="m-margin-right-8 m-margin-top-16 m-margin-top-0@sm m-color_white"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://www.facebook.com/allegro.tech/"><img src="https://assets.allegrostatic.com/metrum/icon/facebook-a2b92f9dcb.svg" alt="Facebook" class="m-icon"/></a></li><li style="filter:brightness(0) invert(1);opacity:0.5" class="m-margin-right-8 m-margin-top-16 m-margin-top-0@sm m-color_white"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/allegrotech"><img src="https://assets.allegrostatic.com/metrum/icon/twitter-25164a58aa.svg" alt="Twitter" class="m-icon"/></a></li></ul></div></footer><div style="visibility:hidden;height:0;overflow:hidden;position:relative"><img alt="doubleclick" width="1" height="1" style="position:absolute" src="https://pubads.g.doubleclick.net/activity;dc_iu=/21612525419/DFPAudiencePixel;ord=2698963201385.014;dc_seg=507368552?"/><img alt="fb" height="1" width="1" style="position:absolute" src="https://www.facebook.com/tr?id=1650870088530325&amp;ev=PageView&amp;noscript=1"/></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"Example of modularization in Allegro Pay Android application","link":"https://blog.allegro.tech/2022/09/example-of-modularization-in-allegro-pay-android-application.html","pubDate":"Mon, 26 Sep 2022 00:00:00 +0200","authors":{"author":[{"name":["Michał Kwiatek"],"photo":["https://blog.allegro.tech/img/authors/michal.kwiatek.jpg"],"url":["https://blog.allegro.tech/authors/michal.kwiatek"]}]},"content":"\u003cp\u003eCurrently, in the Android world, the topic of modularization is very popular. Many bloggers describe their experiences\nwith it and analyze what \u003ca href=\"https://developer.android.com/topic/modularization/patterns\"\u003eGoogle recommends\u003c/a\u003e. Our team\nstarted the modularization process before it was hot. I will describe our reasons, decisions, problems and give you some\nadvice. We will see if modularization makes sense and what it brings to the table. I will also post some statistics\nshowing what it looked like before and after the modularization process.\u003c/p\u003e\n\n\u003ch2 id=\"some-theory\"\u003eSome theory\u003c/h2\u003e\n\n\u003ch3 id=\"module\"\u003eModule\u003c/h3\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003eA \u003ca href=\"https://developer.android.com/studio/projects#:~:text=inside%20your%20project.-,Modules,test%2C%20and%20debug%20each%20module\"\u003emodule\u003c/a\u003e\nis a collection of source files and build settings that allow you to divide your project into discrete units of\nfunctionality. Your project can have one or many modules, and one module may use another module as a dependency. You can\nindependently build, test, and debug each module.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch3 id=\"background\"\u003eBackground\u003c/h3\u003e\n\n\u003cp\u003eAllegro Pay is a payment method on Allegro that allows you to postpone the payment by 30 days or divide it into smaller\nparts. People who use Allegro Pay know how many functionalities it has, those who don’t use it yet will know after\nreading this article. It started from 3 modules. At the time of writing this article the Allegro application for the\nAndroid platform consists of over 120 modules, 9 of which are maintained by Allegro Pay Team. In this quarter, we\nfocused on extracting several domains (features) from the main Allegro Pay module into separate, smaller and specialized\nmodules.\u003c/p\u003e\n\n\u003ch2 id=\"what-made-us-start-the-modularization-process\"\u003eWhat made us start the modularization process?\u003c/h2\u003e\n\n\u003cp\u003eThe main reason for the modularization process was the build time of one of these 3 modules — containing the entire\nAllegro Pay domain. Our internal monitoring tools showed that build times started to average 100 seconds, and at their\nworst point grew to just over 120 seconds. The module contains over 40k LoC (lines of code). In addition, we faced\nproblems when introducing changes, such as conflicts or the possibility of accidental modification of another\nfunctionality.\n\u003cimg src=\"/img/articles/2022-09-26-example-of-modularization-in-allegro-pay-android-application/before_both.png\" alt=\"Build time in seconds and LoC.\" /\u003e\u003c/p\u003e\n\n\u003ch3 id=\"cheat\"\u003eCheat\u003c/h3\u003e\n\n\u003cp\u003eI mention the build time for a reason. In our case, in a multi-module project, we use some Gradle instructions. Our\n\u003ccode class=\"language-plaintext highlighter-rouge\"\u003egradle.properties\u003c/code\u003e file looks something like this:\u003c/p\u003e\n\n\u003cdiv class=\"language-groovy highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"c1\"\u003e// some instructions\u003c/span\u003e\n\u003cspan class=\"n\"\u003eorg\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003egradle\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eparallel\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003etrue\u003c/span\u003e\n\u003cspan class=\"n\"\u003eorg\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003egradle\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003econfigureondemand\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003etrue\u003c/span\u003e\n\u003cspan class=\"n\"\u003eorg\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003egradle\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003ecaching\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"kc\"\u003etrue\u003c/span\u003e\n\u003cspan class=\"c1\"\u003e// more instructions\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eThe first instruction\nenables \u003ca href=\"https://docs.gradle.org/current/userguide/performance.html#parallel_execution\"\u003eparallelization\u003c/a\u003e\nso that Gradle can perform more than one task at a time as long as the tasks are in different modules. The second one\nallows you to\n\u003ca href=\"https://docs.gradle.org/current/userguide/multi_project_configuration_and_execution.html#sec:configuration_on_demand\"\u003econfigure modules\u003c/a\u003e\nthat are relevant only to the task you want, rather than configuring them all, which is the default behavior.\nImportantly, this instruction should be used for multi-module projects. And the last one is\n\u003ca href=\"https://docs.gradle.org/current/userguide/build_cache.html\"\u003ecaching\u003c/a\u003e. It is „a cache mechanism that aims to save time\nby reusing outputs produced by other builds. The build cache works by storing (locally or remotely) build outputs and\nallowing builds to fetch these outputs from the cache when it is determined that inputs have not changed, avoiding the\nexpensive work of regenerating them.” By default, the build cache is disabled.\u003c/p\u003e\n\n\u003ch2 id=\"refinement-decisions-and-plans\"\u003eRefinement, decisions and plans\u003c/h2\u003e\n\n\u003cp\u003eAt one of the weekly meetings, we discussed how to solve the problem of the growing module and the increasing number of\ndependencies and functionalities. We decided that the best way would be to extract several domains (features) into\nseparate modules. Every new module should contain the implemented part of the domain that it represents according to the\nname and a small contract module that can be attached to other modules in order to provide them with the implemented\nfunctionality. So, we have planned the following modules:\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003eais (a banking service that isn’t relevant in the context of this article) with contract module,\u003c/li\u003e\n  \u003cli\u003ecommon,\u003c/li\u003e\n  \u003cli\u003econsolidation with contract module,\u003c/li\u003e\n  \u003cli\u003eonboarding with contract module,\u003c/li\u003e\n  \u003cli\u003eoverpayment with contract module,\u003c/li\u003e\n  \u003cli\u003erepayment with contract module.\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch2 id=\"contract\"\u003eContract\u003c/h2\u003e\n\n\u003cp\u003eThe contract is a special module containing all the necessary interfaces, classes and methods that allow you to use the\nfunctionality in other places in an easy way. It is defined inside the module containing the functionality\nimplementation. It should be emphasized here that the implementation module can only be based on a contract. This\nsolution means that every developer working on the project knows where to find the necessary information and interfaces\nto run any feature.\u003c/p\u003e\n\n\u003cdiv class=\"language-kotlin highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"kd\"\u003einterface\u003c/span\u003e \u003cspan class=\"nc\"\u003eAllegroPaySomeProcessHandler\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003efun\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreateSomeIntent\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003econtext\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eContext\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esomeId\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eString\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eotherData\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eOtherData\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e \u003cspan class=\"nc\"\u003eIntent\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003efun\u003c/span\u003e \u003cspan class=\"nf\"\u003eobserveSomeResult\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e \u003cspan class=\"nc\"\u003eObservable\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nc\"\u003eSomeResultEvent\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cdiv class=\"language-kotlin highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003einternal\u003c/span\u003e \u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eAllegroPaySomeProcessHandlerImpl\u003c/span\u003e \u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eAllegroPaySomeProcessHandler\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003eoverride\u003c/span\u003e \u003cspan class=\"k\"\u003efun\u003c/span\u003e \u003cspan class=\"nf\"\u003ecreateSomeIntent\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003econtext\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eContext\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esomeId\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eString\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eotherData\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eOtherData\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e \u003cspan class=\"nc\"\u003eIntent\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e\n        \u003cspan class=\"nc\"\u003eSomeActivity\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003egetIntent\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003econtext\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003esomeId\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eotherData\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003eoverride\u003c/span\u003e \u003cspan class=\"k\"\u003efun\u003c/span\u003e \u003cspan class=\"nf\"\u003eobserveSomeResult\u003c/span\u003e\u003cspan class=\"p\"\u003e():\u003c/span\u003e \u003cspan class=\"nc\"\u003eObservable\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nc\"\u003eSomeResultEvent\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e\n        \u003cspan class=\"nc\"\u003eDataBus\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003elisten\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"nc\"\u003eSomeResultEvent\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"k\"\u003eclass\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003ejava\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eThe above example shows what one of the assumptions of object-oriented programming — encapsulation — looks like in\npractice. The \u003cem\u003eAllegroPaySomeProcessHandler\u003c/em\u003e interface provides two methods, one of them creates\nthe \u003ca href=\"https://developer.android.com/reference/android/content/Intent\"\u003eIntent\u003c/a\u003e necessary to run the process, and the other\nobserves its result. The exact implementation is hidden in an internal class, not accessible from the contract module.\nEvery change of interface implementation is transparent to contract clients. Example of how to declare a dependency on a\ncontract:\u003c/p\u003e\n\n\u003cdiv class=\"language-kotlin highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"nf\"\u003edependencies\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eimplementation\u003c/span\u003e \u003cspan class=\"nf\"\u003eproject\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"err\"\u003e'\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"n\"\u003eallegropay-some\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"n\"\u003econtract\u003c/span\u003e\u003cspan class=\"err\"\u003e'\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch2 id=\"tool\"\u003eTool\u003c/h2\u003e\n\n\u003cp\u003eThe Allegro application consists of many modules and it is important to provide programmers with the right tools to work\neffectively. In the organization, the delivery of this type of tools is handled by the core team. A tool that allows us\nto check whether our module meets the requirement set for it is\nthe \u003ca href=\"https://github.com/jraska/modules-graph-assert\"\u003eModule Graph Assert\u003c/a\u003e. It is a Gradle plugin which „helps keep your\nmodule graph healthy and lean.” This tool defines the types of modules that are allowed in the application, the\ndependencies between them and the height of the dependency tree. The following types are defined in the Allegro\napplication: \u003cem\u003eApp\u003c/em\u003e, \u003cem\u003eFeature\u003c/em\u003e, \u003cem\u003eContract\u003c/em\u003e, \u003cem\u003eLibrary\u003c/em\u003e, \u003cem\u003eUtil\u003c/em\u003e and \u003cem\u003eNeedsMigration\u003c/em\u003e. The last type tells us that the\nmodule still requires work from its owners and appropriate adaptation to one of the other types. We can also define\nallowed and restricted dependencies between modules, e.g. a contract may depend only on another contract or a module\nmarked as a feature depends only on the contract or library. Allegro app configuration:\u003c/p\u003e\n\n\u003cdiv class=\"language-groovy highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"n\"\u003emoduleGraphAssert\u003c/span\u003e \u003cspan class=\"o\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"n\"\u003emaxHeight\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e5\u003c/span\u003e\n    \u003cspan class=\"n\"\u003eallowed\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"o\"\u003e[\u003c/span\u003e\n        \u003cspan class=\"s1\"\u003e'App -\u0026gt; Feature'\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e\n        \u003cspan class=\"s1\"\u003e'App -\u0026gt; Library'\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e\n        \u003cspan class=\"s1\"\u003e'App -\u0026gt; Util'\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e\n        \u003cspan class=\"s1\"\u003e'App -\u0026gt; Contract'\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e\n        \u003cspan class=\"s1\"\u003e'Feature -\u0026gt; Library'\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e\n        \u003cspan class=\"s1\"\u003e'Feature -\u0026gt; Util'\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e\n        \u003cspan class=\"s1\"\u003e'Feature -\u0026gt; Contract'\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e\n        \u003cspan class=\"s1\"\u003e'Contract -\u0026gt; Contract'\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e\n        \u003cspan class=\"s1\"\u003e'NeedsMigration -\u0026gt; .*'\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e\n        \u003cspan class=\"s1\"\u003e'.* -\u0026gt; NeedsMigration'\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"o\"\u003e]\u003c/span\u003e\n    \u003cspan class=\"n\"\u003erestricted\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"o\"\u003e[\u003c/span\u003e\n        \u003cspan class=\"s1\"\u003e'Contract -X\u0026gt; NeedsMigration'\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e\n        \u003cspan class=\"s1\"\u003e'Library -X\u0026gt; .*'\u003c/span\u003e\n    \u003cspan class=\"o\"\u003e]\u003c/span\u003e\n\u003cspan class=\"o\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch2 id=\"initial-modules\"\u003eInitial modules\u003c/h2\u003e\n\n\u003cp\u003eThe first separated feature module was overpayment. We immediately prepared a common module containing functionalities\nused in more than one Allegro Pay module. The contract that is shown earlier contains one method returning an Intent\nneeded to run the overpayment process. The feature module includes user-visible screens, use cases and network\ncommunication. Several thousand lines of code were added to this module and the time needed to build the main Allegro\nPay module was shortened. At that time, the build time of the main module was around 87.5 seconds, common and\noverpayment modules around 10.5 seconds.\n\u003cimg src=\"/img/articles/2022-09-26-example-of-modularization-in-allegro-pay-android-application/first_modules_both.png\" alt=\"Build time in seconds and LoC.\" /\u003e\u003c/p\u003e\n\n\u003ch2 id=\"following-modules\"\u003eFollowing modules\u003c/h2\u003e\n\n\u003cp\u003eIn the next stages, we separated the ais, consolidation and repayment modules. The current values of the build times of\nindividual modules are around 33.7 seconds for the Allegro Pay main module, 13.4 seconds for the ais, 12 seconds for the\nconsolidation, 10.6 seconds for the repayment. The extraction process was analogous to that of the first module.\n\u003cimg src=\"/img/articles/2022-09-26-example-of-modularization-in-allegro-pay-android-application/few_both.png\" alt=\"Build time in seconds and LoC.\" /\u003e\u003c/p\u003e\n\n\u003ch2 id=\"onboarding-module\"\u003eOnboarding module\u003c/h2\u003e\n\n\u003cp\u003eThis module was the most challenging and possibly the most time consuming. This was due to the combination of the\nprocess being available from multiple screens in different modules and ensuring unchanged functionality. During this\nmodularization process, we discovered the possibility of optimizing and reducing the amount of code. This module\ncontains approximately 10k LoC and the build time is less than 20 seconds. It is a really huge module.\n\u003cimg src=\"/img/articles/2022-09-26-example-of-modularization-in-allegro-pay-android-application/onboarding_both.png\" alt=\"Build time in seconds and LoC.\" /\u003e\u003c/p\u003e\n\n\u003ch2 id=\"other-two-modules\"\u003eOther two modules\u003c/h2\u003e\n\n\u003cp\u003eIf you remember, I mentioned three modules at the beginning of this text. So far, I have described the division of the\nlargest module. Let me now describe others in more detail. The first is the special analytical module. Includes an\nexternal library and a small contract. It was created at the same time as the main Allegro Pay module. The current value\nof the build time is 3 seconds and the module has more than 150 lines of code.\n\u003cimg src=\"/img/articles/2022-09-26-example-of-modularization-in-allegro-pay-android-application/sms_both.png\" alt=\"Build time in seconds and LoC.\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eThe second is the SMS verification module. It contains a functionality that allows users to authorize operations by\nproviding SMS code. Currently, it is used in the processes of buying, consolidation, onboarding and overpayment. We only\nwrote a contract here, which provides a universal and easy interface. The build time is approximately 9 seconds and the\nmodule contains almost 2k lines of code.\n\u003cimg src=\"/img/articles/2022-09-26-example-of-modularization-in-allegro-pay-android-application/sa_both.png\" alt=\"Build time in seconds and LoC.\" /\u003e\u003c/p\u003e\n\n\u003ch2 id=\"fin\"\u003eFin\u003c/h2\u003e\n\n\u003cp\u003eProbably for some of you, the division method used may be associated with the Latin term \u003cem\u003edivide et impera\u003c/em\u003e. This\nparadigm of algorithm design could also be used in the modularization process by dividing one large module into several\nsmaller ones, each specialized in one task. The use of the concept of this paradigm, encapsulation by creating a\ncontract and Gradle configuration allowed to significantly reduce the build time and speed up the development of the\napplication. This solution introduces consistency in the module and decreases the possibility of introducing a\nregression by encapsulating each individual domain. Also the problem with the redundant conflicts has been minimalized.\nAfter the implementation of the modules described above, the main module containing the Allegro Pay responsibilities has\nshrunk significantly, and now contains around 18.4k LoC (which means it was reduced by half). In addition,\nmodularization will allow us to add new features and extend the existing ones in an easier and safer way. It was an\ninteresting challenge from a technical point of view.\n\u003cimg src=\"/img/articles/2022-09-26-example-of-modularization-in-allegro-pay-android-application/after_both.png\" alt=\"Build time in seconds and LoC.\" /\u003e\u003c/p\u003e\n","contentSnippet":"Currently, in the Android world, the topic of modularization is very popular. Many bloggers describe their experiences\nwith it and analyze what Google recommends. Our team\nstarted the modularization process before it was hot. I will describe our reasons, decisions, problems and give you some\nadvice. We will see if modularization makes sense and what it brings to the table. I will also post some statistics\nshowing what it looked like before and after the modularization process.\nSome theory\nModule\nA module\nis a collection of source files and build settings that allow you to divide your project into discrete units of\nfunctionality. Your project can have one or many modules, and one module may use another module as a dependency. You can\nindependently build, test, and debug each module.\nBackground\nAllegro Pay is a payment method on Allegro that allows you to postpone the payment by 30 days or divide it into smaller\nparts. People who use Allegro Pay know how many functionalities it has, those who don’t use it yet will know after\nreading this article. It started from 3 modules. At the time of writing this article the Allegro application for the\nAndroid platform consists of over 120 modules, 9 of which are maintained by Allegro Pay Team. In this quarter, we\nfocused on extracting several domains (features) from the main Allegro Pay module into separate, smaller and specialized\nmodules.\nWhat made us start the modularization process?\nThe main reason for the modularization process was the build time of one of these 3 modules — containing the entire\nAllegro Pay domain. Our internal monitoring tools showed that build times started to average 100 seconds, and at their\nworst point grew to just over 120 seconds. The module contains over 40k LoC (lines of code). In addition, we faced\nproblems when introducing changes, such as conflicts or the possibility of accidental modification of another\nfunctionality.\n\nCheat\nI mention the build time for a reason. In our case, in a multi-module project, we use some Gradle instructions. Our\ngradle.properties file looks something like this:\n\n// some instructions\norg.gradle.parallel = true\norg.gradle.configureondemand = true\norg.gradle.caching = true\n// more instructions\n\n\nThe first instruction\nenables parallelization\nso that Gradle can perform more than one task at a time as long as the tasks are in different modules. The second one\nallows you to\nconfigure modules\nthat are relevant only to the task you want, rather than configuring them all, which is the default behavior.\nImportantly, this instruction should be used for multi-module projects. And the last one is\ncaching. It is „a cache mechanism that aims to save time\nby reusing outputs produced by other builds. The build cache works by storing (locally or remotely) build outputs and\nallowing builds to fetch these outputs from the cache when it is determined that inputs have not changed, avoiding the\nexpensive work of regenerating them.” By default, the build cache is disabled.\nRefinement, decisions and plans\nAt one of the weekly meetings, we discussed how to solve the problem of the growing module and the increasing number of\ndependencies and functionalities. We decided that the best way would be to extract several domains (features) into\nseparate modules. Every new module should contain the implemented part of the domain that it represents according to the\nname and a small contract module that can be attached to other modules in order to provide them with the implemented\nfunctionality. So, we have planned the following modules:\nais (a banking service that isn’t relevant in the context of this article) with contract module,\ncommon,\nconsolidation with contract module,\nonboarding with contract module,\noverpayment with contract module,\nrepayment with contract module.\nContract\nThe contract is a special module containing all the necessary interfaces, classes and methods that allow you to use the\nfunctionality in other places in an easy way. It is defined inside the module containing the functionality\nimplementation. It should be emphasized here that the implementation module can only be based on a contract. This\nsolution means that every developer working on the project knows where to find the necessary information and interfaces\nto run any feature.\n\ninterface AllegroPaySomeProcessHandler {\n\n    fun createSomeIntent(context: Context, someId: String, otherData: OtherData): Intent\n\n    fun observeSomeResult(): Observable\u003cSomeResultEvent\u003e\n}\n\n\n\ninternal class AllegroPaySomeProcessHandlerImpl : AllegroPaySomeProcessHandler {\n\n    override fun createSomeIntent(context: Context, someId: String, otherData: OtherData): Intent =\n        SomeActivity.getIntent(context, someId, otherData)\n\n    override fun observeSomeResult(): Observable\u003cSomeResultEvent\u003e =\n        DataBus.listen(SomeResultEvent::class.java)\n}\n\n\nThe above example shows what one of the assumptions of object-oriented programming — encapsulation — looks like in\npractice. The AllegroPaySomeProcessHandler interface provides two methods, one of them creates\nthe Intent necessary to run the process, and the other\nobserves its result. The exact implementation is hidden in an internal class, not accessible from the contract module.\nEvery change of interface implementation is transparent to contract clients. Example of how to declare a dependency on a\ncontract:\n\ndependencies {\n    implementation project (':allegropay-some:contract')\n}\n\n\nTool\nThe Allegro application consists of many modules and it is important to provide programmers with the right tools to work\neffectively. In the organization, the delivery of this type of tools is handled by the core team. A tool that allows us\nto check whether our module meets the requirement set for it is\nthe Module Graph Assert. It is a Gradle plugin which „helps keep your\nmodule graph healthy and lean.” This tool defines the types of modules that are allowed in the application, the\ndependencies between them and the height of the dependency tree. The following types are defined in the Allegro\napplication: App, Feature, Contract, Library, Util and NeedsMigration. The last type tells us that the\nmodule still requires work from its owners and appropriate adaptation to one of the other types. We can also define\nallowed and restricted dependencies between modules, e.g. a contract may depend only on another contract or a module\nmarked as a feature depends only on the contract or library. Allegro app configuration:\n\nmoduleGraphAssert {\n    maxHeight = 5\n    allowed = [\n        'App -\u003e Feature',\n        'App -\u003e Library',\n        'App -\u003e Util',\n        'App -\u003e Contract',\n        'Feature -\u003e Library',\n        'Feature -\u003e Util',\n        'Feature -\u003e Contract',\n        'Contract -\u003e Contract',\n        'NeedsMigration -\u003e .*',\n        '.* -\u003e NeedsMigration',\n    ]\n    restricted = [\n        'Contract -X\u003e NeedsMigration',\n        'Library -X\u003e .*'\n    ]\n}\n\n\nInitial modules\nThe first separated feature module was overpayment. We immediately prepared a common module containing functionalities\nused in more than one Allegro Pay module. The contract that is shown earlier contains one method returning an Intent\nneeded to run the overpayment process. The feature module includes user-visible screens, use cases and network\ncommunication. Several thousand lines of code were added to this module and the time needed to build the main Allegro\nPay module was shortened. At that time, the build time of the main module was around 87.5 seconds, common and\noverpayment modules around 10.5 seconds.\n\nFollowing modules\nIn the next stages, we separated the ais, consolidation and repayment modules. The current values of the build times of\nindividual modules are around 33.7 seconds for the Allegro Pay main module, 13.4 seconds for the ais, 12 seconds for the\nconsolidation, 10.6 seconds for the repayment. The extraction process was analogous to that of the first module.\n\nOnboarding module\nThis module was the most challenging and possibly the most time consuming. This was due to the combination of the\nprocess being available from multiple screens in different modules and ensuring unchanged functionality. During this\nmodularization process, we discovered the possibility of optimizing and reducing the amount of code. This module\ncontains approximately 10k LoC and the build time is less than 20 seconds. It is a really huge module.\n\nOther two modules\nIf you remember, I mentioned three modules at the beginning of this text. So far, I have described the division of the\nlargest module. Let me now describe others in more detail. The first is the special analytical module. Includes an\nexternal library and a small contract. It was created at the same time as the main Allegro Pay module. The current value\nof the build time is 3 seconds and the module has more than 150 lines of code.\n\nThe second is the SMS verification module. It contains a functionality that allows users to authorize operations by\nproviding SMS code. Currently, it is used in the processes of buying, consolidation, onboarding and overpayment. We only\nwrote a contract here, which provides a universal and easy interface. The build time is approximately 9 seconds and the\nmodule contains almost 2k lines of code.\n\nFin\nProbably for some of you, the division method used may be associated with the Latin term divide et impera. This\nparadigm of algorithm design could also be used in the modularization process by dividing one large module into several\nsmaller ones, each specialized in one task. The use of the concept of this paradigm, encapsulation by creating a\ncontract and Gradle configuration allowed to significantly reduce the build time and speed up the development of the\napplication. This solution introduces consistency in the module and decreases the possibility of introducing a\nregression by encapsulating each individual domain. Also the problem with the redundant conflicts has been minimalized.\nAfter the implementation of the modules described above, the main module containing the Allegro Pay responsibilities has\nshrunk significantly, and now contains around 18.4k LoC (which means it was reduced by half). In addition,\nmodularization will allow us to add new features and extend the existing ones in an easier and safer way. It was an\ninteresting challenge from a technical point of view.","guid":"https://blog.allegro.tech/2022/09/example-of-modularization-in-allegro-pay-android-application.html","categories":["tech","kotlin","mobile","android","modularization","gradle","allegro-pay"],"isoDate":"2022-09-25T22:00:00.000Z","thumbnail":"images/post-headers/default.jpg"},{"title":"How to efficiently write millions of records in the cloud and not go bankrupt — an Azure CosmosDB case study","link":"https://blog.allegro.tech/2022/09/azure-cosmosdb-case-study.html","pubDate":"Tue, 13 Sep 2022 00:00:00 +0200","authors":{"author":[{"name":["Kamil Starczak"],"photo":["https://blog.allegro.tech/img/authors/kamil.starczak.jpg"],"url":["https://blog.allegro.tech/authors/kamil.starczak"]}]},"content":"\u003cp\u003eCloud providers like to brag about high availability and unlimited scaling of their services – and they are correct,\nas these features are indeed significant advantages of cloud solutions. Their computational power is so high that for\nmost use cases, it’s almost unlimited. In this blog post, I would like to tell you about our experiences with \u003ca href=\"https://azure.microsoft.com/services/cosmos-db/\"\u003eAzure\nCosmos DB\u003c/a\u003e and batch processing.\u003c/p\u003e\n\n\u003ch2 id=\"our-story\"\u003eOur story\u003c/h2\u003e\n\n\u003cp\u003eAt Allegro Pay we are taking advantage of Azure’s no-SQL database, Cosmos DB. It does a great job when it comes to\nhandling operations on individual records — let’s say, fetching specific user’s data or modifying it. But what if we\nwanted to change the status of 10 million users based on some external analytic query? What’s more, we want it neither\nto last a couple of hours nor to cost us a little fortune. Actually, we may even want to run such operations on a daily\nbasis.\u003c/p\u003e\n\n\u003cp\u003eIn this blog post, I want to focus on the technical aspect of this challenge rather than diving deep into the business\nscenario. So let’s specify our technical requirements explicitly:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eThe overall time of such a batch operation cannot exceed 5 minutes per 1 million records.\u003c/li\u003e\n  \u003cli\u003eThe processing cannot starve other operations that are being run on the database at the same time. The batches will\nbe executed from time to time, but the database still needs to be able to handle regular traffic that is generated by\nusers’ requests.\u003c/li\u003e\n  \u003cli\u003eThe solution must be cost-effective. The problem with the cloud is not making a solution that is scalable and fast,\nit’s making it so at a reasonable price. All these features that cloud providers brag about do come at a cost.\u003c/li\u003e\n  \u003cli\u003eThe solution must be scalable to handle the increasing size of the database. Today we are talking about writing 10\nmillion records, but if in one year we will be writing 100 million, all these requirements should still be met — of\ncourse, not at an exponentially higher price.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThe outcomes of this case study are published as an open source repository (see \u003ca href=\"#our-library\"\u003eOur library\u003c/a\u003e).\u003c/p\u003e\n\n\u003ch2 id=\"cosmos-db--the-basics\"\u003eCosmos DB — the basics\u003c/h2\u003e\n\n\u003cp\u003eBefore going into detail, let’s look at the basic concepts of Cosmos DB. If you are familiar with this service and its\nprovisioning modes, you may want to jump directly to the \u003ca href=\"#database-utilization\"\u003eDatabase utilization\u003c/a\u003e chapter. As\nalready mentioned, Cosmos DB is a no-SQL database available in the Azure cloud. Some of its core features are unlimited\nautomatic scaling and guaranteed read and write latencies at any\nscale (\u003ca href=\"https://azure.microsoft.com/en-us/services/cosmos-db/#features\"\u003esource\u003c/a\u003e). If we compare them with the previously\nset requirements, it seems like Cosmos DB is a perfect choice. It scales automatically, so the database should scale\nitself up during batch processing. Besides, the “guaranteed latencies” feature may suggest that the response times\nshould not increase under heavy load, and the processing should be fast.\u003c/p\u003e\n\n\u003cp\u003eHow does it look in reality? Let’s take a look at a quick experiment. I created the most naive implementation of a batch\nupdate process. Its pseudocode may look like this:\u003c/p\u003e\n\n\u003cdiv class=\"language-plaintext highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003eforeach record\n{\n    Item = CosmosClient.Get(record.ID)\n    ProcessChange(Item)\n    CosmosClient.Update(Item)\n}\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eFor each batch record, we first fetch it from the database, then execute some logic that modifies it, and at last, save\nit in the database. The Cosmos’ API is quite simple, allowing us to perform simple atomic operations, such as getting a\nrecord by an ID, updating, inserting etc. It also allows querying through multiple APIs, such as SQL, MongoDB,\nCassandra, Gremlin or Azure Table API, which is out of this document’s scope.\u003c/p\u003e\n\n\u003cp\u003eWhat’s the result of executing this code? It processed 50k records in about 10 minutes. This doesn’t seem too long, but if\nwe estimate the time needed to process a million records, that would be more than 3 hours. Or even worse, if we think\nabout processing tens or hundreds of millions, it becomes almost impossible. But that’s not all — looking at the Cosmos\nDB metrics, I noticed that the database utilization was as low as about 6%. To explain what exactly it means, I will\nfirst talk about how Cosmos DB scales and how it calculates the costs.\u003c/p\u003e\n\n\u003ch2 id=\"cosmos-db--scaling-and-provisioning\"\u003eCosmos DB — scaling and provisioning\u003c/h2\u003e\n\n\u003cp\u003eCosmos DB uses so-called Request Units to calculate resource utilization. They represent a normalised operation cost in\nterms of CPU, memory and IO needed to execute the request. This way, we don’t need to care about physical (or virtual)\nmachines that are being used or their parameters — the database size and the operation costs are always expressed in\nRUs. Microsoft estimates a single read operation of a 1KB item as 1 RU and other operations’ cost correspondingly more.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-09-13-azure-cosmosdb-case-study/img01.png\" alt=\"Cosmos DB Request Units overview\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eSource: \u003ca href=\"https://docs.microsoft.com/en-us/azure/cosmos-db/request-units\"\u003ehttps://docs.microsoft.com/en-us/azure/cosmos-db/request-units\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003eBut what does “correspondingly more” mean exactly? Microsoft does not precisely define this as it depends on multiple\nfactors — such as item’s size, index configuration, query complexity, etc. We do not know how many RUs the operation\nwill consume until we actually execute it. Luckily, every response from Cosmos DB contains the operation’s cost inside\nthe headers. What’s more, RU consumption is quite repeatable. For example, if one write operation has previously\ncost 5 RUs, and we execute the same request on a similar item, we can presume that it will also cost 5 RUs. Of course,\nit may change in time — along with the increasing database size, RU consumption may also increase.\u003c/p\u003e\n\n\u003cp\u003eAt this point, the question is: how do all these affect the price of the service, and how many of these RU units are we\nactually able to use? Cosmos DB offers us three so-called provisioning modes, which determine how Azure scales the\ndatabase and bills us for the consumed resources.\u003c/p\u003e\n\n\u003ch3 id=\"manual\"\u003eManual\u003c/h3\u003e\n\n\u003cp\u003eIn the manual mode (aka “provisioned throughput”), we declare how many RUs we are going to consume per second — the\nhigher we set this limit, the higher the price. The minimal value is 400 RU/s which converts to around 20 euros per\nmonth. This can be increased at any time if needed, but we will pay more. The billing is per hour, so we pay for the\nhighest configured value during a single wall-clock hour.\u003c/p\u003e\n\n\u003cp\u003eWhat happens if we try to exceed this declared value? Some of the requests will be rejected with HTTP status code 429\n(Too Many Requests) — Cosmos DB will throttle the traffic so that the actual sum of the consumed RU in each second does\nnot exceed the configured limit.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-09-13-azure-cosmosdb-case-study/img02.png\" alt=\"Manual mode visualized\" /\u003e\u003c/p\u003e\n\n\u003ch3 id=\"autoscale\"\u003eAutoscale\u003c/h3\u003e\n\n\u003cp\u003eThe second mode is autoscale. As the name suggests, it will automatically scale based on the current load, that is, the\nactually consumed RUs, but not higher than the configured limit. To be precise, autoscale mode can scale the\ndatabase up to 10 times. For example, if we configure the max autoscale limit to 4000 RU/s, then the basic available RU\nlimit will be 400 RU/s, which converts to 20 euros per month. If we try to consume more, it will automatically scale up\nto 4000 RU/s, which converts to 200 euros per month. The bill at the end of the month will range between 20 and 200\neuros, depending on how many times and how much the database needed to scale.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-09-13-azure-cosmosdb-case-study/img03.png\" alt=\"Autoscale mode visualized\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eWhat’s the catch? We can easily set the max autoscale throughput to any value we want, but we will not always be able to\nreturn to the previous value. In fact, we can only decrease it to 1/10 of the maximum value we ever set. For example,\nif we set the database to autoscale in the range of 6k-60k RU/s, the lowest we can go back with is 600-6k RU/s.\u003c/p\u003e\n\n\u003cp\u003eNevertheless, this mode sounds quite promising. As the requirements state, we want to put a high load on the database\nfrom time to time without affecting other processes. It seems that autoscale mode can be useful for this use case.\u003c/p\u003e\n\n\u003ch3 id=\"serverless\"\u003eServerless\u003c/h3\u003e\n\n\u003cp\u003eThe last mode is serverless. It’s rather straightforward — at the end of the month, we pay for the exact number of RUs\nthat we have consumed. No need to declare anything, no need to scale. A million RUs cost around 25 euro cents. This may\nsound tempting. We can calculate how much it costs to process a million records, estimate how many we process during\na month, and when we put it together, it may look like the final price is not even very high.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-09-13-azure-cosmosdb-case-study/img04.png\" alt=\"Serverless mode visualized\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eUnfortunately, if we read the docs, we can find some additional information:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eThe maximum storage for the Serverless Cosmos DB is 50 GB. For a big production database of a high-scale service, such\nas Allegro Pay — it is simply not enough.\u003c/li\u003e\n  \u003cli\u003eThe guarantees for the operation latencies are worse — 30ms instead of 10ms.\u003c/li\u003e\n  \u003cli\u003eServerless mode is incompatible with High Availability settings and cannot be replicated in another Azure region.\u003c/li\u003e\n  \u003cli\u003eMoreover, the maximum throughput during a single second is 5000 RUs.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eAs we can see, the more we learn about the Serverless mode, the more evident it seems that it’s not intended for\napplications in production. Even Microsoft suggests that this mode is best suited for the development or test databases\nand new services with low throughput.\u003c/p\u003e\n\n\u003cp\u003eTo sum up, Cosmos offers us three interesting options when it comes to scaling that seem pretty simple to use. But if we\ndig deeper, there are quite a few catches.\u003c/p\u003e\n\n\u003ch2 id=\"database-utilization\"\u003eDatabase utilization\u003c/h2\u003e\n\n\u003cp\u003eLet’s go back to the sample code I was running.\u003c/p\u003e\n\n\u003cdiv class=\"language-plaintext highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003eForeach record\n{\n    Item = CosmosClient.Get(record.ID)\n    ProcessChange(Item)\n    CosmosClient.Update(Item)\n}\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eIt processed 50k records in about 10 minutes. How loaded was the database?\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-09-13-azure-cosmosdb-case-study/img05.png\" alt=\"Normalized RU Consumption metric\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eNormalized RU Consumption shows the percentage of the database load, which at this time was scaled up to 4000 RU/s.\nIts utilization was only around 6% during the batch processing. It’s a bit low and it obviously could take more load.\u003c/p\u003e\n\n\u003cp\u003eIf we look back at the code I was running, it’s easy to see that it’s lacking one important thing — parallelism. The\noperations are executed one after another synchronously, which makes it impossible to fully utilize the database.\nSending the requests in parallel is a simple optimization that obviously comes to mind. Let’s see what happens if we run\nthe code with parallelism added.\u003c/p\u003e\n\n\u003cp\u003eThis time, with the database scaled up to 40k RU/s, the processing of 1 million records took 8 minutes. What’s more, the\ndatabase utilization was reaching 100%. This may look very promising, but hang on a minute — running at 100% database\nusage means that we are on the edge of throttling. I checked the logs and it actually happened — some of the requests\nwere being throttled and retried. What if some other operation would try to access the database in the meantime, for\nexample customer’s purchase process? It could easily be throttled and rejected or at least delayed by the retries.\u003c/p\u003e\n\n\u003ch3 id=\"ru-limiter\"\u003eRU limiter\u003c/h3\u003e\n\n\u003cp\u003eIs there anything we can do to make this solution fulfil the previously set requirements? Let’s think about it. We know\nhow many RUs we consume (Cosmos DB is providing this information in the response headers), and we know how high we\nscaled the database… Then why not try and precisely control the flow of outgoing requests, aiming at a specific RU/s\nusage? This is what we have done at Allegro Pay — we have built our own RU limiter, as we called it. In order to do\nthat, we implemented a simple counter that tracks RUs consumed in a given interval. Using this counter, we can limit the\noutgoing requests so that RU limit is not exceeded in any second, but instead wait until the next second before\nreleasing the queued requests.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-09-13-azure-cosmosdb-case-study/img06.png\" alt=\"RU limiter visualized\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eThe mechanism sounds pretty simple, doesn’t it? And here is how it worked. I ran another test, this time with RU limiter\nset to 32k RU/s. Although the requests were being limited, the processing of 1 million records took only 5 minutes this\ntime and no request was throttled. Below we can see the Total Request Units metric during the test. The consumption was\nalmost precisely 1,92 mln RU / minute, which gives us 32k RU/s — exactly as the RU limiter was configured.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-09-13-azure-cosmosdb-case-study/img07.png\" alt=\"Total Request Units metric\" /\u003e\u003c/p\u003e\n\n\u003ch3 id=\"partition-key-ranges\"\u003ePartition key ranges\u003c/h3\u003e\n\n\u003cp\u003eIt almost looks as if we could wrap up and call it a day. But let’s take another look at the Normalized RU\nConsumption metric.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-09-13-azure-cosmosdb-case-study/img08.png\" alt=\"Normalized RU Consumption metric\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eSomething is not right here. With the database scaled up to 40k RU/s and the consumption rate of precisely 32k RU/s\n(confirmed with the Total Request Units metric), the database utilization should be around 80%, not 100%. What exactly\nis happening here? If we dig deeper into the documentation or just look around the metrics, we could discover something\ncalled \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ePartitionKeyRangeId\u003c/code\u003e. And what is the partition key range? Every item stored in a Cosmos DB collection has its\nPartitionKey — a key used by Cosmos to partition the data. In our case, that could for example be an Allegro user\nidentifier. The partition key passed to the API is hashed, so that the distribution of partition keys is even. As the\ndatabase grows, Cosmos DB automatically splits it into partitions. It does it using the partition key ranges — items\nfrom each range make up a physical partition. The problem is that these ranges are not always of equal size — they usually\nare, but there are periods when Cosmos has just split some of the partitions, but has not yet split others. Below is\nthe Normalized RU Consumption metric split by partitions.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-09-13-azure-cosmosdb-case-study/img09.png\" alt=\"Normalized RU Consumption metric split by Partition Key ranges\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eIf we dig into the documentation even further it turns out that the 40k RU/s that we configured as the provisioned\nthroughput is equally split between the partitions — even if their sizes are not equal. Odds are that even if we consume\nup to 40k RU/s in total, we are still overloading some of the partitions. If at that moment we received a request from\na customer whose ID falls into that partition key range, the request could be throttled.\u003c/p\u003e\n\n\u003ch3 id=\"a-bit-of-reverse-engineering\"\u003eA bit of reverse engineering\u003c/h3\u003e\n\n\u003cp\u003eIs there anything that could be done to limit RU consumption per partition? Well, technically yes. If we knew the\npartition key hashing mechanism that Cosmos DB is using and knew the exact partition ranges that our database is\ncurrently split into, we could count the RU limits not per the whole database, but per each partition. The good news is\nthat this is indeed possible, as the hashing is done on the client side, inside the CosmosDB SDK, which is open source.\nThe bad news is that probably we don’t want to do that, except maybe out of academic curiosity. In fact, I implemented\nsuch a partition-based RU limiter and it worked like a charm. But would I use that in production? Absolutely not. Copy\npasting and making a dependency on some internal implementation of the database, which may change at any time (well,\nprobably with some backward compatibility, because that would also break the SDK) does not sound like a production-ready\nsolution or something that my colleagues at Allegro Pay would approve in a code review.\u003c/p\u003e\n\n\u003ch2 id=\"the-autoscaler-auto-scaler\"\u003eThe “Autoscaler auto scaler”\u003c/h2\u003e\n\n\u003cp\u003eThe problem of the uneven partition key ranges persists, but is there any decent solution? Well, probably just one — to\nscale the database so far up, that we always have some RUs buffer. If we use autoscale mode and set the Max\nAutoscale Throughput high enough, we may on one hand not overpay during periods when the partition distribution is\nuneven, and on the other hand, not risk overloading some of the partitions when it happens.\u003c/p\u003e\n\n\u003cp\u003eThe one last catch is that, as already mentioned, Cosmos DB in autoscale mode can only scale up to 10x. If we configure\nthe Max Autoscale Throughput to 60k RU/s, then the lowest it will scale down is 6k RU/s, costing us at least 300 euros a\nmonth, and every processed batch tops the bill up. Is it much for a company such as Allegro? Probably not, but let’s say\nwe do not have a single database like that, but tens, maybe even hundreds? It turns out the game is worth it.\u003c/p\u003e\n\n\u003cp\u003eBut what if we increase the Max Autoscale Throughput value up to 60k RU/s only just before the batch processing has\nstarted? This is exactly what we did. Fortunately, Microsoft has given us the possibility to change the max throughput\nusing not only the Azure Portal, but also through the API. This way we can automatically scale up when the batch is\nstarting, and scale back down when the batch processing has finished. All we need to remember is that after rising the\nMax Autoscale Throughput, we can only go 10x lower. If we scale up to 60k RU/s — we can go back just to 6k RU/s Max\nAutoscale Throughput (meaning Cosmos will be scaled in range of 600-6000k RU/s).\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-09-13-azure-cosmosdb-case-study/img10.png\" alt=\"Autoscaler visualized during batch processing\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eWith this one simple trick, we created an “Autoscaler auto scaler”, as we automatically scale the Cosmos DB’s Autoscaler\nrange and achieve in turn the possibility to scale 100x times instead of just 10x. When the traffic on the database is\nat its minimum, we operate at just 600 RU/s, and during the batch processing, we go up to 60k RU/s, maintaining a buffer\nhigh enough that there is no risk of throttling.\u003c/p\u003e\n\n\u003cp\u003eThis way, we have fulfilled all the requirements that were set at the beginning:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eBatch processing time — 5 minutes per 1 million records.\u003c/li\u003e\n  \u003cli\u003eNo risk of starving other processes, thanks to the RU limiter.\u003c/li\u003e\n  \u003cli\u003eCost-effectiveness — thanks to the developed autoscaler we only pay for what we actually need.\u003c/li\u003e\n  \u003cli\u003eScalability — we can easily scale the solution up by scaling the database and if needed, also the number of batch\nprocessing service replicas. Although this will eventually increase the minimal throughput we can go back to, but with\nthe increasing scale, the minimal traffic on the database will also grow — and we can scale even 100x.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2 id=\"our-library\"\u003eOur library\u003c/h2\u003e\n\n\u003cp\u003eThe outcomes of this work have been published as an opensource .NET library on our GitHub page:\n\u003ca href=\"https://github.com/allegro/cosmosdb-utils/tree/main/src/Allegro.CosmosDb.BatchUtilities\"\u003eAllegro.CosmosDb.BatchUtilities\u003c/a\u003e.\nFeel free to use it or even contribute new features.\u003c/p\u003e\n\n\u003ch2 id=\"conclusions\"\u003eConclusions\u003c/h2\u003e\n\n\u003cp\u003eAnd here we are, at the end of the story. We have reached the intended goal, but there were a few plot twists and\nsurprises on the way. To sum it up, I would like to point out a few aspects of working with Cosmos DB or with almost any\ncloud service in general:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eCosmos DB (and the cloud in general) gives predictable costs as long as we get time to know it and study the\ndocumentation. Sometimes we may even need a PoC or some quick experiment because the documentation does not say\neverything or is not precise.\u003c/li\u003e\n  \u003cli\u003eCosmos DB gives precise control over the database scaling, but again — we need to get to know how exactly it works\nfirst.\u003c/li\u003e\n  \u003cli\u003eYou must pay close attention to the costs, as it is very easy to get high bills by misusing the service.\u003c/li\u003e\n  \u003cli\u003eIt’s worth making data-based decisions — do the PoCs, and experiments and watch the metrics. This is exactly what we\ndid here to get to the final and optimal solution.\u003c/li\u003e\n\u003c/ul\u003e\n","contentSnippet":"Cloud providers like to brag about high availability and unlimited scaling of their services – and they are correct,\nas these features are indeed significant advantages of cloud solutions. Their computational power is so high that for\nmost use cases, it’s almost unlimited. In this blog post, I would like to tell you about our experiences with Azure\nCosmos DB and batch processing.\nOur story\nAt Allegro Pay we are taking advantage of Azure’s no-SQL database, Cosmos DB. It does a great job when it comes to\nhandling operations on individual records — let’s say, fetching specific user’s data or modifying it. But what if we\nwanted to change the status of 10 million users based on some external analytic query? What’s more, we want it neither\nto last a couple of hours nor to cost us a little fortune. Actually, we may even want to run such operations on a daily\nbasis.\nIn this blog post, I want to focus on the technical aspect of this challenge rather than diving deep into the business\nscenario. So let’s specify our technical requirements explicitly:\nThe overall time of such a batch operation cannot exceed 5 minutes per 1 million records.\nThe processing cannot starve other operations that are being run on the database at the same time. The batches will\nbe executed from time to time, but the database still needs to be able to handle regular traffic that is generated by\nusers’ requests.\nThe solution must be cost-effective. The problem with the cloud is not making a solution that is scalable and fast,\nit’s making it so at a reasonable price. All these features that cloud providers brag about do come at a cost.\nThe solution must be scalable to handle the increasing size of the database. Today we are talking about writing 10\nmillion records, but if in one year we will be writing 100 million, all these requirements should still be met — of\ncourse, not at an exponentially higher price.\nThe outcomes of this case study are published as an open source repository (see Our library).\nCosmos DB — the basics\nBefore going into detail, let’s look at the basic concepts of Cosmos DB. If you are familiar with this service and its\nprovisioning modes, you may want to jump directly to the Database utilization chapter. As\nalready mentioned, Cosmos DB is a no-SQL database available in the Azure cloud. Some of its core features are unlimited\nautomatic scaling and guaranteed read and write latencies at any\nscale (source). If we compare them with the previously\nset requirements, it seems like Cosmos DB is a perfect choice. It scales automatically, so the database should scale\nitself up during batch processing. Besides, the “guaranteed latencies” feature may suggest that the response times\nshould not increase under heavy load, and the processing should be fast.\nHow does it look in reality? Let’s take a look at a quick experiment. I created the most naive implementation of a batch\nupdate process. Its pseudocode may look like this:\n\nforeach record\n{\n    Item = CosmosClient.Get(record.ID)\n    ProcessChange(Item)\n    CosmosClient.Update(Item)\n}\n\n\nFor each batch record, we first fetch it from the database, then execute some logic that modifies it, and at last, save\nit in the database. The Cosmos’ API is quite simple, allowing us to perform simple atomic operations, such as getting a\nrecord by an ID, updating, inserting etc. It also allows querying through multiple APIs, such as SQL, MongoDB,\nCassandra, Gremlin or Azure Table API, which is out of this document’s scope.\nWhat’s the result of executing this code? It processed 50k records in about 10 minutes. This doesn’t seem too long, but if\nwe estimate the time needed to process a million records, that would be more than 3 hours. Or even worse, if we think\nabout processing tens or hundreds of millions, it becomes almost impossible. But that’s not all — looking at the Cosmos\nDB metrics, I noticed that the database utilization was as low as about 6%. To explain what exactly it means, I will\nfirst talk about how Cosmos DB scales and how it calculates the costs.\nCosmos DB — scaling and provisioning\nCosmos DB uses so-called Request Units to calculate resource utilization. They represent a normalised operation cost in\nterms of CPU, memory and IO needed to execute the request. This way, we don’t need to care about physical (or virtual)\nmachines that are being used or their parameters — the database size and the operation costs are always expressed in\nRUs. Microsoft estimates a single read operation of a 1KB item as 1 RU and other operations’ cost correspondingly more.\n\nSource: https://docs.microsoft.com/en-us/azure/cosmos-db/request-units\nBut what does “correspondingly more” mean exactly? Microsoft does not precisely define this as it depends on multiple\nfactors — such as item’s size, index configuration, query complexity, etc. We do not know how many RUs the operation\nwill consume until we actually execute it. Luckily, every response from Cosmos DB contains the operation’s cost inside\nthe headers. What’s more, RU consumption is quite repeatable. For example, if one write operation has previously\ncost 5 RUs, and we execute the same request on a similar item, we can presume that it will also cost 5 RUs. Of course,\nit may change in time — along with the increasing database size, RU consumption may also increase.\nAt this point, the question is: how do all these affect the price of the service, and how many of these RU units are we\nactually able to use? Cosmos DB offers us three so-called provisioning modes, which determine how Azure scales the\ndatabase and bills us for the consumed resources.\nManual\nIn the manual mode (aka “provisioned throughput”), we declare how many RUs we are going to consume per second — the\nhigher we set this limit, the higher the price. The minimal value is 400 RU/s which converts to around 20 euros per\nmonth. This can be increased at any time if needed, but we will pay more. The billing is per hour, so we pay for the\nhighest configured value during a single wall-clock hour.\nWhat happens if we try to exceed this declared value? Some of the requests will be rejected with HTTP status code 429\n(Too Many Requests) — Cosmos DB will throttle the traffic so that the actual sum of the consumed RU in each second does\nnot exceed the configured limit.\n\nAutoscale\nThe second mode is autoscale. As the name suggests, it will automatically scale based on the current load, that is, the\nactually consumed RUs, but not higher than the configured limit. To be precise, autoscale mode can scale the\ndatabase up to 10 times. For example, if we configure the max autoscale limit to 4000 RU/s, then the basic available RU\nlimit will be 400 RU/s, which converts to 20 euros per month. If we try to consume more, it will automatically scale up\nto 4000 RU/s, which converts to 200 euros per month. The bill at the end of the month will range between 20 and 200\neuros, depending on how many times and how much the database needed to scale.\n\nWhat’s the catch? We can easily set the max autoscale throughput to any value we want, but we will not always be able to\nreturn to the previous value. In fact, we can only decrease it to 1/10 of the maximum value we ever set. For example,\nif we set the database to autoscale in the range of 6k-60k RU/s, the lowest we can go back with is 600-6k RU/s.\nNevertheless, this mode sounds quite promising. As the requirements state, we want to put a high load on the database\nfrom time to time without affecting other processes. It seems that autoscale mode can be useful for this use case.\nServerless\nThe last mode is serverless. It’s rather straightforward — at the end of the month, we pay for the exact number of RUs\nthat we have consumed. No need to declare anything, no need to scale. A million RUs cost around 25 euro cents. This may\nsound tempting. We can calculate how much it costs to process a million records, estimate how many we process during\na month, and when we put it together, it may look like the final price is not even very high.\n\nUnfortunately, if we read the docs, we can find some additional information:\nThe maximum storage for the Serverless Cosmos DB is 50 GB. For a big production database of a high-scale service, such\nas Allegro Pay — it is simply not enough.\nThe guarantees for the operation latencies are worse — 30ms instead of 10ms.\nServerless mode is incompatible with High Availability settings and cannot be replicated in another Azure region.\nMoreover, the maximum throughput during a single second is 5000 RUs.\nAs we can see, the more we learn about the Serverless mode, the more evident it seems that it’s not intended for\napplications in production. Even Microsoft suggests that this mode is best suited for the development or test databases\nand new services with low throughput.\nTo sum up, Cosmos offers us three interesting options when it comes to scaling that seem pretty simple to use. But if we\ndig deeper, there are quite a few catches.\nDatabase utilization\nLet’s go back to the sample code I was running.\n\nForeach record\n{\n    Item = CosmosClient.Get(record.ID)\n    ProcessChange(Item)\n    CosmosClient.Update(Item)\n}\n\n\nIt processed 50k records in about 10 minutes. How loaded was the database?\n\nNormalized RU Consumption shows the percentage of the database load, which at this time was scaled up to 4000 RU/s.\nIts utilization was only around 6% during the batch processing. It’s a bit low and it obviously could take more load.\nIf we look back at the code I was running, it’s easy to see that it’s lacking one important thing — parallelism. The\noperations are executed one after another synchronously, which makes it impossible to fully utilize the database.\nSending the requests in parallel is a simple optimization that obviously comes to mind. Let’s see what happens if we run\nthe code with parallelism added.\nThis time, with the database scaled up to 40k RU/s, the processing of 1 million records took 8 minutes. What’s more, the\ndatabase utilization was reaching 100%. This may look very promising, but hang on a minute — running at 100% database\nusage means that we are on the edge of throttling. I checked the logs and it actually happened — some of the requests\nwere being throttled and retried. What if some other operation would try to access the database in the meantime, for\nexample customer’s purchase process? It could easily be throttled and rejected or at least delayed by the retries.\nRU limiter\nIs there anything we can do to make this solution fulfil the previously set requirements? Let’s think about it. We know\nhow many RUs we consume (Cosmos DB is providing this information in the response headers), and we know how high we\nscaled the database… Then why not try and precisely control the flow of outgoing requests, aiming at a specific RU/s\nusage? This is what we have done at Allegro Pay — we have built our own RU limiter, as we called it. In order to do\nthat, we implemented a simple counter that tracks RUs consumed in a given interval. Using this counter, we can limit the\noutgoing requests so that RU limit is not exceeded in any second, but instead wait until the next second before\nreleasing the queued requests.\n\nThe mechanism sounds pretty simple, doesn’t it? And here is how it worked. I ran another test, this time with RU limiter\nset to 32k RU/s. Although the requests were being limited, the processing of 1 million records took only 5 minutes this\ntime and no request was throttled. Below we can see the Total Request Units metric during the test. The consumption was\nalmost precisely 1,92 mln RU / minute, which gives us 32k RU/s — exactly as the RU limiter was configured.\n\nPartition key ranges\nIt almost looks as if we could wrap up and call it a day. But let’s take another look at the Normalized RU\nConsumption metric.\n\nSomething is not right here. With the database scaled up to 40k RU/s and the consumption rate of precisely 32k RU/s\n(confirmed with the Total Request Units metric), the database utilization should be around 80%, not 100%. What exactly\nis happening here? If we dig deeper into the documentation or just look around the metrics, we could discover something\ncalled PartitionKeyRangeId. And what is the partition key range? Every item stored in a Cosmos DB collection has its\nPartitionKey — a key used by Cosmos to partition the data. In our case, that could for example be an Allegro user\nidentifier. The partition key passed to the API is hashed, so that the distribution of partition keys is even. As the\ndatabase grows, Cosmos DB automatically splits it into partitions. It does it using the partition key ranges — items\nfrom each range make up a physical partition. The problem is that these ranges are not always of equal size — they usually\nare, but there are periods when Cosmos has just split some of the partitions, but has not yet split others. Below is\nthe Normalized RU Consumption metric split by partitions.\n\nIf we dig into the documentation even further it turns out that the 40k RU/s that we configured as the provisioned\nthroughput is equally split between the partitions — even if their sizes are not equal. Odds are that even if we consume\nup to 40k RU/s in total, we are still overloading some of the partitions. If at that moment we received a request from\na customer whose ID falls into that partition key range, the request could be throttled.\nA bit of reverse engineering\nIs there anything that could be done to limit RU consumption per partition? Well, technically yes. If we knew the\npartition key hashing mechanism that Cosmos DB is using and knew the exact partition ranges that our database is\ncurrently split into, we could count the RU limits not per the whole database, but per each partition. The good news is\nthat this is indeed possible, as the hashing is done on the client side, inside the CosmosDB SDK, which is open source.\nThe bad news is that probably we don’t want to do that, except maybe out of academic curiosity. In fact, I implemented\nsuch a partition-based RU limiter and it worked like a charm. But would I use that in production? Absolutely not. Copy\npasting and making a dependency on some internal implementation of the database, which may change at any time (well,\nprobably with some backward compatibility, because that would also break the SDK) does not sound like a production-ready\nsolution or something that my colleagues at Allegro Pay would approve in a code review.\nThe “Autoscaler auto scaler”\nThe problem of the uneven partition key ranges persists, but is there any decent solution? Well, probably just one — to\nscale the database so far up, that we always have some RUs buffer. If we use autoscale mode and set the Max\nAutoscale Throughput high enough, we may on one hand not overpay during periods when the partition distribution is\nuneven, and on the other hand, not risk overloading some of the partitions when it happens.\nThe one last catch is that, as already mentioned, Cosmos DB in autoscale mode can only scale up to 10x. If we configure\nthe Max Autoscale Throughput to 60k RU/s, then the lowest it will scale down is 6k RU/s, costing us at least 300 euros a\nmonth, and every processed batch tops the bill up. Is it much for a company such as Allegro? Probably not, but let’s say\nwe do not have a single database like that, but tens, maybe even hundreds? It turns out the game is worth it.\nBut what if we increase the Max Autoscale Throughput value up to 60k RU/s only just before the batch processing has\nstarted? This is exactly what we did. Fortunately, Microsoft has given us the possibility to change the max throughput\nusing not only the Azure Portal, but also through the API. This way we can automatically scale up when the batch is\nstarting, and scale back down when the batch processing has finished. All we need to remember is that after rising the\nMax Autoscale Throughput, we can only go 10x lower. If we scale up to 60k RU/s — we can go back just to 6k RU/s Max\nAutoscale Throughput (meaning Cosmos will be scaled in range of 600-6000k RU/s).\n\nWith this one simple trick, we created an “Autoscaler auto scaler”, as we automatically scale the Cosmos DB’s Autoscaler\nrange and achieve in turn the possibility to scale 100x times instead of just 10x. When the traffic on the database is\nat its minimum, we operate at just 600 RU/s, and during the batch processing, we go up to 60k RU/s, maintaining a buffer\nhigh enough that there is no risk of throttling.\nThis way, we have fulfilled all the requirements that were set at the beginning:\nBatch processing time — 5 minutes per 1 million records.\nNo risk of starving other processes, thanks to the RU limiter.\nCost-effectiveness — thanks to the developed autoscaler we only pay for what we actually need.\nScalability — we can easily scale the solution up by scaling the database and if needed, also the number of batch\nprocessing service replicas. Although this will eventually increase the minimal throughput we can go back to, but with\nthe increasing scale, the minimal traffic on the database will also grow — and we can scale even 100x.\nOur library\nThe outcomes of this work have been published as an opensource .NET library on our GitHub page:\nAllegro.CosmosDb.BatchUtilities.\nFeel free to use it or even contribute new features.\nConclusions\nAnd here we are, at the end of the story. We have reached the intended goal, but there were a few plot twists and\nsurprises on the way. To sum it up, I would like to point out a few aspects of working with Cosmos DB or with almost any\ncloud service in general:\nCosmos DB (and the cloud in general) gives predictable costs as long as we get time to know it and study the\ndocumentation. Sometimes we may even need a PoC or some quick experiment because the documentation does not say\neverything or is not precise.\nCosmos DB gives precise control over the database scaling, but again — we need to get to know how exactly it works\nfirst.\nYou must pay close attention to the costs, as it is very easy to get high bills by misusing the service.\nIt’s worth making data-based decisions — do the PoCs, and experiments and watch the metrics. This is exactly what we\ndid here to get to the final and optimal solution.","guid":"https://blog.allegro.tech/2022/09/azure-cosmosdb-case-study.html","categories":["tech","cloud","azure","cosmosdb"],"isoDate":"2022-09-12T22:00:00.000Z","thumbnail":"images/post-headers/default.jpg"},{"title":"MBox: server-driven UI for mobile apps","link":"https://blog.allegro.tech/2022/08/mbox-server-driven-ui-for-mobile-apps.html","pubDate":"Wed, 03 Aug 2022 00:00:00 +0200","authors":{"author":[{"name":["Paulina Sadowska"],"photo":["https://blog.allegro.tech/img/authors/paulina.sadowska.jpg"],"url":["https://blog.allegro.tech/authors/paulina.sadowska"]}]},"content":"\u003cp\u003eIn this article, we want to share our approach to using server-driven UI in native mobile apps. In 2019 we created the\nfirst version of the in-house server-driven rendering tool called MBox and used it to render the\nhomepage in the Allegro app on \u003ca href=\"https://play.google.com/store/apps/details?id=pl.allegro\"\u003eAndroid\u003c/a\u003e\nand \u003ca href=\"https://apps.apple.com/pl/app/allegro/id305659772\"\u003eiOS\u003c/a\u003e. We have come a long way since then, and now we use this\ntool to render more and more screens in the Allegro app.\u003c/p\u003e\n\n\u003cp\u003eAfter over three years of working on MBox, we want to share how it works and the key advantages and challenges of using this approach.\u003c/p\u003e\n\n\u003ch2 id=\"why-server-driven-ui\"\u003eWhy server-driven UI?\u003c/h2\u003e\n\n\u003cp\u003eThe idea behind MBox was to make mobile development faster without compromising the app quality. Implementing a\nfeature twice for Android and iOS takes a lot of time and requires two people with unique skill sets (knowledge of\nAndroid and iOS frameworks). There is also the risk that both apps will not behave consistently because each person may\ninterpret the requirements slightly differently.\u003c/p\u003e\n\n\u003cp\u003eUsing a server-driven UI solves that problem because each business feature is implemented only once on the backend.\nThat gives us consistency out of the box and shortens the time needed to implement the feature.\nAlso, developers don’t need to know mobile frameworks to develop for mobile anymore.\u003c/p\u003e\n\n\u003cp\u003eAnother advantage of server-driven UI is that it allows releasing features independently of the release train. We\ncan deploy changes multiple times a day and when something goes wrong — roll back to the previous version immediately.\nIt gives teams a lot more flexibility and allows them to experiment and iterate much faster. What’s more, deployed\nchanges are visible to all clients, no matter which app version they use.\u003c/p\u003e\n\n\u003ch2 id=\"how-does-mbox-work\"\u003eHow does MBox work?\u003c/h2\u003e\n\n\u003ch3 id=\"defining-the-screen-layout\"\u003eDefining the screen layout\u003c/h3\u003e\n\n\u003cp\u003eWhile designing MBox, we wanted to create a tool that would give developers total flexibility to implement any layout\nthey need — as long as it’s consistent with our design system, Metrum.\u003c/p\u003e\n\n\u003cp\u003eThat’s why MBox screens are built using primitive components, which our rendering libraries map to native views.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-08-03-mbox-server-driven-ui-for-mobile-apps/1_MBox_SG.png\" alt=\"MessageWidget structure\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eDevelopers can arrange MBox components freely using different types of containers that MBox supports (\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eflex-container\u003c/code\u003e,\n\u003ccode class=\"language-plaintext highlighter-rouge\"\u003estack-container\u003c/code\u003e, \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eabsolute-container\u003c/code\u003e, \u003ccode class=\"language-plaintext highlighter-rouge\"\u003elist-container\u003c/code\u003e, etc.). Those components can be styled and configured to match\ndifferent business scenarios.\u003c/p\u003e\n\n\u003cp\u003eMBox renders components on mobile apps consistently, but it also respects slight differences unique to Android and\niOS platforms.\nFor example, dialog action in MBox supports the same functionalities on both platforms, but the dialog itself looks\ndifferent on Android and iOS:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-08-03-mbox-server-driven-ui-for-mobile-apps/6_alert.png\" alt=\"MBox dialog action on Android and iOS\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eThat gives MBox screens a native look and feel and perfectly blends in with parts of the app developed\nnatively, without MBox. We had to add a label that shows which parts of the app are rendered by MBox, because\neven mobile developers couldn’t tell where native screens ended and MBox started.\u003c/p\u003e\n\n\u003ch3 id=\"what-about-more-complex-views\"\u003eWhat about more complex views?\u003c/h3\u003e\n\n\u003cp\u003eCreating more complex, reusable views is also possible. For example, our design system specifies something called the\nmessage: an element with a vertical line, an icon, and some texts and buttons. However, because this element is complex\nand its requirements may change over time, it’s defined on the backend service as a widget — the element that developers\ncan reuse across different screens.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-08-03-mbox-server-driven-ui-for-mobile-apps/2_MessageWidget.png\" alt=\"MessageWidget structure\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eIf the requirements for the message widget change, we can easily modify it on the backend side without the need to\nrelease the app. That’s because it’s not defined directly in the MBox libraries included in the mobile apps, but\nspecified on the backend using MBox components.\u003c/p\u003e\n\n\u003ch3 id=\"unified-tracking\"\u003eUnified tracking\u003c/h3\u003e\n\n\u003cp\u003eBesides defining layouts, MBox also allows us to specify tracking events on the backend. For tracking events,\nconsistency is crucial. If events are not triggered under the same scenarios and with the same data\non both platforms, it’s hard to compare the data and make business decisions.\u003c/p\u003e\n\n\u003cp\u003eMBox solves that problem. All events tracked on MBox screens are defined on the backend, meaning unified tracking\nbetween Android and iOS and across different app versions.\u003c/p\u003e\n\n\u003ch3 id=\"testing\"\u003eTesting\u003c/h3\u003e\n\n\u003cp\u003eSince the MBox rendering engine is a core of more and more screens in the app, it had to be thoroughly covered by unit\ntests and integration tests. We also have screenshot tests that ensure that MBox components render correctly. That\nallows us to find out early about possible regressions.\u003c/p\u003e\n\n\u003cp\u003eTeams that develop screens using MBox also have various tools that allow them to test their features. They can write\nunit tests in the MBox backend service and check if correct MBox components are created for the given data.\nThey can also add a URL of their page to Visual Regression — the tool that creates a screenshot of\nthe page whenever someone commits anything to the MBox backend and if any change in the page is detected, the author is\nautomatically notified in their pull request.\u003c/p\u003e\n\n\u003cp\u003eFeature teams can also write UI tests for the native apps to test how their page integrates with the rest of the app and\nif all interactions work as expected. However, those tests have to be written on both platforms by the mobile developers\nand should take into account that the content of the page under tests can be changed on the backend.\u003c/p\u003e\n\n\u003ch2 id=\"the-journey-to-make-mbox-interactive\"\u003eThe journey to make MBox interactive\u003c/h2\u003e\n\n\u003cp\u003eWhen we started working on MBox, we were focused mainly on pages that contain a lot of frequently changing content but\nnot many interactions with users. In the first version of MBox, it was possible to define only basic actions like\nopening a new screen or adding an offer to the cart. That changed gradually when new teams started using MBox.\u003c/p\u003e\n\n\u003cp\u003eTo make MBox more interactive, we used the same atomic approach we adopted when designing MBox layout components. We\ngradually added generic actions that were not custom-made to serve specific business features but were reusable across\ndifferent use cases.\u003c/p\u003e\n\n\u003ch3 id=\"for-example\"\u003eFor example:\u003c/h3\u003e\n\n\u003cp\u003eOne of the first challenges that we faced was allowing the implementation of an “add to watchlist” star in MBox. We\ncould’ve just added the ”watchlist star” component that checks if a user is logged in (redirects to the login page if it’s\nnot), adds an offer to the watchlist, and changes the star icon from empty to full. In the short term, it should have\nbeen easier. But it’s not a way that would allow MBox to scale.\u003c/p\u003e\n\n\u003cp\u003eInstead, we designed a couple of atomic mechanisms that allow building this feature on the backend and could be reused\nin the future in different use cases.\u003c/p\u003e\n\n\u003cp\u003eWe added a logic component called \u003ccode class=\"language-plaintext highlighter-rouge\"\u003emultivariant\u003c/code\u003e that allows changing one component into another thanks to the\n\u003ccode class=\"language-plaintext highlighter-rouge\"\u003echangeVariant\u003c/code\u003e action. That enabled us to switch the star icon from empty to full. Next, we added the \u003ccode class=\"language-plaintext highlighter-rouge\"\u003esendRequest\u003c/code\u003e\naction\nthat sends requests with given URL, headers, and other data to our services. That allows adding and removing an offer to\nand from the watchlist. Lastly, we added the \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eloginIfNeeded\u003c/code\u003e action that allows checking if a user is logged in and\nredirecting to the login screen if needed. That allows ensuring the user is logged in before making the request.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-08-03-mbox-server-driven-ui-for-mobile-apps/3_add_to_watched.png\" alt=\"Add to watchlist: scheme\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eOf course, doing it this way took much more time than just implementing the ”add to watchlist” component in MBox libraries\nnatively. But this is the way that scales and gives us flexibility.\u003c/p\u003e\n\n\u003cp\u003eOver time mechanisms that we designed earlier were reused on other screens. And more and more often, when the new team\nwanted to use MBox on their screen, most of the building blocks they needed were already there. It definitely\nwouldn’t be the case if not for our atomic approach.\u003c/p\u003e\n\n\u003ch2 id=\"the-challenges\"\u003eThe challenges\u003c/h2\u003e\n\n\u003cp\u003eWe also encountered many challenges while working on MBox.\u003c/p\u003e\n\n\u003ch3 id=\"consistency-of-the-engines\"\u003eConsistency of the engines\u003c/h3\u003e\n\n\u003cp\u003eWe create two separate rendering engines for mobile platforms, so we must be extra cautious to ensure everything works consistently.\nEven a tiny inconsistency in the behavior of the engines may be hugely problematic for the developers that use MBox.\nIt may force them to, for example, define different layouts for each mobile platform.\u003c/p\u003e\n\n\u003cp\u003eTo make sure the engines are consistent, each feature in MBox is implemented synchronously by a pair of developers\n(Android and iOS) who consult with each other regularly. During the work, they make sure that they interpret the\nrequirements and cover edge cases in the same way.\nThe new features are ready to merge only after thorough tests on both platforms that check both correctness and\nconsistency.\u003c/p\u003e\n\n\u003ch3 id=\"versioning\"\u003eVersioning\u003c/h3\u003e\n\n\u003cp\u003eOn MBox, we also have to pay close attention to versioning. We use semantic versioning in the engines. Each new feature\nhas to be marked with the same minor and major version on both platforms. We also prepare changelogs containing\ninformation about what\nfunctionalities are available in which version.\u003c/p\u003e\n\n\u003cp\u003eOn the backend, we allow checking the version of the MBox engine that the user has and serve different content depending\non it.\nFor example, when the screen contains the \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eswitch\u003c/code\u003e component, supported since version \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e1.21\u003c/code\u003e,\nwe can define that for users who have the app with the older versions of MBox, \u003ccode class=\"language-plaintext highlighter-rouge\"\u003echeckbox\u003c/code\u003e will be displayed instead.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-08-03-mbox-server-driven-ui-for-mobile-apps/5_fallback.png\" alt=\"Fallback mechanism\" /\u003e\u003c/p\u003e\n\n\u003ch3 id=\"testing-changes-introduced-to-the-engines\"\u003eTesting changes introduced to the engines\u003c/h3\u003e\n\n\u003cp\u003eAnd last but not least: testing. Because MBox is used to render various screens in Allegro mobile apps, we must be\ncautious whenever we introduce engine changes to avoid negatively impacting existing MBox screens.\nThe screenshot and UI tests cover every MBox component and action. We’re also encouraging feature teams to add their\nscreens to the Visual Regression and cover their screens with UI tests in the mobile repositories. All those things\nallow us to minimize the risk of introducing a regression.\u003c/p\u003e\n\n\u003ch2 id=\"how-does-mbox-connect-to-other-parts-of-the-allegro-ecosystem\"\u003eHow does MBox connect to other parts of the Allegro ecosystem?\u003c/h2\u003e\n\n\u003cp\u003eConsistency across mobile platforms is not everything. Another important aspect of our work is making sure mobile and\nweb platforms are as consistent as possible, respecting native differences that make each platform unique.\u003c/p\u003e\n\n\u003cp\u003eMBox integrates with our content management system, also used for the web (\u003ca href=\"https://blog.allegro.tech/2016/03/Managing-Frontend-in-the-microservices-architecture.html\"\u003eOpbox\u003c/a\u003e Page Manager). The screen’s content\nconfigured in the Opbox admin panel is sent through the Opbox services to the MBox backend service. The MBox service\nmaps the\ndata into MBox components that make up the MBox screen. Then the screen definition in JSON format is sent to apps and is\nrendered using native views.\u003c/p\u003e\n\n\u003cp\u003eThe same data from Opbox is also used to render the web equivalent of the same screen. Opbox defines its own mappings\nfor the web: Opbox Components, which describe how to map the data into HTML elements that make up the Allegro web pages.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-08-03-mbox-server-driven-ui-for-mobile-apps/4_architecture.png\" alt=\"Add to watchlist: scheme\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eIntegration with Opbox gives us a lot of advantages. Very often, to change the content in the app and web, you don’t\nneed to change the code at all — all you need to do is change the content in the Opbox admin panel.\u003c/p\u003e\n\n\u003cp\u003eAnother huge advantage is that we have unified tracking between all platforms and can use the same tools for A/B testing\nthat are used for the web. Previously, code for A/B tests had to be written for each mobile platform separately in\nnative\ncode and then cleaned up after the finished experiment. Now, some experiments work out of the box since Opbox sends\ndifferent data to MBox depending on the experiment variant the user falls into. Sometimes a little bit of code in the\nMBox backend is required to conduct an experiment, but it’s not comparable to the amount of work A/B tests take when\nthey’re performed in the native code without MBox.\u003c/p\u003e\n\n\u003ch2 id=\"conclusions\"\u003eConclusions\u003c/h2\u003e\n\n\u003cp\u003eMBox is a tool that changed how we work on mobile apps in Allegro. It allowed us to shorten the development time without\ncompromising the quality and stability of the app and without losing the native look and feel of the Allegro apps.\u003c/p\u003e\n\n\u003cp\u003eWe have come a long way during those three years since we started working on MBox. At first, our ambition was to create\na tool that would be used on content screens with very few interactions. Over time, we pushed the boundaries of what\nMBox\nis capable of and entered screens with more and more interactions with the user.\u003c/p\u003e\n\n\u003cp\u003eCurrently MBox is used in over 25 screens in Allegro mobile apps and the number is still growing. In the first half of\n2022 alone, 27 teams made changes to the app using MBox and created about 300 pull requests. We deployed changes over\n100 times which means ~4.15 releases a week.\u003c/p\u003e\n\n\u003cp\u003eWe’re confident that it’s not the end of the possibilities ahead of us. We still see how we can make MBox even more\npowerful. We’d love to shorten development time even more by providing tools that allow defining MBox screens in\nTypeScript. That’ll enable developers to reuse some parts of the code between mobile and web and take advantage of\nbetter tools such as hot reload. Another thing we’re currently focused on is adding the binding mechanism to MBox and\nthe client-side logic to allow defining the business logic on the backend. Implementing those mechanisms will allow\nintroducing even more interactivity into MBox screens.\u003c/p\u003e\n\n\u003cp\u003eBut that is the topic for the next articles. Stay tuned!\u003c/p\u003e\n","contentSnippet":"In this article, we want to share our approach to using server-driven UI in native mobile apps. In 2019 we created the\nfirst version of the in-house server-driven rendering tool called MBox and used it to render the\nhomepage in the Allegro app on Android\nand iOS. We have come a long way since then, and now we use this\ntool to render more and more screens in the Allegro app.\nAfter over three years of working on MBox, we want to share how it works and the key advantages and challenges of using this approach.\nWhy server-driven UI?\nThe idea behind MBox was to make mobile development faster without compromising the app quality. Implementing a\nfeature twice for Android and iOS takes a lot of time and requires two people with unique skill sets (knowledge of\nAndroid and iOS frameworks). There is also the risk that both apps will not behave consistently because each person may\ninterpret the requirements slightly differently.\nUsing a server-driven UI solves that problem because each business feature is implemented only once on the backend.\nThat gives us consistency out of the box and shortens the time needed to implement the feature.\nAlso, developers don’t need to know mobile frameworks to develop for mobile anymore.\nAnother advantage of server-driven UI is that it allows releasing features independently of the release train. We\ncan deploy changes multiple times a day and when something goes wrong — roll back to the previous version immediately.\nIt gives teams a lot more flexibility and allows them to experiment and iterate much faster. What’s more, deployed\nchanges are visible to all clients, no matter which app version they use.\nHow does MBox work?\nDefining the screen layout\nWhile designing MBox, we wanted to create a tool that would give developers total flexibility to implement any layout\nthey need — as long as it’s consistent with our design system, Metrum.\nThat’s why MBox screens are built using primitive components, which our rendering libraries map to native views.\n\nDevelopers can arrange MBox components freely using different types of containers that MBox supports (flex-container,\nstack-container, absolute-container, list-container, etc.). Those components can be styled and configured to match\ndifferent business scenarios.\nMBox renders components on mobile apps consistently, but it also respects slight differences unique to Android and\niOS platforms.\nFor example, dialog action in MBox supports the same functionalities on both platforms, but the dialog itself looks\ndifferent on Android and iOS:\n\nThat gives MBox screens a native look and feel and perfectly blends in with parts of the app developed\nnatively, without MBox. We had to add a label that shows which parts of the app are rendered by MBox, because\neven mobile developers couldn’t tell where native screens ended and MBox started.\nWhat about more complex views?\nCreating more complex, reusable views is also possible. For example, our design system specifies something called the\nmessage: an element with a vertical line, an icon, and some texts and buttons. However, because this element is complex\nand its requirements may change over time, it’s defined on the backend service as a widget — the element that developers\ncan reuse across different screens.\n\nIf the requirements for the message widget change, we can easily modify it on the backend side without the need to\nrelease the app. That’s because it’s not defined directly in the MBox libraries included in the mobile apps, but\nspecified on the backend using MBox components.\nUnified tracking\nBesides defining layouts, MBox also allows us to specify tracking events on the backend. For tracking events,\nconsistency is crucial. If events are not triggered under the same scenarios and with the same data\non both platforms, it’s hard to compare the data and make business decisions.\nMBox solves that problem. All events tracked on MBox screens are defined on the backend, meaning unified tracking\nbetween Android and iOS and across different app versions.\nTesting\nSince the MBox rendering engine is a core of more and more screens in the app, it had to be thoroughly covered by unit\ntests and integration tests. We also have screenshot tests that ensure that MBox components render correctly. That\nallows us to find out early about possible regressions.\nTeams that develop screens using MBox also have various tools that allow them to test their features. They can write\nunit tests in the MBox backend service and check if correct MBox components are created for the given data.\nThey can also add a URL of their page to Visual Regression — the tool that creates a screenshot of\nthe page whenever someone commits anything to the MBox backend and if any change in the page is detected, the author is\nautomatically notified in their pull request.\nFeature teams can also write UI tests for the native apps to test how their page integrates with the rest of the app and\nif all interactions work as expected. However, those tests have to be written on both platforms by the mobile developers\nand should take into account that the content of the page under tests can be changed on the backend.\nThe journey to make MBox interactive\nWhen we started working on MBox, we were focused mainly on pages that contain a lot of frequently changing content but\nnot many interactions with users. In the first version of MBox, it was possible to define only basic actions like\nopening a new screen or adding an offer to the cart. That changed gradually when new teams started using MBox.\nTo make MBox more interactive, we used the same atomic approach we adopted when designing MBox layout components. We\ngradually added generic actions that were not custom-made to serve specific business features but were reusable across\ndifferent use cases.\nFor example:\nOne of the first challenges that we faced was allowing the implementation of an “add to watchlist” star in MBox. We\ncould’ve just added the ”watchlist star” component that checks if a user is logged in (redirects to the login page if it’s\nnot), adds an offer to the watchlist, and changes the star icon from empty to full. In the short term, it should have\nbeen easier. But it’s not a way that would allow MBox to scale.\nInstead, we designed a couple of atomic mechanisms that allow building this feature on the backend and could be reused\nin the future in different use cases.\nWe added a logic component called multivariant that allows changing one component into another thanks to the\nchangeVariant action. That enabled us to switch the star icon from empty to full. Next, we added the sendRequest\naction\nthat sends requests with given URL, headers, and other data to our services. That allows adding and removing an offer to\nand from the watchlist. Lastly, we added the loginIfNeeded action that allows checking if a user is logged in and\nredirecting to the login screen if needed. That allows ensuring the user is logged in before making the request.\n\nOf course, doing it this way took much more time than just implementing the ”add to watchlist” component in MBox libraries\nnatively. But this is the way that scales and gives us flexibility.\nOver time mechanisms that we designed earlier were reused on other screens. And more and more often, when the new team\nwanted to use MBox on their screen, most of the building blocks they needed were already there. It definitely\nwouldn’t be the case if not for our atomic approach.\nThe challenges\nWe also encountered many challenges while working on MBox.\nConsistency of the engines\nWe create two separate rendering engines for mobile platforms, so we must be extra cautious to ensure everything works consistently.\nEven a tiny inconsistency in the behavior of the engines may be hugely problematic for the developers that use MBox.\nIt may force them to, for example, define different layouts for each mobile platform.\nTo make sure the engines are consistent, each feature in MBox is implemented synchronously by a pair of developers\n(Android and iOS) who consult with each other regularly. During the work, they make sure that they interpret the\nrequirements and cover edge cases in the same way.\nThe new features are ready to merge only after thorough tests on both platforms that check both correctness and\nconsistency.\nVersioning\nOn MBox, we also have to pay close attention to versioning. We use semantic versioning in the engines. Each new feature\nhas to be marked with the same minor and major version on both platforms. We also prepare changelogs containing\ninformation about what\nfunctionalities are available in which version.\nOn the backend, we allow checking the version of the MBox engine that the user has and serve different content depending\non it.\nFor example, when the screen contains the switch component, supported since version 1.21,\nwe can define that for users who have the app with the older versions of MBox, checkbox will be displayed instead.\n\nTesting changes introduced to the engines\nAnd last but not least: testing. Because MBox is used to render various screens in Allegro mobile apps, we must be\ncautious whenever we introduce engine changes to avoid negatively impacting existing MBox screens.\nThe screenshot and UI tests cover every MBox component and action. We’re also encouraging feature teams to add their\nscreens to the Visual Regression and cover their screens with UI tests in the mobile repositories. All those things\nallow us to minimize the risk of introducing a regression.\nHow does MBox connect to other parts of the Allegro ecosystem?\nConsistency across mobile platforms is not everything. Another important aspect of our work is making sure mobile and\nweb platforms are as consistent as possible, respecting native differences that make each platform unique.\nMBox integrates with our content management system, also used for the web (Opbox Page Manager). The screen’s content\nconfigured in the Opbox admin panel is sent through the Opbox services to the MBox backend service. The MBox service\nmaps the\ndata into MBox components that make up the MBox screen. Then the screen definition in JSON format is sent to apps and is\nrendered using native views.\nThe same data from Opbox is also used to render the web equivalent of the same screen. Opbox defines its own mappings\nfor the web: Opbox Components, which describe how to map the data into HTML elements that make up the Allegro web pages.\n\nIntegration with Opbox gives us a lot of advantages. Very often, to change the content in the app and web, you don’t\nneed to change the code at all — all you need to do is change the content in the Opbox admin panel.\nAnother huge advantage is that we have unified tracking between all platforms and can use the same tools for A/B testing\nthat are used for the web. Previously, code for A/B tests had to be written for each mobile platform separately in\nnative\ncode and then cleaned up after the finished experiment. Now, some experiments work out of the box since Opbox sends\ndifferent data to MBox depending on the experiment variant the user falls into. Sometimes a little bit of code in the\nMBox backend is required to conduct an experiment, but it’s not comparable to the amount of work A/B tests take when\nthey’re performed in the native code without MBox.\nConclusions\nMBox is a tool that changed how we work on mobile apps in Allegro. It allowed us to shorten the development time without\ncompromising the quality and stability of the app and without losing the native look and feel of the Allegro apps.\nWe have come a long way during those three years since we started working on MBox. At first, our ambition was to create\na tool that would be used on content screens with very few interactions. Over time, we pushed the boundaries of what\nMBox\nis capable of and entered screens with more and more interactions with the user.\nCurrently MBox is used in over 25 screens in Allegro mobile apps and the number is still growing. In the first half of\n2022 alone, 27 teams made changes to the app using MBox and created about 300 pull requests. We deployed changes over\n100 times which means ~4.15 releases a week.\nWe’re confident that it’s not the end of the possibilities ahead of us. We still see how we can make MBox even more\npowerful. We’d love to shorten development time even more by providing tools that allow defining MBox screens in\nTypeScript. That’ll enable developers to reuse some parts of the code between mobile and web and take advantage of\nbetter tools such as hot reload. Another thing we’re currently focused on is adding the binding mechanism to MBox and\nthe client-side logic to allow defining the business logic on the backend. Implementing those mechanisms will allow\nintroducing even more interactivity into MBox screens.\nBut that is the topic for the next articles. Stay tuned!","guid":"https://blog.allegro.tech/2022/08/mbox-server-driven-ui-for-mobile-apps.html","categories":["tech","Server-driven UI","mobile","mbox"],"isoDate":"2022-08-02T22:00:00.000Z","thumbnail":"images/post-headers/default.jpg"},{"title":"How to facilitate EventStorming workshops","link":"https://blog.allegro.tech/2022/07/event-storming-workshops.html","pubDate":"Tue, 19 Jul 2022 00:00:00 +0200","authors":{"author":[{"name":["Krzysztof Przychodzki"],"photo":["https://blog.allegro.tech/img/authors/krzysztof.przychodzki.jpg"],"url":["https://blog.allegro.tech/authors/krzysztof.przychodzki"]}]},"content":"\u003cp\u003eWith this article, I would like to introduce you to EventStorming and explain to you how to get started. I am not discovering\nanything new, just gathering available knowledge in one place. What I will show you is a few tips on how to conduct\nand facilitate EventStorming workshops.\u003c/p\u003e\n\n\u003ch2 id=\"guide-to-big-picture-eventstorming\"\u003eGuide to Big Picture EventStorming\u003c/h2\u003e\n\n\u003ch3 id=\"introducing-eventstorming\"\u003eIntroducing EventStorming\u003c/h3\u003e\n\n\u003cp\u003eIn 2013 Alberto Brandolini posted an \u003ca href=\"https://ziobrando.blogspot.com/2013/11/introducing-event-storming.html\"\u003earticle\u003c/a\u003e\nabout a new workshop format for quick exploration of complex business domains. It was warmly welcomed by the DDD community.\nIn 2015 \u003ca href=\"https://www.thoughtworks.com/radar/techniques/event-storming\"\u003eTechnology Radar\u003c/a\u003e described EventStorming as \u003cem\u003eworthy of attention\u003c/em\u003e\nand three years later as \u003cem\u003ea recommended method\u003c/em\u003e for business domain modelling in information systems.\u003c/p\u003e\n\n\u003cp\u003eDuring the years a lot has changed, the technique has developed and matured but the main idea remained the same:\u003c/p\u003e\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cem\u003eEventStorming is a flexible workshop format that allows a massive collaborative exploration of complex domains (…)\nwhere software and business practitioners are building together a behavioural model of the whole business line.\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eThe above definition is from Alberto Brandolini’s \u003cem\u003e\u003ca href=\"https://leanpub.com/introducing_eventstorming\"\u003eIntroducing EventStorming\u003c/a\u003e\u003c/em\u003e,\nto which I will be referring in this article.\u003c/p\u003e\n\n\u003ch2 id=\"before-launching\"\u003eBefore launching\u003c/h2\u003e\n\n\u003ch3 id=\"provide-unlimited-modelling-space\"\u003eProvide unlimited modelling space\u003c/h3\u003e\n\n\u003cp\u003eWhy is it important? Because you want participants to explore and experiment during the workshop. You don’t want to\nimpose limits on them or to allow a situation where someone doesn’t add an event because there is no space left.\u003c/p\u003e\n\n\u003cp\u003eFor stationary session you need:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003ewall where you attach plotter paper (it is easier to stick post-its on plotter paper),\u003c/li\u003e\n  \u003cli\u003estickies in different colours, shapes and quantity (will discuss it later),\u003c/li\u003e\n  \u003cli\u003emarkers\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eWhen it has to be online, you can use a virtual boards such as:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e\u003ca href=\"https://miro.com/\"\u003emiro\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"https://www.mural.co/\"\u003emural\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3 id=\"approach\"\u003eApproach\u003c/h3\u003e\n\n\u003cp\u003eThere are two approaches to facilitate and that depends on general participants’ understanding of the business process.\u003c/p\u003e\n\n\u003cp\u003eIf your team does not know the domain it is good to conduct a workshop in an exploratory way, because there are a lot\nof unknowns. You can start with adding a central event, or if the domain is large - several events. Then look at\nwhat is happening before and after those events regarding time flow.\u003c/p\u003e\n\n\u003cp\u003eHowever, if your participants are familiar with the system (domain) and the goal is to discover only a part of it, see\nhow something works or immerse into a specific \u003cem\u003euse-case\u003c/em\u003e. You may want to impose certain boundaries - e.g. by\ninitial and final events.\u003c/p\u003e\n\n\u003cp\u003eDepending on what you want to achieve and how deep you want to explore your business, we can distinguish three possible formats:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eBig Picture EventStorming - when you want to look at your business from above (\u003cem\u003ea helicopter view\u003c/em\u003e),\u003c/li\u003e\n  \u003cli\u003eProcess Level EventStorming - going deeper with details but you still focus on whole view,\u003c/li\u003e\n  \u003cli\u003eDesign Level EventStorming - you break down your current process into smaller areas and then model them step by step using DDD, CQRS and/or Event Sourcing.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eIn his book Alberto Brandolini is mentioning also other formats, however, I would like to narrow the scope for the most\nimportant ones. In this article I focus on the \u003cem\u003eBig Picture\u003c/em\u003e approach as it is the first and crucial step to start exploring our business.\u003c/p\u003e\n\n\u003ch2 id=\"building-blocks\"\u003eBuilding blocks\u003c/h2\u003e\n\n\u003cp\u003eI focus here on the main building blocks without going into details. A comprehensive description can be found in the\nbook mentioned earlier.\u003c/p\u003e\n\n\u003ch3 id=\"invite-the-right-people---business-ux-it\"\u003eInvite the right people - business, UX, IT\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003ebut how do you describe the right people?\u003c/em\u003e\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003ethose who have questions\n    \u003cul\u003e\n      \u003cli\u003edevelopers, architects, designers etc.\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eand those who know the answers\n    \u003cul\u003e\n      \u003cli\u003eyou will need people that care about the problem\u003c/li\u003e\n      \u003cli\u003epeople who know the business. Try to gather people who know and understand it. Don’t confuse them with users —\npeople who are using our business/system (I mean these two words interchangeably and will use \u003cem\u003ebusiness\u003c/em\u003e across the\narticle) — these two are totally opposite.\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3 id=\"orange-sticky-note\"\u003eOrange sticky note\u003c/h3\u003e\n\n\u003cp\u003eOn which we will write down our events in the following form:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e\u003cem\u003eVerb in past tense\u003c/em\u003e to indicate that it already happened\u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e\u003cem\u003eRelevant for domain experts\u003c/em\u003e - describing specific and pertinent events or changes in our business - these\nare changes that at the end of the day we want to save in the database.\u003c/p\u003e\n\n    \u003cp\u003e\u003cimg src=\"/img/articles/2022-07-19-eventstorming/image1.png\" alt=\"domain event\" /\u003e\u003c/p\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: It is a good practice to define the concept of an event together (with participants) at the beginning of the\nworkshop. Then we can verify our definition with events that are appearing on the wall.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eFor example:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-07-19-eventstorming/image5.png\" alt=\"example of events\" /\u003e\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003ewe have verbs in past tense,\u003c/li\u003e\n  \u003cli\u003ethey are all relevant changes in our \u003cem\u003eblog business\u003c/em\u003e,\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2 id=\"phases-of-big-picture-eventstorming-workshop\"\u003ePhases of Big Picture EventStorming workshop\u003c/h2\u003e\n\n\u003ch3 id=\"introduction\"\u003eIntroduction\u003c/h3\u003e\n\n\u003cp\u003eIt is good to start the workshop with a short introduction of all participants - but it has to be rather quick before\neverybody gets bored. Generally you can omit this step and ask only new participants to introduce themselves.\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cem\u003eWe are going to explore the business process as a whole by placing all the relevant events along a timeline. We will\nhighlight ideas, risks and opportunities along the way.\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eWhat is necessary - we need to set a goal. What will we model? Say “What is our goal? What we will model?” and try to\nanalyse.\u003c/p\u003e\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: Remember - EventStorming is not a goal by itself - it is only a tool / framework.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch3 id=\"because-the-big-picture-is-all-about-events\"\u003eBecause the Big Picture is all about events\u003c/h3\u003e\n\n\u003cp\u003eProvide participants with an idea of a domain event, why it is important and that it has to be a relevant change in our\nsystem. Imagine you do not have a computer and by the end of the day every event in our system needs to be written\ndown in a notebook, by hand. Is the event ‘offer was shown’ a relevant change you want or is it worth noting?\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: A good ice-breaker is also demonstrating how to peel the sticky note so it would not curl\nup… \u003ca href=\"https://www.youtube.com/watch?v=rPHLxOLuyLY\"\u003efor example here\u003c/a\u003e.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch2 id=\"phase-1-chaotic-exploration-brain-dump\"\u003ePhase 1 Chaotic exploration (brain dump)\u003c/h2\u003e\n\n\u003ch3 id=\"what-is-happening\"\u003eWhat is happening\u003c/h3\u003e\n\n\u003cp\u003eAll participants are using orange sticky notes, writing down events and putting them on the board. When events start\nappearing on the board, a discussion will naturally start about what kind of events they are, when they are happening or\nhow or what is triggering them.\u003c/p\u003e\n\n\u003ch3 id=\"your-role-as-a-facilitator\"\u003eYour role as a facilitator\u003c/h3\u003e\n\n\u003cp\u003eExplain that we treat our whole board as a timeline and time is passing from left to right - it helps to see what is\nhappening before and after. Sometimes it is worth showing the importance of time in an example:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003ea locker was opened,\u003c/li\u003e\n  \u003cli\u003ea package was taken out,\u003c/li\u003e\n  \u003cli\u003ethe door was closed.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eIn a different order it does not make sense.\u003c/p\u003e\n\n\u003cp\u003eYour role as a facilitator is to listen and observe - how fast new stickies are appearing, where discussion is taking\nplace (try to capture events people are arguing about). Encourage the team to try to identify as many events as possible.\nIf somebody is wrong, it’s okay and others will correct.\u003c/p\u003e\n\n\u003cp\u003eWhen someone is mentioning some mysterious term, capture its definition. As a facilitator you can and you should ask\nobvious questions as it takes the burden off the other participants.\u003c/p\u003e\n\n\u003cp\u003eThis is also a phase where divergent thinking takes place as a part of \u003cem\u003echaotic exploration\u003c/em\u003e. So on the board we have a lot\nof events (ideas). Some of them are better and some are worse but we do not judge them at this point — later we will see\nwhere they lead us. Once again you should encourage the participants to generate new ideas and set aside critical thinking and judgement.\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cstrong\u003eTips\u003c/strong\u003e:\nAs an icebreaker you can place the first event or events - to show how easy it is, and help draw participants into\nworkshops.\u003c/p\u003e\n\n  \u003cp\u003eTry to eliminate actors from the events - because we don’t want to impose mental boundaries as we may not notice that\nthere is some other case. For example instead of \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eBuyer added item to cart\u003c/code\u003e use \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eItem added to cart\u003c/code\u003e.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch3 id=\"how-to-manage-people\"\u003eHow to manage people\u003c/h3\u003e\n\n\u003cp\u003eSometimes it is a good idea to divide them into smaller groups and make them work together on the same issue\nor, quite the opposite, to focus on different areas of the system.\u003c/p\u003e\n\n\u003cp\u003eDepending on whether we are exploring or modelling the process, especially during online sessions, I think it is good to\nhave boundaries — like a start event and an end event — among which everybody can create their vision. Then\nthe most difficult part is to merge it. Another approach is to give a free hand to your participants and see how the process is going to develop.\u003c/p\u003e\n\n\u003ch3 id=\"how-long-should-it-take\"\u003eHow long should it take?\u003c/h3\u003e\n\n\u003cp\u003eWhen the speed of new events showing up dramatically slows down, it is a good time to proceed to the next phase.\nUsually chaotic exploration takes about 5 to 15 minutes, but I have noticed that after about 8 minutes people are getting\nbored and busy with other things. So especially during online meetings, when you do not control the environment (like\ncomputers, phones, chat, mails…) it is easy to lose attention. And if you add to it a \u003cem\u003ezoom fatigue\u003c/em\u003e syndrome, you can\nspoil the whole session when key participants leave.\u003c/p\u003e\n\n\u003ch2 id=\"phase-2-timeline\"\u003ePhase 2 Timeline\u003c/h2\u003e\n\n\u003cp\u003eAfter the divergent step, now it is the time for the emergent phase where we want to explore and experiment - this is what\nwe will be doing during the next phases.\u003c/p\u003e\n\n\u003ch3 id=\"what-is-happening-1\"\u003eWhat is happening\u003c/h3\u003e\n\n\u003cp\u003eNow our goal is to make sure we are actually following the timeline - we would like the flow of events to be consistent\nfrom the beginning to the end.\u003c/p\u003e\n\n\u003ch3 id=\"your-role-as-a-facilitator-1\"\u003eYour role as a facilitator:\u003c/h3\u003e\n\n\u003cp\u003eA lot of events are going to change their place, also participants will find them irrelevant or duplicated and that is\nokay. Remove the duplicates, but be careful — ask if those duplicated events mean the same thing for everybody! Do\nnot hesitate to add, remove or change some sticky notes on the board.\u003c/p\u003e\n\n\u003cp\u003eAt this step some issue points may appear, so it is good to mark them as \u003cstrong\u003ehotspots\u003c/strong\u003e. Use red sticky notes and\nwrite the issue down but this is not a good time to deliberate about it now. Try to postpone this discussion until we have\nstructured the whole process.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-07-19-eventstorming/image2.png\" alt=\"hot-spot\" /\u003e\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: During the online session when everybody is working solo, it is hard to merge all events and, including\nattention problems, you may be left alone. So my solution is to introduce the next phase right now.\u003c/p\u003e\n\n  \u003cp\u003eDepending on the team - you can pick some random person who is going to start creating a timeline based\non available events. To sustain attention, replace this person with another one. In case of inconsistencies with the timeline,\nwe complete it with the missing events.\u003c/p\u003e\n\n  \u003cp\u003eHowever, you can do all of it — if among participants there are some shy people or your participants’ supervisor is in\nthe room, when you tell the story you can make intentional errors or ask silly questions. All of this eventually will\nhelp to explore the domain.\u003c/p\u003e\n\n  \u003cp\u003eBecause as a facilitator you do not have to know everything — especially the domain or business your participants are\nexploring — you help them effectively and safely discover processes, find new solutions or define problems.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch2 id=\"phase-3-explicit-walk-through-and-reverse-narrative\"\u003ePhase 3 Explicit walk-through and reverse narrative\u003c/h2\u003e\n\n\u003ch3 id=\"what-is-happening-2\"\u003eWhat is happening:\u003c/h3\u003e\n\n\u003cp\u003eNext step is to do a walk-through by creating some sort of a story that can be told based on the events placed on the board.\nDuring this step a lot of discussions (arguments) are going to take place. Maybe some events are missing, so do not hesitate to add,\nremove or change some sticky notes on the board. We should focus on the happy path in the first place.\u003c/p\u003e\n\n\u003ch3 id=\"1-explicit-walk-through\"\u003e1. Explicit walk-through\u003c/h3\u003e\n\n\u003ch3 id=\"your-role-as-a-facilitator-2\"\u003eYour role as a facilitator:\u003c/h3\u003e\n\n\u003cp\u003ePick some random person who is going to start telling a story based on available events according to timeflow (from left\nto right). Sometimes the team gets blocked. In this situation you can add or move an event and place it in an obviously\nwrong place. Your error will be fixed quickly and help the team to move on.\u003c/p\u003e\n\n\u003ch3 id=\"how-to-help-the-participants-discover-more\"\u003eHow to help the participants discover more?\u003c/h3\u003e\n\n\u003cp\u003eThe answer is simple — by asking questions. There are some useful questions that you can ask when discussing\nalmost every event, e.g.:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eWhy did this event happen?\u003c/li\u003e\n  \u003cli\u003eWhat are the consequences of this event?\u003c/li\u003e\n  \u003cli\u003eWhat has to / needs to happen next?\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eGoing deeper (of course that depends on how deep you want to go)\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eWhat, how, when, why is it changing?\u003c/li\u003e\n  \u003cli\u003eWhen it can’t change?\u003c/li\u003e\n  \u003cli\u003eHow does this affect the business?\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: Also in this phase it can be convenient to introduce actors (phase 4 - people and systems) — if it\nhelps to tell a story or better understand the process do not hesitate (remember I told you that EventStorming is a tool?)\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch3 id=\"2-reverse-narrative\"\u003e2. Reverse narrative\u003c/h3\u003e\n\n\u003ch3 id=\"your-role-as-a-facilitator-3\"\u003eYour role as a facilitator:\u003c/h3\u003e\n\n\u003cp\u003eSometimes it is good to propose a reverse narrative / reverse chronology. Pick an event from the end of the flow and\nlook for the event that made it possible - it must be consistent - no magic gaps between events. Again if we miss some\nevents - add them.\u003c/p\u003e\n\n\u003cp\u003eSome questions you can ask:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eBefore\n    \u003cul\u003e\n      \u003cli\u003e\u003cem\u003eWhat has happened before X\u003c/em\u003e\u003c/li\u003e\n      \u003cli\u003e\u003cem\u003eWhat else has to happen for X to happen\u003c/em\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eBetween - we take two corresponding events\n    \u003cul\u003e\n      \u003cli\u003e\u003cem\u003eIs there anything else happening between X and Y\u003c/em\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eAlternative - ask about alternative events\n    \u003cul\u003e\n      \u003cli\u003e\u003cem\u003eWhat if X did not happen\u003c/em\u003e\u003c/li\u003e\n      \u003cli\u003e\u003cem\u003eWhat if 10% of X happened or 150% of X happened\u003c/em\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2 id=\"phase-4-people-and-systems\"\u003ePhase 4 People and systems\u003c/h2\u003e\n\n\u003ch3 id=\"what-is-happening-3\"\u003eWhat is happening\u003c/h3\u003e\n\n\u003cp\u003eWhen we finish enforcing the timeline and we have a consistent flow of our business we can add people and external\nsystems. We need them for clarity and better understanding of events and forces governing our business.\u003c/p\u003e\n\n\u003cp\u003eFor marking people we use a yellow sticky note with a symbolic drawing of a person or clock if we want to show that time\nmatters. External systems may be represented by large pink stickies with their names on it. By an external system I mean\na piece of the whole process which is beyond our control e.g. an application, a department, other companies.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-07-19-eventstorming/image3.png\" alt=\"actor\" /\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-07-19-eventstorming/image4.png\" alt=\"system\" /\u003e\u003c/p\u003e\n\n\u003ch3 id=\"who-is-an-actor\"\u003eWho is an actor?\u003c/h3\u003e\n\n\u003cp\u003eIn his book Alberto Brandolini explains that\u003c/p\u003e\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cem\u003eThe goal is not to match the right yellow sticky note to every event in the flow. Adding significant people adds more\nclarity, but the goal is to trigger some insightful conversation: wherever the behaviour depends on a different type\nof user, wherever special actions need to be taken, and so on.\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eThe lack of precision is helping in discussion and exploration. It can be a specific person for example:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e\u003cem\u003ein our business model only Mrs. Smith can issue an invoice\u003c/em\u003e.\u003c/li\u003e\n  \u003cli\u003eor \u003cem\u003eafter some time reservation is cancelled\u003c/em\u003e so even \u003cem\u003etime\u003c/em\u003e can be an actor.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eAnother example:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e\u003cem\u003eorder cancellation\u003c/em\u003e can have two actors: client and CEX worker.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2 id=\"phase-5-opportunities-and-risks\"\u003ePhase 5 Opportunities and risks\u003c/h2\u003e\n\n\u003cp\u003eIn this phase we can literally take three steps back and look at the whole business flow as it is.\n\u003cstrong\u003eHot spots\u003c/strong\u003e are the most conspicuous things - and it is easy to say where the biggest impediment is. This\nis a great occasion for additional discussion and a subject for further exploration.\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: Remember that each \u003cem\u003ehot spot\u003c/em\u003e should be addressed and resolved before the next session takes place.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eAnother way to find where problems might lay is voting for a specific event or marking events that indicate where in our\nflow we are generating / losing money or value. For example by green stripes we indicate events where we are earning money,\nby red stripes where we are losing money or value.\u003c/p\u003e\n\n\u003ch2 id=\"it-is-like-pizzas\"\u003eIt is like Pizzas\u003c/h2\u003e\n\n\u003cp\u003eWhen all hotspots are addressed, you have found the biggest impediment, or you know on what part you have to focus on\nduring next session. The only thing left to do is to close the workshop, thank all stakeholders and participants,\nschedule the next session and ask for feedback.\u003c/p\u003e\n\n\u003cp\u003eAfter the session you will have a clear business narrative on the board. What is more important, participants will\nshare general understanding of the process. They have gone through the massive learning process, gained experience and\nshared the common knowledge — everybody uses the domain language. Due to the fact that we used simple building\nblocks, the outcome is understandable to everyone PMs, UX designers, developers etc.\u003c/p\u003e\n\n\u003cp\u003eThe steps described above and their sequence should be regarded as optional during the session.\nThere is no such thing as one recipe. For example, if during the \u003cem\u003etimeline step\u003c/em\u003e you feel that introduction of\npeople and systems is going to help, do not hesitate to do so. In other cases you will be interested only in\nfinding impediments or where your system is delivering values and do not feel obligated to use all the steps.\nAs Alberto says:\u003c/p\u003e\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cem\u003eI like to think about it like Pizzas: there’s a common base, but different toppings.\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch3 id=\"nobody-is-excluded\"\u003eNobody is excluded\u003c/h3\u003e\n\n\u003cp\u003eBig Picture EventStorming is the first and crucial step, its outcome is visible and valuable. Depending on what the team\nneeds, it can be sufficient, but if we want to go deeper and explore more, next there are Process Level and Design Level\nEventStorming. We use the same stickies’ grammar enhanced with more colours to explain the complexity of our system. Due\nto the fact that we use the same grammar, developers and businesses can speak the same language — nobody is\nexcluded, isn’t that great?\u003c/p\u003e\n\n\u003cp\u003eThose further steps (Process/Design Level) are getting us closer into the domain-driven-design and implementation. We (\ndevelopers/architects) can start thinking how to change what we have learned into working code, because\u003c/p\u003e\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cem\u003e(…) it’s developer understanding that gets captured in code and released in production.\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch2 id=\"call-for-action\"\u003eCall for action\u003c/h2\u003e\n\n\u003cp\u003eIf you are Allegro worker and you are interested in EventStorming, you want to develop, participate in workshops\nor help as a facilitator I strongly encourage you to join the guild.\nIf you are not yet working at Allegro but are interested in how we use EventStorming maybe it is good opportunity to\njoin\nus — \u003ca href=\"https://www.linkedin.com/company/allegro-pl/life/team\"\u003e#goodtobehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch2 id=\"more-about-eventstroming\"\u003eMore about EventStroming\u003c/h2\u003e\n\n\u003cp\u003eOn the Internet you can find a lot of materials about EventStorming. Below is a list of those I found most valuable.\u003c/p\u003e\n\n\u003ch3 id=\"books\"\u003eBooks\u003c/h3\u003e\n\n\u003col\u003e\n  \u003cli\u003e\u003ca href=\"https://leanpub.com/introducing_eventstorming\"\u003eIntroducing EventStorming\u003c/a\u003e Alberto Brandolini’s book —\n\u003cem\u003eEventStorming Bible\u003c/em\u003e — mandatory book!\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"https://leanpub.com/eventstorming_handbook\"\u003eThe EventStorming Handbook\u003c/a\u003e by Paul Rayner — a great summary of\n\u003cem\u003eIntroducing EventStorming\u003c/em\u003e with a lot of valuable tips, tricks and recipes. After that you will be able to explain\nEventStorming even to your own child.\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"https://gamestorming.com/\"\u003eGameStorming A Playbook for Innovators, Rulebreakers, and Changemakers\u003c/a\u003e by Dave Gray,\nSunni Brown, James Macanufo — if you want to use the full potential of your storming sessions.\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"https://allegro.pl/oferta/facilitator-s-guide-to-participatory-decision-maki-10017700512\"\u003eFacilitator’s Guide to Participatory Decision-making\u003c/a\u003e\nby Sam Kaner, Lenny Lind — how to be a better facilitator, not only for EventStorming. You will find precious\ninformation about divergent, emergent and convergent thinking and why it is important.\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch3 id=\"link\"\u003eLink\u003c/h3\u003e\n\n\u003col\u003e\n  \u003cli\u003e\u003ca href=\"https://github.com/mariuszgil/awesome-eventstorming\"\u003eAwesome EventStorming\u003c/a\u003e by Mariusz Gil — I belive this is\nthe biggest source of links about EventStorming topics.\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch2 id=\"thanks\"\u003eThanks\u003c/h2\u003e\n\n\u003cp\u003eI would like to thank all of my colleagues from \u003cem\u003eAllegro EventStorming Guild\u003c/em\u003e for their help in creating this article.\u003c/p\u003e\n","contentSnippet":"With this article, I would like to introduce you to EventStorming and explain to you how to get started. I am not discovering\nanything new, just gathering available knowledge in one place. What I will show you is a few tips on how to conduct\nand facilitate EventStorming workshops.\nGuide to Big Picture EventStorming\nIntroducing EventStorming\nIn 2013 Alberto Brandolini posted an article\nabout a new workshop format for quick exploration of complex business domains. It was warmly welcomed by the DDD community.\nIn 2015 Technology Radar described EventStorming as worthy of attention\nand three years later as a recommended method for business domain modelling in information systems.\nDuring the years a lot has changed, the technique has developed and matured but the main idea remained the same:\nEventStorming is a flexible workshop format that allows a massive collaborative exploration of complex domains (…)\nwhere software and business practitioners are building together a behavioural model of the whole business line.\nThe above definition is from Alberto Brandolini’s Introducing EventStorming,\nto which I will be referring in this article.\nBefore launching\nProvide unlimited modelling space\nWhy is it important? Because you want participants to explore and experiment during the workshop. You don’t want to\nimpose limits on them or to allow a situation where someone doesn’t add an event because there is no space left.\nFor stationary session you need:\nwall where you attach plotter paper (it is easier to stick post-its on plotter paper),\nstickies in different colours, shapes and quantity (will discuss it later),\nmarkers\nWhen it has to be online, you can use a virtual boards such as:\nmiro\nmural\nApproach\nThere are two approaches to facilitate and that depends on general participants’ understanding of the business process.\nIf your team does not know the domain it is good to conduct a workshop in an exploratory way, because there are a lot\nof unknowns. You can start with adding a central event, or if the domain is large - several events. Then look at\nwhat is happening before and after those events regarding time flow.\nHowever, if your participants are familiar with the system (domain) and the goal is to discover only a part of it, see\nhow something works or immerse into a specific use-case. You may want to impose certain boundaries - e.g. by\ninitial and final events.\nDepending on what you want to achieve and how deep you want to explore your business, we can distinguish three possible formats:\nBig Picture EventStorming - when you want to look at your business from above (a helicopter view),\nProcess Level EventStorming - going deeper with details but you still focus on whole view,\nDesign Level EventStorming - you break down your current process into smaller areas and then model them step by step using DDD, CQRS and/or Event Sourcing.\nIn his book Alberto Brandolini is mentioning also other formats, however, I would like to narrow the scope for the most\nimportant ones. In this article I focus on the Big Picture approach as it is the first and crucial step to start exploring our business.\nBuilding blocks\nI focus here on the main building blocks without going into details. A comprehensive description can be found in the\nbook mentioned earlier.\nInvite the right people - business, UX, IT\nbut how do you describe the right people?\nthose who have questions\n    \ndevelopers, architects, designers etc.\nand those who know the answers\n    \nyou will need people that care about the problem\npeople who know the business. Try to gather people who know and understand it. Don’t confuse them with users —\npeople who are using our business/system (I mean these two words interchangeably and will use business across the\narticle) — these two are totally opposite.\nOrange sticky note\nOn which we will write down our events in the following form:\nVerb in past tense to indicate that it already happened\nRelevant for domain experts - describing specific and pertinent events or changes in our business - these\nare changes that at the end of the day we want to save in the database.\n\nTip: It is a good practice to define the concept of an event together (with participants) at the beginning of the\nworkshop. Then we can verify our definition with events that are appearing on the wall.\nFor example:\n\nwe have verbs in past tense,\nthey are all relevant changes in our blog business,\nPhases of Big Picture EventStorming workshop\nIntroduction\nIt is good to start the workshop with a short introduction of all participants - but it has to be rather quick before\neverybody gets bored. Generally you can omit this step and ask only new participants to introduce themselves.\nWe are going to explore the business process as a whole by placing all the relevant events along a timeline. We will\nhighlight ideas, risks and opportunities along the way.\nWhat is necessary - we need to set a goal. What will we model? Say “What is our goal? What we will model?” and try to\nanalyse.\nTip: Remember - EventStorming is not a goal by itself - it is only a tool / framework.\nBecause the Big Picture is all about events\nProvide participants with an idea of a domain event, why it is important and that it has to be a relevant change in our\nsystem. Imagine you do not have a computer and by the end of the day every event in our system needs to be written\ndown in a notebook, by hand. Is the event ‘offer was shown’ a relevant change you want or is it worth noting?\nTip: A good ice-breaker is also demonstrating how to peel the sticky note so it would not curl\nup… for example here.\nPhase 1 Chaotic exploration (brain dump)\nWhat is happening\nAll participants are using orange sticky notes, writing down events and putting them on the board. When events start\nappearing on the board, a discussion will naturally start about what kind of events they are, when they are happening or\nhow or what is triggering them.\nYour role as a facilitator\nExplain that we treat our whole board as a timeline and time is passing from left to right - it helps to see what is\nhappening before and after. Sometimes it is worth showing the importance of time in an example:\na locker was opened,\na package was taken out,\nthe door was closed.\nIn a different order it does not make sense.\nYour role as a facilitator is to listen and observe - how fast new stickies are appearing, where discussion is taking\nplace (try to capture events people are arguing about). Encourage the team to try to identify as many events as possible.\nIf somebody is wrong, it’s okay and others will correct.\nWhen someone is mentioning some mysterious term, capture its definition. As a facilitator you can and you should ask\nobvious questions as it takes the burden off the other participants.\nThis is also a phase where divergent thinking takes place as a part of chaotic exploration. So on the board we have a lot\nof events (ideas). Some of them are better and some are worse but we do not judge them at this point — later we will see\nwhere they lead us. Once again you should encourage the participants to generate new ideas and set aside critical thinking and judgement.\nTips:\nAs an icebreaker you can place the first event or events - to show how easy it is, and help draw participants into\nworkshops.\nTry to eliminate actors from the events - because we don’t want to impose mental boundaries as we may not notice that\nthere is some other case. For example instead of Buyer added item to cart use Item added to cart.\nHow to manage people\nSometimes it is a good idea to divide them into smaller groups and make them work together on the same issue\nor, quite the opposite, to focus on different areas of the system.\nDepending on whether we are exploring or modelling the process, especially during online sessions, I think it is good to\nhave boundaries — like a start event and an end event — among which everybody can create their vision. Then\nthe most difficult part is to merge it. Another approach is to give a free hand to your participants and see how the process is going to develop.\nHow long should it take?\nWhen the speed of new events showing up dramatically slows down, it is a good time to proceed to the next phase.\nUsually chaotic exploration takes about 5 to 15 minutes, but I have noticed that after about 8 minutes people are getting\nbored and busy with other things. So especially during online meetings, when you do not control the environment (like\ncomputers, phones, chat, mails…) it is easy to lose attention. And if you add to it a zoom fatigue syndrome, you can\nspoil the whole session when key participants leave.\nPhase 2 Timeline\nAfter the divergent step, now it is the time for the emergent phase where we want to explore and experiment - this is what\nwe will be doing during the next phases.\nWhat is happening\nNow our goal is to make sure we are actually following the timeline - we would like the flow of events to be consistent\nfrom the beginning to the end.\nYour role as a facilitator:\nA lot of events are going to change their place, also participants will find them irrelevant or duplicated and that is\nokay. Remove the duplicates, but be careful — ask if those duplicated events mean the same thing for everybody! Do\nnot hesitate to add, remove or change some sticky notes on the board.\nAt this step some issue points may appear, so it is good to mark them as hotspots. Use red sticky notes and\nwrite the issue down but this is not a good time to deliberate about it now. Try to postpone this discussion until we have\nstructured the whole process.\n\nTip: During the online session when everybody is working solo, it is hard to merge all events and, including\nattention problems, you may be left alone. So my solution is to introduce the next phase right now.\nDepending on the team - you can pick some random person who is going to start creating a timeline based\non available events. To sustain attention, replace this person with another one. In case of inconsistencies with the timeline,\nwe complete it with the missing events.\nHowever, you can do all of it — if among participants there are some shy people or your participants’ supervisor is in\nthe room, when you tell the story you can make intentional errors or ask silly questions. All of this eventually will\nhelp to explore the domain.\nBecause as a facilitator you do not have to know everything — especially the domain or business your participants are\nexploring — you help them effectively and safely discover processes, find new solutions or define problems.\nPhase 3 Explicit walk-through and reverse narrative\nWhat is happening:\nNext step is to do a walk-through by creating some sort of a story that can be told based on the events placed on the board.\nDuring this step a lot of discussions (arguments) are going to take place. Maybe some events are missing, so do not hesitate to add,\nremove or change some sticky notes on the board. We should focus on the happy path in the first place.\n1. Explicit walk-through\nYour role as a facilitator:\nPick some random person who is going to start telling a story based on available events according to timeflow (from left\nto right). Sometimes the team gets blocked. In this situation you can add or move an event and place it in an obviously\nwrong place. Your error will be fixed quickly and help the team to move on.\nHow to help the participants discover more?\nThe answer is simple — by asking questions. There are some useful questions that you can ask when discussing\nalmost every event, e.g.:\nWhy did this event happen?\nWhat are the consequences of this event?\nWhat has to / needs to happen next?\nGoing deeper (of course that depends on how deep you want to go)\nWhat, how, when, why is it changing?\nWhen it can’t change?\nHow does this affect the business?\nTip: Also in this phase it can be convenient to introduce actors (phase 4 - people and systems) — if it\nhelps to tell a story or better understand the process do not hesitate (remember I told you that EventStorming is a tool?)\n2. Reverse narrative\nYour role as a facilitator:\nSometimes it is good to propose a reverse narrative / reverse chronology. Pick an event from the end of the flow and\nlook for the event that made it possible - it must be consistent - no magic gaps between events. Again if we miss some\nevents - add them.\nSome questions you can ask:\nBefore\n    \nWhat has happened before X\nWhat else has to happen for X to happen\nBetween - we take two corresponding events\n    \nIs there anything else happening between X and Y\nAlternative - ask about alternative events\n    \nWhat if X did not happen\nWhat if 10% of X happened or 150% of X happened\nPhase 4 People and systems\nWhat is happening\nWhen we finish enforcing the timeline and we have a consistent flow of our business we can add people and external\nsystems. We need them for clarity and better understanding of events and forces governing our business.\nFor marking people we use a yellow sticky note with a symbolic drawing of a person or clock if we want to show that time\nmatters. External systems may be represented by large pink stickies with their names on it. By an external system I mean\na piece of the whole process which is beyond our control e.g. an application, a department, other companies.\n\n\nWho is an actor?\nIn his book Alberto Brandolini explains that\nThe goal is not to match the right yellow sticky note to every event in the flow. Adding significant people adds more\nclarity, but the goal is to trigger some insightful conversation: wherever the behaviour depends on a different type\nof user, wherever special actions need to be taken, and so on.\nThe lack of precision is helping in discussion and exploration. It can be a specific person for example:\nin our business model only Mrs. Smith can issue an invoice.\nor after some time reservation is cancelled so even time can be an actor.\nAnother example:\norder cancellation can have two actors: client and CEX worker.\nPhase 5 Opportunities and risks\nIn this phase we can literally take three steps back and look at the whole business flow as it is.\nHot spots are the most conspicuous things - and it is easy to say where the biggest impediment is. This\nis a great occasion for additional discussion and a subject for further exploration.\nTip: Remember that each hot spot should be addressed and resolved before the next session takes place.\nAnother way to find where problems might lay is voting for a specific event or marking events that indicate where in our\nflow we are generating / losing money or value. For example by green stripes we indicate events where we are earning money,\nby red stripes where we are losing money or value.\nIt is like Pizzas\nWhen all hotspots are addressed, you have found the biggest impediment, or you know on what part you have to focus on\nduring next session. The only thing left to do is to close the workshop, thank all stakeholders and participants,\nschedule the next session and ask for feedback.\nAfter the session you will have a clear business narrative on the board. What is more important, participants will\nshare general understanding of the process. They have gone through the massive learning process, gained experience and\nshared the common knowledge — everybody uses the domain language. Due to the fact that we used simple building\nblocks, the outcome is understandable to everyone PMs, UX designers, developers etc.\nThe steps described above and their sequence should be regarded as optional during the session.\nThere is no such thing as one recipe. For example, if during the timeline step you feel that introduction of\npeople and systems is going to help, do not hesitate to do so. In other cases you will be interested only in\nfinding impediments or where your system is delivering values and do not feel obligated to use all the steps.\nAs Alberto says:\nI like to think about it like Pizzas: there’s a common base, but different toppings.\nNobody is excluded\nBig Picture EventStorming is the first and crucial step, its outcome is visible and valuable. Depending on what the team\nneeds, it can be sufficient, but if we want to go deeper and explore more, next there are Process Level and Design Level\nEventStorming. We use the same stickies’ grammar enhanced with more colours to explain the complexity of our system. Due\nto the fact that we use the same grammar, developers and businesses can speak the same language — nobody is\nexcluded, isn’t that great?\nThose further steps (Process/Design Level) are getting us closer into the domain-driven-design and implementation. We (\ndevelopers/architects) can start thinking how to change what we have learned into working code, because\n(…) it’s developer understanding that gets captured in code and released in production.\nCall for action\nIf you are Allegro worker and you are interested in EventStorming, you want to develop, participate in workshops\nor help as a facilitator I strongly encourage you to join the guild.\nIf you are not yet working at Allegro but are interested in how we use EventStorming maybe it is good opportunity to\njoin\nus — #goodtobehere.\nMore about EventStroming\nOn the Internet you can find a lot of materials about EventStorming. Below is a list of those I found most valuable.\nBooks\nIntroducing EventStorming Alberto Brandolini’s book —\nEventStorming Bible — mandatory book!\nThe EventStorming Handbook by Paul Rayner — a great summary of\nIntroducing EventStorming with a lot of valuable tips, tricks and recipes. After that you will be able to explain\nEventStorming even to your own child.\nGameStorming A Playbook for Innovators, Rulebreakers, and Changemakers by Dave Gray,\nSunni Brown, James Macanufo — if you want to use the full potential of your storming sessions.\nFacilitator’s Guide to Participatory Decision-making\nby Sam Kaner, Lenny Lind — how to be a better facilitator, not only for EventStorming. You will find precious\ninformation about divergent, emergent and convergent thinking and why it is important.\nLink\nAwesome EventStorming by Mariusz Gil — I belive this is\nthe biggest source of links about EventStorming topics.\nThanks\nI would like to thank all of my colleagues from Allegro EventStorming Guild for their help in creating this article.","guid":"https://blog.allegro.tech/2022/07/event-storming-workshops.html","categories":["eventstorming","tech","communication"],"isoDate":"2022-07-18T22:00:00.000Z","thumbnail":"images/post-headers/eventstorming.png"}],"jobs":[],"events":[{"created":1664275530000,"duration":5400000,"id":"288748190","name":"Allegro Tech Talk #30 - Toruń","date_in_series_pattern":false,"status":"upcoming","time":1665676800000,"local_date":"2022-10-13","local_time":"18:00","updated":1664276321000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":1,"is_online_event":false,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/288748190/","description":"**➡ Obowiązkowa rejestracja na udział offline:** [https://app.evenea.pl/event/allegro-tech-talk-30](https://app.evenea.pl/event/allegro-tech-talk-30) Mamy dla Was dobrą wiadomość! Wracamy do stacjonarnych spotkań Allegro Tech Talks, na których dzielimy się wiedzą, wzajemnie…","visibility":"public","member_pay_fee":false},{"created":1657193453000,"duration":7200000,"id":"287035383","name":"Allegro Tech Labs #10 Online: Poskromić stan w React","date_in_series_pattern":false,"status":"past","time":1658934000000,"local_date":"2022-07-27","local_time":"17:00","updated":1658944632000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":26,"is_online_event":false,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/287035383/","description":"❗NA WYDARZENIE OBOWIĄZUJE REJESTRACJA: Liczba miejsc jest organiczona: [https://app.evenea.pl/event/allegro-tech-labs-10/](https://app.evenea.pl/event/allegro-tech-labs-10/?fbclid=IwAR1Zj3sIcfx3WEWiFfS_hgiW6BJQD6stYouSGuSqfxDq9YVeom8fTFcrE1Q) ❗ **Allegro Tech Labs** to w 100% zdalna odsłona naszych stacjonarnych spotkań warsztatowych. Zazwyczaj spotykaliśmy się…","visibility":"public","member_pay_fee":false},{"created":1655131243000,"duration":5400000,"id":"286545395","name":"Allegro Tech Live #29 - Wyzwania Product Managera","date_in_series_pattern":false,"status":"past","time":1656604800000,"local_date":"2022-06-30","local_time":"18:00","updated":1656612323000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":88,"is_online_event":false,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/286545395/","description":"Allegro Tech Live to w 100% zdalna odsłona naszych stacjonarnych meetupów Allegro Tech Talks. Zazwyczaj spotykaliśmy się w naszych biurach, ale tym razem to my…","visibility":"public","member_pay_fee":false},{"created":1650552918000,"duration":100800000,"id":"285416318","name":"UX Research Confetti - II edycja","date_in_series_pattern":false,"status":"past","time":1653562800000,"local_date":"2022-05-26","local_time":"13:00","updated":1653666063000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":48,"is_online_event":true,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/285416318/","description":"REJESTRACJA NA WYDARZENIE -\u0026gt; https://app.evenea.pl/event/ux-research-confetti-2/ 🎉 Niech ponownie rozsypie się confetti wiedzy o badaniach UX! 🎉 Szukaliśmy konferencji badawczej UX w Polsce i nie znaleźliśmy……","visibility":"public","member_pay_fee":false}],"podcasts":[{"title":"S03E03 - Paweł Marcinkowski - O Data \u0026 AI w Allegro Pay","link":"https://podcast.allegro.tech/o-data-i-ai-w-allegro-pay/","pubDate":"Thu, 22 Sep 2022 00:00:00 GMT","content":"Jak zbudowany jest obszar Data \u0026 AI w Allegro Pay i jak (współ)pracują w nim ze sobą poszczególne role oraz zespoły? Jak działa decision engine, kluczowy komponent, od którego zależy sukces Allegro Pay? Jak wyglądałby proces wprowadzenia zupełnie nowej funkcjonalności lub nowego produktu w Allegro Pay? Kim jest i za co odpowiada Data Product Manager? Jak w modelach Machine Learning do predykcji ryzyka kredytowego Allegro Pay wykorzystuje kontekst otoczenia? Na te i inne pytania związane z pracą w największym fintechu w Europie Środkowej odpowiada Paweł Marcinkowski - lider obszaru Data \u0026 AI w Allegro Pay.","contentSnippet":"Jak zbudowany jest obszar Data \u0026 AI w Allegro Pay i jak (współ)pracują w nim ze sobą poszczególne role oraz zespoły? Jak działa decision engine, kluczowy komponent, od którego zależy sukces Allegro Pay? Jak wyglądałby proces wprowadzenia zupełnie nowej funkcjonalności lub nowego produktu w Allegro Pay? Kim jest i za co odpowiada Data Product Manager? Jak w modelach Machine Learning do predykcji ryzyka kredytowego Allegro Pay wykorzystuje kontekst otoczenia? Na te i inne pytania związane z pracą w największym fintechu w Europie Środkowej odpowiada Paweł Marcinkowski - lider obszaru Data \u0026 AI w Allegro Pay.","guid":"https://podcast.allegro.tech/o-data-i-ai-w-allegro-pay/","isoDate":"2022-09-22T00:00:00.000Z"},{"title":"S03E02 - Barbara Kaczorek, Jakub Kwietko - O tym jak powstawały zielone automaty paczkowe Allegro One Box","link":"https://podcast.allegro.tech/o-tym-jak-powstawaly-zielone-automaty-paczkowe-allegro-one-box/","pubDate":"Thu, 08 Sep 2022 00:00:00 GMT","content":"Jak wyglądała współpraca ponad 350 osób przy tak dużym i złożonym projekcie jak uruchomienie Allegro One Box?  Z jakimi wyzwaniami zmierzyły się osoby, które przy nim pracowały? Jak można mierzyć efekty swojej pracy w projektach takich, jak ten? Dlaczego Product Manager musi czasem siedzieć z laptopem za prototypem urządzenia? Na te i inne pytania odpowiadają Barbara Kaczorek - Product Manager w obszarze Delivery Experience w Allegro i Jakub Kwietko - lider zespołów developerskich OpenNet zaangażowanych w powstawanie Allegro One Box. Dobrze wiedzieć: OpenNet to wiodący dostawca rozwiązań technologicznych dla branży logistycznej w Polsce i za granicą, od 2021 roku jest częścią Grupy Allegro.","contentSnippet":"Jak wyglądała współpraca ponad 350 osób przy tak dużym i złożonym projekcie jak uruchomienie Allegro One Box?  Z jakimi wyzwaniami zmierzyły się osoby, które przy nim pracowały? Jak można mierzyć efekty swojej pracy w projektach takich, jak ten? Dlaczego Product Manager musi czasem siedzieć z laptopem za prototypem urządzenia? Na te i inne pytania odpowiadają Barbara Kaczorek - Product Manager w obszarze Delivery Experience w Allegro i Jakub Kwietko - lider zespołów developerskich OpenNet zaangażowanych w powstawanie Allegro One Box. Dobrze wiedzieć: OpenNet to wiodący dostawca rozwiązań technologicznych dla branży logistycznej w Polsce i za granicą, od 2021 roku jest częścią Grupy Allegro.","guid":"https://podcast.allegro.tech/o-tym-jak-powstawaly-zielone-automaty-paczkowe-allegro-one-box/","isoDate":"2022-09-08T00:00:00.000Z"},{"title":"S03E01 - Ewa Ludwiczak - O Quality Assurance w Allegro","link":"https://podcast.allegro.tech/o-quality-assurance-w-allegro/","pubDate":"Thu, 25 Aug 2022 00:00:00 GMT","content":"Na czym polega rola testera w Allegro? Dlaczego testerzy w Allegro są blisko technologii i produktu? Jak może rozwinąć się kariera testera, gdzie szukać aktualnej wiedzy i kim jest “Full Stack Tester”? Czy pierwsze kroki w branży IT muszą być trudne i jak programowania uczą się dzieci? Na te i inne pytania odpowiada Ewa Ludwiczak - liderka i testerka w Allegro. ","contentSnippet":"Na czym polega rola testera w Allegro? Dlaczego testerzy w Allegro są blisko technologii i produktu? Jak może rozwinąć się kariera testera, gdzie szukać aktualnej wiedzy i kim jest “Full Stack Tester”? Czy pierwsze kroki w branży IT muszą być trudne i jak programowania uczą się dzieci? Na te i inne pytania odpowiada Ewa Ludwiczak - liderka i testerka w Allegro.","guid":"https://podcast.allegro.tech/o-quality-assurance-w-allegro/","isoDate":"2022-08-25T00:00:00.000Z"},{"title":"S02E12 - Piotr Betkier - Rola architekta w Allegro","link":"https://podcast.allegro.tech/rola_architekta_w_allegro/","pubDate":"Wed, 16 Jun 2021 00:00:00 GMT","content":"Od kodowania do tworzenia strategii technicznej... Jak wygląda rola architekta w Allegro? Ile takich osób pracuje w naszej firmie i dlaczego ta rola jest tak różnorodna? Czym jest Andamio i jak rozwijamy naszą platformę – o tym wszystkim opowie Piotr Betkier – Inżynier, Architekt Platformy Technicznej w Allegro oraz twórca piosenek o IT :)","contentSnippet":"Od kodowania do tworzenia strategii technicznej... Jak wygląda rola architekta w Allegro? Ile takich osób pracuje w naszej firmie i dlaczego ta rola jest tak różnorodna? Czym jest Andamio i jak rozwijamy naszą platformę – o tym wszystkim opowie Piotr Betkier – Inżynier, Architekt Platformy Technicznej w Allegro oraz twórca piosenek o IT :)","guid":"https://podcast.allegro.tech/rola_architekta_w_allegro/","isoDate":"2021-06-16T00:00:00.000Z"}]},"__N_SSG":true},"page":"/","query":{},"buildId":"Iiqoilz9LV1eXVRDdWcZX","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>