<!DOCTYPE html><html lang="pl"><head><meta charSet="utf-8"/><link rel="prefetch" href="https://allegrotechio.disqus.com/count.js"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta name="description" content="Allegro Tech to miejsce, w którym nasi inżynierowie dzielą się wiedzą oraz case study z wybranych projektów w firmie - w formie artykułów, podcastów oraz eventów."/><title>Allegro Tech</title><meta property="og:site_name" content="allegro.tech"/><meta property="og:title" content="allegro.tech"/><meta property="og:url" content="https://allegro.tech"/><meta property="og:type" content="site"/><meta property="og:image" content="https://allegro.tech/images/allegro-tech.png"/><link rel="shortcut icon" href="favicon.ico"/><link rel="canonical" href="https://allegro.tech" itemProp="url"/><link rel="preload" href="images/splash.jpg" as="image"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-1M1FJ5PXWW"></script><script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){dataLayer.push(arguments);}
                    gtag('js', new Date());
                    gtag('config', 'G-1M1FJ5PXWW');
                </script><meta name="next-head-count" content="15"/><link rel="preload" href="/_next/static/css/66933eaa547aae51.css" as="style"/><link rel="stylesheet" href="/_next/static/css/66933eaa547aae51.css" data-n-g=""/><link rel="preload" href="/_next/static/css/79db8b1e27b0a093.css" as="style"/><link rel="stylesheet" href="/_next/static/css/79db8b1e27b0a093.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-69bfa6990bb9e155.js" defer=""></script><script src="/_next/static/chunks/framework-e70c6273bfe3f237.js" defer=""></script><script src="/_next/static/chunks/main-f635b472c367d1c7.js" defer=""></script><script src="/_next/static/chunks/pages/_app-179adf437ae674f2.js" defer=""></script><script src="/_next/static/chunks/206-3a56e5ded293e83e.js" defer=""></script><script src="/_next/static/chunks/pages/index-f037c91132ed6a0a.js" defer=""></script><script src="/_next/static/vPqbtsrqX3GNPCl2N4FFh/_buildManifest.js" defer=""></script><script src="/_next/static/vPqbtsrqX3GNPCl2N4FFh/_ssgManifest.js" defer=""></script><script src="/_next/static/vPqbtsrqX3GNPCl2N4FFh/_middlewareManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><header class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card Header_navbar__Zc5aN m-color-bg_card"><nav class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-display-flex m-flex-justify-between m-flex-items-center"><a href="/"><img src="images/logo.svg" alt="Allegro Tech" width="205" height="45"/></a><div><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0 m-display-flex@lg m-display-none"><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://blog.allegro.tech">Blog</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://ml.allegro.tech">Machine Learning</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://podcast.allegro.tech">Podcast</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://github.com/Allegro">Open Source</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://www.meetup.com/allegrotech/events">Wydarzenia</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://praca.allegro.pl">Praca</a></li></ul><button class="m-display-none@lg m-height_40 m-line-height_40 m-border-style-top_none m-border-style-right_none m-border-style-bottom_none m-border-style-left_none m-border-radius-top-left_2 m-border-radius-top-right_2 m-border-radius-bottom-left_2 m-border-radius-bottom-right_2 m-cursor_pointer m-overflow_hidden m-appearance_none m-padding-left_4 m-padding-right_4 m-padding-top_4 m-padding-bottom_4 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button" style="background:transparent" aria-label="Otwórz menu"><img src="https://assets.allegrostatic.com/metrum/icon/menu-23e046bf68.svg" alt="" class="m-icon" width="32" height="32"/></button></div></nav></header><div class="Header_hero__PYE0B"><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-display-flex m-flex-column m-flex-justify-end Header_image__Cj6ZF"><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-color-bg_desk"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text  m-font-weight_100 m-font-size_32 m-font-size_43_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125">O nas</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">Allegro to jedna z najbardziej zaawansowanych technologicznie firm w naszej części Europy. Allegro to również ponad 1000 specjalistów IT, różnych specjalizacji, rozwijających nasz serwis. Unikatowa skala i złożoność problemów, które rozwiązujemy na co dzień, dają nam możliwość rozwoju przy bardzo różnorodnych projektach. Allegro Tech to miejsce, w którym nasi inżynierowie dzielą się wiedzą oraz case study z wybranych projektów w firmie – w formie artykułów, podcastów oraz eventów.</p></div></div></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24">Blog</h2><div class="m-display_flex m-flex-wrap_1 m-flex-grow_1 m-grid"><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://blog.allegro.tech/2022/07/event-storming-workshops.html" title="How to facilitate EventStorming workshops"><img width="388" src="images/post-headers/eventstorming.png" alt="How to facilitate EventStorming workshops" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://blog.allegro.tech/2022/07/event-storming-workshops.html" title="How to facilitate EventStorming workshops" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">How to facilitate EventStorming workshops</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">około 13 godzin temu</time><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0"><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/eventstorming">#<!-- -->eventstorming</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/tech">#<!-- -->tech</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/communication">#<!-- -->communication</a></li></ul><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1 m-padding-top-16">With this article, I would like to introduce you to EventStorming and explain to you how to get started. I am not discovering
anything new, just…</p><div class="m-display-flex m-flex-justify-between m-padding-top-16 m-flex-items_center"><div class="m-display-flex m-flex-items_center"><div class="MuiAvatarGroup-root m-padding-right_16 Post_avatars__FHMgb"><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar" style="z-index:1"><img alt="Krzysztof Przychodzki" src="https://blog.allegro.tech/img/authors/krzysztof.przychodzki.jpg" class="MuiAvatar-img" width="32" height="32"/></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/authors/krzysztof.przychodzki">Krzysztof Przychodzki</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/2022/07/event-storming-workshops.html#disqus_thread">0 Comments</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech/2022/07/event-storming-workshops.html">przejdź do wpisu</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://blog.allegro.tech/2022/06/gc-hands-off-my-data.html" title="GC, hands off my data!"><img width="388" src="images/post-headers/default.jpg" alt="GC, hands off my data!" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://blog.allegro.tech/2022/06/gc-hands-off-my-data.html" title="GC, hands off my data!" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">GC, hands off my data!</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">20 dni temu</time><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0"><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/tech">#<!-- -->tech</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/cache">#<!-- -->cache</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/performance">#<!-- -->performance</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/off-heap">#<!-- -->off-heap</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/garbage collectors">#<!-- -->garbage collectors</a></li></ul><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1 m-padding-top-16">Certainly one of the main distinguishing features of the Java world is the Garbage Collector.
Using it is safe and convenient, it allows us to forget…</p><div class="m-display-flex m-flex-justify-between m-padding-top-16 m-flex-items_center"><div class="m-display-flex m-flex-items_center"><div class="MuiAvatarGroup-root m-padding-right_16 Post_avatars__FHMgb"><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar" style="z-index:1"><img alt="Michał Knasiecki" src="https://blog.allegro.tech/img/authors/michal.knasiecki.jpg" class="MuiAvatar-img" width="32" height="32"/></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/authors/michal.knasiecki">Michał Knasiecki</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/2022/06/gc-hands-off-my-data.html#disqus_thread">0 Comments</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech/2022/06/gc-hands-off-my-data.html">przejdź do wpisu</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://blog.allegro.tech/2022/06/graphql-perf-tradeoffs.html" title="Exploring GraphQL’s performance tradeoffs"><img width="388" src="images/post-headers/java.png" alt="Exploring GraphQL’s performance tradeoffs" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://blog.allegro.tech/2022/06/graphql-perf-tradeoffs.html" title="Exploring GraphQL’s performance tradeoffs" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Exploring GraphQL’s performance tradeoffs</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">30 dni temu</time><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0"><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/tech">#<!-- -->tech</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/backend">#<!-- -->backend</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/performance">#<!-- -->performance</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/graphql">#<!-- -->graphql</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/kotlin">#<!-- -->kotlin</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/java">#<!-- -->java</a></li></ul><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1 m-padding-top-16">At Allegro we decided to introduce GraphQL as our API Gateway for building several internal client systems.
By building such a solution we’ve learnt a lot…</p><div class="m-display-flex m-flex-justify-between m-padding-top-16 m-flex-items_center"><div class="m-display-flex m-flex-items_center"><div class="MuiAvatarGroup-root m-padding-right_16 Post_avatars__FHMgb"><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar" style="z-index:2"><img alt="Alicja Halamska" src="https://blog.allegro.tech/img/authors/alicja.halamska.jpg" class="MuiAvatar-img" width="32" height="32"/></div><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar" style="z-index:1"><img alt="Dawid Kubicki" src="https://blog.allegro.tech/img/authors/dawid.kubicki.jpg" class="MuiAvatar-img" width="32" height="32"/></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/authors/alicja.halamska">Alicja Halamska…</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/2022/06/graphql-perf-tradeoffs.html#disqus_thread">0 Comments</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech/2022/06/graphql-perf-tradeoffs.html">przejdź do wpisu</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://blog.allegro.tech/2022/06/debt-reduction-in-the-product-roadmap.html" title="How to include refactoring into product development roadmap? Reducing technical debt inspired by real options identification"><img width="388" src="images/post-headers/default.jpg" alt="How to include refactoring into product development roadmap? Reducing technical debt inspired by real options identification" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://blog.allegro.tech/2022/06/debt-reduction-in-the-product-roadmap.html" title="How to include refactoring into product development roadmap? Reducing technical debt inspired by real options identification" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">How to include refactoring into product development roadmap? Reducing technical debt inspired by real options identification</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">około miesiąc temu</time><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0"><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/tech">#<!-- -->tech</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/roadmaps">#<!-- -->roadmaps</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/tech debt">#<!-- -->tech debt</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/product">#<!-- -->product</a></li></ul><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1 m-padding-top-16">Nowadays, technical debt can be considered the bread and butter of most IT-powered enterprises around the world.
Almost every company that survived the startup phase and…</p><div class="m-display-flex m-flex-justify-between m-padding-top-16 m-flex-items_center"><div class="m-display-flex m-flex-items_center"><div class="MuiAvatarGroup-root m-padding-right_16 Post_avatars__FHMgb"><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar" style="z-index:1"><img alt="Olga Dudzik" src="https://blog.allegro.tech/img/authors/olga.dudzik.jpg" class="MuiAvatar-img" width="32" height="32"/></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/authors/olga.dudzik">Olga Dudzik</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/2022/06/debt-reduction-in-the-product-roadmap.html#disqus_thread">0 Comments</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech/2022/06/debt-reduction-in-the-product-roadmap.html">przejdź do wpisu</a></div></article></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display_block m-margin-bottom_8 m-width_100 m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech">Zobacz więcej wpisów</a></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24">Podcasty</h2><div class="m-display_flex m-flex-wrap_1 m-flex-grow_1 m-grid"><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://podcast.allegro.tech/rola_architekta_w_allegro/" title="S02E12 - Piotr Betkier - Rola architekta w Allegro"><img src="images/podcast.png" alt="S02E12 - Piotr Betkier - Rola architekta w Allegro" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://podcast.allegro.tech/rola_architekta_w_allegro/" title="S02E12 - Piotr Betkier - Rola architekta w Allegro" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">S02E12 - Piotr Betkier - Rola architekta w Allegro</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">około rok temu</time><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1">Od kodowania do tworzenia strategii technicznej... Jak wygląda rola architekta w Allegro? Ile takich osób pracuje w naszej firmie i dlaczego ta rola jest tak różnorodna? Czym jest Andamio i jak rozwijamy naszą platformę – o tym wszystkim opowie Piotr Betkier – Inżynier, Architekt Platformy Technicznej w Allegro oraz twórca piosenek o IT :)</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech/rola_architekta_w_allegro/">Posłuchaj odcinka</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://podcast.allegro.tech/infrastruktura_Allegro/" title="S02E11 - Piotr Michoński - Infrastruktura Allegro"><img src="images/podcast.png" alt="S02E11 - Piotr Michoński - Infrastruktura Allegro" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://podcast.allegro.tech/infrastruktura_Allegro/" title="S02E11 - Piotr Michoński - Infrastruktura Allegro" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">S02E11 - Piotr Michoński - Infrastruktura Allegro</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">około rok temu</time><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1">Jak jest zbudowane środowisko uruchomienia aplikacji Allegro? Jak działają serwerownie firmy i ile ich potrzeba, a które elementy Allegro działają w chmurze publicznej? Jak przebiegała transformacja w Allegro i co zmieniało się przez lata? Jak wzrost biznesu wpływa na wielkość infrastruktury i jak infrastruktura Allegro odczuła przyjście pandemii? O tym, a także o rozwoju liderów technologii w Allegro oraz o historii powstania dżingla do naszych podcastów, opowie Piotr Michoński - menadżer Zespołów tworzących infrastrukturę Allegro.</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech/infrastruktura_Allegro/">Posłuchaj odcinka</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://podcast.allegro.tech/praca_architekta_ekosystemu_big_data_w_Allegro/" title="S02E10 - Dariusz Eliasz - Praca architekta ekosystemu big data w Allegro"><img src="images/podcast.png" alt="S02E10 - Dariusz Eliasz - Praca architekta ekosystemu big data w Allegro" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://podcast.allegro.tech/praca_architekta_ekosystemu_big_data_w_Allegro/" title="S02E10 - Dariusz Eliasz - Praca architekta ekosystemu big data w Allegro" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">S02E10 - Dariusz Eliasz - Praca architekta ekosystemu big data w Allegro</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">około rok temu</time><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1">Jak wygląda praca architekta ekosystemu big data w Allegro? Jakie zadania realizuje nasz zespół odpowiedzialny za narzędzia i infrastrukturę dla przetwarzania danych? Kiedy możemy mówić o dużych danych i ile petabajtów przetwarza Allegro? Skąd pochodzą dane Allegro i dlaczego jest ich tak dużo oraz z jakiego powodu dopiero teraz przenosimy się do chmury? O tym wszystkim opowie zdobywca statuetki Allegro Tech Hero - Dariusz Eliasz – Team Manager &amp; Platform Architect w Allegro.</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech/praca_architekta_ekosystemu_big_data_w_Allegro/">Posłuchaj odcinka</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://podcast.allegro.tech/od_inzyniera_do_lidera_w_allegro/" title="S02E09 - Bartosz Gałek - Od inżyniera do lidera w Allegro"><img src="images/podcast.png" alt="S02E09 - Bartosz Gałek - Od inżyniera do lidera w Allegro" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://podcast.allegro.tech/od_inzyniera_do_lidera_w_allegro/" title="S02E09 - Bartosz Gałek - Od inżyniera do lidera w Allegro" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">S02E09 - Bartosz Gałek - Od inżyniera do lidera w Allegro</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">około rok temu</time><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1">Czym jest Opbox i jakie wyzwania przed nim stoją? Jak w Allegro angażujemy się w rozwój kultury Open Source? Ile mamy projektów na GitHubie i jak świętujemy Hacktoberfest? W jaki sposób można rozwinąć się od inżyniera do lidera? Na te pytania w najnowszym Allegro Tech Podcast odpowie Bartek Gałek, Team Leader w Allegro.</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech/od_inzyniera_do_lidera_w_allegro/">Posłuchaj odcinka</a></div></article></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display_block m-margin-bottom_8 m-width_100 m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech">Zobacz więcej podcastów</a></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24">Wydarzenia</h2><div class="m-display_flex m-flex-wrap_1 m-flex-grow_1 m-grid"><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--6@xl m-display-flex m-flex-direction_column"><div class="m-margin-bottom_16 m-display-flex m-flex-direction_column m-flex-direction_row_sm m-padding-bottom_0"><a href="https://www.meetup.com/allegrotech/events/287035383/" title="Allegro Tech Labs #10 Online: Poskromić stan w React" class="m-display_none m-display_block_lg" style="background-color:#fd4a02"><img width="218" src="images/event.png" alt="Allegro Tech Labs #10 Online: Poskromić stan w React"/></a><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-direction_column m-padding-bottom_0 m-flex_1 m-flex-justify_between m-color-bg_card"><a href="https://www.meetup.com/allegrotech/events/287035383/" title="Allegro Tech Labs #10 Online: Poskromić stan w React" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Allegro Tech Labs #10 Online: Poskromić stan w React</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">za 2 dni</time><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-top-8">❗NA WYDARZENIE OBOWIĄZUJE REJESTRACJA: Liczba miejsc jest organiczona: [https://app.evenea.pl/event/allegro-tech-labs-10/](https://app.evenea.pl/event/allegro-tech-labs-10/?fbclid=IwAR1Zj3sIcfx3WEWiFfS_hgiW6BJQD6stYouSGuSqfxDq9YVeom8fTFcrE1Q) ❗ **Allegro Tech Labs** to w 100% zdalna odsłona naszych stacjonarnych spotkań warsztatowych. Zazwyczaj spotykaliśmy się…</time><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/287035383/">Szczegóły</a></article></div></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--6@xl m-display-flex m-flex-direction_column"><div class="m-margin-bottom_16 m-display-flex m-flex-direction_column m-flex-direction_row_sm m-padding-bottom_0"><a href="https://www.meetup.com/allegrotech/events/286545395/" title="Allegro Tech Live #29 - Wyzwania Product Managera" class="m-display_none m-display_block_lg" style="background-color:#fd4a02"><img width="218" src="images/event.png" alt="Allegro Tech Live #29 - Wyzwania Product Managera"/></a><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-direction_column m-padding-bottom_0 m-flex_1 m-flex-justify_between m-color-bg_card"><a href="https://www.meetup.com/allegrotech/events/286545395/" title="Allegro Tech Live #29 - Wyzwania Product Managera" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Allegro Tech Live #29 - Wyzwania Product Managera</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">19 dni temu</time><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-top-8">Allegro Tech Live to w 100% zdalna odsłona naszych stacjonarnych meetupów Allegro Tech Talks. Zazwyczaj spotykaliśmy się w naszych biurach, ale tym razem to my…</time><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/286545395/">Szczegóły</a></article></div></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--6@xl m-display-flex m-flex-direction_column"><div class="m-margin-bottom_16 m-display-flex m-flex-direction_column m-flex-direction_row_sm m-padding-bottom_0"><a href="https://www.meetup.com/allegrotech/events/285416318/" title="UX Research Confetti - II edycja" class="m-display_none m-display_block_lg" style="background-color:#fd4a02"><img width="218" src="images/event.png" alt="UX Research Confetti - II edycja"/></a><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-direction_column m-padding-bottom_0 m-flex_1 m-flex-justify_between m-color-bg_card"><a href="https://www.meetup.com/allegrotech/events/285416318/" title="UX Research Confetti - II edycja" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">UX Research Confetti - II edycja</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">około 2 miesiące temu</time><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-top-8">REJESTRACJA NA WYDARZENIE -&amp;gt; https://app.evenea.pl/event/ux-research-confetti-2/ 🎉 Niech ponownie rozsypie się confetti wiedzy o badaniach UX! 🎉 Szukaliśmy konferencji badawczej UX w Polsce i nie znaleźliśmy……</time><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/285416318/">Szczegóły</a></article></div></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--6@xl m-display-flex m-flex-direction_column"><div class="m-margin-bottom_16 m-display-flex m-flex-direction_column m-flex-direction_row_sm m-padding-bottom_0"><a href="https://www.meetup.com/allegrotech/events/285691203/" title="Allegro Tech Live #28 - Mobile: Architektura softu i architektura sprzętu" class="m-display_none m-display_block_lg" style="background-color:#fd4a02"><img width="218" src="images/event.png" alt="Allegro Tech Live #28 - Mobile: Architektura softu i architektura sprzętu"/></a><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-direction_column m-padding-bottom_0 m-flex_1 m-flex-justify_between m-color-bg_card"><a href="https://www.meetup.com/allegrotech/events/285691203/" title="Allegro Tech Live #28 - Mobile: Architektura softu i architektura sprzętu" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Allegro Tech Live #28 - Mobile: Architektura softu i architektura sprzętu</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">2 miesiące temu</time><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-top-8">**Allegro Tech Live** to w 100% zdalna odsłona naszych stacjonarnych meetupów Allegro Tech Talks. Kiedyś spotykaliśmy się w naszych biurach, a teraz to my gościmy…</time><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/285691203/">Szczegóły</a></article></div></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display_block m-margin-bottom_8 m-width_100 m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/">Zobacz więcej wydarzeń</a></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24">Oferty pracy</h2><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto"><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm m-margin-bottom_0_sm m-flex-grow_1">Research Engineer - Machine Learning (Computer Vision)</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-font-size_21 m-font-size_25_sm m-font-weight_300 m-line-height_normal m-margin-top_16 m-text-align_left m-padding-right_16">Warszawa, Kraków, Poznań, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.smartrecruiters.com/Allegro/743999810853837-research-engineer-machine-learning-computer-vision?trid=de9dfdf3-7f9e-4ebf-8a64-49f6c69ad640">Sprawdź</a></article><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm m-margin-bottom_0_sm m-flex-grow_1">Research Engineer - Machine Learning (Ranking and Recommendations)</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-font-size_21 m-font-size_25_sm m-font-weight_300 m-line-height_normal m-margin-top_16 m-text-align_left m-padding-right_16">Warszawa, Poznań, Kraków, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.smartrecruiters.com/Allegro/743999785421861-research-engineer-machine-learning-ranking-and-recommendations?trid=de9dfdf3-7f9e-4ebf-8a64-49f6c69ad640">Sprawdź</a></article><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm m-margin-bottom_0_sm m-flex-grow_1">Research Engineer - Machine Learning (Ranking and Recommendations)</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-font-size_21 m-font-size_25_sm m-font-weight_300 m-line-height_normal m-margin-top_16 m-text-align_left m-padding-right_16">Warszawa, Poznań, Kraków, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.smartrecruiters.com/Allegro/743999779448676-research-engineer-machine-learning-ranking-and-recommendations?trid=de9dfdf3-7f9e-4ebf-8a64-49f6c69ad640">Sprawdź</a></article></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display_block m-margin-bottom_8 m-width_100 m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://allegro.pl/praca">Zobacz więcej ofert</a></div><footer class="m-color-bg_navy m-margin-top-32"><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24 m-padding-bottom-24 m-display-flex@sm m-flex-justify-between m-flex-items-center m-text-align_center"><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-color_white m-padding-left-24@sm">Proudly built by Allegro Tech engineers</p><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0 m-display-flex m-flex-justify-center"><li style="filter:brightness(0) invert(1);opacity:0.5" class="m-margin-right-8 m-margin-top-16 m-margin-top-0@sm m-color_white"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://github.com/allegro"><img src="https://assets.allegrostatic.com/metrum/icon/github-6a18df1729.svg" alt="Github" class="m-icon"/></a></li><li style="filter:brightness(0) invert(1);opacity:0.5" class="m-margin-right-8 m-margin-top-16 m-margin-top-0@sm m-color_white"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://www.facebook.com/allegro.tech/"><img src="https://assets.allegrostatic.com/metrum/icon/facebook-a2b92f9dcb.svg" alt="Facebook" class="m-icon"/></a></li><li style="filter:brightness(0) invert(1);opacity:0.5" class="m-margin-right-8 m-margin-top-16 m-margin-top-0@sm m-color_white"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/allegrotech"><img src="https://assets.allegrostatic.com/metrum/icon/twitter-25164a58aa.svg" alt="Twitter" class="m-icon"/></a></li></ul></div></footer><div style="visibility:hidden;height:0;overflow:hidden;position:relative"><img alt="doubleclick" width="1" height="1" style="position:absolute" src="https://pubads.g.doubleclick.net/activity;dc_iu=/21612525419/DFPAudiencePixel;ord=1082100570153.508;dc_seg=507368552?"/><img alt="fb" height="1" width="1" style="position:absolute" src="https://www.facebook.com/tr?id=1650870088530325&amp;ev=PageView&amp;noscript=1"/></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"How to facilitate EventStorming workshops","link":"https://blog.allegro.tech/2022/07/event-storming-workshops.html","pubDate":"Tue, 19 Jul 2022 00:00:00 +0200","authors":{"author":[{"name":["Krzysztof Przychodzki"],"photo":["https://blog.allegro.tech/img/authors/krzysztof.przychodzki.jpg"],"url":["https://blog.allegro.tech/authors/krzysztof.przychodzki"]}]},"content":"\u003cp\u003eWith this article, I would like to introduce you to EventStorming and explain to you how to get started. I am not discovering\nanything new, just gathering available knowledge in one place. What I will show you is a few tips on how to conduct\nand facilitate EventStorming workshops.\u003c/p\u003e\n\n\u003ch2 id=\"guide-to-big-picture-eventstorming\"\u003eGuide to Big Picture EventStorming\u003c/h2\u003e\n\n\u003ch3 id=\"introducing-eventstorming\"\u003eIntroducing EventStorming\u003c/h3\u003e\n\n\u003cp\u003eIn 2013 Alberto Brandolini posted an \u003ca href=\"https://ziobrando.blogspot.com/2013/11/introducing-event-storming.html\"\u003earticle\u003c/a\u003e\nabout a new workshop format for quick exploration of complex business domains. It was warmly welcomed by the DDD community.\nIn 2015 \u003ca href=\"https://www.thoughtworks.com/radar/techniques/event-storming\"\u003eTechnology Radar\u003c/a\u003e described EventStorming as \u003cem\u003eworthy of attention\u003c/em\u003e\nand three years later as \u003cem\u003ea recommended method\u003c/em\u003e for business domain modelling in information systems.\u003c/p\u003e\n\n\u003cp\u003eDuring the years a lot has changed, the technique has developed and matured but the main idea remained the same:\u003c/p\u003e\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cem\u003eEventStorming is a flexible workshop format that allows a massive collaborative exploration of complex domains (…)\nwhere software and business practitioners are building together a behavioural model of the whole business line.\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eThe above definition is from Alberto Brandolini’s \u003cem\u003e\u003ca href=\"https://leanpub.com/introducing_eventstorming\"\u003eIntroducing EventStorming\u003c/a\u003e\u003c/em\u003e,\nto which I will be referring in this article.\u003c/p\u003e\n\n\u003ch2 id=\"before-launching\"\u003eBefore launching\u003c/h2\u003e\n\n\u003ch3 id=\"provide-unlimited-modelling-space\"\u003eProvide unlimited modelling space\u003c/h3\u003e\n\n\u003cp\u003eWhy is it important? Because you want participants to explore and experiment during the workshop. You don’t want to\nimpose limits on them or to allow a situation where someone doesn’t add an event because there is no space left.\u003c/p\u003e\n\n\u003cp\u003eFor stationary session you need:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003ewall where you attach plotter paper (it is easier to stick post-its on plotter paper),\u003c/li\u003e\n  \u003cli\u003estickies in different colours, shapes and quantity (will discuss it later),\u003c/li\u003e\n  \u003cli\u003emarkers\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eWhen it has to be online, you can use a virtual boards such as:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e\u003ca href=\"https://miro.com/\"\u003emiro\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"https://www.mural.co/\"\u003emural\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3 id=\"approach\"\u003eApproach\u003c/h3\u003e\n\n\u003cp\u003eThere are two approaches to facilitate and that depends on general participants’ understanding of the business process.\u003c/p\u003e\n\n\u003cp\u003eIf your team does not know the domain it is good to conduct a workshop in an exploratory way, because there are a lot\nof unknowns. You can start with adding a central event, or if the domain is large - several events. Then look at\nwhat is happening before and after those events regarding time flow.\u003c/p\u003e\n\n\u003cp\u003eHowever, if your participants are familiar with the system (domain) and the goal is to discover only a part of it, see\nhow something works or immerse into a specific \u003cem\u003euse-case\u003c/em\u003e. You may want to impose certain boundaries - e.g. by\ninitial and final events.\u003c/p\u003e\n\n\u003cp\u003eDepending on what you want to achieve and how deep you want to explore your business, we can distinguish three possible formats:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eBig Picture EventStorming - when you want to look at your business from above (\u003cem\u003ea helicopter view\u003c/em\u003e),\u003c/li\u003e\n  \u003cli\u003eProcess Level EventStorming - going deeper with details but you still focus on whole view,\u003c/li\u003e\n  \u003cli\u003eDesign Level EventStorming - you break down your current process into smaller areas and then model them step by step using DDD, CQRS and/or Event Sourcing.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eIn his book Alberto Brandolini is mentioning also other formats, however, I would like to narrow the scope for the most\nimportant ones. In this article I focus on the \u003cem\u003eBig Picture\u003c/em\u003e approach as it is the first and crucial step to start exploring our business.\u003c/p\u003e\n\n\u003ch2 id=\"building-blocks\"\u003eBuilding blocks\u003c/h2\u003e\n\n\u003cp\u003eI focus here on the main building blocks without going into details. A comprehensive description can be found in the\nbook mentioned earlier.\u003c/p\u003e\n\n\u003ch3 id=\"invite-the-right-people---business-ux-it\"\u003eInvite the right people - business, UX, IT\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003ebut how do you describe the right people?\u003c/em\u003e\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003ethose who have questions\n    \u003cul\u003e\n      \u003cli\u003edevelopers, architects, designers etc.\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eand those who know the answers\n    \u003cul\u003e\n      \u003cli\u003eyou will need people that care about the problem\u003c/li\u003e\n      \u003cli\u003epeople who know the business. Try to gather people who know and understand it. Don’t confuse them with users —\npeople who are using our business/system (I mean these two words interchangeably and will use \u003cem\u003ebusiness\u003c/em\u003e across the\narticle) — these two are totally opposite.\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3 id=\"orange-sticky-note\"\u003eOrange sticky note\u003c/h3\u003e\n\n\u003cp\u003eOn which we will write down our events in the following form:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e\u003cem\u003eVerb in past tense\u003c/em\u003e to indicate that it already happened\u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003e\u003cem\u003eRelevant for domain experts\u003c/em\u003e - describing specific and pertinent events or changes in our business - these\nare changes that at the end of the day we want to save in the database.\u003c/p\u003e\n\n    \u003cp\u003e\u003cimg src=\"/img/articles/2022-07-19-eventstorming/image1.png\" alt=\"domain event\" /\u003e\u003c/p\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: It is a good practice to define the concept of an event together (with participants) at the beginning of the\nworkshop. Then we can verify our definition with events that are appearing on the wall.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eFor example:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-07-19-eventstorming/image5.png\" alt=\"example of events\" /\u003e\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003ewe have verbs in past tense,\u003c/li\u003e\n  \u003cli\u003ethey are all relevant changes in our \u003cem\u003eblog business\u003c/em\u003e,\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2 id=\"phases-of-big-picture-eventstorming-workshop\"\u003ePhases of Big Picture EventStorming workshop\u003c/h2\u003e\n\n\u003ch3 id=\"introduction\"\u003eIntroduction\u003c/h3\u003e\n\n\u003cp\u003eIt is good to start the workshop with a short introduction of all participants - but it has to be rather quick before\neverybody gets bored. Generally you can omit this step and ask only new participants to introduce themselves.\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cem\u003eWe are going to explore the business process as a whole by placing all the relevant events along a timeline. We will\nhighlight ideas, risks and opportunities along the way.\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eWhat is necessary - we need to set a goal. What will we model? Say “What is our goal? What we will model?” and try to\nanalyse.\u003c/p\u003e\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: Remember - EventStorming is not a goal by itself - it is only a tool / framework.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch3 id=\"because-the-big-picture-is-all-about-events\"\u003eBecause the Big Picture is all about events\u003c/h3\u003e\n\n\u003cp\u003eProvide participants with an idea of a domain event, why it is important and that it has to be a relevant change in our\nsystem. Imagine you do not have a computer and by the end of the day every event in our system needs to be written\ndown in a notebook, by hand. Is the event ‘offer was shown’ a relevant change you want or is it worth noting?\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: A good ice-breaker is also demonstrating how to peel the sticky note so it would not curl\nup… \u003ca href=\"https://www.youtube.com/watch?v=rPHLxOLuyLY\"\u003efor example here\u003c/a\u003e.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch2 id=\"phase-1-chaotic-exploration-brain-dump\"\u003ePhase 1 Chaotic exploration (brain dump)\u003c/h2\u003e\n\n\u003ch3 id=\"what-is-happening\"\u003eWhat is happening\u003c/h3\u003e\n\n\u003cp\u003eAll participants are using orange sticky notes, writing down events and putting them on the board. When events start\nappearing on the board, a discussion will naturally start about what kind of events they are, when they are happening or\nhow or what is triggering them.\u003c/p\u003e\n\n\u003ch3 id=\"your-role-as-a-facilitator\"\u003eYour role as a facilitator\u003c/h3\u003e\n\n\u003cp\u003eExplain that we treat our whole board as a timeline and time is passing from left to right - it helps to see what is\nhappening before and after. Sometimes it is worth showing the importance of time in an example:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003ea locker was opened,\u003c/li\u003e\n  \u003cli\u003ea package was taken out,\u003c/li\u003e\n  \u003cli\u003ethe door was closed.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eIn a different order it does not make sense.\u003c/p\u003e\n\n\u003cp\u003eYour role as a facilitator is to listen and observe - how fast new stickies are appearing, where discussion is taking\nplace (try to capture events people are arguing about). Encourage the team to try to identify as many events as possible.\nIf somebody is wrong, it’s okay and others will correct.\u003c/p\u003e\n\n\u003cp\u003eWhen someone is mentioning some mysterious term, capture its definition. As a facilitator you can and you should ask\nobvious questions as it takes the burden off the other participants.\u003c/p\u003e\n\n\u003cp\u003eThis is also a phase where divergent thinking takes place as a part of \u003cem\u003echaotic exploration\u003c/em\u003e. So on the board we have a lot\nof events (ideas). Some of them are better and some are worse but we do not judge them at this point — later we will see\nwhere they lead us. Once again you should encourage the participants to generate new ideas and set aside critical thinking and judgement.\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cstrong\u003eTips\u003c/strong\u003e:\nAs an icebreaker you can place the first event or events - to show how easy it is, and help draw participants into\nworkshops.\u003c/p\u003e\n\n  \u003cp\u003eTry to eliminate actors from the events - because we don’t want to impose mental boundaries as we may not notice that\nthere is some other case. For example instead of \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eBuyer added item to cart\u003c/code\u003e use \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eItem added to cart\u003c/code\u003e.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch3 id=\"how-to-manage-people\"\u003eHow to manage people\u003c/h3\u003e\n\n\u003cp\u003eSometimes it is a good idea to divide them into smaller groups and make them work together on the same issue\nor, quite the opposite, to focus on different areas of the system.\u003c/p\u003e\n\n\u003cp\u003eDepending on whether we are exploring or modelling the process, especially during online sessions, I think it is good to\nhave boundaries — like a start event and an end event — among which everybody can create their vision. Then\nthe most difficult part is to merge it. Another approach is to give a free hand to your participants and see how the process is going to develop.\u003c/p\u003e\n\n\u003ch3 id=\"how-long-should-it-take\"\u003eHow long should it take?\u003c/h3\u003e\n\n\u003cp\u003eWhen the speed of new events showing up dramatically slows down, it is a good time to proceed to the next phase.\nUsually chaotic exploration takes about 5 to 15 minutes, but I have noticed that after about 8 minutes people are getting\nbored and busy with other things. So especially during online meetings, when you do not control the environment (like\ncomputers, phones, chat, mails…) it is easy to lose attention. And if you add to it a \u003cem\u003ezoom fatigue\u003c/em\u003e syndrome, you can\nspoil the whole session when key participants leave.\u003c/p\u003e\n\n\u003ch2 id=\"phase-2-timeline\"\u003ePhase 2 Timeline\u003c/h2\u003e\n\n\u003cp\u003eAfter the divergent step, now it is the time for the emergent phase where we want to explore and experiment - this is what\nwe will be doing during the next phases.\u003c/p\u003e\n\n\u003ch3 id=\"what-is-happening-1\"\u003eWhat is happening\u003c/h3\u003e\n\n\u003cp\u003eNow our goal is to make sure we are actually following the timeline - we would like the flow of events to be consistent\nfrom the beginning to the end.\u003c/p\u003e\n\n\u003ch3 id=\"your-role-as-a-facilitator-1\"\u003eYour role as a facilitator:\u003c/h3\u003e\n\n\u003cp\u003eA lot of events are going to change their place, also participants will find them irrelevant or duplicated and that is\nokay. Remove the duplicates, but be careful — ask if those duplicated events mean the same thing for everybody! Do\nnot hesitate to add, remove or change some sticky notes on the board.\u003c/p\u003e\n\n\u003cp\u003eAt this step some issue points may appear, so it is good to mark them as \u003cstrong\u003ehotspots\u003c/strong\u003e. Use red sticky notes and\nwrite the issue down but this is not a good time to deliberate about it now. Try to postpone this discussion until we have\nstructured the whole process.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-07-19-eventstorming/image2.png\" alt=\"hot-spot\" /\u003e\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: During the online session when everybody is working solo, it is hard to merge all events and, including\nattention problems, you may be left alone. So my solution is to introduce the next phase right now.\u003c/p\u003e\n\n  \u003cp\u003eDepending on the team - you can pick some random person who is going to start creating a timeline based\non available events. To sustain attention, replace this person with another one. In case of inconsistencies with the timeline,\nwe complete it with the missing events.\u003c/p\u003e\n\n  \u003cp\u003eHowever, you can do all of it — if among participants there are some shy people or your participants’ supervisor is in\nthe room, when you tell the story you can make intentional errors or ask silly questions. All of this eventually will\nhelp to explore the domain.\u003c/p\u003e\n\n  \u003cp\u003eBecause as a facilitator you do not have to know everything — especially the domain or business your participants are\nexploring — you help them effectively and safely discover processes, find new solutions or define problems.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch2 id=\"phase-3-explicit-walk-through-and-reverse-narrative\"\u003ePhase 3 Explicit walk-through and reverse narrative\u003c/h2\u003e\n\n\u003ch3 id=\"what-is-happening-2\"\u003eWhat is happening:\u003c/h3\u003e\n\n\u003cp\u003eNext step is to do a walk-through by creating some sort of a story that can be told based on the events placed on the board.\nDuring this step a lot of discussions (arguments) are going to take place. Maybe some events are missing, so do not hesitate to add,\nremove or change some sticky notes on the board. We should focus on the happy path in the first place.\u003c/p\u003e\n\n\u003ch3 id=\"1-explicit-walk-through\"\u003e1. Explicit walk-through\u003c/h3\u003e\n\n\u003ch3 id=\"your-role-as-a-facilitator-2\"\u003eYour role as a facilitator:\u003c/h3\u003e\n\n\u003cp\u003ePick some random person who is going to start telling a story based on available events according to timeflow (from left\nto right). Sometimes the team gets blocked. In this situation you can add or move an event and place it in an obviously\nwrong place. Your error will be fixed quickly and help the team to move on.\u003c/p\u003e\n\n\u003ch3 id=\"how-to-help-the-participants-discover-more\"\u003eHow to help the participants discover more?\u003c/h3\u003e\n\n\u003cp\u003eThe answer is simple — by asking questions. There are some useful questions that you can ask when discussing\nalmost every event, e.g.:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eWhy did this event happen?\u003c/li\u003e\n  \u003cli\u003eWhat are the consequences of this event?\u003c/li\u003e\n  \u003cli\u003eWhat has to / needs to happen next?\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eGoing deeper (of course that depends on how deep you want to go)\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eWhat, how, when, why is it changing?\u003c/li\u003e\n  \u003cli\u003eWhen it can’t change?\u003c/li\u003e\n  \u003cli\u003eHow does this affect the business?\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: Also in this phase it can be convenient to introduce actors (phase 4 - people and systems) — if it\nhelps to tell a story or better understand the process do not hesitate (remember I told you that EventStorming is a tool?)\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch3 id=\"2-reverse-narrative\"\u003e2. Reverse narrative\u003c/h3\u003e\n\n\u003ch3 id=\"your-role-as-a-facilitator-3\"\u003eYour role as a facilitator:\u003c/h3\u003e\n\n\u003cp\u003eSometimes it is good to propose a reverse narrative / reverse chronology. Pick an event from the end of the flow and\nlook for the event that made it possible - it must be consistent - no magic gaps between events. Again if we miss some\nevents - add them.\u003c/p\u003e\n\n\u003cp\u003eSome questions you can ask:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eBefore\n    \u003cul\u003e\n      \u003cli\u003e\u003cem\u003eWhat has happened before X\u003c/em\u003e\u003c/li\u003e\n      \u003cli\u003e\u003cem\u003eWhat else has to happen for X to happen\u003c/em\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eBetween - we take two corresponding events\n    \u003cul\u003e\n      \u003cli\u003e\u003cem\u003eIs there anything else happening between X and Y\u003c/em\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eAlternative - ask about alternative events\n    \u003cul\u003e\n      \u003cli\u003e\u003cem\u003eWhat if X did not happen\u003c/em\u003e\u003c/li\u003e\n      \u003cli\u003e\u003cem\u003eWhat if 10% of X happened or 150% of X happened\u003c/em\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2 id=\"phase-4-people-and-systems\"\u003ePhase 4 People and systems\u003c/h2\u003e\n\n\u003ch3 id=\"what-is-happening-3\"\u003eWhat is happening\u003c/h3\u003e\n\n\u003cp\u003eWhen we finish enforcing the timeline and we have a consistent flow of our business we can add people and external\nsystems. We need them for clarity and better understanding of events and forces governing our business.\u003c/p\u003e\n\n\u003cp\u003eFor marking people we use a yellow sticky note with a symbolic drawing of a person or clock if we want to show that time\nmatters. External systems may be represented by large pink stickies with their names on it. By an external system I mean\na piece of the whole process which is beyond our control e.g. an application, a department, other companies.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-07-19-eventstorming/image3.png\" alt=\"actor\" /\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-07-19-eventstorming/image4.png\" alt=\"system\" /\u003e\u003c/p\u003e\n\n\u003ch3 id=\"who-is-an-actor\"\u003eWho is an actor?\u003c/h3\u003e\n\n\u003cp\u003eIn his book Alberto Brandolini explains that\u003c/p\u003e\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cem\u003eThe goal is not to match the right yellow sticky note to every event in the flow. Adding significant people adds more\nclarity, but the goal is to trigger some insightful conversation: wherever the behaviour depends on a different type\nof user, wherever special actions need to be taken, and so on.\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eThe lack of precision is helping in discussion and exploration. It can be a specific person for example:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e\u003cem\u003ein our business model only Mrs. Smith can issue an invoice\u003c/em\u003e.\u003c/li\u003e\n  \u003cli\u003eor \u003cem\u003eafter some time reservation is cancelled\u003c/em\u003e so even \u003cem\u003etime\u003c/em\u003e can be an actor.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eAnother example:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e\u003cem\u003eorder cancellation\u003c/em\u003e can have two actors: client and CEX worker.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2 id=\"phase-5-opportunities-and-risks\"\u003ePhase 5 Opportunities and risks\u003c/h2\u003e\n\n\u003cp\u003eIn this phase we can literally take three steps back and look at the whole business flow as it is.\n\u003cstrong\u003eHot spots\u003c/strong\u003e are the most conspicuous things - and it is easy to say where the biggest impediment is. This\nis a great occasion for additional discussion and a subject for further exploration.\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: Remember that each \u003cem\u003ehot spot\u003c/em\u003e should be addressed and resolved before the next session takes place.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eAnother way to find where problems might lay is voting for a specific event or marking events that indicate where in our\nflow we are generating / losing money or value. For example by green stripes we indicate events where we are earning money,\nby red stripes where we are losing money or value.\u003c/p\u003e\n\n\u003ch2 id=\"it-is-like-pizzas\"\u003eIt is like Pizzas\u003c/h2\u003e\n\n\u003cp\u003eWhen all hotspots are addressed, you have found the biggest impediment, or you know on what part you have to focus on\nduring next session. The only thing left to do is to close the workshop, thank all stakeholders and participants,\nschedule the next session and ask for feedback.\u003c/p\u003e\n\n\u003cp\u003eAfter the session you will have a clear business narrative on the board. What is more important, participants will\nshare general understanding of the process. They have gone through the massive learning process, gained experience and\nshared the common knowledge — everybody uses the domain language. Due to the fact that we used simple building\nblocks, the outcome is understandable to everyone PMs, UX designers, developers etc.\u003c/p\u003e\n\n\u003cp\u003eThe steps described above and their sequence should be regarded as optional during the session.\nThere is no such thing as one recipe. For example, if during the \u003cem\u003etimeline step\u003c/em\u003e you feel that introduction of\npeople and systems is going to help, do not hesitate to do so. In other cases you will be interested only in\nfinding impediments or where your system is delivering values and do not feel obligated to use all the steps.\nAs Alberto says:\u003c/p\u003e\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cem\u003eI like to think about it like Pizzas: there’s a common base, but different toppings.\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch3 id=\"nobody-is-excluded\"\u003eNobody is excluded\u003c/h3\u003e\n\n\u003cp\u003eBig Picture EventStorming is the first and crucial step, its outcome is visible and valuable. Depending on what the team\nneeds, it can be sufficient, but if we want to go deeper and explore more, next there are Process Level and Design Level\nEventStorming. We use the same stickies’ grammar enhanced with more colours to explain the complexity of our system. Due\nto the fact that we use the same grammar, developers and businesses can speak the same language — nobody is\nexcluded, isn’t that great?\u003c/p\u003e\n\n\u003cp\u003eThose further steps (Process/Design Level) are getting us closer into the domain-driven-design and implementation. We (\ndevelopers/architects) can start thinking how to change what we have learned into working code, because\u003c/p\u003e\n\u003cblockquote\u003e\n  \u003cp\u003e\u003cem\u003e(…) it’s developer understanding that gets captured in code and released in production.\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch2 id=\"call-for-action\"\u003eCall for action\u003c/h2\u003e\n\n\u003cp\u003eIf you are Allegro worker and you are interested in EventStorming, you want to develop, participate in workshops\nor help as a facilitator I strongly encourage you to join the guild.\nIf you are not yet working at Allegro but are interested in how we use EventStorming maybe it is good opportunity to\njoin\nus — \u003ca href=\"https://www.linkedin.com/company/allegro-pl/life/team\"\u003e#goodtobehere\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch2 id=\"more-about-eventstroming\"\u003eMore about EventStroming\u003c/h2\u003e\n\n\u003cp\u003eOn the Internet you can find a lot of materials about EventStorming. Below is a list of those I found most valuable.\u003c/p\u003e\n\n\u003ch3 id=\"books\"\u003eBooks\u003c/h3\u003e\n\n\u003col\u003e\n  \u003cli\u003e\u003ca href=\"https://leanpub.com/introducing_eventstorming\"\u003eIntroducing EventStorming\u003c/a\u003e Alberto Brandolini’s book —\n\u003cem\u003eEventStorming Bible\u003c/em\u003e — mandatory book!\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"https://leanpub.com/eventstorming_handbook\"\u003eThe EventStorming Handbook\u003c/a\u003e by Paul Rayner — a great summary of\n\u003cem\u003eIntroducing EventStorming\u003c/em\u003e with a lot of valuable tips, tricks and recipes. After that you will be able to explain\nEventStorming even to your own child.\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"https://gamestorming.com/\"\u003eGameStorming A Playbook for Innovators, Rulebreakers, and Changemakers\u003c/a\u003e by Dave Gray,\nSunni Brown, James Macanufo — if you want to use the full potential of your storming sessions.\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"https://allegro.pl/oferta/facilitator-s-guide-to-participatory-decision-maki-10017700512\"\u003eFacilitator’s Guide to Participatory Decision-making\u003c/a\u003e\nby Sam Kaner, Lenny Lind — how to be a better facilitator, not only for EventStorming. You will find precious\ninformation about divergent, emergent and convergent thinking and why it is important.\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch3 id=\"link\"\u003eLink\u003c/h3\u003e\n\n\u003col\u003e\n  \u003cli\u003e\u003ca href=\"https://github.com/mariuszgil/awesome-eventstorming\"\u003eAwesome EventStorming\u003c/a\u003e by Mariusz Gil — I belive this is\nthe biggest source of links about EventStorming topics.\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003ch2 id=\"thanks\"\u003eThanks\u003c/h2\u003e\n\n\u003cp\u003eI would like to thank all of my colleagues from \u003cem\u003eAllegro EventStorming Guild\u003c/em\u003e for their help in creating this article.\u003c/p\u003e\n","contentSnippet":"With this article, I would like to introduce you to EventStorming and explain to you how to get started. I am not discovering\nanything new, just gathering available knowledge in one place. What I will show you is a few tips on how to conduct\nand facilitate EventStorming workshops.\nGuide to Big Picture EventStorming\nIntroducing EventStorming\nIn 2013 Alberto Brandolini posted an article\nabout a new workshop format for quick exploration of complex business domains. It was warmly welcomed by the DDD community.\nIn 2015 Technology Radar described EventStorming as worthy of attention\nand three years later as a recommended method for business domain modelling in information systems.\nDuring the years a lot has changed, the technique has developed and matured but the main idea remained the same:\nEventStorming is a flexible workshop format that allows a massive collaborative exploration of complex domains (…)\nwhere software and business practitioners are building together a behavioural model of the whole business line.\nThe above definition is from Alberto Brandolini’s Introducing EventStorming,\nto which I will be referring in this article.\nBefore launching\nProvide unlimited modelling space\nWhy is it important? Because you want participants to explore and experiment during the workshop. You don’t want to\nimpose limits on them or to allow a situation where someone doesn’t add an event because there is no space left.\nFor stationary session you need:\nwall where you attach plotter paper (it is easier to stick post-its on plotter paper),\nstickies in different colours, shapes and quantity (will discuss it later),\nmarkers\nWhen it has to be online, you can use a virtual boards such as:\nmiro\nmural\nApproach\nThere are two approaches to facilitate and that depends on general participants’ understanding of the business process.\nIf your team does not know the domain it is good to conduct a workshop in an exploratory way, because there are a lot\nof unknowns. You can start with adding a central event, or if the domain is large - several events. Then look at\nwhat is happening before and after those events regarding time flow.\nHowever, if your participants are familiar with the system (domain) and the goal is to discover only a part of it, see\nhow something works or immerse into a specific use-case. You may want to impose certain boundaries - e.g. by\ninitial and final events.\nDepending on what you want to achieve and how deep you want to explore your business, we can distinguish three possible formats:\nBig Picture EventStorming - when you want to look at your business from above (a helicopter view),\nProcess Level EventStorming - going deeper with details but you still focus on whole view,\nDesign Level EventStorming - you break down your current process into smaller areas and then model them step by step using DDD, CQRS and/or Event Sourcing.\nIn his book Alberto Brandolini is mentioning also other formats, however, I would like to narrow the scope for the most\nimportant ones. In this article I focus on the Big Picture approach as it is the first and crucial step to start exploring our business.\nBuilding blocks\nI focus here on the main building blocks without going into details. A comprehensive description can be found in the\nbook mentioned earlier.\nInvite the right people - business, UX, IT\nbut how do you describe the right people?\nthose who have questions\n    \ndevelopers, architects, designers etc.\nand those who know the answers\n    \nyou will need people that care about the problem\npeople who know the business. Try to gather people who know and understand it. Don’t confuse them with users —\npeople who are using our business/system (I mean these two words interchangeably and will use business across the\narticle) — these two are totally opposite.\nOrange sticky note\nOn which we will write down our events in the following form:\nVerb in past tense to indicate that it already happened\nRelevant for domain experts - describing specific and pertinent events or changes in our business - these\nare changes that at the end of the day we want to save in the database.\n\nTip: It is a good practice to define the concept of an event together (with participants) at the beginning of the\nworkshop. Then we can verify our definition with events that are appearing on the wall.\nFor example:\n\nwe have verbs in past tense,\nthey are all relevant changes in our blog business,\nPhases of Big Picture EventStorming workshop\nIntroduction\nIt is good to start the workshop with a short introduction of all participants - but it has to be rather quick before\neverybody gets bored. Generally you can omit this step and ask only new participants to introduce themselves.\nWe are going to explore the business process as a whole by placing all the relevant events along a timeline. We will\nhighlight ideas, risks and opportunities along the way.\nWhat is necessary - we need to set a goal. What will we model? Say “What is our goal? What we will model?” and try to\nanalyse.\nTip: Remember - EventStorming is not a goal by itself - it is only a tool / framework.\nBecause the Big Picture is all about events\nProvide participants with an idea of a domain event, why it is important and that it has to be a relevant change in our\nsystem. Imagine you do not have a computer and by the end of the day every event in our system needs to be written\ndown in a notebook, by hand. Is the event ‘offer was shown’ a relevant change you want or is it worth noting?\nTip: A good ice-breaker is also demonstrating how to peel the sticky note so it would not curl\nup… for example here.\nPhase 1 Chaotic exploration (brain dump)\nWhat is happening\nAll participants are using orange sticky notes, writing down events and putting them on the board. When events start\nappearing on the board, a discussion will naturally start about what kind of events they are, when they are happening or\nhow or what is triggering them.\nYour role as a facilitator\nExplain that we treat our whole board as a timeline and time is passing from left to right - it helps to see what is\nhappening before and after. Sometimes it is worth showing the importance of time in an example:\na locker was opened,\na package was taken out,\nthe door was closed.\nIn a different order it does not make sense.\nYour role as a facilitator is to listen and observe - how fast new stickies are appearing, where discussion is taking\nplace (try to capture events people are arguing about). Encourage the team to try to identify as many events as possible.\nIf somebody is wrong, it’s okay and others will correct.\nWhen someone is mentioning some mysterious term, capture its definition. As a facilitator you can and you should ask\nobvious questions as it takes the burden off the other participants.\nThis is also a phase where divergent thinking takes place as a part of chaotic exploration. So on the board we have a lot\nof events (ideas). Some of them are better and some are worse but we do not judge them at this point — later we will see\nwhere they lead us. Once again you should encourage the participants to generate new ideas and set aside critical thinking and judgement.\nTips:\nAs an icebreaker you can place the first event or events - to show how easy it is, and help draw participants into\nworkshops.\nTry to eliminate actors from the events - because we don’t want to impose mental boundaries as we may not notice that\nthere is some other case. For example instead of Buyer added item to cart use Item added to cart.\nHow to manage people\nSometimes it is a good idea to divide them into smaller groups and make them work together on the same issue\nor, quite the opposite, to focus on different areas of the system.\nDepending on whether we are exploring or modelling the process, especially during online sessions, I think it is good to\nhave boundaries — like a start event and an end event — among which everybody can create their vision. Then\nthe most difficult part is to merge it. Another approach is to give a free hand to your participants and see how the process is going to develop.\nHow long should it take?\nWhen the speed of new events showing up dramatically slows down, it is a good time to proceed to the next phase.\nUsually chaotic exploration takes about 5 to 15 minutes, but I have noticed that after about 8 minutes people are getting\nbored and busy with other things. So especially during online meetings, when you do not control the environment (like\ncomputers, phones, chat, mails…) it is easy to lose attention. And if you add to it a zoom fatigue syndrome, you can\nspoil the whole session when key participants leave.\nPhase 2 Timeline\nAfter the divergent step, now it is the time for the emergent phase where we want to explore and experiment - this is what\nwe will be doing during the next phases.\nWhat is happening\nNow our goal is to make sure we are actually following the timeline - we would like the flow of events to be consistent\nfrom the beginning to the end.\nYour role as a facilitator:\nA lot of events are going to change their place, also participants will find them irrelevant or duplicated and that is\nokay. Remove the duplicates, but be careful — ask if those duplicated events mean the same thing for everybody! Do\nnot hesitate to add, remove or change some sticky notes on the board.\nAt this step some issue points may appear, so it is good to mark them as hotspots. Use red sticky notes and\nwrite the issue down but this is not a good time to deliberate about it now. Try to postpone this discussion until we have\nstructured the whole process.\n\nTip: During the online session when everybody is working solo, it is hard to merge all events and, including\nattention problems, you may be left alone. So my solution is to introduce the next phase right now.\nDepending on the team - you can pick some random person who is going to start creating a timeline based\non available events. To sustain attention, replace this person with another one. In case of inconsistencies with the timeline,\nwe complete it with the missing events.\nHowever, you can do all of it — if among participants there are some shy people or your participants’ supervisor is in\nthe room, when you tell the story you can make intentional errors or ask silly questions. All of this eventually will\nhelp to explore the domain.\nBecause as a facilitator you do not have to know everything — especially the domain or business your participants are\nexploring — you help them effectively and safely discover processes, find new solutions or define problems.\nPhase 3 Explicit walk-through and reverse narrative\nWhat is happening:\nNext step is to do a walk-through by creating some sort of a story that can be told based on the events placed on the board.\nDuring this step a lot of discussions (arguments) are going to take place. Maybe some events are missing, so do not hesitate to add,\nremove or change some sticky notes on the board. We should focus on the happy path in the first place.\n1. Explicit walk-through\nYour role as a facilitator:\nPick some random person who is going to start telling a story based on available events according to timeflow (from left\nto right). Sometimes the team gets blocked. In this situation you can add or move an event and place it in an obviously\nwrong place. Your error will be fixed quickly and help the team to move on.\nHow to help the participants discover more?\nThe answer is simple — by asking questions. There are some useful questions that you can ask when discussing\nalmost every event, e.g.:\nWhy did this event happen?\nWhat are the consequences of this event?\nWhat has to / needs to happen next?\nGoing deeper (of course that depends on how deep you want to go)\nWhat, how, when, why is it changing?\nWhen it can’t change?\nHow does this affect the business?\nTip: Also in this phase it can be convenient to introduce actors (phase 4 - people and systems) — if it\nhelps to tell a story or better understand the process do not hesitate (remember I told you that EventStorming is a tool?)\n2. Reverse narrative\nYour role as a facilitator:\nSometimes it is good to propose a reverse narrative / reverse chronology. Pick an event from the end of the flow and\nlook for the event that made it possible - it must be consistent - no magic gaps between events. Again if we miss some\nevents - add them.\nSome questions you can ask:\nBefore\n    \nWhat has happened before X\nWhat else has to happen for X to happen\nBetween - we take two corresponding events\n    \nIs there anything else happening between X and Y\nAlternative - ask about alternative events\n    \nWhat if X did not happen\nWhat if 10% of X happened or 150% of X happened\nPhase 4 People and systems\nWhat is happening\nWhen we finish enforcing the timeline and we have a consistent flow of our business we can add people and external\nsystems. We need them for clarity and better understanding of events and forces governing our business.\nFor marking people we use a yellow sticky note with a symbolic drawing of a person or clock if we want to show that time\nmatters. External systems may be represented by large pink stickies with their names on it. By an external system I mean\na piece of the whole process which is beyond our control e.g. an application, a department, other companies.\n\n\nWho is an actor?\nIn his book Alberto Brandolini explains that\nThe goal is not to match the right yellow sticky note to every event in the flow. Adding significant people adds more\nclarity, but the goal is to trigger some insightful conversation: wherever the behaviour depends on a different type\nof user, wherever special actions need to be taken, and so on.\nThe lack of precision is helping in discussion and exploration. It can be a specific person for example:\nin our business model only Mrs. Smith can issue an invoice.\nor after some time reservation is cancelled so even time can be an actor.\nAnother example:\norder cancellation can have two actors: client and CEX worker.\nPhase 5 Opportunities and risks\nIn this phase we can literally take three steps back and look at the whole business flow as it is.\nHot spots are the most conspicuous things - and it is easy to say where the biggest impediment is. This\nis a great occasion for additional discussion and a subject for further exploration.\nTip: Remember that each hot spot should be addressed and resolved before the next session takes place.\nAnother way to find where problems might lay is voting for a specific event or marking events that indicate where in our\nflow we are generating / losing money or value. For example by green stripes we indicate events where we are earning money,\nby red stripes where we are losing money or value.\nIt is like Pizzas\nWhen all hotspots are addressed, you have found the biggest impediment, or you know on what part you have to focus on\nduring next session. The only thing left to do is to close the workshop, thank all stakeholders and participants,\nschedule the next session and ask for feedback.\nAfter the session you will have a clear business narrative on the board. What is more important, participants will\nshare general understanding of the process. They have gone through the massive learning process, gained experience and\nshared the common knowledge — everybody uses the domain language. Due to the fact that we used simple building\nblocks, the outcome is understandable to everyone PMs, UX designers, developers etc.\nThe steps described above and their sequence should be regarded as optional during the session.\nThere is no such thing as one recipe. For example, if during the timeline step you feel that introduction of\npeople and systems is going to help, do not hesitate to do so. In other cases you will be interested only in\nfinding impediments or where your system is delivering values and do not feel obligated to use all the steps.\nAs Alberto says:\nI like to think about it like Pizzas: there’s a common base, but different toppings.\nNobody is excluded\nBig Picture EventStorming is the first and crucial step, its outcome is visible and valuable. Depending on what the team\nneeds, it can be sufficient, but if we want to go deeper and explore more, next there are Process Level and Design Level\nEventStorming. We use the same stickies’ grammar enhanced with more colours to explain the complexity of our system. Due\nto the fact that we use the same grammar, developers and businesses can speak the same language — nobody is\nexcluded, isn’t that great?\nThose further steps (Process/Design Level) are getting us closer into the domain-driven-design and implementation. We (\ndevelopers/architects) can start thinking how to change what we have learned into working code, because\n(…) it’s developer understanding that gets captured in code and released in production.\nCall for action\nIf you are Allegro worker and you are interested in EventStorming, you want to develop, participate in workshops\nor help as a facilitator I strongly encourage you to join the guild.\nIf you are not yet working at Allegro but are interested in how we use EventStorming maybe it is good opportunity to\njoin\nus — #goodtobehere.\nMore about EventStroming\nOn the Internet you can find a lot of materials about EventStorming. Below is a list of those I found most valuable.\nBooks\nIntroducing EventStorming Alberto Brandolini’s book —\nEventStorming Bible — mandatory book!\nThe EventStorming Handbook by Paul Rayner — a great summary of\nIntroducing EventStorming with a lot of valuable tips, tricks and recipes. After that you will be able to explain\nEventStorming even to your own child.\nGameStorming A Playbook for Innovators, Rulebreakers, and Changemakers by Dave Gray,\nSunni Brown, James Macanufo — if you want to use the full potential of your storming sessions.\nFacilitator’s Guide to Participatory Decision-making\nby Sam Kaner, Lenny Lind — how to be a better facilitator, not only for EventStorming. You will find precious\ninformation about divergent, emergent and convergent thinking and why it is important.\nLink\nAwesome EventStorming by Mariusz Gil — I belive this is\nthe biggest source of links about EventStorming topics.\nThanks\nI would like to thank all of my colleagues from Allegro EventStorming Guild for their help in creating this article.","guid":"https://blog.allegro.tech/2022/07/event-storming-workshops.html","categories":["eventstorming","tech","communication"],"isoDate":"2022-07-18T22:00:00.000Z","thumbnail":"images/post-headers/eventstorming.png"},{"title":"GC, hands off my data!","link":"https://blog.allegro.tech/2022/06/gc-hands-off-my-data.html","pubDate":"Thu, 30 Jun 2022 00:00:00 +0200","authors":{"author":[{"name":["Michał Knasiecki"],"photo":["https://blog.allegro.tech/img/authors/michal.knasiecki.jpg"],"url":["https://blog.allegro.tech/authors/michal.knasiecki"]}]},"content":"\u003cp\u003eCertainly one of the main distinguishing features of the Java world is the Garbage Collector.\nUsing it is safe and convenient, it allows us to forget about many tedious responsibilities, letting us focus on the\npure joy of coding. Yet sometimes it can cause a headache too, especially when we notice that GC uses our resources\ntoo intensively. Each of us has probably experienced a time in our career when we wanted to get\nrid of the Garbage Collector from our application because it was running too long, too often, and perhaps even led to temporary system freezes.\u003c/p\u003e\n\n\u003cp\u003eWhat if we could still benefit from the GC, but in special cases, also be able to store data beyond its control? We\ncould still take advantage of its convenience and, at the same time, be able to easily get rid of long GC pauses.\u003c/p\u003e\n\n\u003cp\u003eIt turns out that it is possible. In this article, we will look at whether and when it is worth storing data\nbeyond the reach of the Garbage Collector’s greedy hands.\u003c/p\u003e\n\n\u003ch2 id=\"comfort-comes-at-a-price\"\u003eComfort comes at a price\u003c/h2\u003e\n\n\u003cp\u003eAt \u003ca href=\"https://allegro.tech\"\u003eAllegro\u003c/a\u003e we are very keen on metrics. We measure anything that can tell us something about the condition of\nour services. Apart from the most obvious metrics directly related to the application, such as throughput, the number of\nerrors, CPU and memory usage, we also pay a great deal of attention to metrics related to the garbage collecting — GC working\ntime and number of its cycles. Too much time spent on releasing the memory or too frequent GC launches may signal problems with\nmemory leaks or indicate that it is worth considering optimising memory usage or switching to a different GC strategy.\u003c/p\u003e\n\n\u003cp\u003eFollowing the example of large technology companies, we have been organising company meetups within the so-called guilds\nfor some time now. In one of such guilds, over a hundred engineers meet regularly once a month and discuss various\ntopics related to performance, scaling and service optimisation. At one of these meetings, our colleague\ndiscussed the method of determining the actual size of data stored in a cache. Apparently, this is not a\nsimple matter, as internal mechanisms for optimising memory usage, such as deduplication or compression, must be taken\ninto account. After the presentation, an interesting discussion ensued about how much memory\non the heap is actually used by the cache and how long it takes to clean it up. Someone pointed out that there is a hidden cost of using the cache\nthat takes the form of time needed to free the memory of expired cache items, which not everyone is aware of. What is more, the\nmanner in which the cache works does not quite fit the\n\u003ca href=\"http://insightfullogic.com/2013/Feb/20/garbage-collection-java-1/\"\u003egenerational hypothesis\u003c/a\u003e and may mislead the JVM by preventing it\nfrom properly tuning the GC mechanism. I then began to wonder whether it might not be worth keeping the cache in an area\nexcluded from the GC’s control? I knew this is possible, although I had never seen a practical implementation of this\ntechnique. This topic was bothering me for some time, so I decided to investigate.\u003c/p\u003e\n\n\u003ch2 id=\"memory-architecture\"\u003eMemory architecture\u003c/h2\u003e\n\n\u003cp\u003eAny skilled Java programmer knows the division of memory into young and old generation areas. People interested in\ndetails are probably also familiar with the more precise division into eden, survivor, tenured and perm.\nThere are many excellent articles discussing this topic\n(like \u003ca href=\"https://www.betsol.com/blog/java-memory-management-for-java-virtual-machine-jvm/\"\u003ethis one\u003c/a\u003e), so we won’t go\ninto details. Instead, we will focus on a very specialised area of memory that the GC\nhas no control over, which is the off-heap memory, sometimes also called native memory. This is a special area under the\ndirect control of the operating system, which the JVM uses for its own purposes. It stores information about classes and\nmethods, internal thread data and cached code necessary for operation. As I mentioned earlier, off-heap memory is not\nsubject to the GC. In particular, it is excluded from garbage collection processes, which means that programmers\ncreating the JVM code using this area are wholly responsible for freeing memory allocated for\nvariables. There is also a dedicated area to which we — the programmers — have access as well.\nThere is a possibility to write and read data from this space, remembering of course, that the responsibility\nfor cleaning up after unnecessary variables lies entirely with us.\u003c/p\u003e\n\n\u003cp\u003eThis area can be accessed using a simple API.\nThe following code allocates 100 bytes of off-heap memory and stores a String and an Integer.\nAt the end the data are loaded from the off-heap memory and then printed out.\u003c/p\u003e\n\n\u003cdiv class=\"language-java highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e \u003cspan class=\"n\"\u003esize\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"mi\"\u003e100\u003c/span\u003e\u003cspan class=\"o\"\u003e;\u003c/span\u003e\n\n\u003cspan class=\"nc\"\u003eByteBuffer\u003c/span\u003e \u003cspan class=\"n\"\u003ebuff\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"nc\"\u003eByteBuffer\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eallocateDirect\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003esize\u003c/span\u003e\u003cspan class=\"o\"\u003e);\u003c/span\u003e\n\u003cspan class=\"n\"\u003ebuff\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eput\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\"Michal\"\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003egetBytes\u003c/span\u003e\u003cspan class=\"o\"\u003e());\u003c/span\u003e\n\u003cspan class=\"n\"\u003ebuff\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eputInt\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e42\u003c/span\u003e\u003cspan class=\"o\"\u003e);\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003ebuff\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eposition\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"o\"\u003e);\u003c/span\u003e \u003cspan class=\"c1\"\u003e// set the pointer back to the beginning\u003c/span\u003e\n\n\u003cspan class=\"kt\"\u003ebyte\u003c/span\u003e\u003cspan class=\"o\"\u003e[]\u003c/span\u003e \u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"kt\"\u003ebyte\u003c/span\u003e\u003cspan class=\"o\"\u003e[\u003c/span\u003e\u003cspan class=\"mi\"\u003e6\u003c/span\u003e\u003cspan class=\"o\"\u003e];\u003c/span\u003e \u003cspan class=\"c1\"\u003e// length of my name\u003c/span\u003e\n\u003cspan class=\"n\"\u003ebuff\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eget\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"o\"\u003e);\u003c/span\u003e\n\n\u003cspan class=\"n\"\u003eout\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eprintln\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"nc\"\u003eString\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"o\"\u003e));\u003c/span\u003e\n\u003cspan class=\"n\"\u003eout\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eprintln\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ebuff\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003egetInt\u003c/span\u003e\u003cspan class=\"o\"\u003e());\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eNote the \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eallocateDirect\u003c/code\u003e method that allocates off-heap memory unlike a similar method: \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eallocate\u003c/code\u003e that allocates\non-heap memory. The behavior of both methods can be compared with the help of a profiler\n(I will use \u003ca href=\"https://openjdk.java.net/tools/svc/jconsole/\"\u003ejConsole\u003c/a\u003e). The following programs allocate 1GB of memory,\nrespectively, on-heap and off-heap:\u003c/p\u003e\n\n\u003cdiv class=\"language-java highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"nc\"\u003eByteBuffer\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eallocate\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e1000000000\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cdiv class=\"language-java highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"nc\"\u003eByteBuffer\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eallocateDirect\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e1000000000\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eThe chart below shows heap memory profile comparison for both programs (on-heap on the left vs. off-heap on the right):\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-06-30-gc-hands-off-my-data/compare.png\" alt=\"on-heap vs off-heap\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eSuch a possibility to bypass Garbage Collector may seem extremely tempting to\ndevelopers struggling with long working time of the GC. However, this raises the question: what type of usage justifies\nthe extra effort involved in manually freeing the memory and the potential risk of error? What are the advantages of\nusing off-heap memory? Is it faster? How much time will we save by bypassing the GC? Why is this method so uncommon?\nTo put it simply: is it worth doing and if so, when?\u003c/p\u003e\n\n\u003ch2 id=\"be-gone-gc\"\u003eBe gone GC!\u003c/h2\u003e\n\n\u003cp\u003eGC is a wonderful tool. It allows us – although sometimes only for a while – to forget about the problems related\nto painful memory management. We can create variables of any type and any scope almost freely, and not worry about what\nhappens to memory once we stop using them. This task is handled by the GC, which does it brilliantly. In each successive\nversion of the JDK we get a new algorithm, which in some specific cases is even better than the previous one.\u003c/p\u003e\n\n\u003cp\u003eHowever, I’m more than sure that many of us have once encountered the problem of long GC time or too frequent GC\ncalls. Every developer has their own ideas on how to deal with this issue - we look for memory leaks, profile the\napplication in search of hot spots, examine the scope of created variables, use object pools, verify the system\nbehaviour with different GC algorithms, and check the cache configuration.\u003c/p\u003e\n\n\u003cp\u003eIn my case, it is the cache that is often responsible for long GC time. Sometimes it stores large numbers of objects, usually\ncomplex ones, containing references to other objects. What is more, the way cache objects are accessed is often not\nuniform. Some objects are never queried after being inserted into the cache, others are read throughout their whole\nlifecycle. This causes the cache to disrupt the somewhat ideal world order defined by the generational hypothesis. Then,\nGC algorithms are faced with a very difficult task of determining the optimal way to clean up the memory freed by the\nitems removed from the cache. All this causes the cache cleanup to be expensive. This made me wonder if there was\nany benefit in storing cache data outside the heap?\u003c/p\u003e\n\n\u003ch2 id=\"off-heap-space-pros-and-cons\"\u003eOff-heap space: Pros and cons\u003c/h2\u003e\n\n\u003cp\u003eIn a sense, the off-heap space lies outside the control of the JVM (though it belongs to the Java process),\nand for this reason, it is not possible to write\ncomplex structures used in JVM languages into it. This raises the need for an intermediate step of serializing the\ndata into a plain byte array, which can then be stored in the off-heap area. When the data is loaded, the reverse\nprocess must be performed: deserialization into a form that we can use in Java. These additional steps will of\ncourse come at an extra cost, which is why accessing off-heap data will, for obvious reasons, take longer than accessing\non-heap data directly.\u003c/p\u003e\n\n\u003cp\u003eSince writing and reading data in the off-heap space takes longer, what is the benefit of this approach then? Well, the data\nstored in the off-heap space are not subject to GC processes, so on the one hand we – the programmers – are responsible\nfor each freeing of memory after a given variable is no longer useful. On the other hand, we relieve the management\nprocesses in the JVM by releasing CPU’s time for the rest of the application, so, theoretically, it should\nresult in some resource savings. The question is, do these differences balance each other out to any degree? Will the savings\nassociated with the GC process balance out our longer data access time? If so, does it depend only on the amount of\ndata, or is there a specific usage scenario? To answer these questions, it is necessary to run a few experiments.\u003c/p\u003e\n\n\u003ch2 id=\"experiments\"\u003eExperiments\u003c/h2\u003e\n\n\u003cp\u003eWe can store any data structure in the on-heap area, which means that the advantage of this approach lies in the fact\nthat there is no overhead involved in transforming the data to another form, while its disadvantage consists of the\nadditional cost related to the GC. On the other hand, in the case of off-heap storage, there is no GC extra cost,\nbut there is the cost of serialising the data to a byte array.\u003c/p\u003e\n\n\u003cp\u003eOver the last years, significant\nprogress has been made in the field of GC and with the right matching of the algorithm to the application profile, its\ntime can be very short. But is there any case where it is worth reaching into the unmanaged space after all?\u003c/p\u003e\n\n\u003cp\u003eI decided to start with an overview of what open-source options are currently available. When it comes to the implementation of the\non-heap cache mechanism, the options are numerous – there is well known:\n\u003ca href=\"https://guava.dev/releases/21.0/api/docs/com/google/common/cache/Cache.html\"\u003eguava\u003c/a\u003e,\n\u003ca href=\"https://www.ehcache.org/\"\u003eehcache\u003c/a\u003e, \u003ca href=\"https://github.com/ben-manes/caffeine\"\u003ecaffeine\u003c/a\u003e and many other solutions. However,\nwhen I began researching cache mechanisms offering the possibility of storing data outside GC control, I found out\nthat there are very few solutions left. Out of the popular ones, only \u003ca href=\"https://www.terracotta.org/\"\u003eTerracotta\u003c/a\u003e is supported.\nIt seems that this is a very niche solution and we do not have many options to choose\nfrom. In terms of less-known projects, I came across \u003ca href=\"https://github.com/OpenHFT/Chronicle-Map\"\u003eChronicle-Map\u003c/a\u003e,\n\u003ca href=\"https://github.com/jankotek/MapDB\"\u003eMapDB\u003c/a\u003e and \u003ca href=\"https://github.com/snazy/ohc\"\u003eOHC\u003c/a\u003e. I chose the\nlast one because it was created as part of the Cassandra project, which I had some experience with and was curious\nabout how this component worked:\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003eOHC was developed in 2014/15 for Apache Cassandra 2.2 and 3.0 to be used as the new row-cache backend.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eTo run the experiment, I decided to use a service built to provide the offer description based on its unique number. After\ndownloading the offer description from the repository, it is placed in the cache to speed up future calls. Obviously, the\ncache has a limited capacity, which is chosen in such a way that it forces the deletion of items that have been placed\nin it for the longest time ago.\u003c/p\u003e\n\n\u003cp\u003eIn our cache, the offer number is the key, while its description in the form of a string of characters is the\nvalue. This allows us to easily simulate almost any size of data in the cache (all we have to do is to make the\noffer description longer), and additionally, it makes the overhead related to the aforementioned serialisation\nrelatively small – serialisation of a text string is obviously faster than a complex DTO object.\u003c/p\u003e\n\n\u003cp\u003eIn my project, I used the \u003ca href=\"https://github.com/ben-manes/caffeine\"\u003eCaffeine cache\u003c/a\u003e to store the data in the on-heap area\nand OHC library to store it in the off-heap area.\u003c/p\u003e\n\n\u003cp\u003eThe test scenario consists of querying for descriptions of different offers. During the test, I will\ncollect data on memory and GC parameters using jConsole. I will run the test scenario using \u003ca href=\"https://jmeter.apache.org/\"\u003ejMeter\u003c/a\u003e,\nwhich additionally will allow me to measure response times.\u003c/p\u003e\n\n\u003cp\u003eFrom my preliminary research I know that this method is only applicable to memory-intensive systems.\nHowever, for the sake of order, let’s first run an experiment on a small cache size with element set to 5 KB:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003emaximum number of cached elements: 10000\u003c/li\u003e\n  \u003cli\u003ecached element size: 5.000 bytes\u003c/li\u003e\n  \u003cli\u003e10 threads querying for random offers in a loop of 100000 iterations each\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eTake a look at the screenshots from jConsole below. The results are in line with expectations: no benefit from the use\nof off-heap space. Both the number of garbage collection cycles (63 vs. 65) and GC run time (0.182s vs 0.235s)\nare nearly identical in both cases:\u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003eThe GC profile of on-heap variant:\u003c/em\u003e\n\u003cimg src=\"/img/articles/2022-06-30-gc-hands-off-my-data/on-heap-small-gc.png\" alt=\"on-heap GC chart\" /\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003eThe GC profile of off-heap variant:\u003c/em\u003e\n\u003cimg src=\"/img/articles/2022-06-30-gc-hands-off-my-data/off-heap-small-gc.png\" alt=\"on-heap GC chart\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eNot much of an improvement for small to medium cache size. However, this result is not disappointing to me because\nI expected it. GC is designed to handle much more memory than 400 MB, it would therefore be strange if we obtained\nan improvement at such an early stage.\u003c/p\u003e\n\n\u003cp\u003eNow let’s see how the comparison looks for a much larger cache element size, let’s increase it up to 100 KB.\nAt the same time, due to the fact that I am running the tests on a laptop with limited resources, I will reduce\nthreads configuration and cache maximum element size.\u003c/p\u003e\n\n\u003cp\u003eThe configuration of the second test is as follows:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003emaximum number of cached elements: 5000\u003c/li\u003e\n  \u003cli\u003ecached element size: 100.000 bytes\u003c/li\u003e\n  \u003cli\u003e10 threads querying for random offers in a loop of 1000 iterations each\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eLet’s take a look at the results.\u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003eThe GC profile of on-heap variant:\u003c/em\u003e\n\u003cimg src=\"/img/articles/2022-06-30-gc-hands-off-my-data/on-heap-gc.png\" alt=\"on-heap GC chart\" /\u003e\nMemory usage increases throughout the test, there are 40 GC collection cycles that together last 0.212s.\u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003eThe GC profile of off-heap variant:\u003c/em\u003e\n\u003cimg src=\"/img/articles/2022-06-30-gc-hands-off-my-data/off-heap-gc.png\" alt=\"on-heap GC chart\" /\u003e\nThis time heap memory usage chart definitely looks different, is shaped like a saw, and reaches half of the previous value.\nPlease note also, that this time there are only 13 GC cycles with total time of 0.108s.\u003c/p\u003e\n\n\u003cp\u003eThe results of the GC profile comparison are therefore as expected, and what about the response times?\u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003ejMeter metrics of on-heap variant:\u003c/em\u003e\n\u003cimg src=\"/img/articles/2022-06-30-gc-hands-off-my-data/on-heap-jmeter.png\" alt=\"on-heap GC chart\" /\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003ejMeter metrics of off-heap variant:\u003c/em\u003e\n\u003cimg src=\"/img/articles/2022-06-30-gc-hands-off-my-data/off-heap-jmeter.png\" alt=\"on-heap GC chart\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eRequest time metrics data is also in line with predictions, off-heap variant proved to be slightly slower than on-heap.\u003c/p\u003e\n\n\u003cp\u003eNow let’s see what effect increasing the data size will have on the results. Let’s do tests for the following sizes:\n100.000 B, 200.000 B and 300.000 B, jMeter configuration stays unchanged: 10 threads with 1000 iterations each.\nThis time, for the sake of clarity, the results are summarized in a table:\u003c/p\u003e\n\n\u003ctable\u003e\n  \u003cthead\u003e\n    \u003ctr\u003e\n      \u003cth\u003eCached item size\u003c/th\u003e\n      \u003cth\u003eVariant\u003c/th\u003e\n      \u003cth\u003eGC cycles count\u003c/th\u003e\n      \u003cth\u003eGC time\u003c/th\u003e\n      \u003cth\u003eRequest time (median)\u003c/th\u003e\n      \u003cth\u003eThroughput\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003ctd\u003e100.000 B\u003c/td\u003e\n      \u003ctd\u003eon-heap\u003c/td\u003e\n      \u003ctd\u003e40\u003c/td\u003e\n      \u003ctd\u003e0.212 s\u003c/td\u003e\n      \u003ctd\u003e171 ms\u003c/td\u003e\n      \u003ctd\u003e83.2 rps\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd\u003e100.000 B\u003c/td\u003e\n      \u003ctd\u003eoff-heap\u003c/td\u003e\n      \u003ctd\u003e13\u003c/td\u003e\n      \u003ctd\u003e0.108 s\u003c/td\u003e\n      \u003ctd\u003e179 ms\u003c/td\u003e\n      \u003ctd\u003e78.1 rps\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd\u003e200.000 B\u003c/td\u003e\n      \u003ctd\u003eon-heap\u003c/td\u003e\n      \u003ctd\u003e84\u003c/td\u003e\n      \u003ctd\u003e0.453 s\u003c/td\u003e\n      \u003ctd\u003e396 ms\u003c/td\u003e\n      \u003ctd\u003e38.2 rps\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd\u003e200.000 B\u003c/td\u003e\n      \u003ctd\u003eoff-heap\u003c/td\u003e\n      \u003ctd\u003e19\u003c/td\u003e\n      \u003ctd\u003e0.182 s\u003c/td\u003e\n      \u003ctd\u003e355 ms\u003c/td\u003e\n      \u003ctd\u003e40.2 rps\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd\u003e300.000 B\u003c/td\u003e\n      \u003ctd\u003eon-heap\u003c/td\u003e\n      \u003ctd\u003e114\u003c/td\u003e\n      \u003ctd\u003e0.6s\u003c/td\u003e\n      \u003ctd\u003e543 ms\u003c/td\u003e\n      \u003ctd\u003e27.3 rps\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd\u003e300.000 B\u003c/td\u003e\n      \u003ctd\u003eoff-heap\u003c/td\u003e\n      \u003ctd\u003e27\u003c/td\u003e\n      \u003ctd\u003e0.185s\u003c/td\u003e\n      \u003ctd\u003e528 ms\u003c/td\u003e\n      \u003ctd\u003e27.9 rps\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\n\u003cp\u003eIt turns out that as the size of cache item increases, the benefits of using off-heap space grow – all metrics are improved.\u003c/p\u003e\n\n\u003cp\u003eWhat about cache maximum elements? Let’s use 200.000B item size and check what happens when we increase the maximum cache\nelement size, we will test cache for 5000, 10.000 and 15.000 elements:\u003c/p\u003e\n\n\u003ctable\u003e\n  \u003cthead\u003e\n    \u003ctr\u003e\n      \u003cth\u003eCache max elements\u003c/th\u003e\n      \u003cth\u003eVariant\u003c/th\u003e\n      \u003cth\u003eGC cycles count\u003c/th\u003e\n      \u003cth\u003eGC time\u003c/th\u003e\n      \u003cth\u003eRequest time (median)\u003c/th\u003e\n      \u003cth\u003eThroughput\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003ctd\u003e5000\u003c/td\u003e\n      \u003ctd\u003eon-heap\u003c/td\u003e\n      \u003ctd\u003e84\u003c/td\u003e\n      \u003ctd\u003e0.453 s\u003c/td\u003e\n      \u003ctd\u003e396 ms\u003c/td\u003e\n      \u003ctd\u003e38.2 rps\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd\u003e5000\u003c/td\u003e\n      \u003ctd\u003eoff-heap\u003c/td\u003e\n      \u003ctd\u003e19\u003c/td\u003e\n      \u003ctd\u003e0.182 s\u003c/td\u003e\n      \u003ctd\u003e355 ms\u003c/td\u003e\n      \u003ctd\u003e40.2 rps\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd\u003e10000\u003c/td\u003e\n      \u003ctd\u003eon-heap\u003c/td\u003e\n      \u003ctd\u003e81\u003c/td\u003e\n      \u003ctd\u003e0.46 s\u003c/td\u003e\n      \u003ctd\u003e393 ms\u003c/td\u003e\n      \u003ctd\u003e38.8 rps\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd\u003e10000\u003c/td\u003e\n      \u003ctd\u003eoff-heap\u003c/td\u003e\n      \u003ctd\u003e19\u003c/td\u003e\n      \u003ctd\u003e0.173 s\u003c/td\u003e\n      \u003ctd\u003e345 ms\u003c/td\u003e\n      \u003ctd\u003e42.6 rps\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd\u003e15000\u003c/td\u003e\n      \u003ctd\u003eon-heap\u003c/td\u003e\n      \u003ctd\u003e84\u003c/td\u003e\n      \u003ctd\u003e0.462 s\u003c/td\u003e\n      \u003ctd\u003e355 ms\u003c/td\u003e\n      \u003ctd\u003e41.8 rps\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd\u003e15000\u003c/td\u003e\n      \u003ctd\u003eoff-heap\u003c/td\u003e\n      \u003ctd\u003e19\u003c/td\u003e\n      \u003ctd\u003e0.167 s\u003c/td\u003e\n      \u003ctd\u003e344 ms\u003c/td\u003e\n      \u003ctd\u003e42.6 rps\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\n\u003cp\u003eNo surprise here either, increasing cache size has a positive impact on both variants. Of course in case of on-heap cache,\nsome of the benefits are offset by the need for cleaning larger memory area.\u003c/p\u003e\n\n\u003cp\u003eWith the experiments conducted, we can conclude that the more data we store in memory, the greater the benefit of using\nthe off-heap area may be. At the same time, it should be added that these benefits are not huge, just a few RPS more.\nIn the case of systems that store tremendous amounts of data, this method may bring some improvements in terms of resource utilization.\nHowever, for most of our apps and services, that’s probably not the way to go, a code audit is a better idea.\u003c/p\u003e\n\n\u003cp\u003eThis is probably a good time to highlight how well implemented the current memory sweeper algorithms are. Well done GC!\u003c/p\u003e\n\n\u003ch2 id=\"conclusions\"\u003eConclusions\u003c/h2\u003e\n\n\u003cp\u003eEveryone has probably come across a case when an application froze as a result of GC’s operation. As the above data\nshow, there is a relationship between the amount of data stored in memory and the time the GC requires to clean it up –\nthe more data we store on the heap, the longer it takes to free the memory. That is why the cases where we process large\namounts of data provide us with a potential benefit of using the off-heap area. There are some very specialised uses of\nthis technique, such as Spark, which can store large amounts of data for subsequent processing steps and can do so using\nthe off-heap space (you can read more about Spark memory model \u003ca href=\"https://medium.com/walmartglobaltech/decoding-memory-in-spark-parameters-that-are-often-confused-c11be7488a24\"\u003ehere\u003c/a\u003e).\nAnother example of the use of the off-heap approach is the Apache Cassandra database. The OHC used\nin this post was developed from this particular project.\u003c/p\u003e\n\n\u003cp\u003eThere is a very narrow group of cases where storing data outside of GC control is justifiable. However, for the\nvast majority of applications, a much better approach is to take advantage of ever-improving GC\nimplementations. If you have experienced problems with the slow performance of the GC while developing your business\nservice, you should definitely audit your code first and experiment with different heap size settings and the GC\nalgorithm. When all other methods fail, you can give the off-heap area a try.\u003c/p\u003e\n\n\u003cp\u003eHowever, if you are working on a server that processes massive amounts of data, it is worth considering off-heap\nstorage earlier, similar to Spark or Cassandra solutions.\u003c/p\u003e\n\n","contentSnippet":"Certainly one of the main distinguishing features of the Java world is the Garbage Collector.\nUsing it is safe and convenient, it allows us to forget about many tedious responsibilities, letting us focus on the\npure joy of coding. Yet sometimes it can cause a headache too, especially when we notice that GC uses our resources\ntoo intensively. Each of us has probably experienced a time in our career when we wanted to get\nrid of the Garbage Collector from our application because it was running too long, too often, and perhaps even led to temporary system freezes.\nWhat if we could still benefit from the GC, but in special cases, also be able to store data beyond its control? We\ncould still take advantage of its convenience and, at the same time, be able to easily get rid of long GC pauses.\nIt turns out that it is possible. In this article, we will look at whether and when it is worth storing data\nbeyond the reach of the Garbage Collector’s greedy hands.\nComfort comes at a price\nAt Allegro we are very keen on metrics. We measure anything that can tell us something about the condition of\nour services. Apart from the most obvious metrics directly related to the application, such as throughput, the number of\nerrors, CPU and memory usage, we also pay a great deal of attention to metrics related to the garbage collecting — GC working\ntime and number of its cycles. Too much time spent on releasing the memory or too frequent GC launches may signal problems with\nmemory leaks or indicate that it is worth considering optimising memory usage or switching to a different GC strategy.\nFollowing the example of large technology companies, we have been organising company meetups within the so-called guilds\nfor some time now. In one of such guilds, over a hundred engineers meet regularly once a month and discuss various\ntopics related to performance, scaling and service optimisation. At one of these meetings, our colleague\ndiscussed the method of determining the actual size of data stored in a cache. Apparently, this is not a\nsimple matter, as internal mechanisms for optimising memory usage, such as deduplication or compression, must be taken\ninto account. After the presentation, an interesting discussion ensued about how much memory\non the heap is actually used by the cache and how long it takes to clean it up. Someone pointed out that there is a hidden cost of using the cache\nthat takes the form of time needed to free the memory of expired cache items, which not everyone is aware of. What is more, the\nmanner in which the cache works does not quite fit the\ngenerational hypothesis and may mislead the JVM by preventing it\nfrom properly tuning the GC mechanism. I then began to wonder whether it might not be worth keeping the cache in an area\nexcluded from the GC’s control? I knew this is possible, although I had never seen a practical implementation of this\ntechnique. This topic was bothering me for some time, so I decided to investigate.\nMemory architecture\nAny skilled Java programmer knows the division of memory into young and old generation areas. People interested in\ndetails are probably also familiar with the more precise division into eden, survivor, tenured and perm.\nThere are many excellent articles discussing this topic\n(like this one), so we won’t go\ninto details. Instead, we will focus on a very specialised area of memory that the GC\nhas no control over, which is the off-heap memory, sometimes also called native memory. This is a special area under the\ndirect control of the operating system, which the JVM uses for its own purposes. It stores information about classes and\nmethods, internal thread data and cached code necessary for operation. As I mentioned earlier, off-heap memory is not\nsubject to the GC. In particular, it is excluded from garbage collection processes, which means that programmers\ncreating the JVM code using this area are wholly responsible for freeing memory allocated for\nvariables. There is also a dedicated area to which we — the programmers — have access as well.\nThere is a possibility to write and read data from this space, remembering of course, that the responsibility\nfor cleaning up after unnecessary variables lies entirely with us.\nThis area can be accessed using a simple API.\nThe following code allocates 100 bytes of off-heap memory and stores a String and an Integer.\nAt the end the data are loaded from the off-heap memory and then printed out.\n\nint size = 100;\n\nByteBuffer buff = ByteBuffer.allocateDirect(size);\nbuff.put(\"Michal\".getBytes());\nbuff.putInt(42);\n\nbuff.position(0); // set the pointer back to the beginning\n\nbyte[] name = new byte[6]; // length of my name\nbuff.get(name);\n\nout.println(new String(name));\nout.println(buff.getInt());\n\n\nNote the allocateDirect method that allocates off-heap memory unlike a similar method: allocate that allocates\non-heap memory. The behavior of both methods can be compared with the help of a profiler\n(I will use jConsole). The following programs allocate 1GB of memory,\nrespectively, on-heap and off-heap:\n\nByteBuffer.allocate(1000000000)\n\n\n\nByteBuffer.allocateDirect(1000000000)\n\n\nThe chart below shows heap memory profile comparison for both programs (on-heap on the left vs. off-heap on the right):\n\nSuch a possibility to bypass Garbage Collector may seem extremely tempting to\ndevelopers struggling with long working time of the GC. However, this raises the question: what type of usage justifies\nthe extra effort involved in manually freeing the memory and the potential risk of error? What are the advantages of\nusing off-heap memory? Is it faster? How much time will we save by bypassing the GC? Why is this method so uncommon?\nTo put it simply: is it worth doing and if so, when?\nBe gone GC!\nGC is a wonderful tool. It allows us – although sometimes only for a while – to forget about the problems related\nto painful memory management. We can create variables of any type and any scope almost freely, and not worry about what\nhappens to memory once we stop using them. This task is handled by the GC, which does it brilliantly. In each successive\nversion of the JDK we get a new algorithm, which in some specific cases is even better than the previous one.\nHowever, I’m more than sure that many of us have once encountered the problem of long GC time or too frequent GC\ncalls. Every developer has their own ideas on how to deal with this issue - we look for memory leaks, profile the\napplication in search of hot spots, examine the scope of created variables, use object pools, verify the system\nbehaviour with different GC algorithms, and check the cache configuration.\nIn my case, it is the cache that is often responsible for long GC time. Sometimes it stores large numbers of objects, usually\ncomplex ones, containing references to other objects. What is more, the way cache objects are accessed is often not\nuniform. Some objects are never queried after being inserted into the cache, others are read throughout their whole\nlifecycle. This causes the cache to disrupt the somewhat ideal world order defined by the generational hypothesis. Then,\nGC algorithms are faced with a very difficult task of determining the optimal way to clean up the memory freed by the\nitems removed from the cache. All this causes the cache cleanup to be expensive. This made me wonder if there was\nany benefit in storing cache data outside the heap?\nOff-heap space: Pros and cons\nIn a sense, the off-heap space lies outside the control of the JVM (though it belongs to the Java process),\nand for this reason, it is not possible to write\ncomplex structures used in JVM languages into it. This raises the need for an intermediate step of serializing the\ndata into a plain byte array, which can then be stored in the off-heap area. When the data is loaded, the reverse\nprocess must be performed: deserialization into a form that we can use in Java. These additional steps will of\ncourse come at an extra cost, which is why accessing off-heap data will, for obvious reasons, take longer than accessing\non-heap data directly.\nSince writing and reading data in the off-heap space takes longer, what is the benefit of this approach then? Well, the data\nstored in the off-heap space are not subject to GC processes, so on the one hand we – the programmers – are responsible\nfor each freeing of memory after a given variable is no longer useful. On the other hand, we relieve the management\nprocesses in the JVM by releasing CPU’s time for the rest of the application, so, theoretically, it should\nresult in some resource savings. The question is, do these differences balance each other out to any degree? Will the savings\nassociated with the GC process balance out our longer data access time? If so, does it depend only on the amount of\ndata, or is there a specific usage scenario? To answer these questions, it is necessary to run a few experiments.\nExperiments\nWe can store any data structure in the on-heap area, which means that the advantage of this approach lies in the fact\nthat there is no overhead involved in transforming the data to another form, while its disadvantage consists of the\nadditional cost related to the GC. On the other hand, in the case of off-heap storage, there is no GC extra cost,\nbut there is the cost of serialising the data to a byte array.\nOver the last years, significant\nprogress has been made in the field of GC and with the right matching of the algorithm to the application profile, its\ntime can be very short. But is there any case where it is worth reaching into the unmanaged space after all?\nI decided to start with an overview of what open-source options are currently available. When it comes to the implementation of the\non-heap cache mechanism, the options are numerous – there is well known:\nguava,\nehcache, caffeine and many other solutions. However,\nwhen I began researching cache mechanisms offering the possibility of storing data outside GC control, I found out\nthat there are very few solutions left. Out of the popular ones, only Terracotta is supported.\nIt seems that this is a very niche solution and we do not have many options to choose\nfrom. In terms of less-known projects, I came across Chronicle-Map,\nMapDB and OHC. I chose the\nlast one because it was created as part of the Cassandra project, which I had some experience with and was curious\nabout how this component worked:\nOHC was developed in 2014/15 for Apache Cassandra 2.2 and 3.0 to be used as the new row-cache backend.\nTo run the experiment, I decided to use a service built to provide the offer description based on its unique number. After\ndownloading the offer description from the repository, it is placed in the cache to speed up future calls. Obviously, the\ncache has a limited capacity, which is chosen in such a way that it forces the deletion of items that have been placed\nin it for the longest time ago.\nIn our cache, the offer number is the key, while its description in the form of a string of characters is the\nvalue. This allows us to easily simulate almost any size of data in the cache (all we have to do is to make the\noffer description longer), and additionally, it makes the overhead related to the aforementioned serialisation\nrelatively small – serialisation of a text string is obviously faster than a complex DTO object.\nIn my project, I used the Caffeine cache to store the data in the on-heap area\nand OHC library to store it in the off-heap area.\nThe test scenario consists of querying for descriptions of different offers. During the test, I will\ncollect data on memory and GC parameters using jConsole. I will run the test scenario using jMeter,\nwhich additionally will allow me to measure response times.\nFrom my preliminary research I know that this method is only applicable to memory-intensive systems.\nHowever, for the sake of order, let’s first run an experiment on a small cache size with element set to 5 KB:\nmaximum number of cached elements: 10000\ncached element size: 5.000 bytes\n10 threads querying for random offers in a loop of 100000 iterations each\nTake a look at the screenshots from jConsole below. The results are in line with expectations: no benefit from the use\nof off-heap space. Both the number of garbage collection cycles (63 vs. 65) and GC run time (0.182s vs 0.235s)\nare nearly identical in both cases:\nThe GC profile of on-heap variant:\n\nThe GC profile of off-heap variant:\n\nNot much of an improvement for small to medium cache size. However, this result is not disappointing to me because\nI expected it. GC is designed to handle much more memory than 400 MB, it would therefore be strange if we obtained\nan improvement at such an early stage.\nNow let’s see how the comparison looks for a much larger cache element size, let’s increase it up to 100 KB.\nAt the same time, due to the fact that I am running the tests on a laptop with limited resources, I will reduce\nthreads configuration and cache maximum element size.\nThe configuration of the second test is as follows:\nmaximum number of cached elements: 5000\ncached element size: 100.000 bytes\n10 threads querying for random offers in a loop of 1000 iterations each\nLet’s take a look at the results.\nThe GC profile of on-heap variant:\n\nMemory usage increases throughout the test, there are 40 GC collection cycles that together last 0.212s.\nThe GC profile of off-heap variant:\n\nThis time heap memory usage chart definitely looks different, is shaped like a saw, and reaches half of the previous value.\nPlease note also, that this time there are only 13 GC cycles with total time of 0.108s.\nThe results of the GC profile comparison are therefore as expected, and what about the response times?\njMeter metrics of on-heap variant:\n\njMeter metrics of off-heap variant:\n\nRequest time metrics data is also in line with predictions, off-heap variant proved to be slightly slower than on-heap.\nNow let’s see what effect increasing the data size will have on the results. Let’s do tests for the following sizes:\n100.000 B, 200.000 B and 300.000 B, jMeter configuration stays unchanged: 10 threads with 1000 iterations each.\nThis time, for the sake of clarity, the results are summarized in a table:\nCached item size\n      Variant\n      GC cycles count\n      GC time\n      Request time (median)\n      Throughput\n    \n100.000 B\n      on-heap\n      40\n      0.212 s\n      171 ms\n      83.2 rps\n    \n100.000 B\n      off-heap\n      13\n      0.108 s\n      179 ms\n      78.1 rps\n    \n200.000 B\n      on-heap\n      84\n      0.453 s\n      396 ms\n      38.2 rps\n    \n200.000 B\n      off-heap\n      19\n      0.182 s\n      355 ms\n      40.2 rps\n    \n300.000 B\n      on-heap\n      114\n      0.6s\n      543 ms\n      27.3 rps\n    \n300.000 B\n      off-heap\n      27\n      0.185s\n      528 ms\n      27.9 rps\n    \nIt turns out that as the size of cache item increases, the benefits of using off-heap space grow – all metrics are improved.\nWhat about cache maximum elements? Let’s use 200.000B item size and check what happens when we increase the maximum cache\nelement size, we will test cache for 5000, 10.000 and 15.000 elements:\nCache max elements\n      Variant\n      GC cycles count\n      GC time\n      Request time (median)\n      Throughput\n    \n5000\n      on-heap\n      84\n      0.453 s\n      396 ms\n      38.2 rps\n    \n5000\n      off-heap\n      19\n      0.182 s\n      355 ms\n      40.2 rps\n    \n10000\n      on-heap\n      81\n      0.46 s\n      393 ms\n      38.8 rps\n    \n10000\n      off-heap\n      19\n      0.173 s\n      345 ms\n      42.6 rps\n    \n15000\n      on-heap\n      84\n      0.462 s\n      355 ms\n      41.8 rps\n    \n15000\n      off-heap\n      19\n      0.167 s\n      344 ms\n      42.6 rps\n    \nNo surprise here either, increasing cache size has a positive impact on both variants. Of course in case of on-heap cache,\nsome of the benefits are offset by the need for cleaning larger memory area.\nWith the experiments conducted, we can conclude that the more data we store in memory, the greater the benefit of using\nthe off-heap area may be. At the same time, it should be added that these benefits are not huge, just a few RPS more.\nIn the case of systems that store tremendous amounts of data, this method may bring some improvements in terms of resource utilization.\nHowever, for most of our apps and services, that’s probably not the way to go, a code audit is a better idea.\nThis is probably a good time to highlight how well implemented the current memory sweeper algorithms are. Well done GC!\nConclusions\nEveryone has probably come across a case when an application froze as a result of GC’s operation. As the above data\nshow, there is a relationship between the amount of data stored in memory and the time the GC requires to clean it up –\nthe more data we store on the heap, the longer it takes to free the memory. That is why the cases where we process large\namounts of data provide us with a potential benefit of using the off-heap area. There are some very specialised uses of\nthis technique, such as Spark, which can store large amounts of data for subsequent processing steps and can do so using\nthe off-heap space (you can read more about Spark memory model here).\nAnother example of the use of the off-heap approach is the Apache Cassandra database. The OHC used\nin this post was developed from this particular project.\nThere is a very narrow group of cases where storing data outside of GC control is justifiable. However, for the\nvast majority of applications, a much better approach is to take advantage of ever-improving GC\nimplementations. If you have experienced problems with the slow performance of the GC while developing your business\nservice, you should definitely audit your code first and experiment with different heap size settings and the GC\nalgorithm. When all other methods fail, you can give the off-heap area a try.\nHowever, if you are working on a server that processes massive amounts of data, it is worth considering off-heap\nstorage earlier, similar to Spark or Cassandra solutions.","guid":"https://blog.allegro.tech/2022/06/gc-hands-off-my-data.html","categories":["tech","cache","performance","off-heap","garbage collectors"],"isoDate":"2022-06-29T22:00:00.000Z","thumbnail":"images/post-headers/default.jpg"},{"title":"Exploring GraphQL’s performance tradeoffs","link":"https://blog.allegro.tech/2022/06/graphql-perf-tradeoffs.html","pubDate":"Mon, 20 Jun 2022 00:00:00 +0200","authors":{"author":[{"name":["Alicja Halamska"],"photo":["https://blog.allegro.tech/img/authors/alicja.halamska.jpg"],"url":["https://blog.allegro.tech/authors/alicja.halamska"]},{"name":["Dawid Kubicki"],"photo":["https://blog.allegro.tech/img/authors/dawid.kubicki.jpg"],"url":["https://blog.allegro.tech/authors/dawid.kubicki"]}]},"content":"\u003cp\u003eAt \u003ca href=\"https://allegro.tech/\"\u003eAllegro\u003c/a\u003e we decided to introduce \u003ca href=\"https://graphql.org/\"\u003eGraphQL\u003c/a\u003e as our API Gateway for building several internal client systems.\nBy building such a solution we’ve learnt a lot about this technology\nand we would like to share it with you in this article.\u003c/p\u003e\n\n\u003ch2 id=\"whats-graphql-and-how-does-it-work\"\u003eWhat’s GraphQL and how does it work?\u003c/h2\u003e\n\u003cp\u003eTo understand how to increase GraphQL’s performance we need to understand how it works under the hood.\nWhy is it so important? In GraphQL most of the common ideas on how to speed up the communication are useless.\nOne of the things we usually do is introduce caching to our application, but you can often hear that GraphQL is not cacheable.\nIndeed it is not that simple in GraphQL and we hope to clarify it to you later in this article.\u003c/p\u003e\n\n\u003cp\u003eSo what is GraphQL? \u003ca href=\"https://graphql.org/\"\u003eGraphQL’s documentation\u003c/a\u003e says:\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003eGraphQL is a query language for APIs and a runtime for fulfilling those queries with your existing data.\nGraphQL provides a complete and understandable description of the data in your API,\ngives clients the power to ask for exactly what they need and nothing more […].\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eGraphQL sends the information through a standard TCP connection (mostly HTTP).\nThere is only one entry point and all needed information is sent in a request parameter or body.\nIn contrast to the REST API, where we often fetch fields that we won’t use, in GraphQL we can ask for and compute only the useful ones.\nThis key feature gives us the first and most important way to speed up our application: ask only for the information that you need.\u003c/p\u003e\n\n\u003cp\u003eThere are three key concepts that we should be aware of:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eSchema — description of your data in a JSON-like format.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cdiv class=\"language-graphql highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003etype\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eUser\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nb\"\u003eID\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nb\"\u003eString\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"n\"\u003eemail\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nb\"\u003eString\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"n\"\u003efriends\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"n\"\u003eUser\u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\u003cul\u003e\n  \u003cli\u003eQueries — the way we ask for processing information.\nWe provide information about which resources we want to fetch or mutate and which fields exactly we want to be returned.\nWe can fetch data with an operation called a query or change data with a mutation.\nBelow we query for the user’s name and his friends’ names.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cdiv class=\"language-graphql highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003equery\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n \u003c/span\u003e\u003cspan class=\"n\"\u003euser\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"1234\"\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"n\"\u003efriends\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\u003cul\u003e\n  \u003cli\u003eResolvers — fragments of code that serve information for specific parts of schema.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2 id=\"resolver-design-is-a-game-changer\"\u003eResolver design is a game changer!\u003c/h2\u003e\n\n\u003cp\u003eWe will spend the whole paragraph on making sure we are on the same page understanding how resolvers work.\nA schema consists of types definitions:\n— defined queries/mutations/subscriptions that we can ask (we can think of it as the root of the graph)\n— input objects that we take as arguments in queries/mutations/subscriptions\n— objects that we return from queries/mutations/subscriptions\n— scalars, the simplest types like int or string (which are always a leaf in a graph)\u003c/p\u003e\n\n\u003cp\u003eAs the schema is composed of queries and types, there are two kinds of resolvers. The first is obligatory and resolves the whole query.\nIt can return the complete result, but also only a part of it.\nThe second part is added by type resolvers. Let us show you an example: let’s say we want to get information about a user.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-06-20-graphql-perf-tradeoffs/resolvers.png\" alt=\"resolver\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eAt first we run \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eUserQueryResolver\u003c/code\u003e, which fetches user data from user domain logic. Only the ID of the user is returned.\nThen we call \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eUserTypeResolver\u003c/code\u003e with the ID resolved earlier.\nIt makes two calls: first one to user email service and second to user name service.\nWhen resolving is over, GraphQL returns the result.\n\u003ccode class=\"language-plaintext highlighter-rouge\"\u003eUserQueryResolver\u003c/code\u003e might also have returned all information.\nOne of the main questions about optimizing GraphQL is when to use a query resolver, and when a type resolver.\nWe decided to use:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e\n    \u003cp\u003eA query resolver for fields that come from the same data source as the identifier field.\nWe may ask for information that we don’t need,\nbut we skip the unnecessary connection time overhead when we ask for more than one field.\nMoreover, most of the sources that are connected to our service are REST APIs and always compute all fields, so why shouldn’t we use them?\nAdding additional resolvers also complicates logic and makes the flow less clear.\u003c/p\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003eA type resolver when some parts of a query can be resolved independently, because those parts can run in parallel.\nTo achieve it, wrap the resolver’s functions with any of the asynchronous abstractions. We also use type resolvers when we ask for some part of the domain\nthat isn’t ours to avoid dependency crossing.\u003c/p\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2 id=\"the-metrics-war\"\u003eThe metrics war\u003c/h2\u003e\n\n\u003cp\u003eThere are different approaches to performance monitoring depending on the element whose performance we monitor:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003ePoor - HTTP endpoint (just one endpoint which always responds with 200 status code)\u003c/li\u003e\n  \u003cli\u003eBetter - GraphQL query/mutation (each query/mutation)\u003c/li\u003e\n  \u003cli\u003eAlmost great - Resolvers (access to data source)\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThe HTTP endpoint is the point at which we measured performance for a REST API.\nFor example one of the simplest ways of monitoring performance for API endpoints is response time.\nSome basic dashboards could look like this:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-06-20-graphql-perf-tradeoffs/p95-response-1.png\" alt=\"dashboard_1\" /\u003e\n\u003cimg src=\"/img/articles/2022-06-20-graphql-perf-tradeoffs/p95-response-2.png\" alt=\"dashboard_2\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eIn the GraphQL universe, there is usually only one endpoint. This approach has advantages and disadvantages.\nWhile we have low latency and no errors it is great for us as developers and business.\nWe have just one entry point and one failure point but if something goes wrong we have to dig deeper.\u003c/p\u003e\n\n\u003cp\u003eThe chart below, showing p95 response times for a single GraphQL endpoint, does not tell the whole story. In reality we have plenty of consumers which use different input data and ask us for variety of payload in extended scope.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-06-20-graphql-perf-tradeoffs/p95-response-3.png\" alt=\"dashboard_3\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eWe are using a simple metric configuration for measuring endpoints:\u003c/p\u003e\n\n\u003cdiv class=\"language-kotlin highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eMetricFilter\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eprivate\u003c/span\u003e \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003emeterRegistry\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eMeterRegistry\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eOncePerRequestFilter\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003eoverride\u003c/span\u003e \u003cspan class=\"k\"\u003efun\u003c/span\u003e \u003cspan class=\"nf\"\u003edoFilterInternal\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n        \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eHttpServletRequest\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eHttpServletResponse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n        \u003cspan class=\"n\"\u003efilterChain\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eFilterChain\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n        \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003estart\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"nc\"\u003eSystem\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003enanoTime\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n        \u003cspan class=\"k\"\u003etry\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n            \u003cspan class=\"n\"\u003efilterChain\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003edoFilter\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003erequest\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e}\u003c/span\u003e \u003cspan class=\"k\"\u003efinally\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n            \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003efinish\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"nc\"\u003eSystem\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003enanoTime\u003c/span\u003e\u003cspan class=\"p\"\u003e();\u003c/span\u003e\n            \u003cspan class=\"n\"\u003emeterRegistry\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003etimer\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n                \u003cspan class=\"s\"\u003e\"api.execution\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                \u003cspan class=\"s\"\u003e\"statusCode\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                \u003cspan class=\"n\"\u003eresponse\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estatus\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003etoString\u003c/span\u003e\u003cspan class=\"p\"\u003e(),\u003c/span\u003e\n                \u003cspan class=\"s\"\u003e\"path\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                \u003cspan class=\"n\"\u003erequest\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erequestURI\u003c/span\u003e\n            \u003cspan class=\"p\"\u003e).\u003c/span\u003e\u003cspan class=\"nf\"\u003erecord\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003efinish\u003c/span\u003e \u003cspan class=\"p\"\u003e-\u003c/span\u003e \u003cspan class=\"n\"\u003estart\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nc\"\u003eTimeUnit\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nc\"\u003eMILLISECONDS\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\u003cp\u003eRemember that our queries can change in time, e.g. by extended business requirements. They can start from a simple query like this:\u003c/p\u003e\n\n\u003cdiv class=\"language-graphql highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003equery\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"n\"\u003euser\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n        \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eID\u003c/span\u003e\u003cspan class=\"w\"\u003e\n        \u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eString\u003c/span\u003e\u003cspan class=\"w\"\u003e\n        \u003c/span\u003e\u003cspan class=\"n\"\u003eemail\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eString\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eAfter a few new features are added, they can end up more complex like the one below. In the same query we ask for ten thousand additional objects from another data source.\nWe can imagine that the previous \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ep95\u003c/code\u003e dashboard doesn’t have much value now because it is perfectly normal that the\ncomputation time increases when we ask for additional data. The pagination plays a big role here, too.\nBoth of these queries can still be executed at the same time and shouldn’t be measured by the same metric.\u003c/p\u003e\n\n\u003cdiv class=\"language-graphql highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"k\"\u003equery\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\t\u003c/span\u003e\u003cspan class=\"n\"\u003euser\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n        \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eID\u003c/span\u003e\u003cspan class=\"w\"\u003e\n        \u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eString\u003c/span\u003e\u003cspan class=\"w\"\u003e\n        \u003c/span\u003e\u003cspan class=\"n\"\u003eemail\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eString\u003c/span\u003e\u003cspan class=\"w\"\u003e\n        \u003c/span\u003e\u003cspan class=\"n\"\u003efriends\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003elimit\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e10000\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eoffset\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e){\u003c/span\u003e\u003cspan class=\"w\"\u003e\n            \u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eString\u003c/span\u003e\u003cspan class=\"w\"\u003e\n            \u003c/span\u003e\u003cspan class=\"n\"\u003elastName\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eString\u003c/span\u003e\u003cspan class=\"w\"\u003e\n        \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n    \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch3 id=\"slow-query-log\"\u003eSlow query log\u003c/h3\u003e\n\n\u003cp\u003eAfter integrating a huge number of new APIs we realized that simple HTTP endpoint monitoring was not enough in our case.\nWe had been looking for a better approach. Slow query log is a simple concept -\nset a threshold at which we consider a query too slow.\nEach query that exceeds that threshold gets logged with all input parameters.\nMoreover we set up metrics which indicate that some problematic query appears.\nIs such an approach perfect?\nNo, we still have to analyze each query and answer the question if the query is slow because\nof query complexity or maybe because of other problems.\nAt the end of the day we can use this approach as a simple and effective tool to find slow queries quite fast.\u003c/p\u003e\n\n\u003cp\u003eAs an example we can show you the code below.\nWe created our own instrumentation at the beginning of each query to measure time and variables.\u003c/p\u003e\n\n\u003cdiv class=\"language-kotlin highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"nd\"\u003e@Component\u003c/span\u003e\n\u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eMonitoringInstrumentation\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eprivate\u003c/span\u003e \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003eclock\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eClock\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eprivate\u003c/span\u003e \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003emeterRegistry\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eMeterRegistry\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eSimpleInstrumentation\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003eoverride\u003c/span\u003e \u003cspan class=\"k\"\u003efun\u003c/span\u003e \u003cspan class=\"nf\"\u003einstrumentExecutionResult\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eexecutionResult\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eExecutionResult\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n        \u003cspan class=\"n\"\u003eparameters\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eInstrumentationExecutionParameters\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e):\u003c/span\u003e \u003cspan class=\"nc\"\u003eCompletableFuture\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nc\"\u003eExecutionResult\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n        \u003cspan class=\"k\"\u003etry\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n            \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003einstrumentationState\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eparameters\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003egetInstrumentationState\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nc\"\u003eMonitoringInstrumentationState\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;()\u003c/span\u003e\n            \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003estartTime\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003einstrumentationState\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003estartTime\u003c/span\u003e\n            \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003eendTime\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"nf\"\u003egetTime\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e\n            \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003eexecutionTime\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003estartTime\u003c/span\u003e \u003cspan class=\"p\"\u003e-\u003c/span\u003e \u003cspan class=\"n\"\u003eendTime\u003c/span\u003e\n            \u003cspan class=\"k\"\u003eif\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eexecutionTime\u003c/span\u003e \u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"mi\"\u003e1000\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n                \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003equery\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eparameters\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003equery\u003c/span\u003e\n                \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003evariables\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eparameters\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003evariables\u003c/span\u003e\n                \u003cspan class=\"n\"\u003emetric\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eincrement\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n                    \u003cspan class=\"nc\"\u003eSLOW_QUERY_METRIC_NAME\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                    \u003cspan class=\"s\"\u003e\"duration\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n                    \u003cspan class=\"n\"\u003eexecutionTime\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n                \u003cspan class=\"n\"\u003elogger\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003ewarn\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n                    \u003cspan class=\"s\"\u003e\"Slow query: $query with variables ${serializeVariables(variables)}.\"\u003c/span\u003e \u003cspan class=\"p\"\u003e+\u003c/span\u003e\n                        \u003cspan class=\"s\"\u003e\" Duration: ${executionTime.toMillis()} ms\"\u003c/span\u003e\n                \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n            \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n        \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n        \u003cspan class=\"k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"k\"\u003esuper\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003einstrumentExecutionResult\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eexecutionResult\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eparameters\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n  \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch3 id=\"per-field-monitoring\"\u003ePer field monitoring\u003c/h3\u003e\n\n\u003cp\u003eLast but not least, an interesting approach which we consider, and is almost out of the box for resolvers and supported by many libraries, is per field monitoring.\nIt is pretty nice for getting extra data to analyze our graph.\nHowever, it can be expensive to collect such a type of data.\nGathering metrics for each field can be more valuable than monitoring each query.\nMoreover, we can easily find the bottleneck of bits and pieces of our graph.\nResolvers monitoring can be achieved by using libraries built into our GraphQL server implementation such as\n\u003ccode class=\"language-plaintext highlighter-rouge\"\u003egraphql-java-server\u003c/code\u003e.\nOur implementation follows the Apollo proposed tracing format (\u003ca href=\"https://github.com/apollographql\"\u003eA community building flexible open source tools for GraphQL\u003c/a\u003e).\u003c/p\u003e\n\n\u003cdiv class=\"language-json highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"data\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n   \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"user\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n     \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"name\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"Javier\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n     \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"friends\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"w\"\u003e\n       \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n         \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"name\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"Clarisa\"\u003c/span\u003e\u003cspan class=\"w\"\u003e\n       \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n     \u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"w\"\u003e\n   \u003c/span\u003e\u003cspan class=\"p\"\u003e},\u003c/span\u003e\u003cspan class=\"w\"\u003e\n \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"extensions\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n   \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"tracing\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n     \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"version\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n     \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"startTime\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"2022-04-14T23:13:39.362Z\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n     \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"endTime\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"2022-04-14T23:13:39.497Z\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n     \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"duration\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e135589186\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n     \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"execution\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n       \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"resolvers\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"w\"\u003e\n         \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"path\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"w\"\u003e\n             \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"user\"\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"parentType\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"Query\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"returnType\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"Character\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"fieldName\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"user\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"startOffset\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e105697585\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"duration\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e79111240\u003c/span\u003e\u003cspan class=\"w\"\u003e\n         \u003c/span\u003e\u003cspan class=\"p\"\u003e},\u003c/span\u003e\u003cspan class=\"w\"\u003e\n         \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"path\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e[\u003c/span\u003e\u003cspan class=\"w\"\u003e\n             \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"user\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n             \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"name\"\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"p\"\u003e],\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"parentType\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"Girl\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"returnType\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"String\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"fieldName\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s2\"\u003e\"name\"\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"startOffset\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e125010028\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n           \u003c/span\u003e\u003cspan class=\"nl\"\u003e\"duration\"\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e20213\u003c/span\u003e\u003cspan class=\"w\"\u003e\n         \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n       \u003c/span\u003e\u003cspan class=\"p\"\u003e]\u003c/span\u003e\u003cspan class=\"w\"\u003e\n     \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n   \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eBottom line of resolver monitoring is thinking about it as checking each data source,\nnot the internal mechanism of GraphQL implementation.\nIt is possible that our internal performance is not the limiting factor as I / O and external connections are often critical.\u003c/p\u003e\n\n\u003ch2 id=\"batching-requests-to-external-services\"\u003eBatching requests to external services\u003c/h2\u003e\n\n\u003cp\u003eIn the paragraph about resolvers we mentioned connecting to the same source many times to\nfetch all the type fields in case of using type resolvers. There is a solution for that, and it is called data loaders.\nHow does it work? It collects all requests from many parts of the schema and retrieves their data in one request.\nThis allows it to solve the N+1 problem, which is very well known in GraphQL.\nImagine the situation where we want to query for three users.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-06-20-graphql-perf-tradeoffs/no-loader.png\" alt=\"no-loader\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eAs the diagram says, we must ask external sources four times for three users – once to fetch all users and once per each user to fetch his name.\nMoreover we call user name service many times even if it has some batch method to get logins for many users.\nIntroducing a data loader solves this problem. The second diagram shows how it works.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-06-20-graphql-perf-tradeoffs/data-loader.png\" alt=\"data-loader\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eWe cumulate all requests and ask user name service only once. Let’s see what the code looks like.\nWe have \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eUserBatchDataLoader\u003c/code\u003e which asks \u003ccode class=\"language-plaintext highlighter-rouge\"\u003euserClient\u003c/code\u003e for users and maps the response to \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eUser\u003c/code\u003e object.\u003c/p\u003e\n\n\u003cdiv class=\"language-kotlin highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"nd\"\u003e@Component\u003c/span\u003e\n\u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eUserBatchDataLoader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n   \u003cspan class=\"n\"\u003euserClient\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eUserClient\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n   \u003cspan class=\"n\"\u003eexecutor\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eExecutor\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eBatchDataLoaderInfo\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nc\"\u003eString\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nc\"\u003eUserResponse\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nc\"\u003eUser\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;(\u003c/span\u003e\n   \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"n\"\u003euserIds\u003c/span\u003e \u003cspan class=\"p\"\u003e-\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003euserClient\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eusers\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003euserIds\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e},\u003c/span\u003e\n   \u003cspan class=\"nc\"\u003eUserResponse\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003euserId\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n   \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"n\"\u003eit\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003etoUser\u003c/span\u003e\u003cspan class=\"p\"\u003e()\u003c/span\u003e \u003cspan class=\"p\"\u003e},\u003c/span\u003e\n   \u003cspan class=\"n\"\u003eexecutor\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eThere is also \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eUserTypeResolver\u003c/code\u003e that uses it while resolving user name.\u003c/p\u003e\n\n\u003cdiv class=\"language-kotlin highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\n\u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eUserTypeResolver\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n   \u003cspan class=\"k\"\u003eprivate\u003c/span\u003e \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003euserBatchDataLoader\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eUserBatchDataLoader\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eGraphQLResolver\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nc\"\u003eUser\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n   \u003cspan class=\"k\"\u003efun\u003c/span\u003e \u003cspan class=\"nf\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n       \u003cspan class=\"n\"\u003euser\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eUser\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n       \u003cspan class=\"n\"\u003edfe\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eDataFetchingEnvironment\u003c/span\u003e\n   \u003cspan class=\"p\"\u003e):\u003c/span\u003e \u003cspan class=\"nc\"\u003eCompletableFuture\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nc\"\u003eString\u003c/span\u003e\u003cspan class=\"err\"\u003e?\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e\n       \u003cspan class=\"nf\"\u003eextractDataLoader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003euserBatchDataLoader\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edfe\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n           \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003euser\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003euserId\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eraw\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n           \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003ethenApply\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"n\"\u003eit\u003c/span\u003e\u003cspan class=\"o\"\u003e?.\u003c/span\u003e\u003cspan class=\"n\"\u003ename\u003c/span\u003e \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eExactly the same can be done with \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eUser\u003c/code\u003e fields in the type resolver.\nWe can accumulate requests for each field and run it once if the source is the same.\nThere is a \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eUserDataLoader\u003c/code\u003e that asks \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eUserClient\u003c/code\u003e for the whole \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eUser\u003c/code\u003e object.\u003c/p\u003e\n\n\u003cdiv class=\"language-kotlin highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"nd\"\u003e@Component\u003c/span\u003e\n\u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eUserDataLoader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n   \u003cspan class=\"n\"\u003euserClient\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eUserClient\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n   \u003cspan class=\"n\"\u003eexecutor\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eExecutor\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eSimpleDataLoaderInfo\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nc\"\u003eString\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nc\"\u003eUserResponse\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;(\u003c/span\u003e\n   \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"n\"\u003euserId\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eString\u003c/span\u003e \u003cspan class=\"p\"\u003e-\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003euserClient\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003euser\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003euserId\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e},\u003c/span\u003e\n   \u003cspan class=\"n\"\u003eexecutor\u003c/span\u003e\n\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eIt is used in \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eUserTypeResolver\u003c/code\u003e while resolving first name and email.\u003c/p\u003e\n\n\u003cdiv class=\"language-kotlin highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"nd\"\u003e@Component\u003c/span\u003e\n\u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eUserTypeResolver\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\n\u003cspan class=\"k\"\u003eprivate\u003c/span\u003e \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003edataLoaderInfo\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eUserDataLoader\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003cspan class=\"k\"\u003eprivate\u003c/span\u003e \u003cspan class=\"kd\"\u003eval\u003c/span\u003e \u003cspan class=\"py\"\u003eexecutor\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eExecutor\u003c/span\u003e\n\u003cspan class=\"p\"\u003e):\u003c/span\u003e \u003cspan class=\"nc\"\u003eGraphQLResolver\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nc\"\u003eUser\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\n\t\u003cspan class=\"k\"\u003efun\u003c/span\u003e \u003cspan class=\"nf\"\u003efirstName\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003euser\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eUser\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edfe\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eDataFetchingEnvironment\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e \u003cspan class=\"nc\"\u003eCompletableFuture\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nc\"\u003eString\u003c/span\u003e\u003cspan class=\"err\"\u003e?\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e\n   \u003cspan class=\"nf\"\u003eextractDataLoader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edataLoaderInfo\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edfe\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n       \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003euser\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003euserId\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eraw\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n       \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003ethenApply\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"n\"\u003eit\u003c/span\u003e\u003cspan class=\"o\"\u003e?.\u003c/span\u003e\u003cspan class=\"n\"\u003eperson\u003c/span\u003e\u003cspan class=\"o\"\u003e?.\u003c/span\u003e\u003cspan class=\"n\"\u003efirstName\u003c/span\u003e \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n\u003cspan class=\"k\"\u003efun\u003c/span\u003e \u003cspan class=\"nf\"\u003eemail\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003euser\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eUser\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edfe\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nc\"\u003eDataFetchingEnvironment\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e \u003cspan class=\"nc\"\u003eCompletableFuture\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026lt;\u003c/span\u003e\u003cspan class=\"nc\"\u003eString\u003c/span\u003e\u003cspan class=\"err\"\u003e?\u003c/span\u003e\u003cspan class=\"p\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"p\"\u003e=\u003c/span\u003e\n   \u003cspan class=\"nf\"\u003eextractDataLoader\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003edataLoaderInfo\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edfe\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n       \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003eload\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003euser\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003euserId\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eraw\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n       \u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nf\"\u003ethenApply\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e \u003cspan class=\"n\"\u003eit\u003c/span\u003e\u003cspan class=\"o\"\u003e?.\u003c/span\u003e\u003cspan class=\"n\"\u003econtacts\u003c/span\u003e\u003cspan class=\"o\"\u003e?.\u003c/span\u003e\u003cspan class=\"n\"\u003eemail\u003c/span\u003e \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch2 id=\"caching---why-is-it-so-troublesome\"\u003eCaching - why is it so troublesome?\u003c/h2\u003e\n\n\u003ch3 id=\"http-caching\"\u003eHTTP caching\u003c/h3\u003e\n\n\u003cp\u003eThe biggest problem that makes using HTTP caching less effective is plenty of different requests that we can make.\nWhen we ask for a user with his name and email the response is saved in cache.\nBut when we ask again without the information about email despite the fact that\nthe information is already available we cannot use it,\nbecause this is a different query (and HTTP cache cannot handle it without understanding GraphQL logic).\nTo make cache work best we should recognise at field level which user name is already in\nmemory and ask only for the rest of them.\u003c/p\u003e\n\n\u003ch3 id=\"server-side-caching\"\u003eServer-side caching\u003c/h3\u003e\n\u003cp\u003eLet’s put aside HTTP caching and focus more on how we can implement server cache that is more focused on GraphQL logic.\nWe could cache specific types from our schema or their fields. A good example of implemented server-side cache is\n\u003ca href=\"https://www.apollographql.com/docs/apollo-server/performance/caching/\"\u003eapollo-server\u003c/a\u003e.\nSo if we run the same type or query resolver with the same arguments it can be returned from cache.\nWith \u003ca href=\"https://github.com/graphql-java/java-dataloader#the-scope-of-a-data-loader-is-important\"\u003edata loaders\u003c/a\u003e you can also cache requests to external sources not only in one query,\nbut even between many queries by selecting a specific strategy. This solution is available out of the box, and can be used easily.\u003c/p\u003e\n\n\u003ch3 id=\"client-side-caching\"\u003eClient-side caching\u003c/h3\u003e\n\u003cp\u003eAnother common way to cache query response is client-side caching. It can be very beneficial, because one client may ask for the same information many times.\nAs an example we can take Apollo client and its solution. The cache uses the ID field to identify whether an object exists in memory.\nThen it checks if all fields that are to be returned are already in memory, if some are not it asks only for them.\u003c/p\u003e\n\n\u003ch3 id=\"our-caching-decisions\"\u003eOur caching decisions\u003c/h3\u003e\n\u003cp\u003eWe’ve decided not to use server-side caching with a global data loader because we have struggled with many clients of our graph and the graph’s data\nchanges frequently. That forced us to use a cache-per-request strategy.\nIf we are talking about caching on the client side we tackle the issue that some of our objects don’t have a unique \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eID\u003c/code\u003e so after a while we skipped this approach and we are not caching them on the client side either.\u003c/p\u003e\n\n\u003ch2 id=\"what-is-the-outcome-of-the-battle\"\u003eWhat is the outcome of the battle?\u003c/h2\u003e\n\n\u003cp\u003eWe have learned a lot about GraphQL’s trade offs while working with it, but there is still a lot to be discovered. The most important feature of it, fetching only those fields that we need, is a huge optimization itself, but also causes many problems with standard ways to make the application effective or even to measure that efficiency.\nThe ideas that we described above need to be implemented by the programmers (most libraries don’t provide that logic) and it’s really complex and time consuming.\u003c/p\u003e\n","contentSnippet":"At Allegro we decided to introduce GraphQL as our API Gateway for building several internal client systems.\nBy building such a solution we’ve learnt a lot about this technology\nand we would like to share it with you in this article.\nWhat’s GraphQL and how does it work?\nTo understand how to increase GraphQL’s performance we need to understand how it works under the hood.\nWhy is it so important? In GraphQL most of the common ideas on how to speed up the communication are useless.\nOne of the things we usually do is introduce caching to our application, but you can often hear that GraphQL is not cacheable.\nIndeed it is not that simple in GraphQL and we hope to clarify it to you later in this article.\nSo what is GraphQL? GraphQL’s documentation says:\nGraphQL is a query language for APIs and a runtime for fulfilling those queries with your existing data.\nGraphQL provides a complete and understandable description of the data in your API,\ngives clients the power to ask for exactly what they need and nothing more […].\nGraphQL sends the information through a standard TCP connection (mostly HTTP).\nThere is only one entry point and all needed information is sent in a request parameter or body.\nIn contrast to the REST API, where we often fetch fields that we won’t use, in GraphQL we can ask for and compute only the useful ones.\nThis key feature gives us the first and most important way to speed up our application: ask only for the information that you need.\nThere are three key concepts that we should be aware of:\nSchema — description of your data in a JSON-like format.\n\ntype User {\n    id: ID\n    name: String\n    email: String\n    friends: [User]\n}\n\n\nQueries — the way we ask for processing information.\nWe provide information about which resources we want to fetch or mutate and which fields exactly we want to be returned.\nWe can fetch data with an operation called a query or change data with a mutation.\nBelow we query for the user’s name and his friends’ names.\n\nquery {\n user(id: \"1234\") {\n    name\n    friends { name }\n }\n}\n\n\nResolvers — fragments of code that serve information for specific parts of schema.\nResolver design is a game changer!\nWe will spend the whole paragraph on making sure we are on the same page understanding how resolvers work.\nA schema consists of types definitions:\n— defined queries/mutations/subscriptions that we can ask (we can think of it as the root of the graph)\n— input objects that we take as arguments in queries/mutations/subscriptions\n— objects that we return from queries/mutations/subscriptions\n— scalars, the simplest types like int or string (which are always a leaf in a graph)\nAs the schema is composed of queries and types, there are two kinds of resolvers. The first is obligatory and resolves the whole query.\nIt can return the complete result, but also only a part of it.\nThe second part is added by type resolvers. Let us show you an example: let’s say we want to get information about a user.\n\nAt first we run UserQueryResolver, which fetches user data from user domain logic. Only the ID of the user is returned.\nThen we call UserTypeResolver with the ID resolved earlier.\nIt makes two calls: first one to user email service and second to user name service.\nWhen resolving is over, GraphQL returns the result.\nUserQueryResolver might also have returned all information.\nOne of the main questions about optimizing GraphQL is when to use a query resolver, and when a type resolver.\nWe decided to use:\nA query resolver for fields that come from the same data source as the identifier field.\nWe may ask for information that we don’t need,\nbut we skip the unnecessary connection time overhead when we ask for more than one field.\nMoreover, most of the sources that are connected to our service are REST APIs and always compute all fields, so why shouldn’t we use them?\nAdding additional resolvers also complicates logic and makes the flow less clear.\nA type resolver when some parts of a query can be resolved independently, because those parts can run in parallel.\nTo achieve it, wrap the resolver’s functions with any of the asynchronous abstractions. We also use type resolvers when we ask for some part of the domain\nthat isn’t ours to avoid dependency crossing.\nThe metrics war\nThere are different approaches to performance monitoring depending on the element whose performance we monitor:\nPoor - HTTP endpoint (just one endpoint which always responds with 200 status code)\nBetter - GraphQL query/mutation (each query/mutation)\nAlmost great - Resolvers (access to data source)\nThe HTTP endpoint is the point at which we measured performance for a REST API.\nFor example one of the simplest ways of monitoring performance for API endpoints is response time.\nSome basic dashboards could look like this:\n\n\nIn the GraphQL universe, there is usually only one endpoint. This approach has advantages and disadvantages.\nWhile we have low latency and no errors it is great for us as developers and business.\nWe have just one entry point and one failure point but if something goes wrong we have to dig deeper.\nThe chart below, showing p95 response times for a single GraphQL endpoint, does not tell the whole story. In reality we have plenty of consumers which use different input data and ask us for variety of payload in extended scope.\n\nWe are using a simple metric configuration for measuring endpoints:\n\nclass MetricFilter(\n    private val meterRegistry: MeterRegistry\n) : OncePerRequestFilter() {\n\n    override fun doFilterInternal(\n        request: HttpServletRequest,\n        response: HttpServletResponse,\n        filterChain: FilterChain\n    ) {\n        val start = System.nanoTime();\n        try {\n            filterChain.doFilter(request, response)\n        } finally {\n            val finish = System.nanoTime();\n            meterRegistry.timer(\n                \"api.execution\",\n                \"statusCode\",\n                response.status.toString(),\n                \"path\",\n                request.requestURI\n            ).record(finish - start, TimeUnit.MILLISECONDS)\n        }\n    }\n}\n\n\nRemember that our queries can change in time, e.g. by extended business requirements. They can start from a simple query like this:\n\nquery {\n    user {\n        id: ID\n        name: String\n        email: String\n    }\n}\n\n\nAfter a few new features are added, they can end up more complex like the one below. In the same query we ask for ten thousand additional objects from another data source.\nWe can imagine that the previous p95 dashboard doesn’t have much value now because it is perfectly normal that the\ncomputation time increases when we ask for additional data. The pagination plays a big role here, too.\nBoth of these queries can still be executed at the same time and shouldn’t be measured by the same metric.\n\nquery {\n\tuser {\n        id: ID\n        name: String\n        email: String\n        friends(limit: 10000, offset: 1){\n            name: String\n            lastName: String\n        }\n    }\n}\n\n\nSlow query log\nAfter integrating a huge number of new APIs we realized that simple HTTP endpoint monitoring was not enough in our case.\nWe had been looking for a better approach. Slow query log is a simple concept -\nset a threshold at which we consider a query too slow.\nEach query that exceeds that threshold gets logged with all input parameters.\nMoreover we set up metrics which indicate that some problematic query appears.\nIs such an approach perfect?\nNo, we still have to analyze each query and answer the question if the query is slow because\nof query complexity or maybe because of other problems.\nAt the end of the day we can use this approach as a simple and effective tool to find slow queries quite fast.\nAs an example we can show you the code below.\nWe created our own instrumentation at the beginning of each query to measure time and variables.\n\n@Component\nclass MonitoringInstrumentation(\n    private val clock: Clock,\n    private val meterRegistry: MeterRegistry,\n) : SimpleInstrumentation() {\n\n    override fun instrumentExecutionResult(\n        executionResult: ExecutionResult,\n        parameters: InstrumentationExecutionParameters\n    ): CompletableFuture\u003cExecutionResult\u003e {\n        try {\n            val instrumentationState = parameters.getInstrumentationState\u003cMonitoringInstrumentationState\u003e()\n            val startTime = instrumentationState.startTime\n            val endTime = getTime()\n            val executionTime = startTime - endTime\n            if (executionTime \u003e 1000) {\n                val query = parameters.query\n                val variables = parameters.variables\n                metric.increment(\n                    SLOW_QUERY_METRIC_NAME,\n                    \"duration\",\n                    executionTime)\n                logger.warn {\n                    \"Slow query: $query with variables ${serializeVariables(variables)}.\" +\n                        \" Duration: ${executionTime.toMillis()} ms\"\n                }\n            }\n        }\n        return super.instrumentExecutionResult(executionResult, parameters)\n    }\n  }\n\n\nPer field monitoring\nLast but not least, an interesting approach which we consider, and is almost out of the box for resolvers and supported by many libraries, is per field monitoring.\nIt is pretty nice for getting extra data to analyze our graph.\nHowever, it can be expensive to collect such a type of data.\nGathering metrics for each field can be more valuable than monitoring each query.\nMoreover, we can easily find the bottleneck of bits and pieces of our graph.\nResolvers monitoring can be achieved by using libraries built into our GraphQL server implementation such as\ngraphql-java-server.\nOur implementation follows the Apollo proposed tracing format (A community building flexible open source tools for GraphQL).\n\n{\n \"data\":\n   \"user\": {\n     \"name\": \"Javier\",\n     \"friends\": [\n       {\n         \"name\": \"Clarisa\"\n       }\n     ]\n   },\n \"extensions\": {\n   \"tracing\": {\n     \"version\": 1,\n     \"startTime\": \"2022-04-14T23:13:39.362Z\",\n     \"endTime\": \"2022-04-14T23:13:39.497Z\",\n     \"duration\": 135589186,\n     \"execution\": {\n       \"resolvers\": [\n         {\n           \"path\": [\n             \"user\"\n           ],\n           \"parentType\": \"Query\",\n           \"returnType\": \"Character\",\n           \"fieldName\": \"user\",\n           \"startOffset\": 105697585,\n           \"duration\": 79111240\n         },\n         {\n           \"path\": [\n             \"user\",\n             \"name\"\n           ],\n           \"parentType\": \"Girl\",\n           \"returnType\": \"String\",\n           \"fieldName\": \"name\",\n           \"startOffset\": 125010028,\n           \"duration\": 20213\n         }\n       ]\n     }\n   }\n }\n}\n\n\nBottom line of resolver monitoring is thinking about it as checking each data source,\nnot the internal mechanism of GraphQL implementation.\nIt is possible that our internal performance is not the limiting factor as I / O and external connections are often critical.\nBatching requests to external services\nIn the paragraph about resolvers we mentioned connecting to the same source many times to\nfetch all the type fields in case of using type resolvers. There is a solution for that, and it is called data loaders.\nHow does it work? It collects all requests from many parts of the schema and retrieves their data in one request.\nThis allows it to solve the N+1 problem, which is very well known in GraphQL.\nImagine the situation where we want to query for three users.\n\nAs the diagram says, we must ask external sources four times for three users – once to fetch all users and once per each user to fetch his name.\nMoreover we call user name service many times even if it has some batch method to get logins for many users.\nIntroducing a data loader solves this problem. The second diagram shows how it works.\n\nWe cumulate all requests and ask user name service only once. Let’s see what the code looks like.\nWe have UserBatchDataLoader which asks userClient for users and maps the response to User object.\n\n@Component\nclass UserBatchDataLoader(\n   userClient: UserClient,\n   executor: Executor\n) : BatchDataLoaderInfo\u003cString, UserResponse, User\u003e(\n   { userIds -\u003e userClient.users(userIds) },\n   UserResponse::userId,\n   { it.toUser() },\n   executor\n)\n\n\nThere is also UserTypeResolver that uses it while resolving user name.\n\n\nclass UserTypeResolver(\n   private val userBatchDataLoader: UserBatchDataLoader\n) : GraphQLResolver\u003cUser\u003e {\n   fun name(\n       user: User,\n       dfe: DataFetchingEnvironment\n   ): CompletableFuture\u003cString?\u003e =\n       extractDataLoader(userBatchDataLoader, dfe)\n           .load(user.userId.raw)\n           .thenApply { it?.name }\n}\n\n\n\nExactly the same can be done with User fields in the type resolver.\nWe can accumulate requests for each field and run it once if the source is the same.\nThere is a UserDataLoader that asks UserClient for the whole User object.\n\n@Component\nclass UserDataLoader(\n   userClient: UserClient,\n   executor: Executor\n) : SimpleDataLoaderInfo\u003cString, UserResponse\u003e(\n   { userId: String -\u003e userClient.user(userId) },\n   executor\n)\n\n\nIt is used in UserTypeResolver while resolving first name and email.\n\n@Component\nclass UserTypeResolver(\nprivate val dataLoaderInfo: UserDataLoader,\nprivate val executor: Executor\n): GraphQLResolver\u003cUser\u003e {\n\n\tfun firstName(user: User, dfe: DataFetchingEnvironment): CompletableFuture\u003cString?\u003e =\n   extractDataLoader(dataLoaderInfo, dfe)\n       .load(user.userId.raw)\n       .thenApply { it?.person?.firstName }\n\nfun email(user: User, dfe: DataFetchingEnvironment): CompletableFuture\u003cString?\u003e =\n   extractDataLoader(dataLoaderInfo, dfe)\n       .load(user.userId.raw)\n       .thenApply { it?.contacts?.email }\n}\n\n\n\nCaching - why is it so troublesome?\nHTTP caching\nThe biggest problem that makes using HTTP caching less effective is plenty of different requests that we can make.\nWhen we ask for a user with his name and email the response is saved in cache.\nBut when we ask again without the information about email despite the fact that\nthe information is already available we cannot use it,\nbecause this is a different query (and HTTP cache cannot handle it without understanding GraphQL logic).\nTo make cache work best we should recognise at field level which user name is already in\nmemory and ask only for the rest of them.\nServer-side caching\nLet’s put aside HTTP caching and focus more on how we can implement server cache that is more focused on GraphQL logic.\nWe could cache specific types from our schema or their fields. A good example of implemented server-side cache is\napollo-server.\nSo if we run the same type or query resolver with the same arguments it can be returned from cache.\nWith data loaders you can also cache requests to external sources not only in one query,\nbut even between many queries by selecting a specific strategy. This solution is available out of the box, and can be used easily.\nClient-side caching\nAnother common way to cache query response is client-side caching. It can be very beneficial, because one client may ask for the same information many times.\nAs an example we can take Apollo client and its solution. The cache uses the ID field to identify whether an object exists in memory.\nThen it checks if all fields that are to be returned are already in memory, if some are not it asks only for them.\nOur caching decisions\nWe’ve decided not to use server-side caching with a global data loader because we have struggled with many clients of our graph and the graph’s data\nchanges frequently. That forced us to use a cache-per-request strategy.\nIf we are talking about caching on the client side we tackle the issue that some of our objects don’t have a unique ID so after a while we skipped this approach and we are not caching them on the client side either.\nWhat is the outcome of the battle?\nWe have learned a lot about GraphQL’s trade offs while working with it, but there is still a lot to be discovered. The most important feature of it, fetching only those fields that we need, is a huge optimization itself, but also causes many problems with standard ways to make the application effective or even to measure that efficiency.\nThe ideas that we described above need to be implemented by the programmers (most libraries don’t provide that logic) and it’s really complex and time consuming.","guid":"https://blog.allegro.tech/2022/06/graphql-perf-tradeoffs.html","categories":["tech","backend","performance","graphql","kotlin","java"],"isoDate":"2022-06-19T22:00:00.000Z","thumbnail":"images/post-headers/java.png"},{"title":"How to include refactoring into product development roadmap? Reducing technical debt inspired by real options identification","link":"https://blog.allegro.tech/2022/06/debt-reduction-in-the-product-roadmap.html","pubDate":"Tue, 07 Jun 2022 00:00:00 +0200","authors":{"author":[{"name":["Olga Dudzik"],"photo":["https://blog.allegro.tech/img/authors/olga.dudzik.jpg"],"url":["https://blog.allegro.tech/authors/olga.dudzik"]}]},"content":"\u003cp\u003eNowadays, technical debt can be considered the bread and butter of most IT-powered enterprises around the world.\nAlmost every company that survived the startup phase and managed to deliver its first products to customers will face at some point technical challenges related to past architectural decisions. Although code engineering gets better every year, we cannot argue with the obvious fact of life: the market will always force many of us to deliver tech products faster than we wish. Time To Market has always been a key success factor for many product companies and it puts a lot of pressure on Engineering to keep up with challenging deadlines.\u003c/p\u003e\n\n\u003cp\u003eStatistics explicitly show the scale of the problem. According to the survey conducted in 2020 by McKinsey\u003csup id=\"fnref:1\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:1\" class=\"footnote\" rel=\"footnote\"\u003e1\u003c/a\u003e\u003c/sup\u003e, tech debt can reach up to as much as 40% of the whole technology value. On average 10-20% of IT budget is ultimately consumed by tech debt management and most CIOs interviewed consider the problem significantly increasing over past years, especially in enterprise-size companies\u003csup id=\"fnref:2\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:2\" class=\"footnote\" rel=\"footnote\"\u003e2\u003c/a\u003e\u003c/sup\u003e.\u003c/p\u003e\n\n\u003cp\u003eAs disturbing as it sounds, acknowledging the magnitude of the problem is the first step to dealing with it.\u003c/p\u003e\n\n\u003cp\u003eSo, here we get to the Product Management reality. Even if we are lucky and after a product discovery we manage to navigate a perfect niche where we can provide a long-awaited, successful product, we still can fail having technology adjusted to our plans and needs. And that would be a real PM tragedy, wouldn’t it? To cap it all, it might be hard to even talk about innovative solutions when maneuvering around limitations imposed by the legacy code. So any further development of our product may become increasingly tricky and take more time which eventually poses a threat to staying competitive.\u003c/p\u003e\n\n\u003cp\u003eBearing that in mind, no reasonable Product Manager can afford ignoring the gravity of code complexity and shady legacy.\u003c/p\u003e\n\n\u003cp\u003eToday is the day to start a crusade against technical debt in your products. Nonetheless before we start we must all admit: building a yearly roadmap consisting mostly of incomprehensible technical deliveries that cannot be easily attributed to business value will not make us most popular Product Managers out there, to put it mildly. In most companies proposing such a backlog will result in heated discussions about targets, KPIs and wasting team’s capacity. Work that does not end up with a significant increment is hard to defend. At the end technical product development is mostly not a charity effort and it is supposed to deliver financial outcomes - the sooner, the better.\u003c/p\u003e\n\n\u003cp\u003eThe situation gets even more complicated in publicly listed companies that report to stakeholders on a regular basis. Declaring work without making any explicit promise of near-future apparent return on investment may seem unexplainable. Technical debt reduction on its own is strictly connected with vast uncertainty as long as it is not presented holistically in a broader context. So how can we approach Roadmaps to make debt reduction more appealing for our audience?\u003c/p\u003e\n\n\u003ch2 id=\"take-a-look-outside-of-the-it-world\"\u003eTake a look outside of the IT world.\u003c/h2\u003e\n\n\u003cp\u003eI believe that especially in Product Management we appreciate inspirations from other industries. And this case should not be an exception. Financial industry and analysts working on companies’ valuations have been struggling with a similar challenge for decades. Is it worth investing in a company that may not seem to be an appealing opportunity now in terms of near-future ROI? How to assess potential profits from innovative ideas on the table? How can we, in general, assess long-term impact of work at the grass roots? And which tech company is a good investment opportunity? Our development backlogs should answer similar questions - which of these debt-reduction tasks are worth pursuing and what can we achieve? Which of them are really good opportunities for us? And finally - how to prove to stakeholders the real value of such initiatives? To approach these questions we can use the idea of real options.\u003c/p\u003e\n\n\u003cp\u003eLet us discover together the roots of real options. The idea itself dates back to 1977. Stewart Myers coined this term describing real options as “opportunities to purchase real assets on possibly favorable terms”\u003csup id=\"fnref:3\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:3\" class=\"footnote\" rel=\"footnote\"\u003e3\u003c/a\u003e\u003c/sup\u003e and declaring that each company should be aware of its real assets and real options. Since then, the idea has evolved significantly and has been used in multiple methodologies not only for financial valuations, but also for determining value drivers in a variety of industries. It has been particularly attractive to IT enterprises as it embraces dealing with high uncertainty.\u003c/p\u003e\n\n\u003cp\u003eInspired by real options theory, I reckon that we should stop considering technical debt in terms of short-term Profit and Loss accounting.\u003c/p\u003e\n\n\u003cp\u003eLooking only at the nearest future, refactoring activities will mostly look as cost centers without any outlook on further potential profits. However, once we change the perspective and start considering current refactoring investments as enablers for future product options, we are able to grasp the full range of benefits to be gained. Real options perspective should open our roadmaps for long-term thinking and it can allow us to optimize our decision-making process.\u003c/p\u003e\n\n\u003cp\u003eHowever, currently existing academic and financial models are mostly complex and time-consuming to perform. Therefore the idea of real options will serve here mostly as an inspiration for a really simple exercise that will aim to transform the general approach towards technical debt.\u003c/p\u003e\n\n\u003cp\u003eBearing in mind the PM’s reality of limited time and resources, the aim is to keep the analysis quick. Moreover, we would like the output to be as easy and understandable as possible, so it can be fitting for the broad audience. Following real options terminology, we can assume that each resolved technical debt issue is our “real option” - a potential value driver and opportunity to create or improve some products (“real assets”). This exercise will focus on identifying and mapping options to future assets.\u003c/p\u003e\n\n\u003cp\u003eIn the Product Management case, investments (time of our developers) will be made to remove some technical obstacles and they will become product enablers. Opportunities on the other hand will be translated into tangible deliveries and potentially attractive positions in our future Roadmaps. And in the best case, these opportunities may even open some new doors to further developments into currently unknown and unreachable areas. Our ultimate goal is to maximize opportunities while minimizing effort required to enable them.\u003c/p\u003e\n\n\u003cp\u003eI strongly believe that it is really tricky to evaluate analyzed efforts and hopes from the financial perspective at an early stage of analysis. Calculating ROI moneywise can be extremely time-consuming and tends to be based heavily on “guesstimates” (“an approximate calculation of the size or amount of something when you do not know all the facts”\u003csup id=\"fnref:4\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:4\" class=\"footnote\" rel=\"footnote\"\u003e4\u003c/a\u003e\u003c/sup\u003e) . Nonetheless, at the same time it should be fairly possible and informative to at least roughly estimate our potential works vs. hopes in T-shirt sizing method (or any other preferred manner, up to you) and I would strongly recommend to follow this path at the beginning. As it is fairly simple and flexible, we can use the same concept to evaluate profits or attractivity of products or opportunities.\u003c/p\u003e\n\n\u003ch2 id=\"where-should-we-start-tech-debt---value-mapping\"\u003eWhere should we start tech debt - value mapping?\u003c/h2\u003e\n\n\u003cp\u003eLet us go through the process step by step. I would recommend going through this discovery process together with your technical team and to transform it into collaborative work. It can be a rewarding exercise for the whole team and it should boost the sense of agency.\u003c/p\u003e\n\n\u003cp\u003eFirst of all we should list all services/topics touched by our technical debt. They can be grouped into areas that will be addressed together to achieve the best efficiency. Depending on the specifics of the system, the granularity or nature of issues can differ. The main aim here is to review the general current state of tech without doing long and costly deep-dives. Our aim is to detect problematic areas avoiding major investments in solution analysis. In this exercise the technical team is the key. The more experienced our engineers are and the better they know their code, the more reliable outcome we get.\u003c/p\u003e\n\n\u003cp\u003eThe second step is ideation. Let’s determine our real options. Each of the listed services or areas, while solved, should be considered as an enabler for further system development. So this is the time to brainstorm together: assuming that problem A is resolved, what kind of new capabilities will be available for us? What kind of services or products can we build then? Or maybe there are some meaningful improvements that will make our product more convenient and should attract more users? We can and should go even further: what can we build assuming that more than one of the detected issues is closed? This is a perfect moment for the Product Manager to step in and to present the broad vision for the Product as inspiration. Wishful thinking, benchmarking, research and UX studies - all of these tools will prove to be useful in this workshop.\u003c/p\u003e\n\n\u003cp\u003eAt the end of step two we should be able to draw a tree diagram presenting clearly technical blockers as potential new opportunity enablers:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-06-07-debt-reduction-in-the-product-roadmap/img1.png\" alt=\"Figure 1\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eTree diagram mapping technical debt areas to related product/business opportunities.\u003c/p\u003e\n\n\u003cp\u003eStep three is all about evaluation. As mentioned before, I recommend using T-shirt sizing as it brings simplicity into very complex situations. I find T-shirt sizing an attractive estimation technique as it is quite intuitive and introduces relativity between analyzed entities. Sizes that we know from T-shirt labels (XS-XXL) are used to assess work needed to deliver a given task. At this stage our problems are not deeply analyzed and they are not broken down into particular stories/development tasks. We are working with high-level problems and ideas as we do not have time to spend weeks on analysis of topics that may not end up on our roadmap. In this step we can split into two work groups: a technical one and a business one. Technical team should focus on assessing the complexity of each detected technical task - both from debt-areas but also from prospective product opportunities (they require some work too!). If given problem seems to be fairly simple, it can be evaluated as an S. If something requires a major rebuild and redesigning the basics - it could be an XL. Let us just bear in mind that assessment should cover end-to-end work so the complexity of E2E \u0026amp; regression testing should be a vital part of this estimation too. What is more, covering the uncertainty factor in this exercise can be useful so I would not hesitate to assign bigger values for more vague areas. Effort estimation will be presented on the diagram below as purple boxes.\u003c/p\u003e\n\n\u003cp\u003eBusiness team (product managers and business stakeholders) will work on evaluating all the listed capabilities. As always, they should be considered in the broader context, so any product validation tools are handy. Apart from the business impact of each solution, we should also bear in mind if it fits into expected company strategy and if we can see it bringing us any competitive advantage when delivered in the more or less distant future (we have some issues to be resolved first!). Opportunities will be marked on the diagram as green boxes.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-06-07-debt-reduction-in-the-product-roadmap/img2.png\" alt=\"Figure 2\" /\u003e\u003c/p\u003e\n\n\u003ch2 id=\"roadmapping\"\u003eRoadmapping\u003c/h2\u003e\n\n\u003cp\u003eHaving this analysis in hand, we can pick our best candidates for the roadmap depending on the team’s capacity available. While it will never be easy to choose the best path, it should be possible to navigate works that have the best potential to bring us noticeable benefits. While pitching the idea of technical debt reduction for the management team, we usually rely on financial aspects of reducing maintenance costs of old code (e.g. we can get potential savings based on maintenance work reports from previous months). After this analysis we should be additionally equipped with the reliable documentation of new business opportunities enabled.\u003c/p\u003e\n\n\u003cp\u003eThere are at least two approaches to include refactoring on the roadmap, depending on the company’s specifics. Presenting detected technical-debt tasks as a stage zero of your product development may prove to be handy for organizations that are particularly reluctant to acknowledge refactoring as opportunities. In such a case debt reduction could be ‘hidden’ in the Opportunity roadmap item represented by longer actual delivery time. It is worth noting that this approach gives less clarity when it comes to presenting dependencies:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-06-07-debt-reduction-in-the-product-roadmap/img3.png\" alt=\"Figure 3\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eFor companies that are more open to the refactoring idea, putting technical tasks as “business enablers” on the roadmap can give more clarity. In this approach, it is also easier to include multiple enablers and opportunities on one graph. Cause and effect sequence would explain interdependencies between deliveries and make it easier to understand overlapping items:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2022-06-07-debt-reduction-in-the-product-roadmap/img4.png\" alt=\"Figure 4\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eI strongly believe that introducing analysis described in this article can be a good starting point for the discussion about reducing technical debt in IT-driven products. It can be further developed and supported by a variety of financial analysis methods available for real options valuations or other approaches applicable for IT. There is a necessity to change general mindset and industry’s way of thinking about code refactoring to make the process sustainable and successful. Becoming aware of new opportunities resulting from the technical debt reduction is a good first step towards this goal.\u003c/p\u003e\n\n\u003cdiv class=\"footnotes\" role=\"doc-endnotes\"\u003e\n  \u003col\u003e\n    \u003cli id=\"fn:1\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca href=\"https://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/tech-debt-reclaiming-tech-equity\"\u003ehttps://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/tech-debt-reclaiming-tech-equity\u003c/a\u003e \u003ca href=\"#fnref:1\" class=\"reversefootnote\" role=\"doc-backlink\"\u003e\u0026#8617;\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:2\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca href=\"https://www.computerweekly.com/news/252504654/Technical-debt-is-holding-back-innovation\"\u003ehttps://www.computerweekly.com/news/252504654/Technical-debt-is-holding-back-innovation\u003c/a\u003e \u003ca href=\"#fnref:2\" class=\"reversefootnote\" role=\"doc-backlink\"\u003e\u0026#8617;\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:3\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca href=\"https://onlinelibrary.wiley.com/doi/10.1111/emre.12324\"\u003ehttps://onlinelibrary.wiley.com/doi/10.1111/emre.12324\u003c/a\u003e \u003ca href=\"#fnref:3\" class=\"reversefootnote\" role=\"doc-backlink\"\u003e\u0026#8617;\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:4\" role=\"doc-endnote\"\u003e\n      \u003cp\u003e\u003ca href=\"https://dictionary.cambridge.org/dictionary/english/guesstimate\"\u003ehttps://dictionary.cambridge.org/dictionary/english/guesstimate\u003c/a\u003e \u003ca href=\"#fnref:4\" class=\"reversefootnote\" role=\"doc-backlink\"\u003e\u0026#8617;\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n  \u003c/ol\u003e\n\u003c/div\u003e\n","contentSnippet":"Nowadays, technical debt can be considered the bread and butter of most IT-powered enterprises around the world.\nAlmost every company that survived the startup phase and managed to deliver its first products to customers will face at some point technical challenges related to past architectural decisions. Although code engineering gets better every year, we cannot argue with the obvious fact of life: the market will always force many of us to deliver tech products faster than we wish. Time To Market has always been a key success factor for many product companies and it puts a lot of pressure on Engineering to keep up with challenging deadlines.\nStatistics explicitly show the scale of the problem. According to the survey conducted in 2020 by McKinsey1, tech debt can reach up to as much as 40% of the whole technology value. On average 10-20% of IT budget is ultimately consumed by tech debt management and most CIOs interviewed consider the problem significantly increasing over past years, especially in enterprise-size companies2.\nAs disturbing as it sounds, acknowledging the magnitude of the problem is the first step to dealing with it.\nSo, here we get to the Product Management reality. Even if we are lucky and after a product discovery we manage to navigate a perfect niche where we can provide a long-awaited, successful product, we still can fail having technology adjusted to our plans and needs. And that would be a real PM tragedy, wouldn’t it? To cap it all, it might be hard to even talk about innovative solutions when maneuvering around limitations imposed by the legacy code. So any further development of our product may become increasingly tricky and take more time which eventually poses a threat to staying competitive.\nBearing that in mind, no reasonable Product Manager can afford ignoring the gravity of code complexity and shady legacy.\nToday is the day to start a crusade against technical debt in your products. Nonetheless before we start we must all admit: building a yearly roadmap consisting mostly of incomprehensible technical deliveries that cannot be easily attributed to business value will not make us most popular Product Managers out there, to put it mildly. In most companies proposing such a backlog will result in heated discussions about targets, KPIs and wasting team’s capacity. Work that does not end up with a significant increment is hard to defend. At the end technical product development is mostly not a charity effort and it is supposed to deliver financial outcomes - the sooner, the better.\nThe situation gets even more complicated in publicly listed companies that report to stakeholders on a regular basis. Declaring work without making any explicit promise of near-future apparent return on investment may seem unexplainable. Technical debt reduction on its own is strictly connected with vast uncertainty as long as it is not presented holistically in a broader context. So how can we approach Roadmaps to make debt reduction more appealing for our audience?\nTake a look outside of the IT world.\nI believe that especially in Product Management we appreciate inspirations from other industries. And this case should not be an exception. Financial industry and analysts working on companies’ valuations have been struggling with a similar challenge for decades. Is it worth investing in a company that may not seem to be an appealing opportunity now in terms of near-future ROI? How to assess potential profits from innovative ideas on the table? How can we, in general, assess long-term impact of work at the grass roots? And which tech company is a good investment opportunity? Our development backlogs should answer similar questions - which of these debt-reduction tasks are worth pursuing and what can we achieve? Which of them are really good opportunities for us? And finally - how to prove to stakeholders the real value of such initiatives? To approach these questions we can use the idea of real options.\nLet us discover together the roots of real options. The idea itself dates back to 1977. Stewart Myers coined this term describing real options as “opportunities to purchase real assets on possibly favorable terms”3 and declaring that each company should be aware of its real assets and real options. Since then, the idea has evolved significantly and has been used in multiple methodologies not only for financial valuations, but also for determining value drivers in a variety of industries. It has been particularly attractive to IT enterprises as it embraces dealing with high uncertainty.\nInspired by real options theory, I reckon that we should stop considering technical debt in terms of short-term Profit and Loss accounting.\nLooking only at the nearest future, refactoring activities will mostly look as cost centers without any outlook on further potential profits. However, once we change the perspective and start considering current refactoring investments as enablers for future product options, we are able to grasp the full range of benefits to be gained. Real options perspective should open our roadmaps for long-term thinking and it can allow us to optimize our decision-making process.\nHowever, currently existing academic and financial models are mostly complex and time-consuming to perform. Therefore the idea of real options will serve here mostly as an inspiration for a really simple exercise that will aim to transform the general approach towards technical debt.\nBearing in mind the PM’s reality of limited time and resources, the aim is to keep the analysis quick. Moreover, we would like the output to be as easy and understandable as possible, so it can be fitting for the broad audience. Following real options terminology, we can assume that each resolved technical debt issue is our “real option” - a potential value driver and opportunity to create or improve some products (“real assets”). This exercise will focus on identifying and mapping options to future assets.\nIn the Product Management case, investments (time of our developers) will be made to remove some technical obstacles and they will become product enablers. Opportunities on the other hand will be translated into tangible deliveries and potentially attractive positions in our future Roadmaps. And in the best case, these opportunities may even open some new doors to further developments into currently unknown and unreachable areas. Our ultimate goal is to maximize opportunities while minimizing effort required to enable them.\nI strongly believe that it is really tricky to evaluate analyzed efforts and hopes from the financial perspective at an early stage of analysis. Calculating ROI moneywise can be extremely time-consuming and tends to be based heavily on “guesstimates” (“an approximate calculation of the size or amount of something when you do not know all the facts”4) . Nonetheless, at the same time it should be fairly possible and informative to at least roughly estimate our potential works vs. hopes in T-shirt sizing method (or any other preferred manner, up to you) and I would strongly recommend to follow this path at the beginning. As it is fairly simple and flexible, we can use the same concept to evaluate profits or attractivity of products or opportunities.\nWhere should we start tech debt - value mapping?\nLet us go through the process step by step. I would recommend going through this discovery process together with your technical team and to transform it into collaborative work. It can be a rewarding exercise for the whole team and it should boost the sense of agency.\nFirst of all we should list all services/topics touched by our technical debt. They can be grouped into areas that will be addressed together to achieve the best efficiency. Depending on the specifics of the system, the granularity or nature of issues can differ. The main aim here is to review the general current state of tech without doing long and costly deep-dives. Our aim is to detect problematic areas avoiding major investments in solution analysis. In this exercise the technical team is the key. The more experienced our engineers are and the better they know their code, the more reliable outcome we get.\nThe second step is ideation. Let’s determine our real options. Each of the listed services or areas, while solved, should be considered as an enabler for further system development. So this is the time to brainstorm together: assuming that problem A is resolved, what kind of new capabilities will be available for us? What kind of services or products can we build then? Or maybe there are some meaningful improvements that will make our product more convenient and should attract more users? We can and should go even further: what can we build assuming that more than one of the detected issues is closed? This is a perfect moment for the Product Manager to step in and to present the broad vision for the Product as inspiration. Wishful thinking, benchmarking, research and UX studies - all of these tools will prove to be useful in this workshop.\nAt the end of step two we should be able to draw a tree diagram presenting clearly technical blockers as potential new opportunity enablers:\n\nTree diagram mapping technical debt areas to related product/business opportunities.\nStep three is all about evaluation. As mentioned before, I recommend using T-shirt sizing as it brings simplicity into very complex situations. I find T-shirt sizing an attractive estimation technique as it is quite intuitive and introduces relativity between analyzed entities. Sizes that we know from T-shirt labels (XS-XXL) are used to assess work needed to deliver a given task. At this stage our problems are not deeply analyzed and they are not broken down into particular stories/development tasks. We are working with high-level problems and ideas as we do not have time to spend weeks on analysis of topics that may not end up on our roadmap. In this step we can split into two work groups: a technical one and a business one. Technical team should focus on assessing the complexity of each detected technical task - both from debt-areas but also from prospective product opportunities (they require some work too!). If given problem seems to be fairly simple, it can be evaluated as an S. If something requires a major rebuild and redesigning the basics - it could be an XL. Let us just bear in mind that assessment should cover end-to-end work so the complexity of E2E \u0026 regression testing should be a vital part of this estimation too. What is more, covering the uncertainty factor in this exercise can be useful so I would not hesitate to assign bigger values for more vague areas. Effort estimation will be presented on the diagram below as purple boxes.\nBusiness team (product managers and business stakeholders) will work on evaluating all the listed capabilities. As always, they should be considered in the broader context, so any product validation tools are handy. Apart from the business impact of each solution, we should also bear in mind if it fits into expected company strategy and if we can see it bringing us any competitive advantage when delivered in the more or less distant future (we have some issues to be resolved first!). Opportunities will be marked on the diagram as green boxes.\n\nRoadmapping\nHaving this analysis in hand, we can pick our best candidates for the roadmap depending on the team’s capacity available. While it will never be easy to choose the best path, it should be possible to navigate works that have the best potential to bring us noticeable benefits. While pitching the idea of technical debt reduction for the management team, we usually rely on financial aspects of reducing maintenance costs of old code (e.g. we can get potential savings based on maintenance work reports from previous months). After this analysis we should be additionally equipped with the reliable documentation of new business opportunities enabled.\nThere are at least two approaches to include refactoring on the roadmap, depending on the company’s specifics. Presenting detected technical-debt tasks as a stage zero of your product development may prove to be handy for organizations that are particularly reluctant to acknowledge refactoring as opportunities. In such a case debt reduction could be ‘hidden’ in the Opportunity roadmap item represented by longer actual delivery time. It is worth noting that this approach gives less clarity when it comes to presenting dependencies:\n\nFor companies that are more open to the refactoring idea, putting technical tasks as “business enablers” on the roadmap can give more clarity. In this approach, it is also easier to include multiple enablers and opportunities on one graph. Cause and effect sequence would explain interdependencies between deliveries and make it easier to understand overlapping items:\n\nI strongly believe that introducing analysis described in this article can be a good starting point for the discussion about reducing technical debt in IT-driven products. It can be further developed and supported by a variety of financial analysis methods available for real options valuations or other approaches applicable for IT. There is a necessity to change general mindset and industry’s way of thinking about code refactoring to make the process sustainable and successful. Becoming aware of new opportunities resulting from the technical debt reduction is a good first step towards this goal.\nhttps://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/tech-debt-reclaiming-tech-equity ↩\nhttps://www.computerweekly.com/news/252504654/Technical-debt-is-holding-back-innovation ↩\nhttps://onlinelibrary.wiley.com/doi/10.1111/emre.12324 ↩\nhttps://dictionary.cambridge.org/dictionary/english/guesstimate ↩","guid":"https://blog.allegro.tech/2022/06/debt-reduction-in-the-product-roadmap.html","categories":["tech","roadmaps","tech debt","product"],"isoDate":"2022-06-06T22:00:00.000Z","thumbnail":"images/post-headers/default.jpg"}],"jobs":[{"id":"743999810853837","name":"Research Engineer - Machine Learning (Computer Vision)","uuid":"98abcad8-b820-4402-85a6-b6b6e03cfdaa","refNumber":"REF2880R","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2022-03-09T12:55:28.000Z","location":{"city":"Warszawa, Kraków, Poznań, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572821","label":"IT - Machine Learning"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"606235fe248e6f5bea0815ed","fieldLabel":"Katowice","valueId":"185eb5a9-b884-4ee8-8ebc-0e5f3e852b27","valueLabel":"Tak"},{"fieldId":"58c1575ee4b01d4b19ddf797","fieldLabel":"Kraków","valueId":"2cfcfcc1-da44-43f7-8eaa-3907faf2797c","valueLabel":"Tak"},{"fieldId":"606235bcefbac7156d6a470a","fieldLabel":"Łódź","valueId":"7d33e23d-3fa7-4d7d-86ae-7d7caff54fa9","valueLabel":"Tak"},{"fieldId":"58c158e9e4b0614667d5973e","fieldLabel":"Więcej lokalizacji","valueId":"3a186e8d-a82c-4955-af81-fcef9a63928a","valueLabel":"Tak"},{"fieldId":"58c1576ee4b0614667d59732","fieldLabel":"Toruń","valueId":"987e8884-bad1-4a8f-b149-99e4184cc221","valueLabel":"Tak"},{"fieldId":"6165609ee6b46b6506c66b63","fieldLabel":"Gdańsk","valueId":"cde0f8e7-5c9d-4d78-9f5c-e1c17ee499a8","valueLabel":"Tak"},{"fieldId":"58c156e6e4b01d4b19ddf793","fieldLabel":"Warszawa","valueId":"6a428533-1586-4372-89ec-65fb45366363","valueLabel":"Tak"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Proces rekrutacji","valueId":"c807eec2-8a53-4b55-b7c5-c03180f2059b","valueLabel":"(Archive) IT Allegro"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c15788e4b0614667d59733","fieldLabel":"Błonie","valueId":"25f6cb8c-81b3-434a-93ec-6dc851d5808d","valueLabel":"Nie"},{"fieldId":"58c15798e4b01d4b19ddf79b","fieldLabel":"Wrocław","valueId":"64818201-cdba-422e-8e8c-8ec633b0d327","valueLabel":"Tak"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572821","valueLabel":"IT - Machine Learning"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro sp. z o.o."},{"fieldId":"61656102a169ed164d546c31","fieldLabel":"Lublin","valueId":"02d54f00-48b9-4669-b7b3-10c16ac4bada","valueLabel":"Tak"},{"fieldId":"58c156b9e4b01d4b19ddf792","fieldLabel":"Poznań","valueId":"ac20917b-cb6a-4280-aff3-4fae2532a33e","valueLabel":"Tak"},{"fieldId":"5cdab2c84cedfd0006e7758c","fieldLabel":"Key words","valueLabel":"CV, Computer Vision, ML, AI, DS, Machine Learning, PyTorch, Python, Deep Learning"}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999810853837","creator":{"name":"Maciej Matwiejczyk"},"language":{"code":"pl","label":"Polish","labelNative":"polski"}},{"id":"743999785421861","name":"Research Engineer - Machine Learning (Ranking and Recommendations)","uuid":"a6b2b59e-28e3-4bfa-89ab-b13ab97f06c8","refNumber":"REF2990T","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2021-11-08T09:54:52.000Z","location":{"city":"Warszawa, Poznań, Kraków, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572821","label":"IT - Machine Learning"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"58c1575ee4b01d4b19ddf797","fieldLabel":"Kraków","valueId":"2cfcfcc1-da44-43f7-8eaa-3907faf2797c","valueLabel":"Tak"},{"fieldId":"58c158e9e4b0614667d5973e","fieldLabel":"Więcej lokalizacji","valueId":"3a186e8d-a82c-4955-af81-fcef9a63928a","valueLabel":"Tak"},{"fieldId":"58c1576ee4b0614667d59732","fieldLabel":"Toruń","valueId":"987e8884-bad1-4a8f-b149-99e4184cc221","valueLabel":"Tak"},{"fieldId":"58c156e6e4b01d4b19ddf793","fieldLabel":"Warszawa","valueId":"6a428533-1586-4372-89ec-65fb45366363","valueLabel":"Tak"},{"fieldId":"60cb31a9c87e511299a3a050","fieldLabel":"Department II","valueId":"b8a4596e-d9ce-42bb-8de5-10995e9ccf99","valueLabel":"IT - Machine Learning"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Proces rekrutacji","valueId":"c807eec2-8a53-4b55-b7c5-c03180f2059b","valueLabel":"(Archive) IT Allegro"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c15788e4b0614667d59733","fieldLabel":"Błonie","valueId":"25f6cb8c-81b3-434a-93ec-6dc851d5808d","valueLabel":"Nie"},{"fieldId":"58c15798e4b01d4b19ddf79b","fieldLabel":"Wrocław","valueId":"64818201-cdba-422e-8e8c-8ec633b0d327","valueLabel":"Tak"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572821","valueLabel":"IT - Machine Learning"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro sp. z o.o."},{"fieldId":"58c156b9e4b01d4b19ddf792","fieldLabel":"Poznań","valueId":"ac20917b-cb6a-4280-aff3-4fae2532a33e","valueLabel":"Tak"},{"fieldId":"5cdab2c84cedfd0006e7758c","fieldLabel":"Key words","valueLabel":"ML, AI, Ranking, Research, Machine Learning"}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999785421861","creator":{"name":"Maciej Matwiejczyk"},"language":{"code":"en","label":"English","labelNative":"English (US)"}},{"id":"743999779448676","name":"Research Engineer - Machine Learning (Ranking and Recommendations)","uuid":"7cb35dfc-f53c-4b51-81ac-61b683060f4c","refNumber":"REF2990T","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2021-10-14T10:29:00.000Z","location":{"city":"Warszawa, Poznań, Kraków, Toruń, Wrocław, Gdańsk, Katowice, Łódź, Lublin","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572821","label":"IT - Machine Learning"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"58c1575ee4b01d4b19ddf797","fieldLabel":"Kraków","valueId":"2cfcfcc1-da44-43f7-8eaa-3907faf2797c","valueLabel":"Tak"},{"fieldId":"58c158e9e4b0614667d5973e","fieldLabel":"Więcej lokalizacji","valueId":"3a186e8d-a82c-4955-af81-fcef9a63928a","valueLabel":"Tak"},{"fieldId":"58c1576ee4b0614667d59732","fieldLabel":"Toruń","valueId":"987e8884-bad1-4a8f-b149-99e4184cc221","valueLabel":"Tak"},{"fieldId":"58c156e6e4b01d4b19ddf793","fieldLabel":"Warszawa","valueId":"6a428533-1586-4372-89ec-65fb45366363","valueLabel":"Tak"},{"fieldId":"60cb31a9c87e511299a3a050","fieldLabel":"Department II","valueId":"b8a4596e-d9ce-42bb-8de5-10995e9ccf99","valueLabel":"IT - Machine Learning"},{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Proces rekrutacji","valueId":"c807eec2-8a53-4b55-b7c5-c03180f2059b","valueLabel":"(Archive) IT Allegro"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"58c15788e4b0614667d59733","fieldLabel":"Błonie","valueId":"25f6cb8c-81b3-434a-93ec-6dc851d5808d","valueLabel":"Nie"},{"fieldId":"58c15798e4b01d4b19ddf79b","fieldLabel":"Wrocław","valueId":"64818201-cdba-422e-8e8c-8ec633b0d327","valueLabel":"Tak"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572821","valueLabel":"IT - Machine Learning"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro sp. z o.o."},{"fieldId":"58c156b9e4b01d4b19ddf792","fieldLabel":"Poznań","valueId":"ac20917b-cb6a-4280-aff3-4fae2532a33e","valueLabel":"Tak"},{"fieldId":"5cdab2c84cedfd0006e7758c","fieldLabel":"Key words","valueLabel":"ML, AI, Ranking, Research, Machine Learning"}],"ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999779448676","creator":{"name":"Maciej Matwiejczyk"},"language":{"code":"pl","label":"Polish","labelNative":"polski"}}],"events":[{"created":1657193453000,"duration":7200000,"id":"287035383","name":"Allegro Tech Labs #10 Online: Poskromić stan w React","date_in_series_pattern":false,"status":"upcoming","time":1658415600000,"local_date":"2022-07-21","local_time":"17:00","updated":1657193565000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":23,"is_online_event":false,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/287035383/","description":"❗NA WYDARZENIE OBOWIĄZUJE REJESTRACJA: Liczba miejsc jest organiczona: [https://app.evenea.pl/event/allegro-tech-labs-10/](https://app.evenea.pl/event/allegro-tech-labs-10/?fbclid=IwAR1Zj3sIcfx3WEWiFfS_hgiW6BJQD6stYouSGuSqfxDq9YVeom8fTFcrE1Q) ❗ **Allegro Tech Labs** to w 100% zdalna odsłona naszych stacjonarnych spotkań warsztatowych. Zazwyczaj spotykaliśmy się…","visibility":"public","member_pay_fee":false},{"created":1655131243000,"duration":5400000,"id":"286545395","name":"Allegro Tech Live #29 - Wyzwania Product Managera","date_in_series_pattern":false,"status":"past","time":1656604800000,"local_date":"2022-06-30","local_time":"18:00","updated":1656612323000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":88,"is_online_event":false,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/286545395/","description":"Allegro Tech Live to w 100% zdalna odsłona naszych stacjonarnych meetupów Allegro Tech Talks. Zazwyczaj spotykaliśmy się w naszych biurach, ale tym razem to my…","visibility":"public","member_pay_fee":false},{"created":1650552918000,"duration":100800000,"id":"285416318","name":"UX Research Confetti - II edycja","date_in_series_pattern":false,"status":"past","time":1653562800000,"local_date":"2022-05-26","local_time":"13:00","updated":1653666063000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":48,"is_online_event":true,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/285416318/","description":"REJESTRACJA NA WYDARZENIE -\u0026gt; https://app.evenea.pl/event/ux-research-confetti-2/ 🎉 Niech ponownie rozsypie się confetti wiedzy o badaniach UX! 🎉 Szukaliśmy konferencji badawczej UX w Polsce i nie znaleźliśmy……","visibility":"public","member_pay_fee":false},{"created":1651656994000,"duration":7200000,"id":"285691203","name":"Allegro Tech Live #28 - Mobile: Architektura softu i architektura sprzętu","date_in_series_pattern":false,"status":"past","time":1652976000000,"local_date":"2022-05-19","local_time":"18:00","updated":1652985850000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":48,"is_online_event":true,"group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/285691203/","description":"**Allegro Tech Live** to w 100% zdalna odsłona naszych stacjonarnych meetupów Allegro Tech Talks. Kiedyś spotykaliśmy się w naszych biurach, a teraz to my gościmy…","visibility":"public","member_pay_fee":false}],"podcasts":[{"title":"S02E12 - Piotr Betkier - Rola architekta w Allegro","link":"https://podcast.allegro.tech/rola_architekta_w_allegro/","pubDate":"Wed, 16 Jun 2021 00:00:00 GMT","content":"Od kodowania do tworzenia strategii technicznej... Jak wygląda rola architekta w Allegro? Ile takich osób pracuje w naszej firmie i dlaczego ta rola jest tak różnorodna? Czym jest Andamio i jak rozwijamy naszą platformę – o tym wszystkim opowie Piotr Betkier – Inżynier, Architekt Platformy Technicznej w Allegro oraz twórca piosenek o IT :)","contentSnippet":"Od kodowania do tworzenia strategii technicznej... Jak wygląda rola architekta w Allegro? Ile takich osób pracuje w naszej firmie i dlaczego ta rola jest tak różnorodna? Czym jest Andamio i jak rozwijamy naszą platformę – o tym wszystkim opowie Piotr Betkier – Inżynier, Architekt Platformy Technicznej w Allegro oraz twórca piosenek o IT :)","guid":"https://podcast.allegro.tech/rola_architekta_w_allegro/","isoDate":"2021-06-16T00:00:00.000Z"},{"title":"S02E11 - Piotr Michoński - Infrastruktura Allegro","link":"https://podcast.allegro.tech/infrastruktura_Allegro/","pubDate":"Tue, 01 Jun 2021 00:00:00 GMT","content":"Jak jest zbudowane środowisko uruchomienia aplikacji Allegro? Jak działają serwerownie firmy i ile ich potrzeba, a które elementy Allegro działają w chmurze publicznej? Jak przebiegała transformacja w Allegro i co zmieniało się przez lata? Jak wzrost biznesu wpływa na wielkość infrastruktury i jak infrastruktura Allegro odczuła przyjście pandemii? O tym, a także o rozwoju liderów technologii w Allegro oraz o historii powstania dżingla do naszych podcastów, opowie Piotr Michoński - menadżer Zespołów tworzących infrastrukturę Allegro.","contentSnippet":"Jak jest zbudowane środowisko uruchomienia aplikacji Allegro? Jak działają serwerownie firmy i ile ich potrzeba, a które elementy Allegro działają w chmurze publicznej? Jak przebiegała transformacja w Allegro i co zmieniało się przez lata? Jak wzrost biznesu wpływa na wielkość infrastruktury i jak infrastruktura Allegro odczuła przyjście pandemii? O tym, a także o rozwoju liderów technologii w Allegro oraz o historii powstania dżingla do naszych podcastów, opowie Piotr Michoński - menadżer Zespołów tworzących infrastrukturę Allegro.","guid":"https://podcast.allegro.tech/infrastruktura_Allegro/","isoDate":"2021-06-01T00:00:00.000Z"},{"title":"S02E10 - Dariusz Eliasz - Praca architekta ekosystemu big data w Allegro","link":"https://podcast.allegro.tech/praca_architekta_ekosystemu_big_data_w_Allegro/","pubDate":"Thu, 20 May 2021 00:00:00 GMT","content":"Jak wygląda praca architekta ekosystemu big data w Allegro? Jakie zadania realizuje nasz zespół odpowiedzialny za narzędzia i infrastrukturę dla przetwarzania danych? Kiedy możemy mówić o dużych danych i ile petabajtów przetwarza Allegro? Skąd pochodzą dane Allegro i dlaczego jest ich tak dużo oraz z jakiego powodu dopiero teraz przenosimy się do chmury? O tym wszystkim opowie zdobywca statuetki Allegro Tech Hero - Dariusz Eliasz – Team Manager \u0026 Platform Architect w Allegro.","contentSnippet":"Jak wygląda praca architekta ekosystemu big data w Allegro? Jakie zadania realizuje nasz zespół odpowiedzialny za narzędzia i infrastrukturę dla przetwarzania danych? Kiedy możemy mówić o dużych danych i ile petabajtów przetwarza Allegro? Skąd pochodzą dane Allegro i dlaczego jest ich tak dużo oraz z jakiego powodu dopiero teraz przenosimy się do chmury? O tym wszystkim opowie zdobywca statuetki Allegro Tech Hero - Dariusz Eliasz – Team Manager \u0026 Platform Architect w Allegro.","guid":"https://podcast.allegro.tech/praca_architekta_ekosystemu_big_data_w_Allegro/","isoDate":"2021-05-20T00:00:00.000Z"},{"title":"S02E09 - Bartosz Gałek - Od inżyniera do lidera w Allegro","link":"https://podcast.allegro.tech/od_inzyniera_do_lidera_w_allegro/","pubDate":"Thu, 06 May 2021 00:00:00 GMT","content":"Czym jest Opbox i jakie wyzwania przed nim stoją? Jak w Allegro angażujemy się w rozwój kultury Open Source? Ile mamy projektów na GitHubie i jak świętujemy Hacktoberfest? W jaki sposób można rozwinąć się od inżyniera do lidera? Na te pytania w najnowszym Allegro Tech Podcast odpowie Bartek Gałek, Team Leader w Allegro.","contentSnippet":"Czym jest Opbox i jakie wyzwania przed nim stoją? Jak w Allegro angażujemy się w rozwój kultury Open Source? Ile mamy projektów na GitHubie i jak świętujemy Hacktoberfest? W jaki sposób można rozwinąć się od inżyniera do lidera? Na te pytania w najnowszym Allegro Tech Podcast odpowie Bartek Gałek, Team Leader w Allegro.","guid":"https://podcast.allegro.tech/od_inzyniera_do_lidera_w_allegro/","isoDate":"2021-05-06T00:00:00.000Z"}]},"__N_SSG":true},"page":"/","query":{},"buildId":"vPqbtsrqX3GNPCl2N4FFh","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>