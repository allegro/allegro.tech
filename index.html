<!DOCTYPE html><html lang="pl"><head><meta charSet="utf-8"/><link rel="prefetch" href="https://allegrotechio.disqus.com/count.js"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta name="description" content="Allegro Tech to miejsce, w którym nasi inżynierowie dzielą się wiedzą oraz case study z wybranych projektów w firmie - w formie artykułów, podcastów oraz eventów."/><title>Allegro Tech</title><meta property="og:site_name" content="allegro.tech"/><meta property="og:title" content="allegro.tech"/><meta property="og:url" content="https://allegro.tech"/><meta property="og:type" content="site"/><meta property="og:image" content="https://allegro.tech/images/allegro-tech.png"/><link rel="shortcut icon" href="favicon.ico"/><link rel="canonical" href="https://allegro.tech" itemProp="url"/><link rel="preload" href="images/splash.jpg" as="image"/><link rel="author" href="humans.txt"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-1M1FJ5PXWW"></script><script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){dataLayer.push(arguments);}
                    gtag('js', new Date());
                    gtag('config', 'G-1M1FJ5PXWW');
                </script><meta name="next-head-count" content="16"/><link rel="preload" href="/_next/static/css/c4277531f90028a4.css" as="style"/><link rel="stylesheet" href="/_next/static/css/c4277531f90028a4.css" data-n-g=""/><link rel="preload" href="/_next/static/css/79db8b1e27b0a093.css" as="style"/><link rel="stylesheet" href="/_next/static/css/79db8b1e27b0a093.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-69bfa6990bb9e155.js" defer=""></script><script src="/_next/static/chunks/framework-e70c6273bfe3f237.js" defer=""></script><script src="/_next/static/chunks/main-f635b472c367d1c7.js" defer=""></script><script src="/_next/static/chunks/pages/_app-179adf437ae674f2.js" defer=""></script><script src="/_next/static/chunks/206-3a56e5ded293e83e.js" defer=""></script><script src="/_next/static/chunks/pages/index-c37e907020e2015b.js" defer=""></script><script src="/_next/static/ubJ3sidEPv9PINacT5eG9/_buildManifest.js" defer=""></script><script src="/_next/static/ubJ3sidEPv9PINacT5eG9/_ssgManifest.js" defer=""></script><script src="/_next/static/ubJ3sidEPv9PINacT5eG9/_middlewareManifest.js" defer=""></script></head><body class="m-color-bg_desk"><div id="__next" data-reactroot=""><header class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card Header_navbar__Zc5aN m-color-bg_card"><nav class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-display-flex m-flex-justify-between m-flex-items-center"><a href="/"><img src="images/logo.svg" alt="Allegro Tech" width="205" height="45"/></a><div><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0 m-display-flex@lg m-display-none"><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://blog.allegro.tech">Blog</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://ml.allegro.tech">Machine Learning</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://podcast.allegro.tech">Podcast</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://github.com/Allegro">Open Source</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://www.meetup.com/allegrotech/events">Wydarzenia</a></li><li class="m-margin-left-16@lg"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display-block m-display-inline@lg m-padding-left-16 m-padding-right-16 m-padding-top-16 m-padding-bottom-16 m-padding-left-0@lg m-padding-top-0@lg m-padding-right-0@lg m-padding-bottom-0@lg m-link--signal m-line-height_21" href="https://praca.allegro.pl">Praca</a></li></ul><button class="m-display-none@lg m-height_40 m-line-height_40 m-border-style-top_none m-border-style-right_none m-border-style-bottom_none m-border-style-left_none m-border-radius-top-left_2 m-border-radius-top-right_2 m-border-radius-bottom-left_2 m-border-radius-bottom-right_2 m-cursor_pointer m-overflow_hidden m-appearance_none m-padding-left_4 m-padding-right_4 m-padding-top_4 m-padding-bottom_4 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button" style="background:transparent" aria-label="Otwórz menu"><img src="https://assets.allegrostatic.com/metrum/icon/menu-23e046bf68.svg" alt="" class="m-icon" width="32" height="32"/></button></div></nav></header><div class="Header_hero__PYE0B"><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-display-flex m-flex-column m-flex-justify-end Header_image__Cj6ZF"><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-color-bg_desk"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text  m-font-weight_100 m-font-size_32 m-font-size_43_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125">About us</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">Allegro is one of the most technologically advanced companies in our part of Europe. Allegro is also over 1700 IT specialists of various specializations, developing our website. The unique scale and complexity of the problems that we solve on a daily basis give us the opportunity to develop on a wide variety of projects. Allegro Tech is a place where our engineers share knowledge and case studies from selected projects in the company – in the form of articles, podcasts and events.</p></div></div></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24">Blog</h2><div class="m-display_flex m-flex-wrap_1 m-flex-grow_1 m-grid"><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://blog.allegro.tech/2024/01/embed-multicolor-icons-using-a-single-DOM-element.html" title="Embed multicolor icons using a single DOM element"><img width="388" src="images/post-headers/default.jpg" alt="Embed multicolor icons using a single DOM element" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://blog.allegro.tech/2024/01/embed-multicolor-icons-using-a-single-DOM-element.html" title="Embed multicolor icons using a single DOM element" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Embed multicolor icons using a single DOM element</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">7 dni temu</time><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0"><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/tech">#<!-- -->tech</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/web">#<!-- -->web</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/svg">#<!-- -->svg</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/css">#<!-- -->css</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/html">#<!-- -->html</a></li></ul><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1 m-padding-top-16">Hello, fellow Web developers!
Icons are an integral part of most modern UIs.
What is the best way to embed icons nowadays?
This area is full of pitfalls.
You…</p><div class="m-display-flex m-flex-justify-between m-padding-top-16 m-flex-items_center"><div class="m-display-flex m-flex-items_center"><div class="MuiAvatarGroup-root m-padding-right_16 Post_avatars__FHMgb"><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar" style="z-index:2"><img alt="Paweł Lesiecki" src="https://blog.allegro.tech/img/authors/pawel.lesiecki.jpg" class="MuiAvatar-img" width="32" height="32"/></div><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar" style="z-index:1"><img alt="Maciej Suszko" src="https://blog.allegro.tech/img/authors/maciej.suszko.jpg" class="MuiAvatar-img" width="32" height="32"/></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/authors/pawel.lesiecki">Paweł Lesiecki…</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/2024/01/embed-multicolor-icons-using-a-single-DOM-element.html#disqus_thread">0 Comments</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech/2024/01/embed-multicolor-icons-using-a-single-DOM-element.html">przejdź do wpisu</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://blog.allegro.tech/2023/12/lmdb-postmortem.html" title="Clever, surprised and gray-haired"><img width="388" src="images/post-headers/default.jpg" alt="Clever, surprised and gray-haired" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://blog.allegro.tech/2023/12/lmdb-postmortem.html" title="Clever, surprised and gray-haired" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Clever, surprised and gray-haired</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">około miesiąc temu</time><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0"><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/tech">#<!-- -->tech</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/postmortem">#<!-- -->postmortem</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/nginx">#<!-- -->nginx</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/libmodsecurity">#<!-- -->libmodsecurity</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/LMDB">#<!-- -->LMDB</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/performance bottleneck">#<!-- -->performance bottleneck</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/open source">#<!-- -->open source</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/debugging">#<!-- -->debugging</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/profiling">#<!-- -->profiling</a></li></ul><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1 m-padding-top-16">This article is a form of a public postmortem in which we would like to share our bumpy way of revealing the cause of a…</p><div class="m-display-flex m-flex-justify-between m-padding-top-16 m-flex-items_center"><div class="m-display-flex m-flex-items_center"><div class="MuiAvatarGroup-root m-padding-right_16 Post_avatars__FHMgb"><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar" style="z-index:1"><img alt="Tomasz Ziółkowski" src="https://blog.allegro.tech/img/authors/tomasz.ziolkowski.jpg" class="MuiAvatar-img" width="32" height="32"/></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/authors/tomasz.ziolkowski">Tomasz Ziółkowski</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/2023/12/lmdb-postmortem.html#disqus_thread">0 Comments</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech/2023/12/lmdb-postmortem.html">przejdź do wpisu</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://blog.allegro.tech/2023/11/how-does-btree-make-your-queries-fast.html" title="How does B-tree make your queries fast?"><img width="388" src="images/post-headers/default.jpg" alt="How does B-tree make your queries fast?" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://blog.allegro.tech/2023/11/how-does-btree-make-your-queries-fast.html" title="How does B-tree make your queries fast?" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">How does B-tree make your queries fast?</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">około 2 miesiące temu</time><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0"><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/tech">#<!-- -->tech</a></li></ul><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1 m-padding-top-16">B-tree is a structure that helps to search through great amounts of data.
It was invented over 40 years ago, yet it is still employed by…</p><div class="m-display-flex m-flex-justify-between m-padding-top-16 m-flex-items_center"><div class="m-display-flex m-flex-items_center"><div class="MuiAvatarGroup-root m-padding-right_16 Post_avatars__FHMgb"><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar" style="z-index:1"><img alt="Mateusz Kuźmik" src="https://blog.allegro.tech/img/authors/mateusz.kuzmik.jpg" class="MuiAvatar-img" width="32" height="32"/></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/authors/mateusz.kuzmik">Mateusz Kuźmik</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/2023/11/how-does-btree-make-your-queries-fast.html#disqus_thread">0 Comments</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech/2023/11/how-does-btree-make-your-queries-fast.html">przejdź do wpisu</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://blog.allegro.tech/2023/10/battle-against-knowledge-loss.html" title="Beyond the Code - An Engineer’s Battle Against Knowledge Loss"><img width="388" src="images/post-headers/eventstorming.png" alt="Beyond the Code - An Engineer’s Battle Against Knowledge Loss" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://blog.allegro.tech/2023/10/battle-against-knowledge-loss.html" title="Beyond the Code - An Engineer’s Battle Against Knowledge Loss" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Beyond the Code - An Engineer’s Battle Against Knowledge Loss</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">3 miesiące temu</time><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0"><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/eventstorming">#<!-- -->eventstorming</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/knowledge-preservation">#<!-- -->knowledge-preservation</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/tech">#<!-- -->tech</a></li><li class="m-margin-right-8 m-display-inline-block"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/hashtag/communication">#<!-- -->communication</a></li></ul><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1 m-padding-top-16">The idea for this article arose during a meeting where we learned that our supervisor would be leaving the company to pursue new opportunities. In…</p><div class="m-display-flex m-flex-justify-between m-padding-top-16 m-flex-items_center"><div class="m-display-flex m-flex-items_center"><div class="MuiAvatarGroup-root m-padding-right_16 Post_avatars__FHMgb"><div class="MuiAvatar-root MuiAvatar-circle MuiAvatarGroup-avatar" style="z-index:1"><img alt="Krzysztof Przychodzki" src="https://blog.allegro.tech/img/authors/krzysztof.przychodzki.jpg" class="MuiAvatar-img" width="32" height="32"/></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/authors/krzysztof.przychodzki">Krzysztof Przychodzki</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://blog.allegro.tech/2023/10/battle-against-knowledge-loss.html#disqus_thread">0 Comments</a></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech/2023/10/battle-against-knowledge-loss.html">przejdź do wpisu</a></div></article></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display_block m-margin-bottom_8 m-width_100 m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://blog.allegro.tech">Zobacz więcej wpisów</a></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24">Podcasty</h2><div class="m-display_flex m-flex-wrap_1 m-flex-grow_1 m-grid"><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://podcast.allegro.tech/mbox-server-driven-ui-dla-aplikacji-mobilnych/" title="MBox: server-driven UI dla aplikacji mobilnych"><img src="images/podcast.png" alt="MBox: server-driven UI dla aplikacji mobilnych" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://podcast.allegro.tech/mbox-server-driven-ui-dla-aplikacji-mobilnych/" title="MBox: server-driven UI dla aplikacji mobilnych" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">MBox: server-driven UI dla aplikacji mobilnych</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">2 miesiące temu</time><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1">Czym jest i jak powstał MBox: wewnętrzna platforma server-driven UI dla aplikacji mobilnych w Allegro? Skąd wziął się pomysł na to rozwiązanie i na jakie bolączki odpowiada? Dlaczego zdecydowaliśmy się na budowanie tego typu rozwiązania in-house i z jakimi wyzwaniami mierzyliśmy się w procesie tworzenia? Co wyróżnia zespoły pracujące nad tym narzędziem i jak pracuje im się bez Product Ownera? Posłuchajcie siódmego odcinka Allegro Tech Podcast z udziałem Pauliny Sadowskiej i Tomasza Gębarowskiego - Managerów w obszarze Technical Platform Services w Allegro.</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech/mbox-server-driven-ui-dla-aplikacji-mobilnych/">Posłuchaj odcinka</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://podcast.allegro.tech/o-chatbotach-i-ich-wplywie-na-allegro/" title="O chatbotach i ich wpływie na Allegro"><img src="images/podcast.png" alt="O chatbotach i ich wpływie na Allegro" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://podcast.allegro.tech/o-chatbotach-i-ich-wplywie-na-allegro/" title="O chatbotach i ich wpływie na Allegro" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">O chatbotach i ich wpływie na Allegro</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">3 miesiące temu</time><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1">Jakie procesy automatyzujemy w Allegro i co warto o nich wiedzieć w kontekście obszaru Customer Experience? W czym pomagają nam chatboty, jak je rozwijamy i dbamy o ich jakość? Kim są Allina oraz Albert i co mają wspólnego z automatyzacją? Za jakie rozwiązania otrzymaliśmy nagrodę hiperautomatyzacji? O tym wszystkim posłuchacie w odcinku z udziałem Rafała Gajewskiego - Managera w obszarze IT Services w Allegro.</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech/o-chatbotach-i-ich-wplywie-na-allegro/">Posłuchaj odcinka</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://podcast.allegro.tech/o-roli-analitykow-biznesowych-w-allegro/" title="O roli analityków biznesowych w Allegro"><img src="images/podcast.png" alt="O roli analityków biznesowych w Allegro" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://podcast.allegro.tech/o-roli-analitykow-biznesowych-w-allegro/" title="O roli analityków biznesowych w Allegro" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">O roli analityków biznesowych w Allegro</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">5 miesięcy temu</time><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1">Czym zajmują się analitycy danych w Allegro i za jakie projekty odpowiadają? Z jakich rodzajów danych i narzędzi korzystają w codziennej pracy? Jakie (przykładowe) obszary tematyczne pokrywamy danymi, które analizujemy w Allegro? Jakich umiejętności szukamy u analityków biznesowych w Allegro i jak można do nas dołączyć? O roli analityków biznesowych i pracy w skali Allegro opowiadają Jakub Król i Mateusz Falkowski - Senior Data Analysts w Allegro.</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech/o-roli-analitykow-biznesowych-w-allegro/">Posłuchaj odcinka</a></div></article></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--3@xl m-display-flex m-flex-direction_column"><article class="m-margin-bottom_16 m-display-flex m-flex-column m-flex-grow_1"><a href="https://podcast.allegro.tech/o-spolecznosci-allegro-tech-i-rozwoju-inzynierow-w-allegro/" title="O społeczności Allegro Tech i rozwoju inżynierów w Allegro"><img src="images/podcast.png" alt="O społeczności Allegro Tech i rozwoju inżynierów w Allegro" class="m-display-block m-width-fluid"/></a><div class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-column m-flex-grow_1 m-padding-bottom-0 m-color-bg_card"><a href="https://podcast.allegro.tech/o-spolecznosci-allegro-tech-i-rozwoju-inzynierow-w-allegro/" title="O społeczności Allegro Tech i rozwoju inżynierów w Allegro" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">O społeczności Allegro Tech i rozwoju inżynierów w Allegro</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-bottom-16">6 miesięcy temu</time><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-flex-grow-1">Na czym polega rola Principal Software Engineera w Allegro oraz co ma wspólnego z rozwijaniem siebie i dzieleniem się wiedzą? Co warto wiedzieć o turystyce, która pojawia się niemal w każdym odcinku naszych podcastów? Na czym polega, kto, kiedy i jak może z niej skorzystać? Jak pracujemy z talentami Gallupa (także w zespołach technicznych)?  Co dają nam wewnętrzne DevDays, hackhathony, gildie, meetupy, konferencje i jak jeszcze wymieniamy się doświadczeniami? Czym jest Allegro Tech Meeting i jaka idea mu przyświeca? O społeczności Allegro Tech i możliwościach rozwoju w Allegro z perspektywy inżynierów rozmawialiśmy z Marcinem Turkiem i Michałem Kosmulskim.</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech/o-spolecznosci-allegro-tech-i-rozwoju-inzynierow-w-allegro/">Posłuchaj odcinka</a></div></article></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display_block m-margin-bottom_8 m-width_100 m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://podcast.allegro.tech">Zobacz więcej podcastów</a></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24">Wydarzenia</h2><div class="m-display_flex m-flex-wrap_1 m-flex-grow_1 m-grid"><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--6@xl m-display-flex m-flex-direction_column"><div class="m-margin-bottom_16 m-display-flex m-flex-direction_column m-flex-direction_row_sm m-padding-bottom_0"><a href="https://www.meetup.com/allegrotech/events/298027809/" title="UX Research Confetti - IV edycja" class="m-display_none m-display_block_lg" style="background-color:#fd4a02"><img width="218" src="images/event.png" alt="UX Research Confetti - IV edycja"/></a><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-direction_column m-padding-bottom_0 m-flex_1 m-flex-justify_between m-color-bg_card"><a href="https://www.meetup.com/allegrotech/events/298027809/" title="UX Research Confetti - IV edycja" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">UX Research Confetti - IV edycja</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">za 4 miesiące<!-- -->, Allegro Warsaw Office</time><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-top-8">**🎉 Przedstawiamy 4. edycję UX Research Confetti - bezpłatną, polską konferencję poświęconą badaniom UX, organizowaną przez zespół badaczy z Allegro.** ✨ Konferencja odbędzie się w…</time><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/298027809/">Szczegóły</a></article></div></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--6@xl m-display-flex m-flex-direction_column"><div class="m-margin-bottom_16 m-display-flex m-flex-direction_column m-flex-direction_row_sm m-padding-bottom_0"><a href="https://www.meetup.com/allegrotech/events/297614064/" title="Allegro Tech Talks #40 - Testy: dynamiczne dashboardy &amp; optymalizacja pracy" class="m-display_none m-display_block_lg" style="background-color:#fd4a02"><img width="218" src="images/event.png" alt="Allegro Tech Talks #40 - Testy: dynamiczne dashboardy &amp; optymalizacja pracy"/></a><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-direction_column m-padding-bottom_0 m-flex_1 m-flex-justify_between m-color-bg_card"><a href="https://www.meetup.com/allegrotech/events/297614064/" title="Allegro Tech Talks #40 - Testy: dynamiczne dashboardy &amp; optymalizacja pracy" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Allegro Tech Talks #40 - Testy: dynamiczne dashboardy &amp; optymalizacja pracy</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">około miesiąc temu<!-- -->, Allegro Kraków Office</time><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-top-8">**➡ Rejestracja:** [https://app.evenea.pl/event/allegro-tech-talk-40/](https://app.evenea.pl/event/allegro-tech-talk-40/) Jeszcze przed świętami zapraszamy Was na #40 wydarzenie z serii Allegro Tech Talk, podczas których dzielimy się wiedzą, wzajemnie inspirujemy oraz integrujemy…</time><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/297614064/">Szczegóły</a></article></div></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--6@xl m-display-flex m-flex-direction_column"><div class="m-margin-bottom_16 m-display-flex m-flex-direction_column m-flex-direction_row_sm m-padding-bottom_0"><a href="https://www.meetup.com/allegrotech/events/297480100/" title="Allegro Tech Talks #39 - Big Data: o podejściu do pracy z danymi" class="m-display_none m-display_block_lg" style="background-color:#fd4a02"><img width="218" src="images/event.png" alt="Allegro Tech Talks #39 - Big Data: o podejściu do pracy z danymi"/></a><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-direction_column m-padding-bottom_0 m-flex_1 m-flex-justify_between m-color-bg_card"><a href="https://www.meetup.com/allegrotech/events/297480100/" title="Allegro Tech Talks #39 - Big Data: o podejściu do pracy z danymi" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Allegro Tech Talks #39 - Big Data: o podejściu do pracy z danymi</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">około 2 miesiące temu<!-- -->, Allegro Warsaw Office</time><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-top-8">**Rejestracja: [https://app.evenea.pl/event/allegro-tech-talk-39/](https://app.evenea.pl/event/allegro-tech-talk-39/)** Bądźcie z nami podczas #39 wydarzenia z serii **Allegro Tech Talk**, podczas których dzielimy się wiedzą, wzajemnie inspirujemy oraz integrujemy podczas rozmów przy…</time><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/297480100/">Szczegóły</a></article></div></div><div class="m-grid__col m-grid__col--12 m-grid__col--6@sm m-grid__col--6@xl m-display-flex m-flex-direction_column"><div class="m-margin-bottom_16 m-display-flex m-flex-direction_column m-flex-direction_row_sm m-padding-bottom_0"><a href="https://www.meetup.com/allegrotech/events/293929321/" title="Allegro Tech Talks #38 - Mobile: o iOS bez spinki" class="m-display_none m-display_block_lg" style="background-color:#fd4a02"><img width="218" src="images/event.png" alt="Allegro Tech Talks #38 - Mobile: o iOS bez spinki"/></a><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-display-flex m-flex-direction_column m-padding-bottom_0 m-flex_1 m-flex-justify_between m-color-bg_card"><a href="https://www.meetup.com/allegrotech/events/293929321/" title="Allegro Tech Talks #38 - Mobile: o iOS bez spinki" class="m-text-decoration_none"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm" style="text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:2;min-height:2em;overflow:hidden">Allegro Tech Talks #38 - Mobile: o iOS bez spinki</h2></a><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text">7 miesięcy temu<!-- -->, Allegro Warsaw Office</time><time class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-padding-top-8">**➡ Rejestracja:** [https://app.evenea.pl/event/allegro-tech-talk-38/](https://app.evenea.pl/event/allegro-tech-talk-38/) Ostatnie przed przerwą wakacyjną, stacjonarne spotkanie z cyklu Allegro Tech Talks, na których dzielimy się wiedzą, wzajemnie inspirujemy oraz integrujemy podczas rozmów…</time><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-margin-top-16 m-display_block m-border-width_1 m-border-color_gray m-border-style-top_solid m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/293929321/">Szczegóły</a></article></div></div></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display_block m-margin-bottom_8 m-width_100 m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.meetup.com/allegrotech/events/">Zobacz więcej wydarzeń</a></div><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_300 m-font-size_27 m-font-size_36_sm m-margin-bottom_16 m-margin-bottom_24_sm m-line-height_125 m-padding-left-24 m-padding-right-24">Oferty pracy</h2><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto"><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm m-margin-bottom_0_sm m-flex-grow_1">Senior Front-End Software Engineer - Merchant Experience</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-font-size_21 m-font-size_25_sm m-font-weight_300 m-line-height_normal m-margin-top_16 m-text-align_left m-padding-right_16">Warszawa, Poznań</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.smartrecruiters.com/Allegro/743999959852738-senior-front-end-software-engineer-merchant-experience?trid=de9dfdf3-7f9e-4ebf-8a64-49f6c69ad640">Sprawdź</a></article><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm m-margin-bottom_0_sm m-flex-grow_1">Software Engineer Java - Allegro Retail</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-font-size_21 m-font-size_25_sm m-font-weight_300 m-line-height_normal m-margin-top_16 m-text-align_left m-padding-right_16">Prague, Hybrid</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.smartrecruiters.com/Allegro/743999958525968-software-engineer-java-allegro-retail?trid=de9dfdf3-7f9e-4ebf-8a64-49f6c69ad640">Sprawdź</a></article><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm m-margin-bottom_0_sm m-flex-grow_1">Software Engineer Java - Allegro Retail</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-font-size_21 m-font-size_25_sm m-font-weight_300 m-line-height_normal m-margin-top_16 m-text-align_left m-padding-right_16">Prague, Remote</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.smartrecruiters.com/Allegro/743999956383556-software-engineer-java-allegro-retail?trid=de9dfdf3-7f9e-4ebf-8a64-49f6c69ad640">Sprawdź</a></article><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm m-margin-bottom_0_sm m-flex-grow_1">SAP Consultant</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-font-size_21 m-font-size_25_sm m-font-weight_300 m-line-height_normal m-margin-top_16 m-text-align_left m-padding-right_16">Prague</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.smartrecruiters.com/Allegro/743999956386883-sap-consultant?trid=de9dfdf3-7f9e-4ebf-8a64-49f6c69ad640">Sprawdź</a></article><article class="m-padding-top_16 m-padding-top_24_lg m-padding-right_16 m-padding-right_24_lg m-padding-bottom_16 m-padding-bottom_24_lg m-padding-left_16 m-padding-left_24_lg m-card m-margin-bottom_16 m-display-flex m-flex-justify_between m-flex-items-center m-flex-direction_column m-flex-direction_row_md m-color-bg_card"><h2 class="m-font-family_roboto m-margin-left_0 m-margin-right_0 m-margin-top_0 m-color_text m-font-weight_500 m-line-height_130 m-margin-bottom_8 m-margin-bottom_16_sm m-font-size_21 m-font-size_25_sm m-margin-bottom_0_sm m-flex-grow_1">Integration Engineer</h2><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-font-size_21 m-font-size_25_sm m-font-weight_300 m-line-height_normal m-margin-top_16 m-text-align_left m-padding-right_16">Warsaw, Poznań</p><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://www.smartrecruiters.com/Allegro/743999955998823-integration-engineer?trid=de9dfdf3-7f9e-4ebf-8a64-49f6c69ad640">Sprawdź</a></article></div><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-display_block m-margin-bottom_8 m-width_100 m-height_40 m-line-height_40 m-text-transform_uppercase m-letter-spacing_2 m-white-space_nowrap m-cursor_pointer m-overflow_hidden m-padding-left_16 m-padding-right_16 m-padding-top_0 m-padding-bottom_0 m-outline-style_dotted--focus m-outline-width_2 m-outline-color_teal m-outline-offset_n2 m-button m-box_border m-text-align_center m-display_inline-block m-color_secondary m-background-position_50p m-background-size_5000p m-transition-property_background-color m-transition-duration_fast m-button--secondary" href="https://allegro.pl/praca">Zobacz więcej ofert</a></div><footer class="m-color-bg_navy m-margin-top-32"><div class="m-width-max_1600 m-margin-left_auto m-margin-right_auto m-padding-top-24 m-padding-bottom-24 m-display-flex@sm m-flex-justify-between m-flex-items-center m-text-align_center"><p class="m-font-family_sans m-line-height_21 m-font-size_14 m-text-size-adjust_100p m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-color_text m-color_white m-padding-left-24@sm">Proudly built by Allegro Tech engineers</p><ul class="m-font-family_sans m-font-size_14 m-line-height_21 m-color_text m-text-size-adjust_100p m-list-style-type_none m-margin-top_0 m-margin-right_0 m-margin-bottom_0 m-margin-left_0 m-padding-top_0 m-padding-right_0 m-padding-bottom_0 m-padding-left_0 m-display-flex m-flex-justify-center"><li style="filter:brightness(0) invert(1);opacity:0.5" class="m-margin-right-8 m-margin-top-16 m-margin-top-0@sm m-color_white"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://github.com/allegro"><img src="https://assets.allegrostatic.com/metrum/icon/github-6a18df1729.svg" alt="Github" class="m-icon"/></a></li><li style="filter:brightness(0) invert(1);opacity:0.5" class="m-margin-right-8 m-margin-top-16 m-margin-top-0@sm m-color_white"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://www.facebook.com/allegro.tech/"><img src="https://assets.allegrostatic.com/metrum/icon/facebook-a2b92f9dcb.svg" alt="Facebook" class="m-icon"/></a></li><li style="filter:brightness(0) invert(1);opacity:0.5" class="m-margin-right-8 m-margin-top-16 m-margin-top-0@sm m-color_white"><a class="m-font-size_14 m-font-family_sans m-color_text m-text-decoration_none m-text-size-adjust_100p m-cursor_pointer m-link m-line-height_21" href="https://twitter.com/allegrotech"><img src="https://assets.allegrostatic.com/metrum/icon/twitter-25164a58aa.svg" alt="Twitter" class="m-icon"/></a></li></ul></div></footer><div style="visibility:hidden;height:0;overflow:hidden;position:relative"></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"Embed multicolor icons using a single DOM element","link":"https://blog.allegro.tech/2024/01/embed-multicolor-icons-using-a-single-DOM-element.html","pubDate":"Wed, 10 Jan 2024 00:00:00 +0100","authors":{"author":[{"name":["Paweł Lesiecki"],"photo":["https://blog.allegro.tech/img/authors/pawel.lesiecki.jpg"],"url":["https://blog.allegro.tech/authors/pawel.lesiecki"]},{"name":["Maciej Suszko"],"photo":["https://blog.allegro.tech/img/authors/maciej.suszko.jpg"],"url":["https://blog.allegro.tech/authors/maciej.suszko"]}]},"content":"\u003cp\u003eHello, fellow Web developers!\u003c/p\u003e\n\n\u003cp\u003eIcons are an integral part of most modern UIs.\nWhat is the best way to embed icons nowadays?\nThis area is full of pitfalls.\nYou better proceed with caution when trying to answer that question.\u003c/p\u003e\n\n\u003cp\u003eThough there are many possibilities, \u003ca href=\"https://twitter.com/_developit/status/1382838799420514317\"\u003esome of which are considered harmful\u003c/a\u003e.\nVarious inline SVG techniques have become more popular over time. Possibly due to the lack of suitable alternatives, although not using the cache is a huge trade-off.\nThankfully, \u003ca href=\"https://twitter.com/getifyX/status/1720810762409566459\"\u003ethere are some voices of reason\u003c/a\u003e in the community.\u003c/p\u003e\n\n\u003cp\u003eAt \u003ca href=\"https://allegro.tech/\"\u003eAllegro\u003c/a\u003e, we’ve been using SVG and CSS filters for quite some time.\nHowever, they have their limits and could be better suited for the challenges of the themeable design system.\u003c/p\u003e\n\n\u003cp\u003eLet’s pause for a moment and rethink the approach to icons.\nIt has to meet several requirements:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003ethemeable,\u003c/li\u003e\n  \u003cli\u003ecacheable,\u003c/li\u003e\n  \u003cli\u003eeasily embeddable.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch2 id=\"can-we-do-better-than-weve-been-doing-so-far\"\u003eCan we do better than we’ve been doing so far?\u003c/h2\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2024-01-10-embed-multicolor-icons-using-a-single-DOM-element/icon.webp\" alt=\"Multilayer icon\" title=\"Multilayer icon\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eAll the tools needed to perform the trick have been available in major browsers for at least few years.\nIs it possible everyone just failed to connect the dots?\nIt turns out that the platform is capable of dealing with icons more efficiently.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eLet us introduce the SVG+CSS technique. It lets you have a 3-color icon using just one DOM element and one external SVG.\u003c/strong\u003e\u003c/p\u003e\n\n\u003cp\u003eWe have found nothing similar, whether online or with ChatGPT, which makes us want to share this idea with you even more.\u003c/p\u003e\n\n\u003cp\u003eConsider the proposed technique if you care about performance.\u003c/p\u003e\n\n\u003ch3 id=\"key-benefits-are\"\u003eKey benefits are:\u003c/h3\u003e\n\n\u003col\u003e\n  \u003cli\u003eCaching.\u003c/li\u003e\n  \u003cli\u003eWorks cross-domain.\u003c/li\u003e\n  \u003cli\u003eCustomizable more than a single color.\u003c/li\u003e\n  \u003cli\u003eIcons load after critical resources and content, not bloating the markup.\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003eWe will control the colors of 3 different parts with a single DOM element and SVG resource.\u003c/p\u003e\n\n\u003cp\u003eSounds interesting? Then, let’s dive into how we can accomplish this.\u003c/p\u003e\n\n\u003ch2 id=\"implementation\"\u003eImplementation\u003c/h2\u003e\n\n\u003cp\u003eSVG and CSS are gifts that keep giving and can do wonders combined.\u003c/p\u003e\n\n\u003cp\u003eThe proposed technique is a combination of two platform capabilities.\u003c/p\u003e\n\u003col\u003e\n  \u003cli\u003e\u003ca href=\"https://css-tricks.com/svg-fragment-identifiers-work/\"\u003eSVG Fragments\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/mask-image\"\u003eCSS Masks\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003e\u003ca href=\"https://caniuse.com/svg-fragment\"\u003eSVG Fragments aren’t really a new technology\u003c/a\u003e.\nAbout five years ago, we considered using CSS masks, but we still supported IE back then.\nAt that time, we had not yet thought of combining it with fragments.\u003c/p\u003e\n\n\u003cp\u003eAs a case study let’s pick one of our icons —\n\u003cimg class=\"inline-image\" alt=\"a-icon\" src=\"https://a.allegroimg.com/original/34412f/ae71613e49d986c5c838698e2e86/illustration-allegro-in-circle-big-db0c91e439\" /\u003e.\u003c/p\u003e\n\n\u003cp\u003eWith the following source:\u003c/p\u003e\n\n\u003cdiv class=\"language-html highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"nt\"\u003e\u0026lt;svg\u003c/span\u003e \u003cspan class=\"na\"\u003eviewBox=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"0 0 32 32\"\u003c/span\u003e \u003cspan class=\"na\"\u003efill=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"none\"\u003c/span\u003e \u003cspan class=\"na\"\u003eheight=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"32\"\u003c/span\u003e \u003cspan class=\"na\"\u003ewidth=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"32\"\u003c/span\u003e \u003cspan class=\"na\"\u003exmlns=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"http://www.w3.org/2000/svg\"\u003c/span\u003e\u003cspan class=\"nt\"\u003e\u0026gt;\u003c/span\u003e\n  \u003cspan class=\"nt\"\u003e\u0026lt;path\u003c/span\u003e \u003cspan class=\"na\"\u003ed=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"...\"\u003c/span\u003e \u003cspan class=\"na\"\u003efill=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"#B0B8BC\"\u003c/span\u003e\u003cspan class=\"nt\"\u003e\u0026gt;\u0026lt;/path\u0026gt;\u003c/span\u003e\n  \u003cspan class=\"nt\"\u003e\u0026lt;path\u003c/span\u003e \u003cspan class=\"na\"\u003eclip-rule=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"evenodd\"\u003c/span\u003e \u003cspan class=\"na\"\u003ed=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"...\"\u003c/span\u003e \u003cspan class=\"na\"\u003efill-rule=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"evenodd\"\u003c/span\u003e \u003cspan class=\"na\"\u003efill=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"#FF7B33\"\u003c/span\u003e\u003cspan class=\"nt\"\u003e\u0026gt;\u0026lt;/path\u0026gt;\u003c/span\u003e\n  \u003cspan class=\"nt\"\u003e\u0026lt;path\u003c/span\u003e \u003cspan class=\"na\"\u003ed=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"...\"\u003c/span\u003e \u003cspan class=\"na\"\u003efill=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"#D9DFE4\"\u003c/span\u003e\u003cspan class=\"nt\"\u003e\u0026gt;\u0026lt;/path\u0026gt;\u003c/span\u003e\n\u003cspan class=\"nt\"\u003e\u0026lt;/svg\u0026gt;\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eThis particular icon consists of 3 parts, each with a different color.\nNow, we’re going to control these colors with the document’s CSS.\u003c/p\u003e\n\n\u003cp\u003eIt’s time to program in SVG and CSS for a moment.\u003c/p\u003e\n\n\u003ch3 id=\"step-1--svg-fragments\"\u003eStep #1 — SVG Fragments\u003c/h3\u003e\n\n\u003cp\u003eFirst, let’s craft our test subject and introduce the fragments.\nEach \u003ccode class=\"language-plaintext highlighter-rouge\"\u003epath\u003c/code\u003e gets a unique Fragment Identifier by setting an \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eid\u003c/code\u003e attribute.\nNext, we add a little CSS to enable rendering fragments in isolation. Think of it as an image sprite.\u003c/p\u003e\n\n\u003cp\u003eFor the sake of CSS simplicity, we also group all the paths under an extra \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eg\u003c/code\u003e element with a unique \u003ccode class=\"language-plaintext highlighter-rouge\"\u003eid\u003c/code\u003e.\u003c/p\u003e\n\n\u003cp\u003eAs a result, the SVG is supposed to look like this:\u003c/p\u003e\n\n\u003cdiv class=\"language-html highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"nt\"\u003e\u0026lt;svg\u003c/span\u003e \u003cspan class=\"na\"\u003eviewBox=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"0 0 32 32\"\u003c/span\u003e \u003cspan class=\"na\"\u003efill=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"none\"\u003c/span\u003e \u003cspan class=\"na\"\u003eheight=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"32\"\u003c/span\u003e \u003cspan class=\"na\"\u003ewidth=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"32\"\u003c/span\u003e \u003cspan class=\"na\"\u003exmlns=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"http://www.w3.org/2000/svg\"\u003c/span\u003e\u003cspan class=\"nt\"\u003e\u0026gt;\u003c/span\u003e\n  \u003cspan class=\"nt\"\u003e\u0026lt;style\u0026gt;\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003epath\u003c/span\u003e\u003cspan class=\"nd\"\u003e:not\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"nd\"\u003e:target\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n      \u003cspan class=\"nl\"\u003edisplay\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003enone\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003eg\u003c/span\u003e\u003cspan class=\"nd\"\u003e:target\u003c/span\u003e \u003cspan class=\"nt\"\u003epath\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n      \u003cspan class=\"nl\"\u003edisplay\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003einline\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n    \u003cspan class=\"p\"\u003e}\u003c/span\u003e\n  \u003cspan class=\"nt\"\u003e\u0026lt;/style\u0026gt;\u003c/span\u003e\n  \u003cspan class=\"nt\"\u003e\u0026lt;g\u003c/span\u003e \u003cspan class=\"na\"\u003eid=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"icon\"\u003c/span\u003e\u003cspan class=\"nt\"\u003e\u0026gt;\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003e\u0026lt;path\u003c/span\u003e \u003cspan class=\"na\"\u003eid=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"border\"\u003c/span\u003e \u003cspan class=\"na\"\u003ed=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"...\"\u003c/span\u003e \u003cspan class=\"na\"\u003efill=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"#B0B8BC\"\u003c/span\u003e\u003cspan class=\"nt\"\u003e\u0026gt;\u0026lt;/path\u0026gt;\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003e\u0026lt;path\u003c/span\u003e \u003cspan class=\"na\"\u003eid=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"a\"\u003c/span\u003e \u003cspan class=\"na\"\u003eclip-rule=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"evenodd\"\u003c/span\u003e \u003cspan class=\"na\"\u003ed=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"...\"\u003c/span\u003e \u003cspan class=\"na\"\u003efill-rule=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"evenodd\"\u003c/span\u003e \u003cspan class=\"na\"\u003efill=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"#FF7B33\"\u003c/span\u003e\u003cspan class=\"nt\"\u003e\u0026gt;\u0026lt;/path\u0026gt;\u003c/span\u003e\n    \u003cspan class=\"nt\"\u003e\u0026lt;path\u003c/span\u003e \u003cspan class=\"na\"\u003eid=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"shadow\"\u003c/span\u003e \u003cspan class=\"na\"\u003ed=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"...\"\u003c/span\u003e \u003cspan class=\"na\"\u003efill=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"#D9DFE4\"\u003c/span\u003e\u003cspan class=\"nt\"\u003e\u0026gt;\u0026lt;/path\u0026gt;\u003c/span\u003e\n  \u003cspan class=\"nt\"\u003e\u0026lt;/g\u0026gt;\u003c/span\u003e\n\u003cspan class=\"nt\"\u003e\u0026lt;/svg\u0026gt;\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eIt produces 4 fragments, one for each of the three paths and the last for the whole icon. Each of them can now be rendered as a separate image:\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003e\u003ca href=\"https://a.allegroimg.com/original/34901c/db3b33c5488eb13bc5244e215953/illustration-allegro-in-circle-big-ab3336c0b3#a\"\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003e#a\u003c/code\u003e\u003c/a\u003e — \u003cimg class=\"inline-image\" alt=\"#a\" src=\"https://a.allegroimg.com/original/34901c/db3b33c5488eb13bc5244e215953/illustration-allegro-in-circle-big-ab3336c0b3#a\" /\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"https://a.allegroimg.com/original/34901c/db3b33c5488eb13bc5244e215953/illustration-allegro-in-circle-big-ab3336c0b3#border\"\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003e#border\u003c/code\u003e\u003c/a\u003e — \u003cimg class=\"inline-image\" alt=\"#border\" src=\"https://a.allegroimg.com/original/34901c/db3b33c5488eb13bc5244e215953/illustration-allegro-in-circle-big-ab3336c0b3#border\" /\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"https://a.allegroimg.com/original/34901c/db3b33c5488eb13bc5244e215953/illustration-allegro-in-circle-big-ab3336c0b3#shadow\"\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003e#shadow\u003c/code\u003e\u003c/a\u003e — \u003cimg class=\"inline-image\" alt=\"#shadow\" src=\"https://a.allegroimg.com/original/34901c/db3b33c5488eb13bc5244e215953/illustration-allegro-in-circle-big-ab3336c0b3#shadow\" /\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ca href=\"https://a.allegroimg.com/original/34901c/db3b33c5488eb13bc5244e215953/illustration-allegro-in-circle-big-ab3336c0b3#icon\"\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003e#icon\u003c/code\u003e\u003c/a\u003e — \u003cimg class=\"inline-image\" alt=\"#icon\" src=\"https://a.allegroimg.com/original/34901c/db3b33c5488eb13bc5244e215953/illustration-allegro-in-circle-big-ab3336c0b3#icon\" /\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003eNow, the regular fragment-less URL will display a blank image.\nThus, for the full icon, we’re going to add a \u003ca href=\"https://a.allegroimg.com/original/34c91a/651290b94002acbe836ae520e8ff/illustration-allegro-in-circle-big-ab3336c0b3#icon\"\u003e\u003ccode class=\"language-plaintext highlighter-rouge\"\u003e#icon\u003c/code\u003e\u003c/a\u003e fragment to the URL.\u003c/p\u003e\n\n\u003cp\u003eWe won’t use the \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e#a\u003c/code\u003e fragment, but let’s keep its identifier.\u003c/p\u003e\n\n\u003ch3 id=\"step-2--css-masks\"\u003eStep #2 — CSS Masks\u003c/h3\u003e\n\n\u003cp\u003eWith SVG Fragment Identifiers up and ready, we can use CSS Masks.\u003c/p\u003e\n\n\u003cp\u003eThe base class \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e.icon\u003c/code\u003e stacks three layers on top of each other, ready for a mask.\u003c/p\u003e\n\n\u003cdiv class=\"language-css highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"nc\"\u003e.icon\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n  \u003cspan class=\"nl\"\u003eposition\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003erelative\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n  \u003cspan class=\"nl\"\u003ewidth\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"m\"\u003e32px\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n  \u003cspan class=\"nl\"\u003eheight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"m\"\u003e32px\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n  \u003cspan class=\"py\"\u003emask-repeat\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003eno-repeat\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n  \u003cspan class=\"nl\"\u003ebackground-color\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"n\"\u003ecurrentColor\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003cspan class=\"nc\"\u003e.icon\u003c/span\u003e\u003cspan class=\"nd\"\u003e::before\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e\n\u003cspan class=\"nc\"\u003e.icon\u003c/span\u003e\u003cspan class=\"nd\"\u003e::after\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n  \u003cspan class=\"nl\"\u003econtent\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"s2\"\u003e''\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n  \u003cspan class=\"nl\"\u003eposition\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003eabsolute\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n  \u003cspan class=\"nl\"\u003ewidth\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003einherit\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n  \u003cspan class=\"nl\"\u003eheight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003einherit\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n  \u003cspan class=\"nl\"\u003ebackground-color\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nb\"\u003einherit\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eThe last CSS class is for our specific icon.\u003c/p\u003e\n\n\u003cdiv class=\"language-css highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"nc\"\u003e.icon--a\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n  \u003cspan class=\"py\"\u003emask-image\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"sx\"\u003eurl('./a.svg#icon')\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"c\"\u003e/* full icon’s shape */\u003c/span\u003e\n  \u003cspan class=\"nl\"\u003ecolor\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"m\"\u003e#FF7B33\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003cspan class=\"nc\"\u003e.icon--a\u003c/span\u003e\u003cspan class=\"nd\"\u003e::before\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n  \u003cspan class=\"py\"\u003emask-image\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"sx\"\u003eurl('./a.svg#shadow')\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"c\"\u003e/* shadow’s shape */\u003c/span\u003e\n  \u003cspan class=\"nl\"\u003ecolor\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"m\"\u003e#D9DFE4\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003cspan class=\"nc\"\u003e.icon--a\u003c/span\u003e\u003cspan class=\"nd\"\u003e::after\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n  \u003cspan class=\"py\"\u003emask-image\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"sx\"\u003eurl('./a.svg#border')\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e \u003cspan class=\"c\"\u003e/* border’s shape */\u003c/span\u003e\n  \u003cspan class=\"nl\"\u003ecolor\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"m\"\u003e#B0B8BC\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003cspan class=\"p\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eThe critical part is that we picked the whole icon, not any fragment, as the parent’s mask, so we have the entire icon visible.\nThat’s because the parent layer masks its children.\u003c/p\u003e\n\n\u003cp\u003eWe selected the orange color of the \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ea\u003c/code\u003e for the parent layer.\nThen, we put the two remaining layers on top of it.\nThe second and third layers are for shadow and border parts, respectively.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eWe can describe this as the whole icon in single color covered by one or more shapes in different colors.\u003c/strong\u003e\u003c/p\u003e\n\n\u003cp\u003eWhen an icon has intersecting parts, there’s one thing to keep in mind.\nBackgrounds render on top of each other in a particular order:\u003c/p\u003e\n\u003col\u003e\n  \u003cli\u003ethe parent’s background,\u003c/li\u003e\n  \u003cli\u003ethe \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e::before\u003c/code\u003e pseudo-element’s background,\u003c/li\u003e\n  \u003cli\u003ethe \u003ccode class=\"language-plaintext highlighter-rouge\"\u003e::after\u003c/code\u003e’s background at the end.\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003eAs a result, we can embed the icon by a single element.\u003c/p\u003e\n\n\u003cdiv class=\"language-html highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e\u003cspan class=\"nt\"\u003e\u0026lt;div\u003c/span\u003e \u003cspan class=\"na\"\u003eclass=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"icon icon--a\"\u003c/span\u003e \u003cspan class=\"na\"\u003earia-hidden=\u003c/span\u003e\u003cspan class=\"s\"\u003e\"true\"\u003c/span\u003e\u003cspan class=\"nt\"\u003e\u0026gt;\u0026lt;/div\u0026gt;\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eLet’s also consider accessibility.\nUsually, icons are \u003ca href=\"https://developer.mozilla.org/en-US/docs/Web/Accessibility/ARIA/Attributes/aria-hidden#description\"\u003epurely decorative content\u003c/a\u003e.\nThat’s why we remove them from the accessibility tree by \u003ccode class=\"language-plaintext highlighter-rouge\"\u003earia-hidden=\"true\"\u003c/code\u003e.\u003c/p\u003e\n\n\u003cp\u003eThe result is supposed to look like the original icon from the start —\n\u003cimg class=\"inline-image\" alt=\"the original icon from the beginning\" src=\"https://a.allegroimg.com/original/34412f/ae71613e49d986c5c838698e2e86/illustration-allegro-in-circle-big-db0c91e439\" /\u003e.\u003c/p\u003e\n\n\u003cp\u003eNow, the single element gives us control over up to three parts of our icon.\nMoreover, we can change colors independently and dynamically.\u003c/p\u003e\n\n\u003ch2 id=\"the-demo\"\u003eThe demo\u003c/h2\u003e\n\u003cp\u003eFeel free to check the \u003ca href=\"https://mpsuszko.github.io/three-colors-one-element-icon/\"\u003edemo\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003ePretty neat.\u003c/p\u003e\n\n\u003cp\u003eWe found this technique practical, and we’re keen to use it in the future.\u003c/p\u003e\n\n\u003ch2 id=\"more-colors\"\u003eMore colors\u003c/h2\u003e\n\u003cp\u003eIf you need more than 3 colors, switch from pseudo-elements to regular elements. Then, you can stack as many layers as you want.\nAnother option is to combine \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ebackground-image\u003c/code\u003e with gradients instead of \u003ccode class=\"language-plaintext highlighter-rouge\"\u003ebackground-color\u003c/code\u003e.\u003c/p\u003e\n\n\u003cp\u003eEnjoy \u0026amp; use the platform ❤️\u003c/p\u003e\n","contentSnippet":"Hello, fellow Web developers!\nIcons are an integral part of most modern UIs.\nWhat is the best way to embed icons nowadays?\nThis area is full of pitfalls.\nYou better proceed with caution when trying to answer that question.\nThough there are many possibilities, some of which are considered harmful.\nVarious inline SVG techniques have become more popular over time. Possibly due to the lack of suitable alternatives, although not using the cache is a huge trade-off.\nThankfully, there are some voices of reason in the community.\nAt Allegro, we’ve been using SVG and CSS filters for quite some time.\nHowever, they have their limits and could be better suited for the challenges of the themeable design system.\nLet’s pause for a moment and rethink the approach to icons.\nIt has to meet several requirements:\nthemeable,\ncacheable,\neasily embeddable.\nCan we do better than we’ve been doing so far?\n\nAll the tools needed to perform the trick have been available in major browsers for at least few years.\nIs it possible everyone just failed to connect the dots?\nIt turns out that the platform is capable of dealing with icons more efficiently.\nLet us introduce the SVG+CSS technique. It lets you have a 3-color icon using just one DOM element and one external SVG.\nWe have found nothing similar, whether online or with ChatGPT, which makes us want to share this idea with you even more.\nConsider the proposed technique if you care about performance.\nKey benefits are:\nCaching.\nWorks cross-domain.\nCustomizable more than a single color.\nIcons load after critical resources and content, not bloating the markup.\nWe will control the colors of 3 different parts with a single DOM element and SVG resource.\nSounds interesting? Then, let’s dive into how we can accomplish this.\nImplementation\nSVG and CSS are gifts that keep giving and can do wonders combined.\nThe proposed technique is a combination of two platform capabilities.\nSVG Fragments\nCSS Masks\nSVG Fragments aren’t really a new technology.\nAbout five years ago, we considered using CSS masks, but we still supported IE back then.\nAt that time, we had not yet thought of combining it with fragments.\nAs a case study let’s pick one of our icons —\n.\nWith the following source:\n\n\u003csvg viewBox=\"0 0 32 32\" fill=\"none\" height=\"32\" width=\"32\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\n  \u003cpath d=\"...\" fill=\"#B0B8BC\"\u003e\u003c/path\u003e\n  \u003cpath clip-rule=\"evenodd\" d=\"...\" fill-rule=\"evenodd\" fill=\"#FF7B33\"\u003e\u003c/path\u003e\n  \u003cpath d=\"...\" fill=\"#D9DFE4\"\u003e\u003c/path\u003e\n\u003c/svg\u003e\n\n\nThis particular icon consists of 3 parts, each with a different color.\nNow, we’re going to control these colors with the document’s CSS.\nIt’s time to program in SVG and CSS for a moment.\nStep #1 — SVG Fragments\nFirst, let’s craft our test subject and introduce the fragments.\nEach path gets a unique Fragment Identifier by setting an id attribute.\nNext, we add a little CSS to enable rendering fragments in isolation. Think of it as an image sprite.\nFor the sake of CSS simplicity, we also group all the paths under an extra g element with a unique id.\nAs a result, the SVG is supposed to look like this:\n\n\u003csvg viewBox=\"0 0 32 32\" fill=\"none\" height=\"32\" width=\"32\" xmlns=\"http://www.w3.org/2000/svg\"\u003e\n  \u003cstyle\u003e\n    path:not(:target) {\n      display: none;\n    }\n    g:target path {\n      display: inline;\n    }\n  \u003c/style\u003e\n  \u003cg id=\"icon\"\u003e\n    \u003cpath id=\"border\" d=\"...\" fill=\"#B0B8BC\"\u003e\u003c/path\u003e\n    \u003cpath id=\"a\" clip-rule=\"evenodd\" d=\"...\" fill-rule=\"evenodd\" fill=\"#FF7B33\"\u003e\u003c/path\u003e\n    \u003cpath id=\"shadow\" d=\"...\" fill=\"#D9DFE4\"\u003e\u003c/path\u003e\n  \u003c/g\u003e\n\u003c/svg\u003e\n\n\nIt produces 4 fragments, one for each of the three paths and the last for the whole icon. Each of them can now be rendered as a separate image:\n#a — \n#border — \n#shadow — \n#icon — \nNow, the regular fragment-less URL will display a blank image.\nThus, for the full icon, we’re going to add a #icon fragment to the URL.\nWe won’t use the #a fragment, but let’s keep its identifier.\nStep #2 — CSS Masks\nWith SVG Fragment Identifiers up and ready, we can use CSS Masks.\nThe base class .icon stacks three layers on top of each other, ready for a mask.\n\n.icon {\n  position: relative;\n  width: 32px;\n  height: 32px;\n  mask-repeat: no-repeat;\n  background-color: currentColor;\n}\n.icon::before,\n.icon::after {\n  content: '';\n  position: absolute;\n  width: inherit;\n  height: inherit;\n  background-color: inherit;\n}\n\n\nThe last CSS class is for our specific icon.\n\n.icon--a {\n  mask-image: url('./a.svg#icon'); /* full icon’s shape */\n  color: #FF7B33;\n}\n.icon--a::before {\n  mask-image: url('./a.svg#shadow'); /* shadow’s shape */\n  color: #D9DFE4;\n}\n.icon--a::after {\n  mask-image: url('./a.svg#border'); /* border’s shape */\n  color: #B0B8BC;\n}\n\n\nThe critical part is that we picked the whole icon, not any fragment, as the parent’s mask, so we have the entire icon visible.\nThat’s because the parent layer masks its children.\nWe selected the orange color of the a for the parent layer.\nThen, we put the two remaining layers on top of it.\nThe second and third layers are for shadow and border parts, respectively.\nWe can describe this as the whole icon in single color covered by one or more shapes in different colors.\nWhen an icon has intersecting parts, there’s one thing to keep in mind.\nBackgrounds render on top of each other in a particular order:\nthe parent’s background,\nthe ::before pseudo-element’s background,\nthe ::after’s background at the end.\nAs a result, we can embed the icon by a single element.\n\n\u003cdiv class=\"icon icon--a\" aria-hidden=\"true\"\u003e\u003c/div\u003e\n\n\nLet’s also consider accessibility.\nUsually, icons are purely decorative content.\nThat’s why we remove them from the accessibility tree by aria-hidden=\"true\".\nThe result is supposed to look like the original icon from the start —\n.\nNow, the single element gives us control over up to three parts of our icon.\nMoreover, we can change colors independently and dynamically.\nThe demo\nFeel free to check the demo.\nPretty neat.\nWe found this technique practical, and we’re keen to use it in the future.\nMore colors\nIf you need more than 3 colors, switch from pseudo-elements to regular elements. Then, you can stack as many layers as you want.\nAnother option is to combine background-image with gradients instead of background-color.\nEnjoy \u0026 use the platform ❤️","guid":"https://blog.allegro.tech/2024/01/embed-multicolor-icons-using-a-single-DOM-element.html","categories":["tech","web","svg","css","html"],"isoDate":"2024-01-09T23:00:00.000Z","thumbnail":"images/post-headers/default.jpg"},{"title":"Clever, surprised and gray-haired","link":"https://blog.allegro.tech/2023/12/lmdb-postmortem.html","pubDate":"Thu, 14 Dec 2023 00:00:00 +0100","authors":{"author":[{"name":["Tomasz Ziółkowski"],"photo":["https://blog.allegro.tech/img/authors/tomasz.ziolkowski.jpg"],"url":["https://blog.allegro.tech/authors/tomasz.ziolkowski"]}]},"content":"\u003cp\u003eThis article is a form of a public postmortem in which we would like to share our bumpy way of revealing the cause of a mysterious performance problem.\nBesides unveiling part of our technical stack based on open-source solutions, we also show how some false assumptions made such a bug triage process much\nharder.\nBesides all NOT TO DOs, you can find some exciting information about performance hunting and reproducing performance issues on a small scale.\nAs a perk, we prepared a \u003ca href=\"https://github.com/ziollek/lmdb-modsecurity-perf-issue\"\u003erepository\u003c/a\u003e where you can reproduce the problem and make yourself familiar with tools\nthat allowed us to confirm the cause.\nThe last part (lessons learned) is the most valuable if you prefer to learn from the mistakes of others.\u003c/p\u003e\n\n\u003cp\u003eBefore you start reading, I must warn you that it will be a pretty long story, and following it without technical knowledge will be challenging.\nHowever, I tried my best to simplify the technicalities as much as possible. If, despite all discouragement, you are interested in solving technical mysteries,\ntake a sip of coffee and enjoy the story!\u003c/p\u003e\n\n\u003ch2 id=\"clever-what-have-we-built\"\u003eClever: what have we built?\u003c/h2\u003e\n\n\u003cp\u003eA few years ago, we researched several platforms that can be used as \u003cem\u003etransparent HTTP proxies\u003c/em\u003e capable of handling HTTP traffic to our services.\nWe needed a solution that would be able to inspect metadata and user data against any suspicious patterns and decide if such traffic should be processed or banned.\nWe chose \u003ca href=\"https://nginx.org/en/docs/\"\u003enginx\u003c/a\u003e in concert with \u003ca href=\"https://github.com/SpiderLabs/ModSecurity\"\u003eModSecurity\u003c/a\u003e as a foundation for a more complex\necosystem.\u003c/p\u003e\n\n\u003cp\u003eDuring increasing usage of such a stack, more than simple non-contextual rules was needed for more complex traffic analysis. One of the most crucial needs was providing the ability to store some contextual information connected\nwith session activity in order to better recognize malicious patterns.\nBy default, \u003cem\u003eModSecurity\u003c/em\u003e allows storing contextual information in memory. Such an approach is not very useful in connection with HTTP servers that utilize\nmultiprocessing as \u003cem\u003enginx\u003c/em\u003e does.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-12-14-lmdb-postmortem/nginx-in-memory.png\" alt=\"In-memory approach\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eHowever, we learned that \u003cem\u003eModSecurity\u003c/em\u003e can use \u003ca href=\"http://www.lmdb.tech/doc/\"\u003eLMDB\u003c/a\u003e as an internal fast storage for contextual information that could be\nshared between requests that come, for example, from the same IP address. \u003cem\u003eLMDB\u003c/em\u003e approach ensures that contextual information stored by one nginx worker process\nis accessible by others.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-12-14-lmdb-postmortem/nginx-with-lmdb.png\" alt=\"LMDB approach\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eAt first glance, it looks great; however, in our case, we could not rely on information that is stored directly by \u003cem\u003eModSecurity\u003c/em\u003e.\nAs you can imagine, our setup is based on more than one server, so we have to be able to pass the same contextual information to each of them.\nMoreover, our algorithms that compute such information are complex and reach for more data than those available to ModSecurity.\u003c/p\u003e\n\n\u003cp\u003eNevertheless, \u003cem\u003eLMDB\u003c/em\u003e has one great advantage: it allows connecting to it from outside the \u003cem\u003enginx\u003c/em\u003e process and altering the contextual data that is available to\n\u003cem\u003eModSecurity\u003c/em\u003e.\nWe built a mechanism that syncs contextual information from dedicated service to LMDB on each transparent proxy host.\nA simplified view of the architecture that allows computing and synchronizing contextual information is depicted below (dotted lines represent asynchronous flow):\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-12-14-lmdb-postmortem/nginx-architecture.png\" alt=\"Final architecture\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eSuch a PoC gave us promising results regarding how fast the contextual information could be provided and how fast it was retrieved by \u003cem\u003eModSecurity\u003c/em\u003e.\nFinally, we rolled out the new approach, and everything worked smoothly for such a long time that we assumed it was a rock-solid solution.\u003c/p\u003e\n\n\u003ch2 id=\"surprised-once-upon-a-time-the-problem-occurred-for-the-first-time\"\u003eSurprised: once upon a time, the problem occurred for the first time\u003c/h2\u003e\n\n\u003cp\u003eWe noticed that response time from the client’s perspective soared, and the number of established connections also increased.\nSuch a correlation is not strange and was noticed many times in the past when the upstream that handles requests from proxy started responding slower.\nWhat was mysterious in that case was that there was no evidence of a problem on the upstream side besides the metric from \u003cem\u003enginx\u003c/em\u003e that was based on\n\u003cem\u003e$upstream_connect_time\u003c/em\u003e.\nAccording to that metric, connecting to the upstream had slowed down significantly.\u003c/p\u003e\n\n\u003cp\u003eHaving such \u003cem\u003ea clue\u003c/em\u003e we blamed the part of infrastructure that is always to blame if no one knows what is happening.\nAs you probably guessed, we assumed that was a temporary network issue (from my experience, it is the best justification to not dig more profound).\nUnfortunately, \u003cem\u003ethe network issue\u003c/em\u003e started occurring quite often, at least a few times a week.\nStrangely enough, if we disable the transparent proxy, the network seems to be stable. Once again, we were convinced that someone from the network team devised blameless culture.\nHence, we started to verify a lot of new hypotheses, from those scary (cyber war, specialized attacks that are hidden in regular traffic) to those that bring\nsmiles upon our faces at least for today (backdoor left by \u003cem\u003eRussian spy\u003c/em\u003e in the nginx source code).\nFalsification of those hypotheses that were at least partially backed up by data is a great story about how to teach engineers that correlation does not mean\ncausation.\u003c/p\u003e\n\n\u003ch2 id=\"turn-gray-investigation\"\u003eTurn gray: investigation\u003c/h2\u003e\n\n\u003cp\u003eLet me introduce a simplified view of our infrastructure to show where we gathered data.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-12-14-lmdb-postmortem/proxy-chain.png\" alt=\"Proxy chain\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eAll proxies measure at least the total processing time, including the time consumed in the proxy and the time that was consumed outside the proxy (passing the\nrequest to the next server in the above chain and waiting for the response).\nAnd those parts could be analyzed independently. Based on such measurements, we can simply compute the approximate overhead of the proxy as a difference between the whole\nrequest (green box) processing and the upstream (red box) waiting.\nHaving that, we were able to discover that the time consumed in transparent proxy was not increased significantly; only the time consumed outside of proxy was\nraised (red box).\nIt was one of the big lies that hindered revealing the truth. You can find a broader explanation of misleading metrics in the lessons learned part.\nAfter excluding network issues, and upstream issues, we were pretty sure that the problem lay in transparent proxy, and we started to doubt what we saw in\nmetrics.\nIt took a while, but finally, we were able to break our unwavering trust in data. Relying on data is encoded in our company DNA, so trusting it was a natural\ninstinct, unfortunately, a bad one in this case.\u003c/p\u003e\n\n\u003cp\u003eHaving that, we could not rely on metrics provided by a transparent proxy. We were starting to try out other means to measure what was going on inside the\ntransparent proxy.\nBeing biased by network issues, we started gathering a lot of network-related information that only showed correlations with problems, but it did not give any\nclues about what was happening.\u003c/p\u003e\n\n\u003cp\u003eIt was a time to use the more straightforward but quite heavy solution - access logs. However, logs are not very useful in giving the overall condition of the proxy;\nthey can be beneficial in analyzing singular problems.\nWhen the problems occurred again, we had some data that we could scrutinize. It turned out that an excellent idea was to log exact timestamps in\na very high resolution (which was not default).\nBelow, you can see a real example reproduced in the local environment (which will be described later).\nEach line contains nginx worker process id, timestamp, request_time, upstream_request_time, upstream_connect_time and the response status code.\u003c/p\u003e\n\u003cpre\u003e\npid:41 t:1700163031.929 rt:\u003cb\u003e8.990\u003c/b\u003e urt:\u003cb\u003e8.990\u003c/b\u003e uct:\u003cb\u003e7.128\u003c/b\u003e status:200\npid:41 t:1700163031.929 rt:12.348 urt:12.348 uct:3.358 status:200\npid:41 t:1700163031.929 rt:\u003cb\u003e8.990\u003c/b\u003e urt:\u003cb\u003e8.990\u003c/b\u003e uct:\u003cb\u003e7.128\u003c/b\u003e status:200\npid:41 t:1700163031.929 rt:\u003cb\u003e8.990\u003c/b\u003e urt:\u003cb\u003e8.990\u003c/b\u003e uct:\u003cb\u003e7.128\u003c/b\u003e status:200\n\u003c/pre\u003e\n\n\u003cp\u003eIt turned out that very often information was logged in bursts with exactly the same timestamp, what was even more intriguing was that some of such entries\nreported the exact same time as an \u003cem\u003e$upstream_request_time\u003c/em\u003e or \u003cem\u003e$upstream_connect_time\u003c/em\u003e.\nLet’s say that even if you are keen on paranormal mystery, odds, that’s the moment when the big red light should start blinking.\nIt definitely looks like something deterministic, not random. In the production realm, it was even more interesting; some bursts were connected with each other\nin some strange arithmetic way - for example:\u003c/p\u003e\n\n\u003cp\u003eLet’s define bursts as:\u003c/p\u003e\n\u003cblockquote\u003e\n  \u003cp\u003eB1, B2, B3 - bursts\u003c/p\u003e\n\n  \u003cp\u003eB1.TS - timestamp of the burst\u003c/p\u003e\n\n  \u003cp\u003eB3.urt, B3.uct - upstream_request_time, upstream_connect_time - reported during last burst\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003ethen such relation was often noticed:\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003eB1.TS + B3.uct = B2.TS\u003c/p\u003e\n\n  \u003cp\u003eB1.TS + B3.urt = B3.TS\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eTo better understand such a relation, let’s draw it:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-12-14-lmdb-postmortem/bursts-relationship.png\" alt=\"Bursts relation\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eHaving a clue that there are extended periods of time when processing for a particular process is stuck, we wanted to know what was going on when processes hung.\nWe used strace to preview what particular system calls were made during such problems. The challenge was to connect to the process when problems occur,\nbut fortunately for us (and less fortunately for our users) we did not wait a long time for the subsequent instability, and we were able to gather strace data.\nIt reveals a large number of \u003ca href=\"https://en.wikipedia.org/wiki/Futex\"\u003efutex\u003c/a\u003e calls that indicated active waiting for some barer / mutex.\u003c/p\u003e\n\n\u003ch2 id=\"connecting-the-dots\"\u003eConnecting the dots\u003c/h2\u003e\n\n\u003cp\u003eAs it was announced earlier, on that stage we have three actors. In order to better understand what was happening under the hood, let’s take a closer look at\neach of them.\u003c/p\u003e\n\n\u003cp\u003eFirst of all \u003cem\u003enginx\u003c/em\u003e server, it uses\n\u003ca href=\"https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/\"\u003ean asynchronous event-driven approach to handling connections\u003c/a\u003e.\nIt means that a single \u003cem\u003enginx\u003c/em\u003e worker can process a large number of requests simultaneously basically because a significant part of processing a single request\nhappens outside the worker. Instead of actively waiting for a response, the nginx process uses such spare time to handle new incoming requests.\nEverything works very efficiently as long as each blocking (IO consuming) operation is handled in an asynchronous manner\n(the control is returned to event-loop).\nWhen such a requirement is unmet, the processing pace slows dramatically.\u003c/p\u003e\n\n\u003cp\u003eThe second actor is the ModSecurity-nginx plugin. \u003cem\u003eNginx\u003c/em\u003e plugins allow extending the logic of the server by adding custom logic.\nModSecurity-nginx plugin allows inspecting requests processed by nginx against \u003cem\u003eModSecurity\u003c/em\u003e rules.\nSuch inspection can be considered a CPU-bound operation, so even if it is called in a synchronous manner, it does not break the concept of processing\nblocking operations asynchronously.\u003c/p\u003e\n\n\u003cp\u003eThe third one is \u003cem\u003eLMDB\u003c/em\u003e, a very efficient mapped DB that allows \u003cstrong\u003econcurrent reads and exclusive writes\u003c/strong\u003e. This database was used as a storage for ModSecurity\ncollections in order to share a state of collections between nginx workers.\nThe documentation and source code of this relatively small project were scrutinized many times as well as integration between ModSecurity and \u003cem\u003eLMDB\u003c/em\u003e, but there\nwas no suspicion of what could be wrong.\u003c/p\u003e\n\n\u003cp\u003eFinally, it turned out that the version of \u003cem\u003eModSecurity\u003c/em\u003e that we scrutinized was from the master branch. Moreover, the master branch contained an improvement related to misusing\n\u003cem\u003eLMDB\u003c/em\u003e exclusive transactions while reading the data. Given that, we had a justified belief that issues came from exclusive transactions. It means that\nnginx workers probably block on acquiring locks.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-12-14-lmdb-postmortem/locking.png\" alt=\"Exclusive locking\" /\u003e\u003c/p\u003e\n\n\u003ch2 id=\"reproducing-the-issue-in-the-isolated-environment\"\u003eReproducing the issue in the isolated environment\u003c/h2\u003e\n\n\u003cp\u003eTo reproduce the issue, we decided to use a technique that we called a fancy name: \u003cem\u003eexaggeration\u003c/em\u003e.\nReproducing a problem that occurs under high traffic that is handled by powerful servers is not simple on a local workstation.\nHowever, in this case, we had some clues and justified hypotheses about what could be wrong and what part we should focus on.\nLet me explain what exaggeration means when it comes to reproducing a problem.\nSome sort of problems can be easily noticeable when the probability of the occurrence of rare events is raised to a significant level.\nIf we have different ways to increase such probability, we can use them interchangeably. I am aware that it sounds like theoretical physics, but believe me or\nnot our problems are relatively easier to solve than those worked on by the guys at LHC.\u003c/p\u003e\n\n\u003cp\u003eIn our case, we were pretty sure that the number of concurrent lookups on a single server to \u003cem\u003eModSecurity\u003c/em\u003e collections is a rare event.\nSo instead of loading a local server in enormous traffic we significantly increased the number of lookups to \u003cem\u003eLMDB\u003c/em\u003e that were performed for each processed\nrequest.\u003c/p\u003e\n\n\u003cp\u003eAll below information is based on data that can be gathered from the docker\n\u003ca href=\"https://github.com/ziollek/lmdb-modsecurity-perf-issue#what-does-the-environment-consist-of\"\u003eenvironment\u003c/a\u003e that was prepared as an integral part of this article.\nIt is worth mentioning that the environment can be built in one of two modes:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eregular that is way faster when it comes to building process\u003c/li\u003e\n  \u003cli\u003eprofiling that allows revealing the exact point where nginx processes hang based on profiling information from the kernel\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eI would not like to deep dive into the profiling process based on kernel capabilities, but it is very cumbersome in a containerized environment because\nit breaks the isolation paradigm.\nMoreover, it is hard to prepare due to compatibility requirements between host and container libraries, header files and compilers.\nHowever, for this particular purpose it was tempting to use limited profiling tools based on \u003ca href=\"https://ebpf.io/\"\u003eeBPF\u003c/a\u003e that do not have such restricted\nrequirements.\u003c/p\u003e\n\n\u003cp\u003eThe first part of the reproducing process is feeding \u003cem\u003eLMDB\u003c/em\u003e collections\nwith \u003ca href=\"https://github.com/ziollek/lmdb-modsecurity-perf-issue#preparing-sample-data\"\u003esample data\u003c/a\u003e.\nWhen the collections are prepared, we can run \u003ca href=\"https://github.com/ziollek/lmdb-modsecurity-perf-issue#testing-performance\"\u003eperformance tests using ab\u003c/a\u003e.\nBy increasing the number of lookups against \u003cem\u003eLMDB\u003c/em\u003e collections during each request, it is relatively simple to reproduce low performance.\nAnalysis of access logs revealed the bursts mentioned in investigation part.\u003c/p\u003e\n\n\u003cp\u003eThe more interesting part was finding the exact place that caused hangs. We started from the entry point (for call inspection of the request headers) to\n\u003cem\u003eModSecurity\u003c/em\u003e from the nginx plugin, namely \u003cstrong\u003emsc_process_request_headers\u003c/strong\u003e function.\nWe helped ourselves with a tool \u003ca href=\"https://manpages.debian.org/unstable/bpfcc-tools/trace-bpfcc.8.en.html\"\u003etrace-bpfcc\u003c/a\u003e provided within package \u003cstrong\u003ebpfcc-tools\u003c/strong\u003e.\nBesides all other features, that tool allows logging the exact point in time when a particular function is called and when it is finished.\nWhen we analyzed the time spent on such a function, we realized that was the exact place where we should dig deeper:\u003c/p\u003e\n\n\u003cpre\u003e\ntrace-bpfcc -t  'p:/usr/local/modsecurity/lib/libmodsecurity.so.3.0.6:msc_process_request_headers \"start\"' \\\n  'r:/usr/local/modsecurity/lib/libmodsecurity.so.3.0.6:msc_process_request_headers \"stop\"' \\\n  'r:/usr/local/modsecurity/lib/libmodsecurity.so.3.0.6:msc_process_logging \"stop\"' 2\u0026gt;/dev/null\n\nTIME     PID     TID     COMM            FUNC             -\n..\n\u003cb\u003e3.981139 10842   10842   nginx           msc_process_request_headers start\u003c/b\u003e\n6.296459 10847   10847   nginx           msc_process_request_headers stop\n6.297111 10847   10847   nginx           msc_process_request_headers start\n6.309465 10844   10844   nginx           msc_process_request_headers stop\n6.310118 10844   10844   nginx           msc_process_request_headers start\n\u003cb\u003e6.314868 10842   10842   nginx           msc_process_request_headers stop\u003c/b\u003e\n6.319024 10840   10840   nginx           msc_process_request_headers stop\n6.323392 10839   10839   nginx           msc_process_request_headers stop\n6.328587 10837   10837   nginx           msc_process_request_headers stop\n6.332937 10843   10843   nginx           msc_process_request_headers stop\n6.338358 10841   10841   nginx           msc_process_request_headers stop\n6.339536 10841   10841   nginx           msc_process_request_headers start\n6.349181 10845   10845   nginx           msc_process_request_headers stop\n6.367007 10838   10838   nginx           msc_process_request_headers stop\n6.368100 10838   10838   nginx           msc_process_request_headers start\n\u003cb\u003e6.522875 10842   10842   nginx           msc_process_logging stop\u003c/b\u003e\n...\n\u003c/pre\u003e\n\n\u003cp\u003ePlease pay attention to highlighted lines related to PID=10842.\nIt turned out that the upstream responded within the required time (in the prepared environment, we are able to control the upstream latency by part of the URL path):\n6.522875 - 6.314868 ~ 200ms.\nHowever, the rest of time: \u003cem\u003e6.314868 - 3.981139 ~ 2.230s\u003c/em\u003e is consumed in \u003cstrong\u003emsc_process_request_headers\u003c/strong\u003e, when we search for the access log entry related to\nthis processing we can see:\u003c/p\u003e\n\n\u003cpre\u003e\nconnection:5824 timestamp:1700222187.657 request_time:2.440 upstream_response_time:2.439 upstream_connect_time:\u003cb\u003e2.235\u003c/b\u003e upstream_header_time:\u003cb\u003e2.438\u003c/b\u003e status:200 request:(GET /users/200/random?arg=unknown HTTP/1.0)\n\u003c/pre\u003e\n\n\u003cp\u003eI would not bore you with the whole process of tracking down but go directly to the \u003cem\u003eLMDB\u003c/em\u003e \u003cstrong\u003emdb_txn_begin\u003c/strong\u003e function that starts the \u003cem\u003eLMDB\u003c/em\u003e transaction.\nThat function is called for each \u003cem\u003eLMDB\u003c/em\u003e lookup, so there are way more calls than in previous profiling.\nHowever, I prepared a command that allows us to aggregate all time consumed while waiting in that function.\u003c/p\u003e\n\n\u003cdiv class=\"language-plaintext highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003e# trace-bpfcc -t 'p:/usr/lib/x86_64-linux-gnu/liblmdb.so.0.0.0:mdb_txn_begin \"start\"' \\\n  'r:/usr/lib/x86_64-linux-gnu/liblmdb.so.0.0.0:mdb_txn_begin \"stop\"' 2\u0026gt;/dev/null | tee /tmp/benchmark.log\n# cat /tmp/benchmark.log  | sort -n | awk '{if ($6 == \"start\") { data[$2] = $1} else { summary += 1000 * ($1 - data[$2]); print $1, $2, 1000 * ($1 - data[$2]) }} END {print \"Total time spent on locking: \", summary, \"ms,  number of calls: \", calls}'\n...\nTotal time spent on locking: 105891ms number of calls:  4064\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eAs a comparison, we can execute the same profiling on version with a fix. Such a version is also available in a prepared environment.\u003c/p\u003e\n\n\u003cdiv class=\"language-plaintext highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003ecat /tmp/benchmark.log  | sort -n | awk '{if ($6 == \"start\") { data[$2] = $1} else { calls++; summary += 1000 * ($1 - data[$2]); print $1, $2, 1000 * ($1 - data[$2]) }} END {print \"Total time spent on locking: \", summary, \"ms,  number of calls: \", calls}'\n...\nTotal time spent on locking: 1811.19ms  number of calls:  4064\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003ch3 id=\"fixing-the-fix\"\u003eFixing the fix\u003c/h3\u003e\n\n\u003cp\u003eAs I have mentioned before, during the investigation we inspected source code that partially solves the problem.\nIt turned out that the fix merged to master does not work at all with the nginx plugin because of some initialization problems.\nThe \u003ca href=\"https://github.com/SpiderLabs/ModSecurity/pull/2688\"\u003ePR\u003c/a\u003e that fixes the found problem has been merged and released in version \u003cem\u003e3.0.7\u003c/em\u003e of \u003cem\u003eModSecurity\u003c/em\u003e.\u003c/p\u003e\n\n\u003ch2 id=\"lessons-learned\"\u003eLessons learned\u003c/h2\u003e\n\n\u003ch3 id=\"make-sure-that-you-inspect-the-exact-version-of-the-source-code-that-you-run\"\u003eMake sure that you inspect the exact version of the source code that you run\u003c/h3\u003e\n\n\u003cp\u003eOne of the struggles that we faced was scrutinizing the version of ModSecurity that had partially fixed the problem with exclusive read access to \u003cem\u003eLMDB\u003c/em\u003e.\nFor sure, we had bad luck that the fix was available in master and not in the last released version that we then used, but at least we can confirm that the\ndevil is in the details.\u003c/p\u003e\n\n\u003ch3 id=\"instrumentation-overhead\"\u003eInstrumentation overhead\u003c/h3\u003e\n\n\u003cp\u003eWhen using such low level profiling methods you have to bear in mind that approach is quite invasive.\nIt means that such observation impacts the observed process.\nIt implies that it is hard to distinguish if we are observing root problems or just a consequence of harnessing very heavy instrumentation.\nSo, it is risky to draw conclusions from such observations.\u003c/p\u003e\n\n\u003ch3 id=\"verify-your-assumptions\"\u003eVerify your assumptions\u003c/h3\u003e\n\n\u003cp\u003eOur lack of understanding of how the particular phases of processing requests are computed led us to the false assumption that we could compute approximate\n\u003cem\u003eModSecurity\u003c/em\u003e overhead by using simple arithmetic: request time - upstream time.\n\u003cimg src=\"/img/articles/2023-12-14-lmdb-postmortem/variables.png\" alt=\"nginx variables\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eIt was one of the biggest mistakes that hindered revealing the truth. It turned out that part of \u003cem\u003eModSecurity\u003c/em\u003e processing was included into upstream time,\nso the red part on above diagram also includes \u003cem\u003eModSecurity\u003c/em\u003e processing that is not part of establishing connection. As a form of self-punishment,\nwe \u003ca href=\"https://github.com/SpiderLabs/ModSecurity-nginx/pull/278\"\u003eextended\u003c/a\u003e the \u003cem\u003enginx-ModSecurity\u003c/em\u003e plugin in such a way that it allows measuring the overhead of\neach \u003cem\u003eModSecurity\u003c/em\u003e phase in a reliable way.\u003c/p\u003e\n\n\u003ch3 id=\"log-timestamps\"\u003eLog timestamps\u003c/h3\u003e\n\n\u003cp\u003eIt may seem redundant because many logger collectors by default add their own timestamp of the moment when log entries are received in the collector.\nHowever, having a timestamp from \u003cstrong\u003ethe moment when the log is produced\u003c/strong\u003e (without any delays) is crucial to reveal suspicious patterns/hangs on the producer\nside that can not be observed if timestamps are affected by random lags.\u003c/p\u003e\n\n\u003ch3 id=\"do-not-abuse-undocumented-behavior\"\u003eDo (not) abuse undocumented behavior\u003c/h3\u003e\n\n\u003cp\u003eOne of the reasons that we faced this issue was abusing usage of \u003cem\u003eModSecurity\u003c/em\u003e collections.\nIn regular and \u003ca href=\"https://github.com/SpiderLabs/ModSecurity/wiki/Reference-Manual-%28v3.x%29#user-content-Persistent_Storage\"\u003edocumented\u003c/a\u003e usage such collections\nare considered to be simple key-value storage.\nWe discovered that under each key, we are able to store a list of values instead of a single value. If you consciously scanned the provided repository\n(especially \u003cem\u003eModSecurity\u003c/em\u003e rules) you could probably find a way to simulate a situation where multiple values are fetched while reading a single key.\nLet’s look at a rule that is available in the repository\u003c/p\u003e\n\n\u003cdiv class=\"language-plaintext highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003eSecRule \u0026amp;REQUEST_HEADERS:x-set-sample \"@eq 1\" \"phase:1,setvar:global.sample%{REQUEST_HEADERS:x-set-sample}=%{REQUEST_HEADERS:x-set-sample},log,deny,status:403,id:50,msg:'value of sample header is blocked',tag:'priority:1',tag:'action:deny'\"\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eIf we call above rule with x-set-sample header with subsequent values \u003cem\u003e1, 2, 3\u003c/em\u003e. We can do that by making HTTP requests as below:\u003c/p\u003e\n\u003cdiv class=\"language-plaintext highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003eworkstation # docker-compose exec nginx-before-fix bash\nnginx-with-lmdb # curl -I -H'x-set-sample: 1' localhost\nnginx-with-lmdb # curl -I -H'x-set-sample: 2' localhost\nnginx-with-lmdb # curl -I -H'x-set-sample: 3' localhost\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eThen, we can expect that there will be stored three key-value pairs:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eglobals[sample1]=1\u003c/li\u003e\n  \u003cli\u003eglobals[sample2]=2\u003c/li\u003e\n  \u003cli\u003eglobals[sample3]=3\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eIndeed, when we try to read \u003cem\u003eLMDB\u003c/em\u003e in a very naive approach, values are stored the way we expect. We can see something like that:\u003c/p\u003e\n\u003cdiv class=\"language-plaintext highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003enginx-with-lmdb # strings /tmp/modsec-shared-collections\nsample::::sample11\nsample::::sample22\nsample::::sample33\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eThe following rule that is interesting is supposed to check if a value under a particular key is equal to a query param.\nBasically, if the request contains query parameter \u003cstrong\u003earg=1\u003c/strong\u003e, then we check if the value in the collection \u003cstrong\u003eglobal\u003c/strong\u003e, under the key \u003cstrong\u003esample\u003c/strong\u003e is also “1”.\nIf the condition is met then the request will be blocked, which means that \u003cstrong\u003e403\u003c/strong\u003e status code will be returned.\u003c/p\u003e\n\n\u003cdiv class=\"language-plaintext highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003eSecRule ARGS_GET \".*\" \"chain,phase:1,log,capture,deny,status:403,id:1001,msg:'value of param %{TX.0} is blocked',setvar:tx.param=%{TX.0}\"\n    SecRule global.sample \"@streq %{tx.param}\" \"t:none\"\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eYou may be confused why we are reading the key \u003cstrong\u003esample\u003c/strong\u003e that was never set.\nLet’s look what happens when we try to make a request with value 1 and -1.\nAs I described earlier, our intention was to check if \u003cstrong\u003eglobal[sample] == 1\u003c/strong\u003e.\u003c/p\u003e\n\n\u003cdiv class=\"language-plaintext highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003enginx-with-lmdb  # curl -I \"http://localhost/users/200/random?arg=1\"\nHTTP/1.1 403 Forbidden\nServer: nginx/1.22.0 (Ubuntu)\nDate: Fri, 17 Nov 2023 10:58:39 GMT\nContent-Type: text/html\nContent-Length: 162\nConnection: keep-alive\nnginx-with-lmdb\n\nnginx-with-lmdb  # curl -I \"http://localhost/users/200/random?arg=-1\"\nHTTP/1.1 200\nServer: nginx/1.22.0 (Ubuntu)\nDate: Fri, 17 Nov 2023 10:58:42 GMT\nContent-Type: application/json\nContent-Length: 79\nConnection: keep-alive\n\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eQuite interesting? It turns out that the match is fulfilled for value “1”, and surprisingly there is a log that gives us an insight:\u003c/p\u003e\n\n\u003cdiv class=\"language-plaintext highlighter-rouge\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"highlight\"\u003e\u003ccode\u003enginx-with-lmdb  # tail -5 /var/log/nginx/modsec_audit.log\n---TL9qTmAS---H--\nModSecurity: Access denied with code 403 (phase 1). Matched \"Operator `StrEq' with parameter `' against variable `GLOBAL:sample::::sample1' (Value: `1' ) [file \"/etc/nginx/rules/rules.conf\"] [line \"32\"] [id \"1001\"] [rev \"\"] [msg \"value of param 1 is blocked\"] [data \"\"] [severity \"0\"] [ver \"\"] [maturity \"0\"] [accuracy \"0\"] [hostname \"127.0.0.1\"] [uri \"/users/200/random\"] [unique_id \"1700218719\"] [ref \"o0,1v27,1\"]\n\n---TL9qTmAS---Z--\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eAs you can see, internally \u003cem\u003eModSecurity\u003c/em\u003e read the value that was stored under the key \u003cem\u003esample1\u003c/em\u003e instead of \u003cem\u003esample\u003c/em\u003e.\nThe same works for each key with matching prefix.\u003c/p\u003e\n\n\u003cp\u003eTo wrap up this somewhat too long digression, we abused undocumented behavior on purpose,\nand it increased the time it took to fetch data. Moreover, such fetching was redundant and nonsense because after fetching all those values we check only\nif the list contains a particular value.\nDue to the increased time of exclusive locks (acquired for the whole time of fetching data), the problem started to be noticeable. On the other hand, if\nwe had not abused it, we would unconsciously still be using buggy code that slowly degrades efficiency.\u003c/p\u003e\n\n","contentSnippet":"This article is a form of a public postmortem in which we would like to share our bumpy way of revealing the cause of a mysterious performance problem.\nBesides unveiling part of our technical stack based on open-source solutions, we also show how some false assumptions made such a bug triage process much\nharder.\nBesides all NOT TO DOs, you can find some exciting information about performance hunting and reproducing performance issues on a small scale.\nAs a perk, we prepared a repository where you can reproduce the problem and make yourself familiar with tools\nthat allowed us to confirm the cause.\nThe last part (lessons learned) is the most valuable if you prefer to learn from the mistakes of others.\nBefore you start reading, I must warn you that it will be a pretty long story, and following it without technical knowledge will be challenging.\nHowever, I tried my best to simplify the technicalities as much as possible. If, despite all discouragement, you are interested in solving technical mysteries,\ntake a sip of coffee and enjoy the story!\nClever: what have we built?\nA few years ago, we researched several platforms that can be used as transparent HTTP proxies capable of handling HTTP traffic to our services.\nWe needed a solution that would be able to inspect metadata and user data against any suspicious patterns and decide if such traffic should be processed or banned.\nWe chose nginx in concert with ModSecurity as a foundation for a more complex\necosystem.\nDuring increasing usage of such a stack, more than simple non-contextual rules was needed for more complex traffic analysis. One of the most crucial needs was providing the ability to store some contextual information connected\nwith session activity in order to better recognize malicious patterns.\nBy default, ModSecurity allows storing contextual information in memory. Such an approach is not very useful in connection with HTTP servers that utilize\nmultiprocessing as nginx does.\n\nHowever, we learned that ModSecurity can use LMDB as an internal fast storage for contextual information that could be\nshared between requests that come, for example, from the same IP address. LMDB approach ensures that contextual information stored by one nginx worker process\nis accessible by others.\n\nAt first glance, it looks great; however, in our case, we could not rely on information that is stored directly by ModSecurity.\nAs you can imagine, our setup is based on more than one server, so we have to be able to pass the same contextual information to each of them.\nMoreover, our algorithms that compute such information are complex and reach for more data than those available to ModSecurity.\nNevertheless, LMDB has one great advantage: it allows connecting to it from outside the nginx process and altering the contextual data that is available to\nModSecurity.\nWe built a mechanism that syncs contextual information from dedicated service to LMDB on each transparent proxy host.\nA simplified view of the architecture that allows computing and synchronizing contextual information is depicted below (dotted lines represent asynchronous flow):\n\nSuch a PoC gave us promising results regarding how fast the contextual information could be provided and how fast it was retrieved by ModSecurity.\nFinally, we rolled out the new approach, and everything worked smoothly for such a long time that we assumed it was a rock-solid solution.\nSurprised: once upon a time, the problem occurred for the first time\nWe noticed that response time from the client’s perspective soared, and the number of established connections also increased.\nSuch a correlation is not strange and was noticed many times in the past when the upstream that handles requests from proxy started responding slower.\nWhat was mysterious in that case was that there was no evidence of a problem on the upstream side besides the metric from nginx that was based on\n$upstream_connect_time.\nAccording to that metric, connecting to the upstream had slowed down significantly.\nHaving such a clue we blamed the part of infrastructure that is always to blame if no one knows what is happening.\nAs you probably guessed, we assumed that was a temporary network issue (from my experience, it is the best justification to not dig more profound).\nUnfortunately, the network issue started occurring quite often, at least a few times a week.\nStrangely enough, if we disable the transparent proxy, the network seems to be stable. Once again, we were convinced that someone from the network team devised blameless culture.\nHence, we started to verify a lot of new hypotheses, from those scary (cyber war, specialized attacks that are hidden in regular traffic) to those that bring\nsmiles upon our faces at least for today (backdoor left by Russian spy in the nginx source code).\nFalsification of those hypotheses that were at least partially backed up by data is a great story about how to teach engineers that correlation does not mean\ncausation.\nTurn gray: investigation\nLet me introduce a simplified view of our infrastructure to show where we gathered data.\n\nAll proxies measure at least the total processing time, including the time consumed in the proxy and the time that was consumed outside the proxy (passing the\nrequest to the next server in the above chain and waiting for the response).\nAnd those parts could be analyzed independently. Based on such measurements, we can simply compute the approximate overhead of the proxy as a difference between the whole\nrequest (green box) processing and the upstream (red box) waiting.\nHaving that, we were able to discover that the time consumed in transparent proxy was not increased significantly; only the time consumed outside of proxy was\nraised (red box).\nIt was one of the big lies that hindered revealing the truth. You can find a broader explanation of misleading metrics in the lessons learned part.\nAfter excluding network issues, and upstream issues, we were pretty sure that the problem lay in transparent proxy, and we started to doubt what we saw in\nmetrics.\nIt took a while, but finally, we were able to break our unwavering trust in data. Relying on data is encoded in our company DNA, so trusting it was a natural\ninstinct, unfortunately, a bad one in this case.\nHaving that, we could not rely on metrics provided by a transparent proxy. We were starting to try out other means to measure what was going on inside the\ntransparent proxy.\nBeing biased by network issues, we started gathering a lot of network-related information that only showed correlations with problems, but it did not give any\nclues about what was happening.\nIt was a time to use the more straightforward but quite heavy solution - access logs. However, logs are not very useful in giving the overall condition of the proxy;\nthey can be beneficial in analyzing singular problems.\nWhen the problems occurred again, we had some data that we could scrutinize. It turned out that an excellent idea was to log exact timestamps in\na very high resolution (which was not default).\nBelow, you can see a real example reproduced in the local environment (which will be described later).\nEach line contains nginx worker process id, timestamp, request_time, upstream_request_time, upstream_connect_time and the response status code.\n8.990 urt:8.990 uct:7.128 status:200\npid:41 t:1700163031.929 rt:12.348 urt:12.348 uct:3.358 status:200\npid:41 t:1700163031.929 rt:8.990 urt:8.990 uct:7.128 status:200\npid:41 t:1700163031.929 rt:8.990 urt:8.990 uct:7.128 status:200\n\n\nIt turned out that very often information was logged in bursts with exactly the same timestamp, what was even more intriguing was that some of such entries\nreported the exact same time as an $upstream_request_time or $upstream_connect_time.\nLet’s say that even if you are keen on paranormal mystery, odds, that’s the moment when the big red light should start blinking.\nIt definitely looks like something deterministic, not random. In the production realm, it was even more interesting; some bursts were connected with each other\nin some strange arithmetic way - for example:\nLet’s define bursts as:\nB1, B2, B3 - bursts\nB1.TS - timestamp of the burst\nB3.urt, B3.uct - upstream_request_time, upstream_connect_time - reported during last burst\nthen such relation was often noticed:\nB1.TS + B3.uct = B2.TS\nB1.TS + B3.urt = B3.TS\nTo better understand such a relation, let’s draw it:\n\nHaving a clue that there are extended periods of time when processing for a particular process is stuck, we wanted to know what was going on when processes hung.\nWe used strace to preview what particular system calls were made during such problems. The challenge was to connect to the process when problems occur,\nbut fortunately for us (and less fortunately for our users) we did not wait a long time for the subsequent instability, and we were able to gather strace data.\nIt reveals a large number of futex calls that indicated active waiting for some barer / mutex.\nConnecting the dots\nAs it was announced earlier, on that stage we have three actors. In order to better understand what was happening under the hood, let’s take a closer look at\neach of them.\nFirst of all nginx server, it uses\nan asynchronous event-driven approach to handling connections.\nIt means that a single nginx worker can process a large number of requests simultaneously basically because a significant part of processing a single request\nhappens outside the worker. Instead of actively waiting for a response, the nginx process uses such spare time to handle new incoming requests.\nEverything works very efficiently as long as each blocking (IO consuming) operation is handled in an asynchronous manner\n(the control is returned to event-loop).\nWhen such a requirement is unmet, the processing pace slows dramatically.\nThe second actor is the ModSecurity-nginx plugin. Nginx plugins allow extending the logic of the server by adding custom logic.\nModSecurity-nginx plugin allows inspecting requests processed by nginx against ModSecurity rules.\nSuch inspection can be considered a CPU-bound operation, so even if it is called in a synchronous manner, it does not break the concept of processing\nblocking operations asynchronously.\nThe third one is LMDB, a very efficient mapped DB that allows concurrent reads and exclusive writes. This database was used as a storage for ModSecurity\ncollections in order to share a state of collections between nginx workers.\nThe documentation and source code of this relatively small project were scrutinized many times as well as integration between ModSecurity and LMDB, but there\nwas no suspicion of what could be wrong.\nFinally, it turned out that the version of ModSecurity that we scrutinized was from the master branch. Moreover, the master branch contained an improvement related to misusing\nLMDB exclusive transactions while reading the data. Given that, we had a justified belief that issues came from exclusive transactions. It means that\nnginx workers probably block on acquiring locks.\n\nReproducing the issue in the isolated environment\nTo reproduce the issue, we decided to use a technique that we called a fancy name: exaggeration.\nReproducing a problem that occurs under high traffic that is handled by powerful servers is not simple on a local workstation.\nHowever, in this case, we had some clues and justified hypotheses about what could be wrong and what part we should focus on.\nLet me explain what exaggeration means when it comes to reproducing a problem.\nSome sort of problems can be easily noticeable when the probability of the occurrence of rare events is raised to a significant level.\nIf we have different ways to increase such probability, we can use them interchangeably. I am aware that it sounds like theoretical physics, but believe me or\nnot our problems are relatively easier to solve than those worked on by the guys at LHC.\nIn our case, we were pretty sure that the number of concurrent lookups on a single server to ModSecurity collections is a rare event.\nSo instead of loading a local server in enormous traffic we significantly increased the number of lookups to LMDB that were performed for each processed\nrequest.\nAll below information is based on data that can be gathered from the docker\nenvironment that was prepared as an integral part of this article.\nIt is worth mentioning that the environment can be built in one of two modes:\nregular that is way faster when it comes to building process\nprofiling that allows revealing the exact point where nginx processes hang based on profiling information from the kernel\nI would not like to deep dive into the profiling process based on kernel capabilities, but it is very cumbersome in a containerized environment because\nit breaks the isolation paradigm.\nMoreover, it is hard to prepare due to compatibility requirements between host and container libraries, header files and compilers.\nHowever, for this particular purpose it was tempting to use limited profiling tools based on eBPF that do not have such restricted\nrequirements.\nThe first part of the reproducing process is feeding LMDB collections\nwith sample data.\nWhen the collections are prepared, we can run performance tests using ab.\nBy increasing the number of lookups against LMDB collections during each request, it is relatively simple to reproduce low performance.\nAnalysis of access logs revealed the bursts mentioned in investigation part.\nThe more interesting part was finding the exact place that caused hangs. We started from the entry point (for call inspection of the request headers) to\nModSecurity from the nginx plugin, namely msc_process_request_headers function.\nWe helped ourselves with a tool trace-bpfcc provided within package bpfcc-tools.\nBesides all other features, that tool allows logging the exact point in time when a particular function is called and when it is finished.\nWhen we analyzed the time spent on such a function, we realized that was the exact place where we should dig deeper:\n3.981139 10842   10842   nginx           msc_process_request_headers start\n6.296459 10847   10847   nginx           msc_process_request_headers stop\n6.297111 10847   10847   nginx           msc_process_request_headers start\n6.309465 10844   10844   nginx           msc_process_request_headers stop\n6.310118 10844   10844   nginx           msc_process_request_headers start\n6.314868 10842   10842   nginx           msc_process_request_headers stop\n6.319024 10840   10840   nginx           msc_process_request_headers stop\n6.323392 10839   10839   nginx           msc_process_request_headers stop\n6.328587 10837   10837   nginx           msc_process_request_headers stop\n6.332937 10843   10843   nginx           msc_process_request_headers stop\n6.338358 10841   10841   nginx           msc_process_request_headers stop\n6.339536 10841   10841   nginx           msc_process_request_headers start\n6.349181 10845   10845   nginx           msc_process_request_headers stop\n6.367007 10838   10838   nginx           msc_process_request_headers stop\n6.368100 10838   10838   nginx           msc_process_request_headers start\n6.522875 10842   10842   nginx           msc_process_logging stop\n...\n\n\nPlease pay attention to highlighted lines related to PID=10842.\nIt turned out that the upstream responded within the required time (in the prepared environment, we are able to control the upstream latency by part of the URL path):\n6.522875 - 6.314868 ~ 200ms.\nHowever, the rest of time: 6.314868 - 3.981139 ~ 2.230s is consumed in msc_process_request_headers, when we search for the access log entry related to\nthis processing we can see:\n2.235 upstream_header_time:2.438 status:200 request:(GET /users/200/random?arg=unknown HTTP/1.0)\n\n\nI would not bore you with the whole process of tracking down but go directly to the LMDB mdb_txn_begin function that starts the LMDB transaction.\nThat function is called for each LMDB lookup, so there are way more calls than in previous profiling.\nHowever, I prepared a command that allows us to aggregate all time consumed while waiting in that function.\n\n# trace-bpfcc -t 'p:/usr/lib/x86_64-linux-gnu/liblmdb.so.0.0.0:mdb_txn_begin \"start\"' \\\n  'r:/usr/lib/x86_64-linux-gnu/liblmdb.so.0.0.0:mdb_txn_begin \"stop\"' 2\u003e/dev/null | tee /tmp/benchmark.log\n# cat /tmp/benchmark.log  | sort -n | awk '{if ($6 == \"start\") { data[$2] = $1} else { summary += 1000 * ($1 - data[$2]); print $1, $2, 1000 * ($1 - data[$2]) }} END {print \"Total time spent on locking: \", summary, \"ms,  number of calls: \", calls}'\n...\nTotal time spent on locking: 105891ms number of calls:  4064\n\n\nAs a comparison, we can execute the same profiling on version with a fix. Such a version is also available in a prepared environment.\n\ncat /tmp/benchmark.log  | sort -n | awk '{if ($6 == \"start\") { data[$2] = $1} else { calls++; summary += 1000 * ($1 - data[$2]); print $1, $2, 1000 * ($1 - data[$2]) }} END {print \"Total time spent on locking: \", summary, \"ms,  number of calls: \", calls}'\n...\nTotal time spent on locking: 1811.19ms  number of calls:  4064\n\n\nFixing the fix\nAs I have mentioned before, during the investigation we inspected source code that partially solves the problem.\nIt turned out that the fix merged to master does not work at all with the nginx plugin because of some initialization problems.\nThe PR that fixes the found problem has been merged and released in version 3.0.7 of ModSecurity.\nLessons learned\nMake sure that you inspect the exact version of the source code that you run\nOne of the struggles that we faced was scrutinizing the version of ModSecurity that had partially fixed the problem with exclusive read access to LMDB.\nFor sure, we had bad luck that the fix was available in master and not in the last released version that we then used, but at least we can confirm that the\ndevil is in the details.\nInstrumentation overhead\nWhen using such low level profiling methods you have to bear in mind that approach is quite invasive.\nIt means that such observation impacts the observed process.\nIt implies that it is hard to distinguish if we are observing root problems or just a consequence of harnessing very heavy instrumentation.\nSo, it is risky to draw conclusions from such observations.\nVerify your assumptions\nOur lack of understanding of how the particular phases of processing requests are computed led us to the false assumption that we could compute approximate\nModSecurity overhead by using simple arithmetic: request time - upstream time.\n\nIt was one of the biggest mistakes that hindered revealing the truth. It turned out that part of ModSecurity processing was included into upstream time,\nso the red part on above diagram also includes ModSecurity processing that is not part of establishing connection. As a form of self-punishment,\nwe extended the nginx-ModSecurity plugin in such a way that it allows measuring the overhead of\neach ModSecurity phase in a reliable way.\nLog timestamps\nIt may seem redundant because many logger collectors by default add their own timestamp of the moment when log entries are received in the collector.\nHowever, having a timestamp from the moment when the log is produced (without any delays) is crucial to reveal suspicious patterns/hangs on the producer\nside that can not be observed if timestamps are affected by random lags.\nDo (not) abuse undocumented behavior\nOne of the reasons that we faced this issue was abusing usage of ModSecurity collections.\nIn regular and documented usage such collections\nare considered to be simple key-value storage.\nWe discovered that under each key, we are able to store a list of values instead of a single value. If you consciously scanned the provided repository\n(especially ModSecurity rules) you could probably find a way to simulate a situation where multiple values are fetched while reading a single key.\nLet’s look at a rule that is available in the repository\n\nSecRule \u0026REQUEST_HEADERS:x-set-sample \"@eq 1\" \"phase:1,setvar:global.sample%{REQUEST_HEADERS:x-set-sample}=%{REQUEST_HEADERS:x-set-sample},log,deny,status:403,id:50,msg:'value of sample header is blocked',tag:'priority:1',tag:'action:deny'\"\n\n\nIf we call above rule with x-set-sample header with subsequent values 1, 2, 3. We can do that by making HTTP requests as below:\n\nworkstation # docker-compose exec nginx-before-fix bash\nnginx-with-lmdb # curl -I -H'x-set-sample: 1' localhost\nnginx-with-lmdb # curl -I -H'x-set-sample: 2' localhost\nnginx-with-lmdb # curl -I -H'x-set-sample: 3' localhost\n\n\nThen, we can expect that there will be stored three key-value pairs:\nglobals[sample1]=1\nglobals[sample2]=2\nglobals[sample3]=3\nIndeed, when we try to read LMDB in a very naive approach, values are stored the way we expect. We can see something like that:\n\nnginx-with-lmdb # strings /tmp/modsec-shared-collections\nsample::::sample11\nsample::::sample22\nsample::::sample33\n\n\nThe following rule that is interesting is supposed to check if a value under a particular key is equal to a query param.\nBasically, if the request contains query parameter arg=1, then we check if the value in the collection global, under the key sample is also “1”.\nIf the condition is met then the request will be blocked, which means that 403 status code will be returned.\n\nSecRule ARGS_GET \".*\" \"chain,phase:1,log,capture,deny,status:403,id:1001,msg:'value of param %{TX.0} is blocked',setvar:tx.param=%{TX.0}\"\n    SecRule global.sample \"@streq %{tx.param}\" \"t:none\"\n\n\nYou may be confused why we are reading the key sample that was never set.\nLet’s look what happens when we try to make a request with value 1 and -1.\nAs I described earlier, our intention was to check if global[sample] == 1.\n\nnginx-with-lmdb  # curl -I \"http://localhost/users/200/random?arg=1\"\nHTTP/1.1 403 Forbidden\nServer: nginx/1.22.0 (Ubuntu)\nDate: Fri, 17 Nov 2023 10:58:39 GMT\nContent-Type: text/html\nContent-Length: 162\nConnection: keep-alive\nnginx-with-lmdb\n\nnginx-with-lmdb  # curl -I \"http://localhost/users/200/random?arg=-1\"\nHTTP/1.1 200\nServer: nginx/1.22.0 (Ubuntu)\nDate: Fri, 17 Nov 2023 10:58:42 GMT\nContent-Type: application/json\nContent-Length: 79\nConnection: keep-alive\n\n\n\nQuite interesting? It turns out that the match is fulfilled for value “1”, and surprisingly there is a log that gives us an insight:\n\nnginx-with-lmdb  # tail -5 /var/log/nginx/modsec_audit.log\n---TL9qTmAS---H--\nModSecurity: Access denied with code 403 (phase 1). Matched \"Operator `StrEq' with parameter `' against variable `GLOBAL:sample::::sample1' (Value: `1' ) [file \"/etc/nginx/rules/rules.conf\"] [line \"32\"] [id \"1001\"] [rev \"\"] [msg \"value of param 1 is blocked\"] [data \"\"] [severity \"0\"] [ver \"\"] [maturity \"0\"] [accuracy \"0\"] [hostname \"127.0.0.1\"] [uri \"/users/200/random\"] [unique_id \"1700218719\"] [ref \"o0,1v27,1\"]\n\n---TL9qTmAS---Z--\n\n\nAs you can see, internally ModSecurity read the value that was stored under the key sample1 instead of sample.\nThe same works for each key with matching prefix.\nTo wrap up this somewhat too long digression, we abused undocumented behavior on purpose,\nand it increased the time it took to fetch data. Moreover, such fetching was redundant and nonsense because after fetching all those values we check only\nif the list contains a particular value.\nDue to the increased time of exclusive locks (acquired for the whole time of fetching data), the problem started to be noticeable. On the other hand, if\nwe had not abused it, we would unconsciously still be using buggy code that slowly degrades efficiency.","guid":"https://blog.allegro.tech/2023/12/lmdb-postmortem.html","categories":["tech","postmortem","nginx","libmodsecurity","LMDB","performance bottleneck","open source","debugging","profiling"],"isoDate":"2023-12-13T23:00:00.000Z","thumbnail":"images/post-headers/default.jpg"},{"title":"How does B-tree make your queries fast?","link":"https://blog.allegro.tech/2023/11/how-does-btree-make-your-queries-fast.html","pubDate":"Mon, 27 Nov 2023 00:00:00 +0100","authors":{"author":[{"name":["Mateusz Kuźmik"],"photo":["https://blog.allegro.tech/img/authors/mateusz.kuzmik.jpg"],"url":["https://blog.allegro.tech/authors/mateusz.kuzmik"]}]},"content":"\u003cp\u003e\u003cstrong\u003eB-tree\u003c/strong\u003e is a structure that helps to search through great amounts of data.\nIt was invented over 40 years ago, yet it is still employed by the majority of modern databases.\nAlthough there are newer index structures, like LSM trees,\n\u003cstrong\u003eB-tree\u003c/strong\u003e is unbeaten when handling most of the database queries.\u003c/p\u003e\n\n\u003cp\u003eAfter reading this post, you will know how \u003cstrong\u003eB-tree\u003c/strong\u003e organises the data and how it performs search queries.\u003c/p\u003e\n\n\u003ch2 id=\"origins\"\u003eOrigins\u003c/h2\u003e\n\n\u003cp\u003eIn order to understand \u003cstrong\u003eB-tree\u003c/strong\u003e let’s focus on \u003cstrong\u003eBinary Search Tree (BST)\u003c/strong\u003e first.\u003c/p\u003e\n\n\u003cp\u003eWait, isn’t it the same?\u003c/p\u003e\n\n\u003cp\u003eWhat does “B” stand for then?\u003c/p\u003e\n\n\u003cp\u003eAccording to \u003ca href=\"https://en.wikipedia.org/wiki/B-tree\"\u003ewikipedia.org\u003c/a\u003e, Edward M. McCreight, the inventor of B-tree, once said:\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003e“the more you think about what the B in B-trees means, the better you understand B-trees.”\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eConfusing \u003cstrong\u003eB-tree\u003c/strong\u003e with \u003cstrong\u003eBST\u003c/strong\u003e is a really common misconception.\nAnyway, in my opinion, BST is a great starting point for reinventing B-tree.\nLet’s start with a simple example of BST:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-11-27-how-does-btree-make-your-queries-fast/bst-basic.webp\" alt=\"Binary Search Tree with three nodes\" class=\"small-image\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eThe greater number is always on the right, the lower on the left. It may become clearer when we add more numbers.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-11-27-how-does-btree-make-your-queries-fast/bst-bigger.webp\" alt=\"Binary Search Tree with seven nodes\" class=\"small-image\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eThis tree contains seven numbers, but we need to visit at most three nodes to locate any number.\nThe following example visualizes searching for 14.\nI used SQL to define the query in order to think about this tree as if it were an actual database index.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-11-27-how-does-btree-make-your-queries-fast/bst-bigger-searching.webp\" alt=\"Searching for single node within Binary Search Tree with seven nodes\" class=\"small-image\" /\u003e\u003c/p\u003e\n\n\u003ch2 id=\"hardware\"\u003eHardware\u003c/h2\u003e\n\n\u003cp\u003eIn theory, using Binary Search Tree for running our queries looks fine. Its time complexity (when searching) is \\(O(log\nn)\\), \u003ca href=\"https://en.wikipedia.org/wiki/B-tree\"\u003esame as B-tree\u003c/a\u003e. However, in practice, this data structure needs to work on actual hardware. An index must be\nstored somewhere on your machine.\u003c/p\u003e\n\n\u003cp\u003eThe computer has three places where the data can be stored:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eCPU caches\u003c/li\u003e\n  \u003cli\u003eRAM (memory)\u003c/li\u003e\n  \u003cli\u003eDisk (storage)\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThe cache is managed fully by CPUs. Moreover, it is relatively small, usually a few megabytes.\nIndex may contain gigabytes of data, so it won’t fit there.\u003c/p\u003e\n\n\u003cp\u003eDatabases vastly use Memory (RAM). It has some great advantages:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eassures fast random access (more on that in the next paragraph)\u003c/li\u003e\n  \u003cli\u003eits size may be pretty big (e.g. AWS RDS cloud service \u003ca href=\"https://aws.amazon.com/rds/instance-types/\"\u003eprovides instances\u003c/a\u003e\nwith a few terabytes of memory available).\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eCons? You lose the data when the power supply goes off. Moreover, when compared to the disk, it is pretty expensive.\u003c/p\u003e\n\n\u003cp\u003eFinally, the cons of a memory are the pros of a disk storage.\nIt’s cheap, and data will remain there even if we lose the power.\nHowever, there are no free lunches!\nThe catch is that we need to be careful about random and sequential access.\nReading from the disk is fast, but only under certain conditions!\nI’ll try to explain them simply.\u003c/p\u003e\n\n\u003ch3 id=\"random-and-sequential-access\"\u003eRandom and sequential access\u003c/h3\u003e\n\n\u003cp\u003eMemory may be visualized as a line of containers for values, where every container is numbered.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-11-27-how-does-btree-make-your-queries-fast/memory.webp\" alt=\"Simple memory visualization\" class=\"small-image\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eNow let’s assume we want to read data from containers 1, 4, and 6. It requires random access:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-11-27-how-does-btree-make-your-queries-fast/memory-random-access.webp\" alt=\"Random access visualized on a small chunk of a memory\" class=\"small-image\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eAnd then let’s compare it with reading containers 3, 4, and 5. It may be done sequentially:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-11-27-how-does-btree-make-your-queries-fast/memory-sequential-access.webp\" alt=\"Sequential access visualized on a small chunk of a memory\" class=\"small-image\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eThe difference between a “random jump” and a “sequential read” can be explained based on Hard Disk Drive.\nIt consists of the head and the disk.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-11-27-how-does-btree-make-your-queries-fast/hdd-disk.webp\" alt=\"Hard Disk Drive with cover removed, Public Domain image from https://en.wikipedia.org/wiki/Hard_disk_drive#/media/File:Laptop-hard-drive-exposed.jpg\" class=\"small-image\" /\u003e\u003c/p\u003e\n\n\u003cp\u003e“Random jump” requires moving the head to the given place on the disk.\n“Sequential read” is simply spinning the disk, allowing the head to read consecutive values.\nWhen reading megabytes of data, the difference between these two types of access is enormous.\nUsing “sequential reads” lowers the time needed to fetch the data significantly.\u003c/p\u003e\n\n\u003cp\u003eDifferences in speed between random and sequential access were researched in the article “The Pathologies of Big Data”\nby Adam Jacobs, \u003ca href=\"https://queue.acm.org/detail.cfm?id=1563874\"\u003epublished in Acm Queue\u003c/a\u003e.\nIt revealed a few mind-blowing facts:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eSequential access on HDD may be hundreds of thousands of times faster than random access. 🤯\u003c/li\u003e\n  \u003cli\u003eIt may be faster to read sequentially from the disk than randomly from the memory.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eWho even uses HDD nowadays?\nWhat about SSD?\nThis research shows that reading fully sequentially from HDD may be faster than SSD.\nHowever, please note that the article is from 2009 and SSD developed significantly through the last decade,\nthus these results are probably outdated.\u003c/p\u003e\n\n\u003cp\u003eTo sum up, the key takeaway is \u003cstrong\u003eto prefer sequential access wherever we can\u003c/strong\u003e.\nIn the next paragraph, I will explain how to apply it to our index structure.\u003c/p\u003e\n\n\u003ch2 id=\"optimizing-a-tree-for-sequential-access\"\u003eOptimizing a tree for sequential access\u003c/h2\u003e\n\n\u003cp\u003eBinary Search Tree may be represented in memory in the same way\nas \u003ca href=\"https://en.wikipedia.org/wiki/Binary_heap\"\u003ethe heap\u003c/a\u003e:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eparent node position is \\(i\\)\u003c/li\u003e\n  \u003cli\u003eleft node position is \\(2i\\)\u003c/li\u003e\n  \u003cli\u003eright node position is \\(2i+1\\)\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThat’s how these positions are calculated based on the example (the parent node starts at 1):\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-11-27-how-does-btree-make-your-queries-fast/tree-representation-in-memory-1.webp\" alt=\"Binary tree representation in the memory—part 1/2\" class=\"small-image\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eAccording to the calculated positions, nodes are aligned into the memory:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-11-27-how-does-btree-make-your-queries-fast/tree-representation-in-memory-2.webp\" alt=\"Binary tree representation in the memory—part 2/2\" class=\"small-image\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eDo you remember the query visualized a few chapters ago?\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-11-27-how-does-btree-make-your-queries-fast/bst-bigger-searching.webp\" alt=\"Searching for single node within Binary Search Tree with seven nodes\" class=\"small-image\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eThat’s what it looks like on the memory level:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-11-27-how-does-btree-make-your-queries-fast/tree-representation-in-memory-query.webp\" alt=\"Binary tree representation in the memory - querying\" class=\"small-image\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eWhen performing the query, memory addresses 1, 3, and 6 need to be visited.\nVisiting three nodes is not a problem; however, as we store more data, the tree gets higher.\nStoring more than one million values requires a tree of height at least 20. It means\nthat 20 values from different places in memory must be read.\nIt causes completely random access!\u003c/p\u003e\n\n\u003ch3 id=\"pages\"\u003ePages\u003c/h3\u003e\n\n\u003cp\u003eWhile a tree grows in height, random access is causing more and more delay.\nThe solution to reduce this problem is simple: grow the tree in width rather than in height.\nIt may be achieved by packing more than one value into a single node.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-11-27-how-does-btree-make-your-queries-fast/tree-with-3-values-in-node.webp\" alt=\"A tree with three values in single node\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eIt brings us the following benefits:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003ethe tree is shallower (two levels instead of three)\u003c/li\u003e\n  \u003cli\u003eit still has a lot of space for new values without the need for growing further\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThe query performed on such index looks as follows:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-11-27-how-does-btree-make-your-queries-fast/tree-with-3-values-query.webp\" alt=\"A query performed on a tree with three values in a single node\" /\u003e\u003c/p\u003e\n\n\u003cp\u003ePlease note that every time we visit a node, we need to load all its values.\nIn this example, we need to load 4 values (or 6 if the tree is full) in order to reach the one we are looking for.\nBelow, you will find a visualization of this tree in a memory:\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-11-27-how-does-btree-make-your-queries-fast/tree-with-3-values-memory.webp\" alt=\"A tree with three values in a single node represented in a memory\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eCompared to \u003ca href=\"#optimizing-a-tree-for-sequential-access\"\u003ethe previous example\u003c/a\u003e (where the tree grows in height),\nthis search should be faster.\nWe need random access only twice (jump to cells 0 and 9) and then sequentially read the rest of values.\u003c/p\u003e\n\n\u003cp\u003eThis solution works better and better as our database grows. If you want to store one million values, then you need:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eBinary Search Tree which has \u003cstrong\u003e20\u003c/strong\u003e levels\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eOR\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003e3-value node Tree which has \u003cstrong\u003e10\u003c/strong\u003e levels\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eValues from a single node make a page.\nIn the example above, each page consists of three values.\nA page is a set of values placed on a disk next to each other,\nso the database may reach the whole page at once with one sequential read.\u003c/p\u003e\n\n\u003cp\u003eAnd how does it refer to the reality?\n\u003ca href=\"https://www.postgresql.org/docs/current/storage-toast.html#:~:text=PostgreSQL%20uses%20a%20fixed%20page,tuples%20to%20span%20multiple%20pages.\"\u003ePostgres page size is 8kB\u003c/a\u003e.\nLet’s assume that 20% is for metadata, so it’s 6kB left.\nHalf of the page is needed to store\npointers to node’s children, so it gives us 3kB for values.\nBIGINT size is 8 bytes, thus we may store ~375 values in a\nsingle page.\u003c/p\u003e\n\n\u003cp\u003eAssuming that some pretty big tables in a database have one billion rows,\nhow many levels in the Postgres tree do we need to store them?\nAccording to the calculations above,\nif we create a tree that can handle 375 values in a single node,\nit may store \u003cstrong\u003e1 billion\u003c/strong\u003e values with a tree that has only \u003cstrong\u003efour\u003c/strong\u003e levels.\nBinary Search Tree would require 30 levels for such amount of data.\u003c/p\u003e\n\n\u003cp\u003eTo sum up, placing multiple values in a single node of the tree helped us to reduce its height, thus using the benefits of sequential access.\nMoreover, a B-tree may grow not only in height, but also in width (by using larger pages).\u003c/p\u003e\n\n\u003ch2 id=\"balancing\"\u003eBalancing\u003c/h2\u003e\n\n\u003cp\u003eThere are two types of operations in databases: writing and reading.\nIn the previous section, we addressed the problems with reading the data from the B-tree.\nNonetheless, writing is also a crucial part.\nWhen writing the data to a database, B-tree needs to be constantly updated with new values.\u003c/p\u003e\n\n\u003cp\u003eThe tree shape depends on the order of values added to the tree.\nIt’s easily visible in a binary tree.\nWe may obtain trees with different depths if the values are added in an incorrect order.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-11-27-how-does-btree-make-your-queries-fast/bst-imbalance.webp\" alt=\"Two Binary Trees with shapes depending on the order of inserted values.\" class=\"small-image\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eWhen the tree has different depths on different nodes, it is called an unbalanced tree.\nThere are basically two ways of returning such a tree to a balanced state:\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003eRebuilding it from the very beginning just by adding the values in the correct order.\u003c/li\u003e\n  \u003cli\u003eKeeping it balanced all the time, as the new values are added.\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003eB-tree implements the second option. A feature that makes the tree balanced all the time is called self-balancing.\u003c/p\u003e\n\n\u003ch3 id=\"self-balancing-algorithm-by-example\"\u003eSelf-balancing algorithm by example\u003c/h3\u003e\n\n\u003cp\u003eBuilding a B-tree can be started simply by creating a single node\nand adding new values until there is no free space in it.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-11-27-how-does-btree-make-your-queries-fast/self-balancing-step-1.webp\" alt=\"Self-balancing, step 1, Add new values until there is a free space in existing nodes.\" class=\"small-image\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eIf there is no space on the corresponding page, it needs to be split.\nTo perform a split, a „split point” is chosen.\nIn that case, it will be 12, because it is in the middle.\nThe „Split point” is a value that will be moved to the upper page.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-11-27-how-does-btree-make-your-queries-fast/self-balancing-step-2a.webp\" alt=\"Self-balancing, step 2a, Splitting the page.\" class=\"small-image\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eNow, it gets us to an interesting point where there is no upper page.\nIn such a case, a new one needs to be generated (and it becomes the new root page!).\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-11-27-how-does-btree-make-your-queries-fast/self-balancing-step-2b.webp\" alt=\"Self-balancing, step 2b, Generating a new root page.\" class=\"small-image\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eAnd finally, there is some free space in the three, so value 14 may be added.\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-11-27-how-does-btree-make-your-queries-fast/self-balancing-step-2c.webp\" alt=\"Self-balancing, step 2c, Adding the 14 to B-tree.\" class=\"small-image\" /\u003e\u003c/p\u003e\n\n\u003cp\u003eFollowing this algorithm, we may constantly add new values to the B-tree, and it will remain balanced all the time!\u003c/p\u003e\n\n\u003cp\u003e\u003cimg src=\"/img/articles/2023-11-27-how-does-btree-make-your-queries-fast/self-balancing-step-final.webp\" alt=\"Self-balancing, Final state of the B-tree, after adding multiple values.\" /\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003eAt this point, you may have a valid concern that there is a lot of free space that has no chance to be\nfilled.\nFor example, values 14, 15, and 16, are on different pages, so these pages will remain with only one value and two free spaces forever.\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003eIt was caused by the split location choice.\nWe always split the page in the middle.\nBut every time we do a split, we may choose any split location we want.\u003c/em\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003ePostgres has an algorithm that is run every time a split is performed!\nIts implementation may be found in the \u003ca href=\"https://github.com/postgres/postgres/blob/54ccfd65868c013a8c6906bc894bc5ea3640740a/src/backend/access/nbtree/nbtsplitloc.c#L87\"\u003e_bt_findsplitloc() function in Postgres source code\u003c/a\u003e.\nIts goal is to leave as little free space as possible.\u003c/em\u003e\u003c/p\u003e\n\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this article, you learned how a B-tree works.\nAll in all, it may be simply described as a Binary Search Tree with two changes:\u003c/p\u003e\n\n\u003cul\u003e\n  \u003cli\u003eevery node may contain more than one value\u003c/li\u003e\n  \u003cli\u003einserting a new value is followed by a self-balancing algorithm.\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eAlthough the structures used by modern databases are usually some variants of a B-tree (like B+tree), they are still based on the original conception.\nIn my opinion, one great strength of a B-tree is the fact that it was designed directly to handle large amounts of data on actual hardware.\nIt may be the reason why the B-tree has remained with us for such a long time.\u003c/p\u003e\n","contentSnippet":"B-tree is a structure that helps to search through great amounts of data.\nIt was invented over 40 years ago, yet it is still employed by the majority of modern databases.\nAlthough there are newer index structures, like LSM trees,\nB-tree is unbeaten when handling most of the database queries.\nAfter reading this post, you will know how B-tree organises the data and how it performs search queries.\nOrigins\nIn order to understand B-tree let’s focus on Binary Search Tree (BST) first.\nWait, isn’t it the same?\nWhat does “B” stand for then?\nAccording to wikipedia.org, Edward M. McCreight, the inventor of B-tree, once said:\n“the more you think about what the B in B-trees means, the better you understand B-trees.”\nConfusing B-tree with BST is a really common misconception.\nAnyway, in my opinion, BST is a great starting point for reinventing B-tree.\nLet’s start with a simple example of BST:\n\nThe greater number is always on the right, the lower on the left. It may become clearer when we add more numbers.\n\nThis tree contains seven numbers, but we need to visit at most three nodes to locate any number.\nThe following example visualizes searching for 14.\nI used SQL to define the query in order to think about this tree as if it were an actual database index.\n\nHardware\nIn theory, using Binary Search Tree for running our queries looks fine. Its time complexity (when searching) is \\(O(log\nn)\\), same as B-tree. However, in practice, this data structure needs to work on actual hardware. An index must be\nstored somewhere on your machine.\nThe computer has three places where the data can be stored:\nCPU caches\nRAM (memory)\nDisk (storage)\nThe cache is managed fully by CPUs. Moreover, it is relatively small, usually a few megabytes.\nIndex may contain gigabytes of data, so it won’t fit there.\nDatabases vastly use Memory (RAM). It has some great advantages:\nassures fast random access (more on that in the next paragraph)\nits size may be pretty big (e.g. AWS RDS cloud service provides instances\nwith a few terabytes of memory available).\nCons? You lose the data when the power supply goes off. Moreover, when compared to the disk, it is pretty expensive.\nFinally, the cons of a memory are the pros of a disk storage.\nIt’s cheap, and data will remain there even if we lose the power.\nHowever, there are no free lunches!\nThe catch is that we need to be careful about random and sequential access.\nReading from the disk is fast, but only under certain conditions!\nI’ll try to explain them simply.\nRandom and sequential access\nMemory may be visualized as a line of containers for values, where every container is numbered.\n\nNow let’s assume we want to read data from containers 1, 4, and 6. It requires random access:\n\nAnd then let’s compare it with reading containers 3, 4, and 5. It may be done sequentially:\n\nThe difference between a “random jump” and a “sequential read” can be explained based on Hard Disk Drive.\nIt consists of the head and the disk.\n\n“Random jump” requires moving the head to the given place on the disk.\n“Sequential read” is simply spinning the disk, allowing the head to read consecutive values.\nWhen reading megabytes of data, the difference between these two types of access is enormous.\nUsing “sequential reads” lowers the time needed to fetch the data significantly.\nDifferences in speed between random and sequential access were researched in the article “The Pathologies of Big Data”\nby Adam Jacobs, published in Acm Queue.\nIt revealed a few mind-blowing facts:\nSequential access on HDD may be hundreds of thousands of times faster than random access. 🤯\nIt may be faster to read sequentially from the disk than randomly from the memory.\nWho even uses HDD nowadays?\nWhat about SSD?\nThis research shows that reading fully sequentially from HDD may be faster than SSD.\nHowever, please note that the article is from 2009 and SSD developed significantly through the last decade,\nthus these results are probably outdated.\nTo sum up, the key takeaway is to prefer sequential access wherever we can.\nIn the next paragraph, I will explain how to apply it to our index structure.\nOptimizing a tree for sequential access\nBinary Search Tree may be represented in memory in the same way\nas the heap:\nparent node position is \\(i\\)\nleft node position is \\(2i\\)\nright node position is \\(2i+1\\)\nThat’s how these positions are calculated based on the example (the parent node starts at 1):\n\nAccording to the calculated positions, nodes are aligned into the memory:\n\nDo you remember the query visualized a few chapters ago?\n\nThat’s what it looks like on the memory level:\n\nWhen performing the query, memory addresses 1, 3, and 6 need to be visited.\nVisiting three nodes is not a problem; however, as we store more data, the tree gets higher.\nStoring more than one million values requires a tree of height at least 20. It means\nthat 20 values from different places in memory must be read.\nIt causes completely random access!\nPages\nWhile a tree grows in height, random access is causing more and more delay.\nThe solution to reduce this problem is simple: grow the tree in width rather than in height.\nIt may be achieved by packing more than one value into a single node.\n\nIt brings us the following benefits:\nthe tree is shallower (two levels instead of three)\nit still has a lot of space for new values without the need for growing further\nThe query performed on such index looks as follows:\n\nPlease note that every time we visit a node, we need to load all its values.\nIn this example, we need to load 4 values (or 6 if the tree is full) in order to reach the one we are looking for.\nBelow, you will find a visualization of this tree in a memory:\n\nCompared to the previous example (where the tree grows in height),\nthis search should be faster.\nWe need random access only twice (jump to cells 0 and 9) and then sequentially read the rest of values.\nThis solution works better and better as our database grows. If you want to store one million values, then you need:\nBinary Search Tree which has 20 levels\nOR\n3-value node Tree which has 10 levels\nValues from a single node make a page.\nIn the example above, each page consists of three values.\nA page is a set of values placed on a disk next to each other,\nso the database may reach the whole page at once with one sequential read.\nAnd how does it refer to the reality?\nPostgres page size is 8kB.\nLet’s assume that 20% is for metadata, so it’s 6kB left.\nHalf of the page is needed to store\npointers to node’s children, so it gives us 3kB for values.\nBIGINT size is 8 bytes, thus we may store ~375 values in a\nsingle page.\nAssuming that some pretty big tables in a database have one billion rows,\nhow many levels in the Postgres tree do we need to store them?\nAccording to the calculations above,\nif we create a tree that can handle 375 values in a single node,\nit may store 1 billion values with a tree that has only four levels.\nBinary Search Tree would require 30 levels for such amount of data.\nTo sum up, placing multiple values in a single node of the tree helped us to reduce its height, thus using the benefits of sequential access.\nMoreover, a B-tree may grow not only in height, but also in width (by using larger pages).\nBalancing\nThere are two types of operations in databases: writing and reading.\nIn the previous section, we addressed the problems with reading the data from the B-tree.\nNonetheless, writing is also a crucial part.\nWhen writing the data to a database, B-tree needs to be constantly updated with new values.\nThe tree shape depends on the order of values added to the tree.\nIt’s easily visible in a binary tree.\nWe may obtain trees with different depths if the values are added in an incorrect order.\n\nWhen the tree has different depths on different nodes, it is called an unbalanced tree.\nThere are basically two ways of returning such a tree to a balanced state:\nRebuilding it from the very beginning just by adding the values in the correct order.\nKeeping it balanced all the time, as the new values are added.\nB-tree implements the second option. A feature that makes the tree balanced all the time is called self-balancing.\nSelf-balancing algorithm by example\nBuilding a B-tree can be started simply by creating a single node\nand adding new values until there is no free space in it.\n\nIf there is no space on the corresponding page, it needs to be split.\nTo perform a split, a „split point” is chosen.\nIn that case, it will be 12, because it is in the middle.\nThe „Split point” is a value that will be moved to the upper page.\n\nNow, it gets us to an interesting point where there is no upper page.\nIn such a case, a new one needs to be generated (and it becomes the new root page!).\n\nAnd finally, there is some free space in the three, so value 14 may be added.\n\nFollowing this algorithm, we may constantly add new values to the B-tree, and it will remain balanced all the time!\n\nAt this point, you may have a valid concern that there is a lot of free space that has no chance to be\nfilled.\nFor example, values 14, 15, and 16, are on different pages, so these pages will remain with only one value and two free spaces forever.\nIt was caused by the split location choice.\nWe always split the page in the middle.\nBut every time we do a split, we may choose any split location we want.\nPostgres has an algorithm that is run every time a split is performed!\nIts implementation may be found in the _bt_findsplitloc() function in Postgres source code.\nIts goal is to leave as little free space as possible.\nSummary\nIn this article, you learned how a B-tree works.\nAll in all, it may be simply described as a Binary Search Tree with two changes:\nevery node may contain more than one value\ninserting a new value is followed by a self-balancing algorithm.\nAlthough the structures used by modern databases are usually some variants of a B-tree (like B+tree), they are still based on the original conception.\nIn my opinion, one great strength of a B-tree is the fact that it was designed directly to handle large amounts of data on actual hardware.\nIt may be the reason why the B-tree has remained with us for such a long time.","guid":"https://blog.allegro.tech/2023/11/how-does-btree-make-your-queries-fast.html","categories":["tech"],"isoDate":"2023-11-26T23:00:00.000Z","thumbnail":"images/post-headers/default.jpg"},{"title":"Beyond the Code - An Engineer’s Battle Against Knowledge Loss","link":"https://blog.allegro.tech/2023/10/battle-against-knowledge-loss.html","pubDate":"Mon, 30 Oct 2023 00:00:00 +0100","authors":{"author":[{"name":["Krzysztof Przychodzki"],"photo":["https://blog.allegro.tech/img/authors/krzysztof.przychodzki.jpg"],"url":["https://blog.allegro.tech/authors/krzysztof.przychodzki"]}]},"content":"\u003cp\u003eThe idea for this article arose during a meeting where we learned that our supervisor would be leaving the company to pursue new opportunities. In response, a\ncolleague lamented that what we would miss most is the knowledge departing with the leader. Unfortunately, that’s how it goes. Not only do we lose a colleague,\nbut we also lose valuable knowledge and experience. However, this isn’t a story about my supervisor; it’s a story about all those individuals who are experts in\ntheir fields, who understand the paths to success and paths that lead to catastrophic failures. When they leave, they take with them knowledge that you won’t\nfind in any book, note, or Jira ticket. And this leads to a fundamental question: \u003cem\u003eWhat can be done to avoid this “black hole” of knowledge? How can we ensure\nit doesn’t vanish along with them?\u003c/em\u003e That’s what this article is all about.\u003c/p\u003e\n\n\u003ch2 id=\"business-decisions-somebody-made-and-didnt-tell-you\"\u003eBusiness Decisions Somebody Made… and didn’t tell you\u003c/h2\u003e\n\n\u003cp\u003eSpecifically for this article I created the term \u003cem\u003eBiological Data Storage\u003c/em\u003e or \u003cem\u003eBDS\u003c/em\u003e for short. This term encompasses nearly every employee in a company. I\nunderstand that nobody wants to be seen as just a resource, and certainly not as part of the \u003cem\u003eBiological Data Storage\u003c/em\u003e. However, in the context of a company’s\nresources, an employee can be likened to a technical data repository, but with the valuable addition of context.\u003c/p\u003e\n\n\u003cp\u003eI wanted to examine this issue more broadly from an engineer’s perspective. We often hear about Conway’s Law:\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003eAny organization that designs a system (defined broadly) will produce a design whose structure is a copy of the organization’s communication structure. \u003csup id=\"fnref:1\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:1\" class=\"footnote\" rel=\"footnote\"\u003e1\u003c/a\u003e\u003c/sup\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eAnd I perceive the loss of knowledge as a depletion of communication, which can ultimately result in its imperfections within the created system.\u003c/p\u003e\n\n\u003cp\u003eThe engineering approach is marked by our commitment to gauging the impact of various events and assessing their real significance using specific metrics. When\ndealing with the challenge of an employee departing, consider these metrics to evaluate organizational effectiveness:\u003c/p\u003e\n\n\u003col\u003e\n  \u003cli\u003eTime to Problem Resolution:\n    \u003cul\u003e\n      \u003cli\u003emeasures how quickly issues or challenges are resolved and helps identify the efficiency of problem-solving processes.\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eKnowledge Transfer Rate:\n    \u003cul\u003e\n      \u003cli\u003emeasures how long it takes for a new employee to become self-sufficient and also indicates the effectiveness of knowledge transfer and onboarding.\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cp\u003eI think these metrics provide valuable insights into organizational efficiency and its capacity to seamlessly integrate new team members.\nIn the context of Conway’s Law, the loss of knowledge becomes a critical factor influencing not only communication but also the very design of systems within\nthe company.\u003c/p\u003e\n\n\u003cp\u003eConsider this: when a team member with a wealth of knowledge and expertise departs, they take with them not just facts and figures but also their unique\ninsights, problem-solving approaches, and understanding of the organization’s intricacies. The lack of such knowledge can disrupt the flow of information within\nteams and across departments. As a result, the communication structure can falter, hindering the organization’s ability to respond to challenges effectively.\u003c/p\u003e\n\n\u003cp\u003eMoreover, the design of systems can be profoundly impacted. Engineers and developers who were privy to invaluable knowledge may have made design choices based\non their expertise. These decisions may not have been documented or clearly understood by others, and when their authors leave, may become opaque. This can lead\nto difficulties in maintaining and developing these systems, potentially causing inefficiencies and vulnerabilities.\u003c/p\u003e\n\n\u003cp\u003eNow, when we introduce the \u003cem\u003eKnowledge Transfer Rate\u003c/em\u003e metric into this context, it becomes evident that measuring how long it takes for a new employee to become\nself-sufficient is crucial. The longer this duration, the more pronounced the knowledge gap becomes, affecting both communication and system design.\nOrganizations must recognize that knowledge isn’t just about data; it’s about understanding and context, and its loss can significantly impede the smooth\nfunctioning of teams and the evolution of systems.\u003c/p\u003e\n\n\u003ch2 id=\"organizations-have-no-memory\"\u003eOrganizations have no memory\u003c/h2\u003e\n\n\u003cp\u003eYou might ask, “What’s the impact of losing this knowledge on a company?” Is it that business processes start collapsing like houses of cards? Innovation loses\nits wings? The company’s efficiency plummets like leaves in an autumn storm?\nThe answer to the above questions in 98% of cases is - of course, no - because we can manage such risks. Companies have ways of dealing with them, but do they,\nreally?\u003c/p\u003e\n\n\u003cp\u003e\u003cem\u003eOrganizations have no memory\u003c/em\u003e is a quote from Trevor Kletz’s book \u003cem\u003eLessons from Disaster\u003c/em\u003e, which highlights the concept of organizational memory and how\nincidents and accidents can recur due to the lack of effective learning from past mistakes within an organization. Prof. Kletz highlights the organization’s\ninability to learn from accidents, even those occurring within the company. I sometimes feel that a similar pattern emerges when knowledge departs from our\ncompany. Perhaps because it can’t be easily measured in money, it’s often downplayed.\u003c/p\u003e\n\n\u003cp\u003eWhile Kletz’s book pertains to chemical engineering, I see several universal truths that apply to any situation and industry. For example, another quote, “What\nyou don’t have, can’t leak” is remarkably similar to the idea that code you don’t have is \u003cem\u003emaintainless\u003c/em\u003e and won’t have bugs. There are likely analogous\nprinciples in our field.\u003c/p\u003e\n\n\u003cp\u003eHowever, even at this stage, the process of knowledge acquisition can be accelerated. There are several ways to do it, such as creating procedures, diagrams,\ncharts, and documentation.\u003c/p\u003e\n\n\u003cp\u003eDocumentation is like treasure maps in the business world. Creating documentation is one thing, but keeping it up-to-date within an organization (regardless of\nits size) is a challenge. Encouraging the team to regularly update documentation is also a challenge. Even the best-prepared documentation often lacks many\ndetails, like the rationale behind specific business decisions, why a particular database or framework was chosen, or why we use technology \u003cem\u003eY\u003c/em\u003e instead of the\nmore prevalent \u003cem\u003eX\u003c/em\u003e throughout the company.\u003c/p\u003e\n\n\u003cp\u003eSo, while documentation is like treasure maps for your company, recorded, organized, and structured information about processes, systems, and practices within\nthe company are akin to Architecture Decision Records (ADRs). ADRs are like the flight recorders of our business. They contain records of critical decisions\nmade during system design or significant technological choices.\u003c/p\u003e\n\n\u003cp\u003eWhy is this important? When creating new things, we make numerous decisions that may appear irrational without the right context later on. ADRs are like opening\na box that explains why these decisions were made. It’s the key to understanding the company’s history and evolution. In the context of our \u003cem\u003eBDS\u003c/em\u003e, ADRs are\nlike recordings of experts’ thoughts when making key decisions. When these experts leave, these recordings become a treasure trove of knowledge, helping us\navoid repeating the same mistakes.\u003c/p\u003e\n\n\u003cp\u003eA common scenario emerges: the team tasked with addressing the problem must invest valuable time in rediscovering solutions, experimenting with potential fixes,\nor even resorting to trial and error. This not only prolongs the problem-solving process but can also result in suboptimal resolutions, increased frustration,\nand a negative impact on overall productivity. Thanks to documentation and ADR we can significantly reduce this time.\u003c/p\u003e\n\n\u003ch2 id=\"an-alternative-to-lengthy-documentation\"\u003eAn alternative to lengthy documentation?\u003c/h2\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003eNo one reads.\nIf someone does read, he doesn’t understand.\nIf he understands, he immediately forgets.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eUnfortunately, just as is the case in the above quote from Stanisław Lem \u003csup id=\"fnref:2\" role=\"doc-noteref\"\u003e\u003ca href=\"#fn:2\" class=\"footnote\" rel=\"footnote\"\u003e2\u003c/a\u003e\u003c/sup\u003e, the problem with documentation, procedures, and ADRs is that people need to\nfamiliarize themselves with them. I suppose that even at SpaceX, it’s doubtful this would be considered the most thrilling reading material, or maybe I am just\nmistaken. Anyway, even if someone manages to get through the documentation, they’ll only retain what they understand. We’re presented with the work of others,\nwith their imposed ways of thinking and decision-making. Often, questions arise to which no one knows the answers, and the people who do know are no longer with\nthe company.\u003c/p\u003e\n\n\u003cp\u003eSince we now know our mental limitations, instead of forcing people to sift through stacks of documentation, we can\nuse \u003ca href=\"https://blog.allegro.tech/2022/07/event-storming-workshops.html\"\u003eEventStorming\u003c/a\u003e. This technique helps understand business processes, identify events and\nactivities, and integrate knowledge in an understandable way. We focus on behaviors, on what changes and why. Together, we develop a solution and understand the\nprocesses because we see them from start to finish. Understanding a process through EventStorming is faster and easier than reading documentation. During an\nEventStorming session, most questions find answers, and knowledge can be conveyed to many people simultaneously, whether they are technical or not. The most\nsignificant artifact of such sessions is that you can discuss why the process looks the way it does, why a specific sequence was chosen, and not another —\nessentially, a mega-mix of documentation, ADR, and conversation. I emphasize once more that this understanding of the process is developed collectively —\neveryone feels as a part of the solution. In the case of our \u003cem\u003eBDS\u003c/em\u003e, EventStorming is like capturing the thoughts of experts when making crucial decisions.\u003c/p\u003e\n\n\u003ch3 id=\"real-life-example\"\u003eReal life example\u003c/h3\u003e\n\n\u003cp\u003eAt \u003ca href=\"https://allegro.tech/\"\u003eAllegro\u003c/a\u003e, we recently had a situation where the entire development team responsible for a critical service was moved to a different\nproject. The new team, which inherited the service, had the opportunity to collaborate with the departing team for a period. However, in this context, we also\nconducted EventStorming sessions. To provide more detail, these sessions extended over two full days, each lasting 8 hours. The knowledge accumulated over the\npast five years was not merely confined to two plotter paper-sized sheets, each stretching 6 meters in length, but was primarily assimilated within the\nparticipants’ minds in a seamless manner. I believe this facilitated the new team in gaining greater confidence when taking over the domain.\u003c/p\u003e\n\n\u003cp\u003eInterestingly, you don’t need to spend a lot of time on EventStorming to uncover enough business knowledge. In the case mentioned earlier, the session lasted\ntwo days, but it involved an entire team. For an individual, a two-hour workshop can be enough to see the big picture of our process. Although EventStorming\nallows us to absorb a dose of knowledge relatively easily to know \u003cem\u003ewhat and why\u003c/em\u003e is changing in our process, the devil is in the detail. To really understand\n\u003cem\u003ehow\u003c/em\u003e this process is changing, it’s best to start by doing small tasks under the guidance of an experienced person.\u003c/p\u003e\n\n\u003ch2 id=\"seeking-uml-like-alternatives\"\u003eSeeking UML-like Alternatives?\u003c/h2\u003e\n\n\u003cp\u003eUnfortunately, EventStorming is not the answer to all knowledge loss-related problems. While I don’t question how fantastic this tool is, the knowledge acquired\nthrough it will remain only in the participants’ minds. If it’s not somehow preserved in the form of documentation or ADRs, it may turn out to be just as\nfleeting as departing employees. What can be done about this? Our initial thoughts may lead us to create some form of description or documentation, which, as we\nknow, comes with the challenge of its preparation and the cognitive overload for someone trying to assimilate new knowledge.\u003c/p\u003e\n\n\u003cp\u003eIt seems that when dealing with the issue of knowledge loss and its effective transfer, it’s worth mentioning tools like BPMN, which stands for Business Process\nModel and Notation. BPMN provides a standardized graphical representation of business processes. By using BPMN diagrams, we can visually map\nworkflows and procedures. Such an approach not only simplifies the understanding of complex processes but also aids in comprehensive documentation. When\ncombined with other knowledge-sharing techniques, such as EventStorming, BPMN can be a powerful asset in preserving and transferring critical business\nknowledge.\u003c/p\u003e\n\n\u003cp\u003eHowever, BPMN has an elaborate set of symbols and notation rules, which can make creating and interpreting diagrams complicated for some individuals. Creating\nadvanced BPMN diagrams and fully utilizing the notation’s potential requires specialized knowledge and experience. People unfamiliar with BPMN may struggle\nto use it effectively. Despite these inconveniences, BPMN still remains a valuable tool for modeling and documenting business processes in many organizations. I\nbelieve it complements the previously mentioned techniques perfectly.\u003c/p\u003e\n\n\u003cp\u003eJust remember to have the right tools in your arsenal and, more importantly, to choose the appropriate tool for the situation, considering both its strengths\nand weaknesses.\u003c/p\u003e\n\n\u003ch2 id=\"one-more-thing\"\u003eOne more thing…\u003c/h2\u003e\n\n\u003cp\u003e\u003cem\u003eTime to Problem Resolution\u003c/em\u003e metric serves as a clear indicator of an organization’s efficiency in addressing challenges. A shorter time to resolution signifies\nthat issues are tackled swiftly, minimizing disruptions and ensuring that the organization operates smoothly.\n\u003cem\u003eKnowledge Transfer Rate\u003c/em\u003e metric is a means to quantify and address the loss of knowledge, shedding light on its impact on communication structures and system\ndesign within an organization.\u003c/p\u003e\n\n\u003cp\u003eBoth metrics are directly influenced by the use of appropriate tools such as documentation, ADRs, EventStorming or BPMN. I have tried to highlight their\nadvantages and disadvantages in the context of knowledge transfer.\u003c/p\u003e\n\n\u003cp\u003eHowever, there is another challenge - changing the company’s culture. Employees must know what tools they have and feel that sharing knowledge is key to\nsuccess. Leadership plays a crucial role here, as leaders need to actively promote and engage in knowledge sharing and open communication. If company leaders\nactively endorse and engage in knowledge sharing, other employees are more likely to follow suit. However, changing organizational culture is a time-consuming\nprocess. Patience and perseverance are essential until new behaviors and beliefs prevail over old ones.\u003c/p\u003e\n\n\u003ch2 id=\"this-can-be-done\"\u003eThis can be done\u003c/h2\u003e\n\n\u003cp\u003eAs an engineer in an organisation, regardless of size, there are several proactive steps you can take to facilitate knowledge transfer. First and foremost,\nactively engage in open communication with your colleagues. Encourage discussion and information sharing, especially within your area of expertise, to ensure\nthat valuable insights are shared. Second, mentorship can be a powerful tool. Offer to mentor junior team members or be open to seeking guidance from more\nexperienced colleagues. In addition, participate in knowledge-sharing initiatives within the company, such as brown bag sessions, workshops or cross-functional\nprojects. Finally, consider creating or contributing to internal documentation and repositories. These resources can serve as valuable references for your\ncolleagues and future team members, ensuring that knowledge is retained within the organisation. By actively participating in these practices, you can play a\nkey role in preserving and transferring critical knowledge within your organisation.\u003c/p\u003e\n\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\n\u003cp\u003eIn this article, I aimed to discuss how knowledge loss in a company appears through an engineer’s eyes and why it can pose a threat. The term \u003cem\u003eBiological Data\nStorage\u003c/em\u003e may sound unconventional, but it emphasises the critical role that every team member plays in preserving and transferring knowledge. It’s important to\nremember that employees are not just resources; they are the living repositories of valuable information, experience and expertise. In the world of \u003cem\u003eBDS\u003c/em\u003e, every\nmember contributes to the collective body of knowledge, shaping the organisation’s communication structure.\nAs we say goodbye to departing colleagues, let’s also say goodbye to the notion that knowledge should be confined to individual minds. Instead, let’s adopt a\nculture of open communication, active knowledge sharing and the right tools, such as EventStorming and BPMN, to capture, preserve and share critical knowledge\nacross our organisation.\u003c/p\u003e\n\n\u003ch3 id=\"footnotes\"\u003eFootnotes\u003c/h3\u003e\n\n\u003cdiv class=\"footnotes\" role=\"doc-endnotes\"\u003e\n  \u003col\u003e\n    \u003cli id=\"fn:1\" role=\"doc-endnote\"\u003e\n      \u003cp\u003eQuote from https://en.wikipedia.org/wiki/Conway%27s_law \u003ca href=\"#fnref:1\" class=\"reversefootnote\" role=\"doc-backlink\"\u003e\u0026#8617;\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n    \u003cli id=\"fn:2\" role=\"doc-endnote\"\u003e\n      \u003cp\u003ehttps://en.wikipedia.org/wiki/Stanis%C5%82aw_Lem \u003ca href=\"#fnref:2\" class=\"reversefootnote\" role=\"doc-backlink\"\u003e\u0026#8617;\u003c/a\u003e\u003c/p\u003e\n    \u003c/li\u003e\n  \u003c/ol\u003e\n\u003c/div\u003e\n","contentSnippet":"The idea for this article arose during a meeting where we learned that our supervisor would be leaving the company to pursue new opportunities. In response, a\ncolleague lamented that what we would miss most is the knowledge departing with the leader. Unfortunately, that’s how it goes. Not only do we lose a colleague,\nbut we also lose valuable knowledge and experience. However, this isn’t a story about my supervisor; it’s a story about all those individuals who are experts in\ntheir fields, who understand the paths to success and paths that lead to catastrophic failures. When they leave, they take with them knowledge that you won’t\nfind in any book, note, or Jira ticket. And this leads to a fundamental question: What can be done to avoid this “black hole” of knowledge? How can we ensure\nit doesn’t vanish along with them? That’s what this article is all about.\nBusiness Decisions Somebody Made… and didn’t tell you\nSpecifically for this article I created the term Biological Data Storage or BDS for short. This term encompasses nearly every employee in a company. I\nunderstand that nobody wants to be seen as just a resource, and certainly not as part of the Biological Data Storage. However, in the context of a company’s\nresources, an employee can be likened to a technical data repository, but with the valuable addition of context.\nI wanted to examine this issue more broadly from an engineer’s perspective. We often hear about Conway’s Law:\nAny organization that designs a system (defined broadly) will produce a design whose structure is a copy of the organization’s communication structure. 1\nAnd I perceive the loss of knowledge as a depletion of communication, which can ultimately result in its imperfections within the created system.\nThe engineering approach is marked by our commitment to gauging the impact of various events and assessing their real significance using specific metrics. When\ndealing with the challenge of an employee departing, consider these metrics to evaluate organizational effectiveness:\nTime to Problem Resolution:\n    \nmeasures how quickly issues or challenges are resolved and helps identify the efficiency of problem-solving processes.\nKnowledge Transfer Rate:\n    \nmeasures how long it takes for a new employee to become self-sufficient and also indicates the effectiveness of knowledge transfer and onboarding.\nI think these metrics provide valuable insights into organizational efficiency and its capacity to seamlessly integrate new team members.\nIn the context of Conway’s Law, the loss of knowledge becomes a critical factor influencing not only communication but also the very design of systems within\nthe company.\nConsider this: when a team member with a wealth of knowledge and expertise departs, they take with them not just facts and figures but also their unique\ninsights, problem-solving approaches, and understanding of the organization’s intricacies. The lack of such knowledge can disrupt the flow of information within\nteams and across departments. As a result, the communication structure can falter, hindering the organization’s ability to respond to challenges effectively.\nMoreover, the design of systems can be profoundly impacted. Engineers and developers who were privy to invaluable knowledge may have made design choices based\non their expertise. These decisions may not have been documented or clearly understood by others, and when their authors leave, may become opaque. This can lead\nto difficulties in maintaining and developing these systems, potentially causing inefficiencies and vulnerabilities.\nNow, when we introduce the Knowledge Transfer Rate metric into this context, it becomes evident that measuring how long it takes for a new employee to become\nself-sufficient is crucial. The longer this duration, the more pronounced the knowledge gap becomes, affecting both communication and system design.\nOrganizations must recognize that knowledge isn’t just about data; it’s about understanding and context, and its loss can significantly impede the smooth\nfunctioning of teams and the evolution of systems.\nOrganizations have no memory\nYou might ask, “What’s the impact of losing this knowledge on a company?” Is it that business processes start collapsing like houses of cards? Innovation loses\nits wings? The company’s efficiency plummets like leaves in an autumn storm?\nThe answer to the above questions in 98% of cases is - of course, no - because we can manage such risks. Companies have ways of dealing with them, but do they,\nreally?\nOrganizations have no memory is a quote from Trevor Kletz’s book Lessons from Disaster, which highlights the concept of organizational memory and how\nincidents and accidents can recur due to the lack of effective learning from past mistakes within an organization. Prof. Kletz highlights the organization’s\ninability to learn from accidents, even those occurring within the company. I sometimes feel that a similar pattern emerges when knowledge departs from our\ncompany. Perhaps because it can’t be easily measured in money, it’s often downplayed.\nWhile Kletz’s book pertains to chemical engineering, I see several universal truths that apply to any situation and industry. For example, another quote, “What\nyou don’t have, can’t leak” is remarkably similar to the idea that code you don’t have is maintainless and won’t have bugs. There are likely analogous\nprinciples in our field.\nHowever, even at this stage, the process of knowledge acquisition can be accelerated. There are several ways to do it, such as creating procedures, diagrams,\ncharts, and documentation.\nDocumentation is like treasure maps in the business world. Creating documentation is one thing, but keeping it up-to-date within an organization (regardless of\nits size) is a challenge. Encouraging the team to regularly update documentation is also a challenge. Even the best-prepared documentation often lacks many\ndetails, like the rationale behind specific business decisions, why a particular database or framework was chosen, or why we use technology Y instead of the\nmore prevalent X throughout the company.\nSo, while documentation is like treasure maps for your company, recorded, organized, and structured information about processes, systems, and practices within\nthe company are akin to Architecture Decision Records (ADRs). ADRs are like the flight recorders of our business. They contain records of critical decisions\nmade during system design or significant technological choices.\nWhy is this important? When creating new things, we make numerous decisions that may appear irrational without the right context later on. ADRs are like opening\na box that explains why these decisions were made. It’s the key to understanding the company’s history and evolution. In the context of our BDS, ADRs are\nlike recordings of experts’ thoughts when making key decisions. When these experts leave, these recordings become a treasure trove of knowledge, helping us\navoid repeating the same mistakes.\nA common scenario emerges: the team tasked with addressing the problem must invest valuable time in rediscovering solutions, experimenting with potential fixes,\nor even resorting to trial and error. This not only prolongs the problem-solving process but can also result in suboptimal resolutions, increased frustration,\nand a negative impact on overall productivity. Thanks to documentation and ADR we can significantly reduce this time.\nAn alternative to lengthy documentation?\nNo one reads.\nIf someone does read, he doesn’t understand.\nIf he understands, he immediately forgets.\nUnfortunately, just as is the case in the above quote from Stanisław Lem 2, the problem with documentation, procedures, and ADRs is that people need to\nfamiliarize themselves with them. I suppose that even at SpaceX, it’s doubtful this would be considered the most thrilling reading material, or maybe I am just\nmistaken. Anyway, even if someone manages to get through the documentation, they’ll only retain what they understand. We’re presented with the work of others,\nwith their imposed ways of thinking and decision-making. Often, questions arise to which no one knows the answers, and the people who do know are no longer with\nthe company.\nSince we now know our mental limitations, instead of forcing people to sift through stacks of documentation, we can\nuse EventStorming. This technique helps understand business processes, identify events and\nactivities, and integrate knowledge in an understandable way. We focus on behaviors, on what changes and why. Together, we develop a solution and understand the\nprocesses because we see them from start to finish. Understanding a process through EventStorming is faster and easier than reading documentation. During an\nEventStorming session, most questions find answers, and knowledge can be conveyed to many people simultaneously, whether they are technical or not. The most\nsignificant artifact of such sessions is that you can discuss why the process looks the way it does, why a specific sequence was chosen, and not another —\nessentially, a mega-mix of documentation, ADR, and conversation. I emphasize once more that this understanding of the process is developed collectively —\neveryone feels as a part of the solution. In the case of our BDS, EventStorming is like capturing the thoughts of experts when making crucial decisions.\nReal life example\nAt Allegro, we recently had a situation where the entire development team responsible for a critical service was moved to a different\nproject. The new team, which inherited the service, had the opportunity to collaborate with the departing team for a period. However, in this context, we also\nconducted EventStorming sessions. To provide more detail, these sessions extended over two full days, each lasting 8 hours. The knowledge accumulated over the\npast five years was not merely confined to two plotter paper-sized sheets, each stretching 6 meters in length, but was primarily assimilated within the\nparticipants’ minds in a seamless manner. I believe this facilitated the new team in gaining greater confidence when taking over the domain.\nInterestingly, you don’t need to spend a lot of time on EventStorming to uncover enough business knowledge. In the case mentioned earlier, the session lasted\ntwo days, but it involved an entire team. For an individual, a two-hour workshop can be enough to see the big picture of our process. Although EventStorming\nallows us to absorb a dose of knowledge relatively easily to know what and why is changing in our process, the devil is in the detail. To really understand\nhow this process is changing, it’s best to start by doing small tasks under the guidance of an experienced person.\nSeeking UML-like Alternatives?\nUnfortunately, EventStorming is not the answer to all knowledge loss-related problems. While I don’t question how fantastic this tool is, the knowledge acquired\nthrough it will remain only in the participants’ minds. If it’s not somehow preserved in the form of documentation or ADRs, it may turn out to be just as\nfleeting as departing employees. What can be done about this? Our initial thoughts may lead us to create some form of description or documentation, which, as we\nknow, comes with the challenge of its preparation and the cognitive overload for someone trying to assimilate new knowledge.\nIt seems that when dealing with the issue of knowledge loss and its effective transfer, it’s worth mentioning tools like BPMN, which stands for Business Process\nModel and Notation. BPMN provides a standardized graphical representation of business processes. By using BPMN diagrams, we can visually map\nworkflows and procedures. Such an approach not only simplifies the understanding of complex processes but also aids in comprehensive documentation. When\ncombined with other knowledge-sharing techniques, such as EventStorming, BPMN can be a powerful asset in preserving and transferring critical business\nknowledge.\nHowever, BPMN has an elaborate set of symbols and notation rules, which can make creating and interpreting diagrams complicated for some individuals. Creating\nadvanced BPMN diagrams and fully utilizing the notation’s potential requires specialized knowledge and experience. People unfamiliar with BPMN may struggle\nto use it effectively. Despite these inconveniences, BPMN still remains a valuable tool for modeling and documenting business processes in many organizations. I\nbelieve it complements the previously mentioned techniques perfectly.\nJust remember to have the right tools in your arsenal and, more importantly, to choose the appropriate tool for the situation, considering both its strengths\nand weaknesses.\nOne more thing…\nTime to Problem Resolution metric serves as a clear indicator of an organization’s efficiency in addressing challenges. A shorter time to resolution signifies\nthat issues are tackled swiftly, minimizing disruptions and ensuring that the organization operates smoothly.\nKnowledge Transfer Rate metric is a means to quantify and address the loss of knowledge, shedding light on its impact on communication structures and system\ndesign within an organization.\nBoth metrics are directly influenced by the use of appropriate tools such as documentation, ADRs, EventStorming or BPMN. I have tried to highlight their\nadvantages and disadvantages in the context of knowledge transfer.\nHowever, there is another challenge - changing the company’s culture. Employees must know what tools they have and feel that sharing knowledge is key to\nsuccess. Leadership plays a crucial role here, as leaders need to actively promote and engage in knowledge sharing and open communication. If company leaders\nactively endorse and engage in knowledge sharing, other employees are more likely to follow suit. However, changing organizational culture is a time-consuming\nprocess. Patience and perseverance are essential until new behaviors and beliefs prevail over old ones.\nThis can be done\nAs an engineer in an organisation, regardless of size, there are several proactive steps you can take to facilitate knowledge transfer. First and foremost,\nactively engage in open communication with your colleagues. Encourage discussion and information sharing, especially within your area of expertise, to ensure\nthat valuable insights are shared. Second, mentorship can be a powerful tool. Offer to mentor junior team members or be open to seeking guidance from more\nexperienced colleagues. In addition, participate in knowledge-sharing initiatives within the company, such as brown bag sessions, workshops or cross-functional\nprojects. Finally, consider creating or contributing to internal documentation and repositories. These resources can serve as valuable references for your\ncolleagues and future team members, ensuring that knowledge is retained within the organisation. By actively participating in these practices, you can play a\nkey role in preserving and transferring critical knowledge within your organisation.\nSummary\nIn this article, I aimed to discuss how knowledge loss in a company appears through an engineer’s eyes and why it can pose a threat. The term Biological Data\nStorage may sound unconventional, but it emphasises the critical role that every team member plays in preserving and transferring knowledge. It’s important to\nremember that employees are not just resources; they are the living repositories of valuable information, experience and expertise. In the world of BDS, every\nmember contributes to the collective body of knowledge, shaping the organisation’s communication structure.\nAs we say goodbye to departing colleagues, let’s also say goodbye to the notion that knowledge should be confined to individual minds. Instead, let’s adopt a\nculture of open communication, active knowledge sharing and the right tools, such as EventStorming and BPMN, to capture, preserve and share critical knowledge\nacross our organisation.\nFootnotes\nQuote from https://en.wikipedia.org/wiki/Conway%27s_law ↩\nhttps://en.wikipedia.org/wiki/Stanis%C5%82aw_Lem ↩","guid":"https://blog.allegro.tech/2023/10/battle-against-knowledge-loss.html","categories":["eventstorming","knowledge-preservation","tech","communication"],"isoDate":"2023-10-29T23:00:00.000Z","thumbnail":"images/post-headers/eventstorming.png"}],"jobs":[{"id":"743999959852738","name":"Senior Front-End Software Engineer - Merchant Experience","uuid":"dd82268e-c1db-4885-9977-4c44d3faa3c2","jobAdId":"db0fc952-c047-4dd0-9c96-c4b6650982fc","defaultJobAd":false,"refNumber":"REF3941R","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2024-01-16T13:31:39.741Z","location":{"city":"Warszawa, Poznań","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572770","label":"IT - Software Development"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"id":"permanent","label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Recruitment Process","valueId":"ed4682c7-33c9-41c2-8d13-428ed39046f5","valueLabel":"Tech. Engineer - IC"},{"fieldId":"6406f92e638cbb2f415a94a9","fieldLabel":"Job Area","valueId":"e8731ea4-48a9-476d-ab1d-9a40eb3426f1","valueLabel":"Technology"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"61583054f15cea434e0be36f","fieldLabel":"Career Level","valueId":"3c97f53f-19c2-4a25-9eb1-513f9fb38b80","valueLabel":"3-5"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572770","valueLabel":"IT - Software Development"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro sp. z o.o."},{"fieldId":"61582f70e72a6b6d239c9857","fieldLabel":"Area","valueId":"76599a72-f283-4550-9303-52e2e0eb6e32","valueLabel":"Technology"}],"visibility":"INTERNAL","ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999959852738","language":{"code":"en-GB","label":"English (UK)","labelNative":"English (UK)"}},{"id":"743999958525968","name":"Software Engineer Java - Allegro Retail","uuid":"2eaf0599-d3d2-4b1f-8676-ec82c58114bb","jobAdId":"2b53fed0-4b15-488e-a1be-516a97bf5866","defaultJobAd":true,"refNumber":"REF4327W","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2024-01-12T08:48:17.078Z","location":{"city":"Prague, Hybrid","country":"cz","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572770","label":"IT - Software Development"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"id":"permanent","label":"Full-time"},"experienceLevel":{"id":"associate","label":"Associate"},"customField":[{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Recruitment Process","valueId":"f2bb5bc2-3fb0-4d5a-96d2-59e7d59ab3d7","valueLabel":"Tech Engineer/Non-Engineer - IC (MG)"},{"fieldId":"6406f92e638cbb2f415a94a9","fieldLabel":"Job Area","valueId":"e8731ea4-48a9-476d-ab1d-9a40eb3426f1","valueLabel":"Technology"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"cz","valueLabel":"Czechia"},{"fieldId":"61583054f15cea434e0be36f","fieldLabel":"Career Level","valueId":"b61e1897-7104-4a9d-b1cf-04fc2c537081","valueLabel":"N/A"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572770","valueLabel":"IT - Software Development"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"d319b522-5d2d-45d8-958a-4b99471a6446","valueLabel":"Allegro Retail a.s."},{"fieldId":"61582f70e72a6b6d239c9857","fieldLabel":"Area","valueId":"76599a72-f283-4550-9303-52e2e0eb6e32","valueLabel":"Technology"}],"visibility":"INTERNAL","ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999958525968","creator":{"name":"Ines Godlewska"},"language":{"code":"en","label":"English","labelNative":"English (US)"}},{"id":"743999956383556","name":"Software Engineer Java - Allegro Retail","uuid":"19c51980-62f3-4ee9-9a59-b39b1fbda7e4","jobAdId":"7236e848-3276-4740-a59d-de2209ea6536","defaultJobAd":false,"refNumber":"REF4327W","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2024-01-03T13:43:27.405Z","location":{"city":"Prague, Remote","country":"cz","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572770","label":"IT - Software Development"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"id":"permanent","label":"Full-time"},"experienceLevel":{"id":"associate","label":"Associate"},"customField":[{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Recruitment Process","valueId":"f2bb5bc2-3fb0-4d5a-96d2-59e7d59ab3d7","valueLabel":"Tech Engineer/Non-Engineer - IC (MG)"},{"fieldId":"6406f92e638cbb2f415a94a9","fieldLabel":"Job Area","valueId":"e8731ea4-48a9-476d-ab1d-9a40eb3426f1","valueLabel":"Technology"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"cz","valueLabel":"Czechia"},{"fieldId":"61583054f15cea434e0be36f","fieldLabel":"Career Level","valueId":"b61e1897-7104-4a9d-b1cf-04fc2c537081","valueLabel":"N/A"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572770","valueLabel":"IT - Software Development"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"d319b522-5d2d-45d8-958a-4b99471a6446","valueLabel":"Allegro Retail a.s."},{"fieldId":"61582f70e72a6b6d239c9857","fieldLabel":"Area","valueId":"76599a72-f283-4550-9303-52e2e0eb6e32","valueLabel":"Technology"}],"visibility":"INTERNAL","ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999956383556","creator":{"name":"Aleksandra Izbińska"},"language":{"code":"cs","label":"Czech","labelNative":"čeština"}},{"id":"743999956386883","name":"SAP Consultant","uuid":"7eef5f94-248b-418e-80df-1ef9b678147b","jobAdId":"9503b99e-152c-4f1c-a342-1bb007ce503c","defaultJobAd":true,"refNumber":"REF4280W","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2024-01-03T13:41:34.350Z","location":{"city":"Prague","region":"Prague","country":"cz","remote":false,"latitude":"50.0755381","longitude":"14.4378005"},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572770","label":"IT - Software Development"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"id":"contract","label":"Contract"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Recruitment Process","valueId":"f2bb5bc2-3fb0-4d5a-96d2-59e7d59ab3d7","valueLabel":"Tech Engineer/Non-Engineer - IC (MG)"},{"fieldId":"6406f92e638cbb2f415a94a9","fieldLabel":"Job Area","valueId":"e8731ea4-48a9-476d-ab1d-9a40eb3426f1","valueLabel":"Technology"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"cz","valueLabel":"Czechia"},{"fieldId":"61583054f15cea434e0be36f","fieldLabel":"Career Level","valueId":"b61e1897-7104-4a9d-b1cf-04fc2c537081","valueLabel":"N/A"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572770","valueLabel":"IT - Software Development"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"d319b522-5d2d-45d8-958a-4b99471a6446","valueLabel":"Allegro Retail a.s."},{"fieldId":"61582f70e72a6b6d239c9857","fieldLabel":"Area","valueId":"76599a72-f283-4550-9303-52e2e0eb6e32","valueLabel":"Technology"}],"visibility":"INTERNAL","ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999956386883","creator":{"name":"Aleksandra Izbińska"},"language":{"code":"en-GB","label":"English (UK)","labelNative":"English (UK)"}},{"id":"743999955998823","name":"Integration Engineer","uuid":"700785e6-e19c-47c6-9215-0294780ac77e","jobAdId":"22b63dc3-61fa-488b-b1cd-ef8588ccfe28","defaultJobAd":true,"refNumber":"REF2138N","company":{"identifier":"Allegro","name":"Allegro"},"releasedDate":"2024-01-02T10:24:30.011Z","location":{"city":"Warsaw, Poznań","country":"pl","remote":false},"industry":{"id":"internet","label":"Internet"},"department":{"id":"2572770","label":"IT - Software Development"},"function":{"id":"information_technology","label":"Information Technology"},"typeOfEmployment":{"id":"permanent","label":"Full-time"},"experienceLevel":{"id":"mid_senior_level","label":"Mid-Senior Level"},"customField":[{"fieldId":"58c15608e4b01d4b19ddf790","fieldLabel":"Recruitment Process","valueId":"ed4682c7-33c9-41c2-8d13-428ed39046f5","valueLabel":"Tech. Engineer - IC"},{"fieldId":"6406f92e638cbb2f415a94a9","fieldLabel":"Job Area","valueId":"e8731ea4-48a9-476d-ab1d-9a40eb3426f1","valueLabel":"Technology"},{"fieldId":"COUNTRY","fieldLabel":"Country","valueId":"pl","valueLabel":"Poland"},{"fieldId":"61583054f15cea434e0be36f","fieldLabel":"Career Level","valueId":"3976147c-fe25-42a8-8c97-78273250960b","valueLabel":"4"},{"fieldId":"58c13159e4b01d4b19ddf729","fieldLabel":"Department","valueId":"2572770","valueLabel":"IT - Software Development"},{"fieldId":"58c13159e4b01d4b19ddf728","fieldLabel":"Brands","valueId":"4ccb4fab-6c3f-4ed0-9140-8533fe17447f","valueLabel":"Allegro sp. z o.o."},{"fieldId":"61582f70e72a6b6d239c9857","fieldLabel":"Area","valueId":"76599a72-f283-4550-9303-52e2e0eb6e32","valueLabel":"Technology"}],"visibility":"INTERNAL","ref":"https://api.smartrecruiters.com/v1/companies/allegro/postings/743999955998823","creator":{"name":"Wiktoria Mitruk"},"language":{"code":"en","label":"English","labelNative":"English (US)"}}],"events":[{"created":1702979844000,"duration":187200000,"id":"298027809","name":"UX Research Confetti - IV edycja","date_in_series_pattern":false,"status":"upcoming","time":1716202800000,"local_date":"2024-05-20","local_time":"13:00","updated":1702985612000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":20,"venue":{"id":27549223,"name":"Allegro Warsaw Office","lat":52.23224639892578,"lon":20.992111206054688,"repinned":true,"address_1":"ul. Żelazna 51/53","city":"Warszawa","country":"pl","localized_country_name":"Poland"},"is_online_event":false,"eventType":"PHYSICAL","group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/298027809/","description":"**🎉 Przedstawiamy 4. edycję UX Research Confetti - bezpłatną, polską konferencję poświęconą badaniom UX, organizowaną przez zespół badaczy z Allegro.** ✨ Konferencja odbędzie się w…","visibility":"public","member_pay_fee":false},{"created":1701092071000,"duration":7200000,"id":"297614064","name":"Allegro Tech Talks #40 - Testy: dynamiczne dashboardy \u0026 optymalizacja pracy","date_in_series_pattern":false,"status":"past","time":1701968400000,"local_date":"2023-12-07","local_time":"18:00","updated":1701978668000,"utc_offset":3600000,"waitlist_count":0,"yes_rsvp_count":13,"venue":{"id":27528185,"name":"Allegro Kraków Office","lat":50.06517028808594,"lon":19.951927185058594,"repinned":true,"address_1":"Lubicz Park A (5 piętro)","address_2":"ul. Lubicz 23","city":"Kraków","country":"pl","localized_country_name":"Poland"},"is_online_event":false,"eventType":"PHYSICAL","group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/297614064/","description":"**➡ Rejestracja:** [https://app.evenea.pl/event/allegro-tech-talk-40/](https://app.evenea.pl/event/allegro-tech-talk-40/) Jeszcze przed świętami zapraszamy Was na #40 wydarzenie z serii Allegro Tech Talk, podczas których dzielimy się wiedzą, wzajemnie inspirujemy oraz integrujemy…","how_to_find_us":"Biuro Allegro znajduje się w Centrum Biurowym Lubicz. \n\nObok budynku znajduje się przystanek Lubicz. Przy przystanku zatrzymują się tramwaje 2, 4, 10, 14, 20, 52, 62, 64 oraz autobusy: 124, 152, 424, 601, 611, 662, 664.\n\n","visibility":"public","member_pay_fee":false},{"created":1700495058000,"duration":7200000,"id":"297480100","name":"Allegro Tech Talks #39 - Big Data: o podejściu do pracy z danymi","date_in_series_pattern":false,"status":"past","time":1701363600000,"local_date":"2023-11-30","local_time":"18:00","updated":1701377876000,"utc_offset":3600000,"waitlist_count":0,"yes_rsvp_count":50,"venue":{"id":27549223,"name":"Allegro Warsaw Office","lat":52.23224639892578,"lon":20.992111206054688,"repinned":true,"address_1":"ul. Żelazna 51/53","city":"Warszawa","country":"pl","localized_country_name":"Poland"},"is_online_event":false,"eventType":"PHYSICAL","group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/297480100/","description":"**Rejestracja: [https://app.evenea.pl/event/allegro-tech-talk-39/](https://app.evenea.pl/event/allegro-tech-talk-39/)** Bądźcie z nami podczas #39 wydarzenia z serii **Allegro Tech Talk**, podczas których dzielimy się wiedzą, wzajemnie inspirujemy oraz integrujemy podczas rozmów przy…","how_to_find_us":"Biuro Allegro znajduje się w kompleksie Fabryki Norblina (wejście Plater 3 od ul. Żelaznej). W niedalekiej odległości znajdują się dwie stacje metra linii M2, Rondo Daszyńskiego i Rondo ONZ. Autobusy, tramwaje i inne środki transportu sprawdzisz też na: https://fabrykanorblina.pl/dojazd","visibility":"public","member_pay_fee":false},{"created":1685697967000,"duration":7200000,"id":"293929321","name":"Allegro Tech Talks #38 - Mobile: o iOS bez spinki","date_in_series_pattern":false,"status":"past","time":1686760200000,"local_date":"2023-06-14","local_time":"18:30","updated":1686773845000,"utc_offset":7200000,"waitlist_count":0,"yes_rsvp_count":17,"venue":{"id":27549223,"name":"Allegro Warsaw Office","lat":0,"lon":0,"repinned":true,"address_1":"ul. Żelazna 51/53","city":"Warszawa","country":"pl","localized_country_name":"Poland"},"is_online_event":false,"eventType":"PHYSICAL","group":{"created":1425052059000,"name":"allegro Tech","id":18465254,"join_mode":"open","lat":52.2599983215332,"lon":21.020000457763672,"urlname":"allegrotech","who":"Techs","localized_location":"Warsaw, Poland","state":"","country":"pl","region":"en_US","timezone":"Europe/Warsaw"},"link":"https://www.meetup.com/allegrotech/events/293929321/","description":"**➡ Rejestracja:** [https://app.evenea.pl/event/allegro-tech-talk-38/](https://app.evenea.pl/event/allegro-tech-talk-38/) Ostatnie przed przerwą wakacyjną, stacjonarne spotkanie z cyklu Allegro Tech Talks, na których dzielimy się wiedzą, wzajemnie inspirujemy oraz integrujemy podczas rozmów…","how_to_find_us":"Biuro Allegro znajduje się w kompleksie Fabryki Norblina (wejście Plater 3 od ul. Żelaznej). W niedalekiej odległości znajdują się dwie stacje metra linii M2, Rondo Daszyńskiego i Rondo ONZ. Autobusy, tramwaje i inne środki transportu sprawdzisz też na: https://fabrykanorblina.pl/dojazd","visibility":"public","member_pay_fee":false}],"podcasts":[{"title":"MBox: server-driven UI dla aplikacji mobilnych","link":"https://podcast.allegro.tech/mbox-server-driven-ui-dla-aplikacji-mobilnych/","pubDate":"Thu, 16 Nov 2023 00:00:00 GMT","content":"Czym jest i jak powstał MBox: wewnętrzna platforma server-driven UI dla aplikacji mobilnych w Allegro? Skąd wziął się pomysł na to rozwiązanie i na jakie bolączki odpowiada? Dlaczego zdecydowaliśmy się na budowanie tego typu rozwiązania in-house i z jakimi wyzwaniami mierzyliśmy się w procesie tworzenia? Co wyróżnia zespoły pracujące nad tym narzędziem i jak pracuje im się bez Product Ownera? Posłuchajcie siódmego odcinka Allegro Tech Podcast z udziałem Pauliny Sadowskiej i Tomasza Gębarowskiego - Managerów w obszarze Technical Platform Services w Allegro.","contentSnippet":"Czym jest i jak powstał MBox: wewnętrzna platforma server-driven UI dla aplikacji mobilnych w Allegro? Skąd wziął się pomysł na to rozwiązanie i na jakie bolączki odpowiada? Dlaczego zdecydowaliśmy się na budowanie tego typu rozwiązania in-house i z jakimi wyzwaniami mierzyliśmy się w procesie tworzenia? Co wyróżnia zespoły pracujące nad tym narzędziem i jak pracuje im się bez Product Ownera? Posłuchajcie siódmego odcinka Allegro Tech Podcast z udziałem Pauliny Sadowskiej i Tomasza Gębarowskiego - Managerów w obszarze Technical Platform Services w Allegro.","guid":"https://podcast.allegro.tech/mbox-server-driven-ui-dla-aplikacji-mobilnych/","isoDate":"2023-11-16T00:00:00.000Z"},{"title":"O chatbotach i ich wpływie na Allegro","link":"https://podcast.allegro.tech/o-chatbotach-i-ich-wplywie-na-allegro/","pubDate":"Wed, 11 Oct 2023 00:00:00 GMT","content":"Jakie procesy automatyzujemy w Allegro i co warto o nich wiedzieć w kontekście obszaru Customer Experience? W czym pomagają nam chatboty, jak je rozwijamy i dbamy o ich jakość? Kim są Allina oraz Albert i co mają wspólnego z automatyzacją? Za jakie rozwiązania otrzymaliśmy nagrodę hiperautomatyzacji? O tym wszystkim posłuchacie w odcinku z udziałem Rafała Gajewskiego - Managera w obszarze IT Services w Allegro.","contentSnippet":"Jakie procesy automatyzujemy w Allegro i co warto o nich wiedzieć w kontekście obszaru Customer Experience? W czym pomagają nam chatboty, jak je rozwijamy i dbamy o ich jakość? Kim są Allina oraz Albert i co mają wspólnego z automatyzacją? Za jakie rozwiązania otrzymaliśmy nagrodę hiperautomatyzacji? O tym wszystkim posłuchacie w odcinku z udziałem Rafała Gajewskiego - Managera w obszarze IT Services w Allegro.","guid":"https://podcast.allegro.tech/o-chatbotach-i-ich-wplywie-na-allegro/","isoDate":"2023-10-11T00:00:00.000Z"},{"title":"O roli analityków biznesowych w Allegro","link":"https://podcast.allegro.tech/o-roli-analitykow-biznesowych-w-allegro/","pubDate":"Thu, 24 Aug 2023 00:00:00 GMT","content":"Czym zajmują się analitycy danych w Allegro i za jakie projekty odpowiadają? Z jakich rodzajów danych i narzędzi korzystają w codziennej pracy? Jakie (przykładowe) obszary tematyczne pokrywamy danymi, które analizujemy w Allegro? Jakich umiejętności szukamy u analityków biznesowych w Allegro i jak można do nas dołączyć? O roli analityków biznesowych i pracy w skali Allegro opowiadają Jakub Król i Mateusz Falkowski - Senior Data Analysts w Allegro.","contentSnippet":"Czym zajmują się analitycy danych w Allegro i za jakie projekty odpowiadają? Z jakich rodzajów danych i narzędzi korzystają w codziennej pracy? Jakie (przykładowe) obszary tematyczne pokrywamy danymi, które analizujemy w Allegro? Jakich umiejętności szukamy u analityków biznesowych w Allegro i jak można do nas dołączyć? O roli analityków biznesowych i pracy w skali Allegro opowiadają Jakub Król i Mateusz Falkowski - Senior Data Analysts w Allegro.","guid":"https://podcast.allegro.tech/o-roli-analitykow-biznesowych-w-allegro/","isoDate":"2023-08-24T00:00:00.000Z"},{"title":"O społeczności Allegro Tech i rozwoju inżynierów w Allegro","link":"https://podcast.allegro.tech/o-spolecznosci-allegro-tech-i-rozwoju-inzynierow-w-allegro/","pubDate":"Thu, 27 Jul 2023 00:00:00 GMT","content":"Na czym polega rola Principal Software Engineera w Allegro oraz co ma wspólnego z rozwijaniem siebie i dzieleniem się wiedzą? Co warto wiedzieć o turystyce, która pojawia się niemal w każdym odcinku naszych podcastów? Na czym polega, kto, kiedy i jak może z niej skorzystać? Jak pracujemy z talentami Gallupa (także w zespołach technicznych)?  Co dają nam wewnętrzne DevDays, hackhathony, gildie, meetupy, konferencje i jak jeszcze wymieniamy się doświadczeniami? Czym jest Allegro Tech Meeting i jaka idea mu przyświeca? O społeczności Allegro Tech i możliwościach rozwoju w Allegro z perspektywy inżynierów rozmawialiśmy z Marcinem Turkiem i Michałem Kosmulskim.","contentSnippet":"Na czym polega rola Principal Software Engineera w Allegro oraz co ma wspólnego z rozwijaniem siebie i dzieleniem się wiedzą? Co warto wiedzieć o turystyce, która pojawia się niemal w każdym odcinku naszych podcastów? Na czym polega, kto, kiedy i jak może z niej skorzystać? Jak pracujemy z talentami Gallupa (także w zespołach technicznych)?  Co dają nam wewnętrzne DevDays, hackhathony, gildie, meetupy, konferencje i jak jeszcze wymieniamy się doświadczeniami? Czym jest Allegro Tech Meeting i jaka idea mu przyświeca? O społeczności Allegro Tech i możliwościach rozwoju w Allegro z perspektywy inżynierów rozmawialiśmy z Marcinem Turkiem i Michałem Kosmulskim.","guid":"https://podcast.allegro.tech/o-spolecznosci-allegro-tech-i-rozwoju-inzynierow-w-allegro/","isoDate":"2023-07-27T00:00:00.000Z"}]},"__N_SSG":true},"page":"/","query":{},"buildId":"ubJ3sidEPv9PINacT5eG9","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>